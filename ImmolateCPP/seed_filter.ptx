//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35059454
// Cuda compilation tools, release 12.6, V12.6.85
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_80
.address_size 64

	// .globl	find_seeds_kernel_balatro
.global .align 8 .f64 PI = 0d400921FB54442D18;
.global .align 8 .f64 HASH_MULT = 0d3FF1FB9C7406BB70;
.global .align 8 .f64 LCG_A = 0d4001135C51C7F716;
.global .align 8 .f64 LCG_B = 0d3FFB96C889463A4C;

.visible .entry find_seeds_kernel_balatro(
	.param .u64 find_seeds_kernel_balatro_param_0,
	.param .u32 find_seeds_kernel_balatro_param_1,
	.param .u32 find_seeds_kernel_balatro_param_2,
	.param .u64 find_seeds_kernel_balatro_param_3,
	.param .u64 find_seeds_kernel_balatro_param_4,
	.param .u64 find_seeds_kernel_balatro_param_5,
	.param .u32 find_seeds_kernel_balatro_param_6,
	.param .u64 find_seeds_kernel_balatro_param_7,
	.param .u64 find_seeds_kernel_balatro_param_8
)
{
	.local .align 16 .b8 	__local_depot0[112];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2989>;
	.reg .b16 	%rs<230>;
	.reg .b32 	%r<6584>;
	.reg .f64 	%fd<3186>;
	.reg .b64 	%rd<6667>;
	.loc	1 211 0


	mov.u64 	%SPL, __local_depot0;
	ld.param.u64 	%rd1192, [find_seeds_kernel_balatro_param_0];
	ld.param.u32 	%r1796, [find_seeds_kernel_balatro_param_1];
	ld.param.u32 	%r1797, [find_seeds_kernel_balatro_param_2];
	ld.param.u64 	%rd1193, [find_seeds_kernel_balatro_param_3];
	ld.param.u64 	%rd1194, [find_seeds_kernel_balatro_param_4];
	ld.param.u64 	%rd1195, [find_seeds_kernel_balatro_param_5];
	ld.param.u32 	%r1798, [find_seeds_kernel_balatro_param_6];
	ld.param.u64 	%rd1196, [find_seeds_kernel_balatro_param_7];
	ld.param.u64 	%rd1197, [find_seeds_kernel_balatro_param_8];
	add.u64 	%rd1, %SPL, 102;
	add.u64 	%rd2, %SPL, 103;
	add.u64 	%rd3, %SPL, 104;
	add.u64 	%rd4, %SPL, 105;
	add.u64 	%rd5, %SPL, 106;
	add.u64 	%rd6, %SPL, 107;
	add.u64 	%rd7, %SPL, 108;
	.loc	1 222 5
	add.u64 	%rd8, %SPL, 109;
	mov.u32 	%r1799, %ntid.x;
	mov.u32 	%r1800, %ctaid.x;
	mov.u32 	%r1801, %tid.x;
	mad.lo.s32 	%r5902, %r1800, %r1799, %r1801;
	.loc	1 224 5
	add.s32 	%r1802, %r1796, %r1797;
	add.s32 	%r1803, %r1802, -1;
	div.u32 	%r2, %r1803, %r1797;
	.loc	1 231 5
	setp.ge.u32 	%p11, %r5902, %r2;
	@%p11 bra 	$L__BB0_1584;

	.loc	1 0 5
	cvta.to.global.u64 	%rd1206, %rd1194;
	add.s64 	%rd9, %rd1206, 116;
	mov.u32 	%r6583, 0;
	cvta.to.global.u64 	%rd1188, %rd1193;
	cvta.to.global.u64 	%rd6109, %rd1196;
	cvta.to.global.u64 	%rd6112, %rd1195;

$L__BB0_2:
	.loc	1 233 9
	and.b32  	%r1805, %r6583, 15;
	setp.ne.s32 	%p12, %r1805, 0;
	@%p12 bra 	$L__BB0_4;

	.loc	1 0 9
	cvta.to.global.u64 	%rd1207, %rd1197;
	.loc	1 233 9
	ld.volatile.global.u32 	%r1806, [%rd1207];
	setp.ne.s32 	%p13, %r1806, 0;
	@%p13 bra 	$L__BB0_1584;

$L__BB0_4:
	.loc	1 0 9
	add.u64 	%rd1209, %SPL, 65;
	.loc	1 235 9
	mul.lo.s32 	%r5904, %r5902, %r1797;
	.loc	1 236 9
	add.s32 	%r1807, %r5904, %r1797;
	.loc	1 240 9
	cvt.u64.u32 	%rd1210, %r5904;
	add.s64 	%rd1211, %rd1210, %rd1192;
	.loc	1 240 9
	.loc	1 202 5, function_name $L__info_string0, inlined_at 1 240 9
	mov.u16 	%rs34, 48;
	st.local.u8 	[%rd1209], %rs34;
	mov.u16 	%rs35, 49;
	st.local.u8 	[%rd1209+1], %rs35;
	mov.u16 	%rs36, 50;
	st.local.u8 	[%rd1209+2], %rs36;
	mov.u16 	%rs37, 51;
	st.local.u8 	[%rd1209+3], %rs37;
	mov.u16 	%rs38, 52;
	st.local.u8 	[%rd1209+4], %rs38;
	mov.u16 	%rs39, 53;
	st.local.u8 	[%rd1209+5], %rs39;
	mov.u16 	%rs40, 54;
	st.local.u8 	[%rd1209+6], %rs40;
	mov.u16 	%rs41, 55;
	st.local.u8 	[%rd1209+7], %rs41;
	mov.u16 	%rs42, 56;
	st.local.u8 	[%rd1209+8], %rs42;
	mov.u16 	%rs43, 57;
	st.local.u8 	[%rd1209+9], %rs43;
	mov.u16 	%rs44, 65;
	st.local.u8 	[%rd1209+10], %rs44;
	mov.u16 	%rs45, 66;
	st.local.u8 	[%rd1209+11], %rs45;
	mov.u16 	%rs46, 67;
	st.local.u8 	[%rd1209+12], %rs46;
	mov.u16 	%rs47, 68;
	st.local.u8 	[%rd1209+13], %rs47;
	mov.u16 	%rs48, 69;
	st.local.u8 	[%rd1209+14], %rs48;
	mov.u16 	%rs49, 70;
	st.local.u8 	[%rd1209+15], %rs49;
	mov.u16 	%rs50, 71;
	st.local.u8 	[%rd1209+16], %rs50;
	mov.u16 	%rs51, 72;
	st.local.u8 	[%rd1209+17], %rs51;
	mov.u16 	%rs52, 73;
	st.local.u8 	[%rd1209+18], %rs52;
	mov.u16 	%rs53, 74;
	st.local.u8 	[%rd1209+19], %rs53;
	mov.u16 	%rs54, 75;
	st.local.u8 	[%rd1209+20], %rs54;
	mov.u16 	%rs55, 76;
	st.local.u8 	[%rd1209+21], %rs55;
	mov.u16 	%rs56, 77;
	st.local.u8 	[%rd1209+22], %rs56;
	mov.u16 	%rs57, 78;
	st.local.u8 	[%rd1209+23], %rs57;
	mov.u16 	%rs58, 79;
	st.local.u8 	[%rd1209+24], %rs58;
	mov.u16 	%rs59, 80;
	st.local.u8 	[%rd1209+25], %rs59;
	mov.u16 	%rs60, 81;
	st.local.u8 	[%rd1209+26], %rs60;
	mov.u16 	%rs61, 82;
	st.local.u8 	[%rd1209+27], %rs61;
	mov.u16 	%rs62, 83;
	st.local.u8 	[%rd1209+28], %rs62;
	mov.u16 	%rs63, 84;
	st.local.u8 	[%rd1209+29], %rs63;
	mov.u16 	%rs64, 85;
	st.local.u8 	[%rd1209+30], %rs64;
	mov.u16 	%rs65, 86;
	st.local.u8 	[%rd1209+31], %rs65;
	mov.u16 	%rs66, 87;
	st.local.u8 	[%rd1209+32], %rs66;
	mov.u16 	%rs67, 88;
	st.local.u8 	[%rd1209+33], %rs67;
	mov.u16 	%rs68, 89;
	st.local.u8 	[%rd1209+34], %rs68;
	mov.u16 	%rs69, 90;
	st.local.u8 	[%rd1209+35], %rs69;
	mov.u16 	%rs70, 0;
	st.local.u8 	[%rd1209+36], %rs70;
	.loc	1 205 9, function_name $L__info_string0, inlined_at 1 240 9
	mul.hi.u64 	%rd1212, %rd1211, -2049638230412172401;
	shr.u64 	%rd1213, %rd1212, 5;
	mul.lo.s64 	%rd1214, %rd1213, 36;
	sub.s64 	%rd1215, %rd1211, %rd1214;
	add.s64 	%rd1216, %rd1209, %rd1215;
	ld.local.u8 	%rs71, [%rd1216];
	st.local.u8 	[%rd8], %rs71;
	mul.hi.u64 	%rd1217, %rd1213, -2049638230412172401;
	shr.u64 	%rd1218, %rd1217, 5;
	mul.lo.s64 	%rd1219, %rd1218, 36;
	sub.s64 	%rd1220, %rd1213, %rd1219;
	add.s64 	%rd1221, %rd1209, %rd1220;
	ld.local.u8 	%rs72, [%rd1221];
	st.local.u8 	[%rd7], %rs72;
	.loc	1 206 9, function_name $L__info_string0, inlined_at 1 240 9
	shr.u64 	%rd1222, %rd1211, 4;
	mul.hi.u64 	%rd1223, %rd1222, 910950324627632179;
	shr.u64 	%rd1224, %rd1223, 2;
	.loc	1 205 9, function_name $L__info_string0, inlined_at 1 240 9
	mul.hi.u64 	%rd1225, %rd1224, -2049638230412172401;
	shr.u64 	%rd1226, %rd1225, 5;
	mul.lo.s64 	%rd1227, %rd1226, 36;
	sub.s64 	%rd1228, %rd1224, %rd1227;
	add.s64 	%rd1229, %rd1209, %rd1228;
	ld.local.u8 	%rs73, [%rd1229];
	st.local.u8 	[%rd6], %rs73;
	.loc	1 206 9, function_name $L__info_string0, inlined_at 1 240 9
	mul.hi.u64 	%rd1230, %rd1211, -5491006123449893965;
	shr.u64 	%rd1231, %rd1230, 15;
	.loc	1 205 9, function_name $L__info_string0, inlined_at 1 240 9
	mul.hi.u64 	%rd1232, %rd1231, -2049638230412172401;
	shr.u64 	%rd1233, %rd1232, 5;
	mul.lo.s64 	%rd1234, %rd1233, 36;
	sub.s64 	%rd1235, %rd1231, %rd1234;
	add.s64 	%rd1236, %rd1209, %rd1235;
	ld.local.u8 	%rs74, [%rd1236];
	st.local.u8 	[%rd5], %rs74;
	.loc	1 206 9, function_name $L__info_string0, inlined_at 1 240 9
	mul.hi.u64 	%rd1237, %rd1211, 1439526438917739739;
	shr.u64 	%rd1238, %rd1237, 17;
	.loc	1 205 9, function_name $L__info_string0, inlined_at 1 240 9
	mul.hi.u64 	%rd1239, %rd1238, -2049638230412172401;
	shr.u64 	%rd1240, %rd1239, 5;
	mul.lo.s64 	%rd1241, %rd1240, 36;
	sub.s64 	%rd1242, %rd1238, %rd1241;
	add.s64 	%rd1243, %rd1209, %rd1242;
	ld.local.u8 	%rs75, [%rd1243];
	st.local.u8 	[%rd4], %rs75;
	.loc	1 206 9, function_name $L__info_string0, inlined_at 1 240 9
	mul.hi.u64 	%rd1244, %rd1211, -8210111619183402361;
	shr.u64 	%rd1245, %rd1244, 25;
	.loc	1 205 9, function_name $L__info_string0, inlined_at 1 240 9
	mul.hi.u64 	%rd1246, %rd1245, -2049638230412172401;
	shr.u64 	%rd1247, %rd1246, 5;
	mul.lo.s64 	%rd1248, %rd1247, 36;
	sub.s64 	%rd1249, %rd1245, %rd1248;
	add.s64 	%rd1250, %rd1209, %rd1249;
	ld.local.u8 	%rs76, [%rd1250];
	st.local.u8 	[%rd3], %rs76;
	.loc	1 206 9, function_name $L__info_string0, inlined_at 1 240 9
	mul.hi.u64 	%rd1251, %rd1211, 9099228848467688227;
	shr.u64 	%rd1252, %rd1251, 30;
	.loc	1 205 9, function_name $L__info_string0, inlined_at 1 240 9
	mul.hi.u64 	%rd1253, %rd1252, -2049638230412172401;
	shr.u64 	%rd1254, %rd1253, 5;
	mul.lo.s64 	%rd1255, %rd1254, 36;
	sub.s64 	%rd1256, %rd1252, %rd1255;
	add.s64 	%rd1257, %rd1209, %rd1256;
	ld.local.u8 	%rs77, [%rd1257];
	st.local.u8 	[%rd2], %rs77;
	.loc	1 206 9, function_name $L__info_string0, inlined_at 1 240 9
	shr.u64 	%rd1258, %rd1211, 14;
	mul.hi.u64 	%rd1259, %rd1258, 493664759573985;
	shr.u64 	%rd1260, %rd1259, 7;
	cvt.u32.u64 	%r1808, %rd1260;
	mul.wide.u32 	%rd1261, %r1808, 954437177;
	shr.u64 	%rd1262, %rd1261, 35;
	cvt.u32.u64 	%r1809, %rd1262;
	mul.lo.s32 	%r1810, %r1809, 36;
	sub.s32 	%r1811, %r1808, %r1810;
	cvt.u64.u32 	%rd1263, %r1811;
	.loc	1 205 9, function_name $L__info_string0, inlined_at 1 240 9
	add.s64 	%rd1264, %rd1209, %rd1263;
	ld.local.u8 	%rs78, [%rd1264];
	st.local.u8 	[%rd1], %rs78;
	.loc	1 236 9
	.loc	2 870 3, function_name $L__info_string1, inlined_at 1 236 9
	min.u32 	%r1812, %r1807, %r1796;
	.loc	1 243 9
	setp.ge.u32 	%p14, %r5904, %r1812;
	@%p14 bra 	$L__BB0_1583;
	bra.uni 	$L__BB0_5;

$L__BB0_1542:
	.loc	1 370 13
	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.ne.s16 	%p2954, %rs229, 90;
	@%p2954 bra 	$L__BB0_1544;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 370 13
	mov.u16 	%rs176, 48;
	st.local.u8 	[%rd8], %rs176;

$L__BB0_1544:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs177, %rs223, -48;
	and.b16  	%rs178, %rs177, 255;
	setp.lt.u16 	%p2955, %rs178, 9;
	mov.u64 	%rd6666, %rd7;
	mov.u16 	%rs229, %rs223;
	@%p2955 bra 	$L__BB0_1581;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.eq.s16 	%p2956, %rs223, 57;
	mov.u64 	%rd6665, %rd7;
	@%p2956 bra 	$L__BB0_1580;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs179, %rs223, -65;
	and.b16  	%rs180, %rs179, 255;
	setp.lt.u16 	%p2957, %rs180, 25;
	mov.u64 	%rd6664, %rd7;
	mov.u16 	%rs229, %rs223;
	@%p2957 bra 	$L__BB0_1579;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.ne.s16 	%p2958, %rs223, 90;
	@%p2958 bra 	$L__BB0_1549;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 370 13
	mov.u16 	%rs181, 48;
	st.local.u8 	[%rd7], %rs181;

$L__BB0_1549:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs182, %rs222, -48;
	and.b16  	%rs183, %rs182, 255;
	setp.lt.u16 	%p2959, %rs183, 9;
	mov.u64 	%rd6666, %rd6;
	mov.u16 	%rs229, %rs222;
	@%p2959 bra 	$L__BB0_1581;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.eq.s16 	%p2960, %rs222, 57;
	mov.u64 	%rd6665, %rd6;
	@%p2960 bra 	$L__BB0_1580;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs184, %rs222, -65;
	and.b16  	%rs185, %rs184, 255;
	setp.lt.u16 	%p2961, %rs185, 25;
	mov.u64 	%rd6664, %rd6;
	mov.u16 	%rs229, %rs222;
	@%p2961 bra 	$L__BB0_1579;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.ne.s16 	%p2962, %rs222, 90;
	@%p2962 bra 	$L__BB0_1554;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 370 13
	mov.u16 	%rs186, 48;
	st.local.u8 	[%rd6], %rs186;

$L__BB0_1554:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs187, %rs221, -48;
	and.b16  	%rs188, %rs187, 255;
	setp.lt.u16 	%p2963, %rs188, 9;
	mov.u64 	%rd6666, %rd5;
	mov.u16 	%rs229, %rs221;
	@%p2963 bra 	$L__BB0_1581;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.eq.s16 	%p2964, %rs221, 57;
	mov.u64 	%rd6665, %rd5;
	@%p2964 bra 	$L__BB0_1580;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs189, %rs221, -65;
	and.b16  	%rs190, %rs189, 255;
	setp.lt.u16 	%p2965, %rs190, 25;
	mov.u64 	%rd6664, %rd5;
	mov.u16 	%rs229, %rs221;
	@%p2965 bra 	$L__BB0_1579;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.ne.s16 	%p2966, %rs221, 90;
	@%p2966 bra 	$L__BB0_1559;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 370 13
	mov.u16 	%rs191, 48;
	st.local.u8 	[%rd5], %rs191;

$L__BB0_1559:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs192, %rs220, -48;
	and.b16  	%rs193, %rs192, 255;
	setp.lt.u16 	%p2967, %rs193, 9;
	mov.u64 	%rd6666, %rd4;
	mov.u16 	%rs229, %rs220;
	@%p2967 bra 	$L__BB0_1581;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.eq.s16 	%p2968, %rs220, 57;
	mov.u64 	%rd6665, %rd4;
	@%p2968 bra 	$L__BB0_1580;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs194, %rs220, -65;
	and.b16  	%rs195, %rs194, 255;
	setp.lt.u16 	%p2969, %rs195, 25;
	mov.u64 	%rd6664, %rd4;
	mov.u16 	%rs229, %rs220;
	@%p2969 bra 	$L__BB0_1579;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.ne.s16 	%p2970, %rs220, 90;
	@%p2970 bra 	$L__BB0_1564;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 370 13
	mov.u16 	%rs196, 48;
	st.local.u8 	[%rd4], %rs196;

$L__BB0_1564:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs197, %rs219, -48;
	and.b16  	%rs198, %rs197, 255;
	setp.lt.u16 	%p2971, %rs198, 9;
	mov.u64 	%rd6666, %rd3;
	mov.u16 	%rs229, %rs219;
	@%p2971 bra 	$L__BB0_1581;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.eq.s16 	%p2972, %rs219, 57;
	mov.u64 	%rd6665, %rd3;
	@%p2972 bra 	$L__BB0_1580;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs199, %rs219, -65;
	and.b16  	%rs200, %rs199, 255;
	setp.lt.u16 	%p2973, %rs200, 25;
	mov.u64 	%rd6664, %rd3;
	mov.u16 	%rs229, %rs219;
	@%p2973 bra 	$L__BB0_1579;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.ne.s16 	%p2974, %rs219, 90;
	@%p2974 bra 	$L__BB0_1569;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 370 13
	mov.u16 	%rs201, 48;
	st.local.u8 	[%rd3], %rs201;

$L__BB0_1569:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs202, %rs218, -48;
	and.b16  	%rs203, %rs202, 255;
	setp.lt.u16 	%p2975, %rs203, 9;
	mov.u64 	%rd6666, %rd2;
	mov.u16 	%rs229, %rs218;
	@%p2975 bra 	$L__BB0_1581;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.eq.s16 	%p2976, %rs218, 57;
	mov.u64 	%rd6665, %rd2;
	@%p2976 bra 	$L__BB0_1580;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs204, %rs218, -65;
	and.b16  	%rs205, %rs204, 255;
	setp.lt.u16 	%p2977, %rs205, 25;
	mov.u64 	%rd6664, %rd2;
	mov.u16 	%rs229, %rs218;
	@%p2977 bra 	$L__BB0_1579;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.ne.s16 	%p2978, %rs218, 90;
	@%p2978 bra 	$L__BB0_1574;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 370 13
	mov.u16 	%rs206, 48;
	st.local.u8 	[%rd2], %rs206;

$L__BB0_1574:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs207, %rs217, -48;
	and.b16  	%rs208, %rs207, 255;
	setp.lt.u16 	%p2979, %rs208, 9;
	mov.u64 	%rd6666, %rd1;
	mov.u16 	%rs229, %rs217;
	@%p2979 bra 	$L__BB0_1581;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.eq.s16 	%p2980, %rs217, 57;
	mov.u64 	%rd6665, %rd1;
	@%p2980 bra 	$L__BB0_1580;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs209, %rs217, -65;
	and.b16  	%rs210, %rs209, 255;
	setp.lt.u16 	%p2981, %rs210, 25;
	mov.u64 	%rd6664, %rd1;
	mov.u16 	%rs229, %rs217;
	@%p2981 bra 	$L__BB0_1579;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.ne.s16 	%p2982, %rs217, 90;
	@%p2982 bra 	$L__BB0_1582;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 370 13
	mov.u16 	%rs211, 48;
	st.local.u8 	[%rd1], %rs211;
	bra.uni 	$L__BB0_1582;

$L__BB0_5:
	.loc	1 245 13
	add.s32 	%r6583, %r6583, 1;
	and.b32  	%r1813, %r6583, 15;
	setp.ne.s32 	%p15, %r1813, 0;
	@%p15 bra 	$L__BB0_7;

	.loc	1 0 13
	cvta.to.global.u64 	%rd1265, %rd1197;
	.loc	1 245 13
	ld.volatile.global.u32 	%r1814, [%rd1265];
	setp.ne.s32 	%p16, %r1814, 0;
	@%p16 bra 	$L__BB0_1584;

$L__BB0_7:
	.loc	1 0 13
	ld.param.u64 	%rd6116, [find_seeds_kernel_balatro_param_4];
	setp.eq.s64 	%p17, %rd6116, 0;
	.loc	1 248 13
	@%p17 bra 	$L__BB0_1121;

	.loc	1 249 17
	.loc	1 71 5, function_name $L__info_string3, inlined_at 1 249 17
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mov.f64 	%fd798, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1815}, %fd798;
	}
	and.b32  	%r9, %r1815, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1816, %temp}, %fd798;
	}
	mov.b64 	%fd3160, {%r1816, %r9};
	setp.gt.u32 	%p18, %r9, 2146435071;
	mul.f64 	%fd2, %fd3160, 0d4350000000000000;
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 71 5
	ld.local.u8 	%rs229, [%rd8];
	cvt.rn.f64.u16 	%fd799, %rs229;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mul.f64 	%fd800, %fd799, 0d3FF1FB9C7406BB70;
	mul.f64 	%fd3, %fd800, 0d400921FB54442D18;
	add.f64 	%fd4, %fd3, 0d403921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd4;
	}
	and.b32  	%r1817, %r10, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1818, %temp}, %fd4;
	}
	mov.b64 	%fd2894, {%r1818, %r1817};
	setp.gt.u32 	%p19, %r1817, 2146435071;
	or.pred  	%p20, %p19, %p18;
	@%p20 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_9;

$L__BB0_25:
	.loc	1 0 9
	setp.le.f64 	%p55, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p56, %fd2894, 0d7FF0000000000000;
	and.pred  	%p57, %p56, %p55;
	@%p57 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_26;

$L__BB0_27:
	setp.eq.f64 	%p58, %fd2894, 0d7FF0000000000000;
	selp.f64 	%fd2897, 0dFFF8000000000000, %fd4, %p58;
	bra.uni 	$L__BB0_28;

$L__BB0_1121:
	.loc	1 260 17
	.loc	1 112 5, function_name $L__info_string5, inlined_at 1 260 17
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	mov.f64 	%fd2386, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4840}, %fd2386;
	}
	and.b32  	%r1297, %r4840, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4841, %temp}, %fd2386;
	}
	mov.b64 	%fd3160, {%r4841, %r1297};
	setp.gt.u32 	%p2211, %r1297, 2146435071;
	mul.f64 	%fd595, %fd3160, 0d4350000000000000;
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 112 5
	ld.local.u8 	%rs229, [%rd8];
	cvt.rn.f64.u16 	%fd2387, %rs229;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	mul.f64 	%fd2388, %fd2387, 0d3FF1FB9C7406BB70;
	fma.rn.f64 	%fd596, %fd2388, 0d400921FB54442D18, 0d403921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1298}, %fd596;
	}
	and.b32  	%r4842, %r1298, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4843, %temp}, %fd596;
	}
	mov.b64 	%fd3112, {%r4843, %r4842};
	setp.gt.u32 	%p2212, %r4842, 2146435071;
	or.pred  	%p2213, %p2212, %p2211;
	@%p2213 bra 	$L__BB0_1138;
	bra.uni 	$L__BB0_1122;

$L__BB0_1138:
	.loc	1 0 9
	setp.le.f64 	%p2248, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2249, %fd3112, 0d7FF0000000000000;
	and.pred  	%p2250, %p2249, %p2248;
	@%p2250 bra 	$L__BB0_1140;
	bra.uni 	$L__BB0_1139;

$L__BB0_1140:
	setp.eq.f64 	%p2251, %fd3112, 0d7FF0000000000000;
	selp.f64 	%fd3115, 0dFFF8000000000000, %fd596, %p2251;
	bra.uni 	$L__BB0_1141;

$L__BB0_9:
	.loc	1 0 9
	setp.eq.f64 	%p21, %fd3160, 0d0000000000000000;
	mov.f64 	%fd2897, 0dFFF8000000000000;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	@%p21 bra 	$L__BB0_28;

	setp.ltu.f64 	%p22, %fd2894, %fd3160;
	mov.f64 	%fd2897, %fd4;
	@%p22 bra 	$L__BB0_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1819}, %fd2894;
	}
	shr.u32 	%r5906, %r1819, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1820}, %fd3160;
	}
	shr.u32 	%r5907, %r1820, 20;
	setp.ne.s32 	%p23, %r5906, 0;
	@%p23 bra 	$L__BB0_13;

	mul.f64 	%fd2894, %fd2894, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1821}, %fd2894;
	}
	shr.u32 	%r1822, %r1821, 20;
	add.s32 	%r5906, %r1822, -54;

$L__BB0_13:
	setp.ne.s32 	%p24, %r5907, 0;
	mov.f64 	%fd2895, %fd3160;
	@%p24 bra 	$L__BB0_15;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1823}, %fd2;
	}
	shr.u32 	%r1824, %r1823, 20;
	add.s32 	%r5907, %r1824, -54;
	mov.f64 	%fd2895, %fd2;

$L__BB0_15:
	mov.b64 	%rd1267, %fd2894;
	and.b64  	%rd1268, %rd1267, 4503599627370495;
	or.b64  	%rd6121, %rd1268, 4503599627370496;
	mov.b64 	%rd1269, %fd2895;
	and.b64  	%rd1270, %rd1269, 4503599627370495;
	or.b64  	%rd12, %rd1270, 4503599627370496;
	sub.s32 	%r5913, %r5906, %r5907;
	not.b32 	%r1825, %r5906;
	add.s32 	%r1826, %r5907, %r1825;
	max.s32 	%r1827, %r1826, -1;
	add.s32 	%r18, %r1827, %r5906;
	mov.u32 	%r1828, 2;
	sub.s32 	%r1829, %r1828, %r5907;
	add.s32 	%r1830, %r1829, %r18;
	and.b32  	%r5909, %r1830, 3;
	setp.eq.s32 	%p25, %r5909, 0;
	@%p25 bra 	$L__BB0_17;

$L__BB0_16:
	.pragma "nounroll";
	sub.s64 	%rd1271, %rd6121, %rd12;
	mov.b64 	%fd802, %rd1271;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1831}, %fd802;
	}
	setp.lt.s32 	%p26, %r1831, 0;
	selp.b64 	%rd6124, %rd6121, %rd1271, %p26;
	shl.b64 	%rd6121, %rd6124, 1;
	add.s32 	%r5913, %r5913, -1;
	add.s32 	%r5909, %r5909, -1;
	setp.ne.s32 	%p27, %r5909, 0;
	@%p27 bra 	$L__BB0_16;

$L__BB0_17:
	mov.u32 	%r1832, 1;
	sub.s32 	%r1833, %r1832, %r5907;
	add.s32 	%r1834, %r1833, %r18;
	setp.lt.u32 	%p28, %r1834, 3;
	@%p28 bra 	$L__BB0_22;

	not.b32 	%r1835, %r5913;
	max.s32 	%r1836, %r1835, -4;
	add.s32 	%r1837, %r5913, %r1836;
	add.s32 	%r25, %r1837, 4;
	shr.u32 	%r1838, %r25, 2;
	add.s32 	%r1839, %r1838, 1;
	and.b32  	%r5912, %r1839, 3;
	setp.eq.s32 	%p29, %r5912, 0;
	@%p29 bra 	$L__BB0_20;

$L__BB0_19:
	.pragma "nounroll";
	sub.s64 	%rd1273, %rd6121, %rd12;
	mov.b64 	%fd803, %rd1273;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1840}, %fd803;
	}
	setp.lt.s32 	%p30, %r1840, 0;
	selp.b64 	%rd1274, %rd6121, %rd1273, %p30;
	shl.b64 	%rd1275, %rd1274, 1;
	sub.s64 	%rd1276, %rd1275, %rd12;
	mov.b64 	%fd804, %rd1276;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1841}, %fd804;
	}
	setp.lt.s32 	%p31, %r1841, 0;
	selp.b64 	%rd1277, %rd1275, %rd1276, %p31;
	shl.b64 	%rd1278, %rd1277, 1;
	sub.s64 	%rd1279, %rd1278, %rd12;
	mov.b64 	%fd805, %rd1279;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1842}, %fd805;
	}
	setp.lt.s32 	%p32, %r1842, 0;
	selp.b64 	%rd1280, %rd1278, %rd1279, %p32;
	shl.b64 	%rd1281, %rd1280, 1;
	sub.s64 	%rd1282, %rd1281, %rd12;
	mov.b64 	%fd806, %rd1282;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1843}, %fd806;
	}
	setp.lt.s32 	%p33, %r1843, 0;
	selp.b64 	%rd6124, %rd1281, %rd1282, %p33;
	shl.b64 	%rd6121, %rd6124, 1;
	add.s32 	%r5913, %r5913, -4;
	add.s32 	%r5912, %r5912, -1;
	setp.ne.s32 	%p34, %r5912, 0;
	@%p34 bra 	$L__BB0_19;

$L__BB0_20:
	setp.lt.u32 	%p35, %r25, 12;
	@%p35 bra 	$L__BB0_22;

$L__BB0_21:
	sub.s64 	%rd1283, %rd6121, %rd12;
	mov.b64 	%fd807, %rd1283;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1844}, %fd807;
	}
	setp.lt.s32 	%p36, %r1844, 0;
	selp.b64 	%rd1284, %rd6121, %rd1283, %p36;
	shl.b64 	%rd1285, %rd1284, 1;
	sub.s64 	%rd1286, %rd1285, %rd12;
	mov.b64 	%fd808, %rd1286;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1845}, %fd808;
	}
	setp.lt.s32 	%p37, %r1845, 0;
	selp.b64 	%rd1287, %rd1285, %rd1286, %p37;
	shl.b64 	%rd1288, %rd1287, 1;
	sub.s64 	%rd1289, %rd1288, %rd12;
	mov.b64 	%fd809, %rd1289;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1846}, %fd809;
	}
	setp.lt.s32 	%p38, %r1846, 0;
	selp.b64 	%rd1290, %rd1288, %rd1289, %p38;
	shl.b64 	%rd1291, %rd1290, 1;
	sub.s64 	%rd1292, %rd1291, %rd12;
	mov.b64 	%fd810, %rd1292;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1847}, %fd810;
	}
	setp.lt.s32 	%p39, %r1847, 0;
	selp.b64 	%rd1293, %rd1291, %rd1292, %p39;
	shl.b64 	%rd1294, %rd1293, 1;
	sub.s64 	%rd1295, %rd1294, %rd12;
	mov.b64 	%fd811, %rd1295;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1848}, %fd811;
	}
	setp.lt.s32 	%p40, %r1848, 0;
	selp.b64 	%rd1296, %rd1294, %rd1295, %p40;
	shl.b64 	%rd1297, %rd1296, 1;
	sub.s64 	%rd1298, %rd1297, %rd12;
	mov.b64 	%fd812, %rd1298;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1849}, %fd812;
	}
	setp.lt.s32 	%p41, %r1849, 0;
	selp.b64 	%rd1299, %rd1297, %rd1298, %p41;
	shl.b64 	%rd1300, %rd1299, 1;
	sub.s64 	%rd1301, %rd1300, %rd12;
	mov.b64 	%fd813, %rd1301;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1850}, %fd813;
	}
	setp.lt.s32 	%p42, %r1850, 0;
	selp.b64 	%rd1302, %rd1300, %rd1301, %p42;
	shl.b64 	%rd1303, %rd1302, 1;
	sub.s64 	%rd1304, %rd1303, %rd12;
	mov.b64 	%fd814, %rd1304;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1851}, %fd814;
	}
	setp.lt.s32 	%p43, %r1851, 0;
	selp.b64 	%rd1305, %rd1303, %rd1304, %p43;
	shl.b64 	%rd1306, %rd1305, 1;
	sub.s64 	%rd1307, %rd1306, %rd12;
	mov.b64 	%fd815, %rd1307;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1852}, %fd815;
	}
	setp.lt.s32 	%p44, %r1852, 0;
	selp.b64 	%rd1308, %rd1306, %rd1307, %p44;
	shl.b64 	%rd1309, %rd1308, 1;
	sub.s64 	%rd1310, %rd1309, %rd12;
	mov.b64 	%fd816, %rd1310;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1853}, %fd816;
	}
	setp.lt.s32 	%p45, %r1853, 0;
	selp.b64 	%rd1311, %rd1309, %rd1310, %p45;
	shl.b64 	%rd1312, %rd1311, 1;
	sub.s64 	%rd1313, %rd1312, %rd12;
	mov.b64 	%fd817, %rd1313;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1854}, %fd817;
	}
	setp.lt.s32 	%p46, %r1854, 0;
	selp.b64 	%rd1314, %rd1312, %rd1313, %p46;
	shl.b64 	%rd1315, %rd1314, 1;
	sub.s64 	%rd1316, %rd1315, %rd12;
	mov.b64 	%fd818, %rd1316;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1855}, %fd818;
	}
	setp.lt.s32 	%p47, %r1855, 0;
	selp.b64 	%rd1317, %rd1315, %rd1316, %p47;
	shl.b64 	%rd1318, %rd1317, 1;
	sub.s64 	%rd1319, %rd1318, %rd12;
	mov.b64 	%fd819, %rd1319;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1856}, %fd819;
	}
	setp.lt.s32 	%p48, %r1856, 0;
	selp.b64 	%rd1320, %rd1318, %rd1319, %p48;
	shl.b64 	%rd1321, %rd1320, 1;
	sub.s64 	%rd1322, %rd1321, %rd12;
	mov.b64 	%fd820, %rd1322;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1857}, %fd820;
	}
	setp.lt.s32 	%p49, %r1857, 0;
	selp.b64 	%rd1323, %rd1321, %rd1322, %p49;
	shl.b64 	%rd1324, %rd1323, 1;
	sub.s64 	%rd1325, %rd1324, %rd12;
	mov.b64 	%fd821, %rd1325;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1858}, %fd821;
	}
	setp.lt.s32 	%p50, %r1858, 0;
	selp.b64 	%rd1326, %rd1324, %rd1325, %p50;
	shl.b64 	%rd1327, %rd1326, 1;
	sub.s64 	%rd1328, %rd1327, %rd12;
	mov.b64 	%fd822, %rd1328;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1859}, %fd822;
	}
	setp.lt.s32 	%p51, %r1859, 0;
	selp.b64 	%rd6124, %rd1327, %rd1328, %p51;
	shl.b64 	%rd6121, %rd6124, 1;
	add.s32 	%r33, %r5913, -16;
	setp.gt.s32 	%p52, %r5913, 15;
	mov.u32 	%r5913, %r33;
	@%p52 bra 	$L__BB0_21;

$L__BB0_22:
	and.b64  	%rd27, %rd6124, 9223372036854775807;
	setp.eq.s64 	%p53, %rd27, 0;
	mov.f64 	%fd2896, 0d0000000000000000;
	@%p53 bra 	$L__BB0_24;

	mov.b64 	%fd824, %rd27;
	mul.f64 	%fd825, %fd824, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1860}, %fd825;
	}
	shr.u32 	%r1861, %r1860, 20;
	mov.u32 	%r1862, 55;
	sub.s32 	%r1863, %r1862, %r1861;
	sub.s32 	%r1864, %r5907, %r1863;
	shl.b64 	%rd1329, %rd27, %r1863;
	setp.lt.s32 	%p54, %r1864, 1;
	mov.u32 	%r1865, 1;
	sub.s32 	%r1866, %r1865, %r1864;
	shr.u64 	%rd1330, %rd1329, %r1866;
	add.s32 	%r1867, %r1864, -1;
	cvt.u64.u32 	%rd1331, %r1867;
	shl.b64 	%rd1332, %rd1331, 52;
	add.s64 	%rd1333, %rd1332, %rd1329;
	selp.b64 	%rd1334, %rd1330, %rd1333, %p54;
	mov.b64 	%fd2896, %rd1334;

$L__BB0_24:
	and.b32  	%r1868, %r10, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1869}, %fd2896;
	}
	or.b32  	%r1870, %r1869, %r1868;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1871, %temp}, %fd2896;
	}
	mov.b64 	%fd2897, {%r1871, %r1870};
	bra.uni 	$L__BB0_28;

$L__BB0_1122:
	.loc	1 0 9
	setp.eq.f64 	%p2214, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3115, 0dFFF8000000000000;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	@%p2214 bra 	$L__BB0_1141;

	setp.ltu.f64 	%p2215, %fd3112, %fd3160;
	mov.f64 	%fd3115, %fd596;
	@%p2215 bra 	$L__BB0_1141;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4844}, %fd3112;
	}
	shr.u32 	%r6386, %r4844, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4845}, %fd3160;
	}
	shr.u32 	%r6387, %r4845, 20;
	setp.ne.s32 	%p2216, %r6386, 0;
	@%p2216 bra 	$L__BB0_1126;

	mul.f64 	%fd3112, %fd3112, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4846}, %fd3112;
	}
	shr.u32 	%r4847, %r4846, 20;
	add.s32 	%r6386, %r4847, -54;

$L__BB0_1126:
	setp.ne.s32 	%p2217, %r6387, 0;
	mov.f64 	%fd3113, %fd3160;
	@%p2217 bra 	$L__BB0_1128;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4848}, %fd595;
	}
	shr.u32 	%r4849, %r4848, 20;
	add.s32 	%r6387, %r4849, -54;
	mov.f64 	%fd3113, %fd595;

$L__BB0_1128:
	mov.b64 	%rd4870, %fd3112;
	and.b64  	%rd4871, %rd4870, 4503599627370495;
	or.b64  	%rd6540, %rd4871, 4503599627370496;
	mov.b64 	%rd4872, %fd3113;
	and.b64  	%rd4873, %rd4872, 4503599627370495;
	or.b64  	%rd904, %rd4873, 4503599627370496;
	sub.s32 	%r6393, %r6386, %r6387;
	not.b32 	%r4850, %r6386;
	add.s32 	%r4851, %r6387, %r4850;
	max.s32 	%r4852, %r4851, -1;
	add.s32 	%r1306, %r4852, %r6386;
	mov.u32 	%r4853, 2;
	sub.s32 	%r4854, %r4853, %r6387;
	add.s32 	%r4855, %r4854, %r1306;
	and.b32  	%r6389, %r4855, 3;
	setp.eq.s32 	%p2218, %r6389, 0;
	@%p2218 bra 	$L__BB0_1130;

$L__BB0_1129:
	.pragma "nounroll";
	sub.s64 	%rd4874, %rd6540, %rd904;
	mov.b64 	%fd2390, %rd4874;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4856}, %fd2390;
	}
	setp.lt.s32 	%p2219, %r4856, 0;
	selp.b64 	%rd6543, %rd6540, %rd4874, %p2219;
	shl.b64 	%rd6540, %rd6543, 1;
	add.s32 	%r6393, %r6393, -1;
	add.s32 	%r6389, %r6389, -1;
	setp.ne.s32 	%p2220, %r6389, 0;
	@%p2220 bra 	$L__BB0_1129;

$L__BB0_1130:
	mov.u32 	%r4857, 1;
	sub.s32 	%r4858, %r4857, %r6387;
	add.s32 	%r4859, %r4858, %r1306;
	setp.lt.u32 	%p2221, %r4859, 3;
	@%p2221 bra 	$L__BB0_1135;

	not.b32 	%r4860, %r6393;
	max.s32 	%r4861, %r4860, -4;
	add.s32 	%r4862, %r6393, %r4861;
	add.s32 	%r1313, %r4862, 4;
	shr.u32 	%r4863, %r1313, 2;
	add.s32 	%r4864, %r4863, 1;
	and.b32  	%r6392, %r4864, 3;
	setp.eq.s32 	%p2222, %r6392, 0;
	@%p2222 bra 	$L__BB0_1133;

$L__BB0_1132:
	.pragma "nounroll";
	sub.s64 	%rd4876, %rd6540, %rd904;
	mov.b64 	%fd2391, %rd4876;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4865}, %fd2391;
	}
	setp.lt.s32 	%p2223, %r4865, 0;
	selp.b64 	%rd4877, %rd6540, %rd4876, %p2223;
	shl.b64 	%rd4878, %rd4877, 1;
	sub.s64 	%rd4879, %rd4878, %rd904;
	mov.b64 	%fd2392, %rd4879;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4866}, %fd2392;
	}
	setp.lt.s32 	%p2224, %r4866, 0;
	selp.b64 	%rd4880, %rd4878, %rd4879, %p2224;
	shl.b64 	%rd4881, %rd4880, 1;
	sub.s64 	%rd4882, %rd4881, %rd904;
	mov.b64 	%fd2393, %rd4882;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4867}, %fd2393;
	}
	setp.lt.s32 	%p2225, %r4867, 0;
	selp.b64 	%rd4883, %rd4881, %rd4882, %p2225;
	shl.b64 	%rd4884, %rd4883, 1;
	sub.s64 	%rd4885, %rd4884, %rd904;
	mov.b64 	%fd2394, %rd4885;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4868}, %fd2394;
	}
	setp.lt.s32 	%p2226, %r4868, 0;
	selp.b64 	%rd6543, %rd4884, %rd4885, %p2226;
	shl.b64 	%rd6540, %rd6543, 1;
	add.s32 	%r6393, %r6393, -4;
	add.s32 	%r6392, %r6392, -1;
	setp.ne.s32 	%p2227, %r6392, 0;
	@%p2227 bra 	$L__BB0_1132;

$L__BB0_1133:
	setp.lt.u32 	%p2228, %r1313, 12;
	@%p2228 bra 	$L__BB0_1135;

$L__BB0_1134:
	sub.s64 	%rd4886, %rd6540, %rd904;
	mov.b64 	%fd2395, %rd4886;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4869}, %fd2395;
	}
	setp.lt.s32 	%p2229, %r4869, 0;
	selp.b64 	%rd4887, %rd6540, %rd4886, %p2229;
	shl.b64 	%rd4888, %rd4887, 1;
	sub.s64 	%rd4889, %rd4888, %rd904;
	mov.b64 	%fd2396, %rd4889;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4870}, %fd2396;
	}
	setp.lt.s32 	%p2230, %r4870, 0;
	selp.b64 	%rd4890, %rd4888, %rd4889, %p2230;
	shl.b64 	%rd4891, %rd4890, 1;
	sub.s64 	%rd4892, %rd4891, %rd904;
	mov.b64 	%fd2397, %rd4892;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4871}, %fd2397;
	}
	setp.lt.s32 	%p2231, %r4871, 0;
	selp.b64 	%rd4893, %rd4891, %rd4892, %p2231;
	shl.b64 	%rd4894, %rd4893, 1;
	sub.s64 	%rd4895, %rd4894, %rd904;
	mov.b64 	%fd2398, %rd4895;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4872}, %fd2398;
	}
	setp.lt.s32 	%p2232, %r4872, 0;
	selp.b64 	%rd4896, %rd4894, %rd4895, %p2232;
	shl.b64 	%rd4897, %rd4896, 1;
	sub.s64 	%rd4898, %rd4897, %rd904;
	mov.b64 	%fd2399, %rd4898;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4873}, %fd2399;
	}
	setp.lt.s32 	%p2233, %r4873, 0;
	selp.b64 	%rd4899, %rd4897, %rd4898, %p2233;
	shl.b64 	%rd4900, %rd4899, 1;
	sub.s64 	%rd4901, %rd4900, %rd904;
	mov.b64 	%fd2400, %rd4901;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4874}, %fd2400;
	}
	setp.lt.s32 	%p2234, %r4874, 0;
	selp.b64 	%rd4902, %rd4900, %rd4901, %p2234;
	shl.b64 	%rd4903, %rd4902, 1;
	sub.s64 	%rd4904, %rd4903, %rd904;
	mov.b64 	%fd2401, %rd4904;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4875}, %fd2401;
	}
	setp.lt.s32 	%p2235, %r4875, 0;
	selp.b64 	%rd4905, %rd4903, %rd4904, %p2235;
	shl.b64 	%rd4906, %rd4905, 1;
	sub.s64 	%rd4907, %rd4906, %rd904;
	mov.b64 	%fd2402, %rd4907;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4876}, %fd2402;
	}
	setp.lt.s32 	%p2236, %r4876, 0;
	selp.b64 	%rd4908, %rd4906, %rd4907, %p2236;
	shl.b64 	%rd4909, %rd4908, 1;
	sub.s64 	%rd4910, %rd4909, %rd904;
	mov.b64 	%fd2403, %rd4910;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4877}, %fd2403;
	}
	setp.lt.s32 	%p2237, %r4877, 0;
	selp.b64 	%rd4911, %rd4909, %rd4910, %p2237;
	shl.b64 	%rd4912, %rd4911, 1;
	sub.s64 	%rd4913, %rd4912, %rd904;
	mov.b64 	%fd2404, %rd4913;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4878}, %fd2404;
	}
	setp.lt.s32 	%p2238, %r4878, 0;
	selp.b64 	%rd4914, %rd4912, %rd4913, %p2238;
	shl.b64 	%rd4915, %rd4914, 1;
	sub.s64 	%rd4916, %rd4915, %rd904;
	mov.b64 	%fd2405, %rd4916;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4879}, %fd2405;
	}
	setp.lt.s32 	%p2239, %r4879, 0;
	selp.b64 	%rd4917, %rd4915, %rd4916, %p2239;
	shl.b64 	%rd4918, %rd4917, 1;
	sub.s64 	%rd4919, %rd4918, %rd904;
	mov.b64 	%fd2406, %rd4919;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4880}, %fd2406;
	}
	setp.lt.s32 	%p2240, %r4880, 0;
	selp.b64 	%rd4920, %rd4918, %rd4919, %p2240;
	shl.b64 	%rd4921, %rd4920, 1;
	sub.s64 	%rd4922, %rd4921, %rd904;
	mov.b64 	%fd2407, %rd4922;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4881}, %fd2407;
	}
	setp.lt.s32 	%p2241, %r4881, 0;
	selp.b64 	%rd4923, %rd4921, %rd4922, %p2241;
	shl.b64 	%rd4924, %rd4923, 1;
	sub.s64 	%rd4925, %rd4924, %rd904;
	mov.b64 	%fd2408, %rd4925;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4882}, %fd2408;
	}
	setp.lt.s32 	%p2242, %r4882, 0;
	selp.b64 	%rd4926, %rd4924, %rd4925, %p2242;
	shl.b64 	%rd4927, %rd4926, 1;
	sub.s64 	%rd4928, %rd4927, %rd904;
	mov.b64 	%fd2409, %rd4928;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4883}, %fd2409;
	}
	setp.lt.s32 	%p2243, %r4883, 0;
	selp.b64 	%rd4929, %rd4927, %rd4928, %p2243;
	shl.b64 	%rd4930, %rd4929, 1;
	sub.s64 	%rd4931, %rd4930, %rd904;
	mov.b64 	%fd2410, %rd4931;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4884}, %fd2410;
	}
	setp.lt.s32 	%p2244, %r4884, 0;
	selp.b64 	%rd6543, %rd4930, %rd4931, %p2244;
	shl.b64 	%rd6540, %rd6543, 1;
	add.s32 	%r1321, %r6393, -16;
	setp.gt.s32 	%p2245, %r6393, 15;
	mov.u32 	%r6393, %r1321;
	@%p2245 bra 	$L__BB0_1134;

$L__BB0_1135:
	and.b64  	%rd919, %rd6543, 9223372036854775807;
	setp.eq.s64 	%p2246, %rd919, 0;
	mov.f64 	%fd3114, 0d0000000000000000;
	@%p2246 bra 	$L__BB0_1137;

	mov.b64 	%fd2412, %rd919;
	mul.f64 	%fd2413, %fd2412, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4885}, %fd2413;
	}
	shr.u32 	%r4886, %r4885, 20;
	mov.u32 	%r4887, 55;
	sub.s32 	%r4888, %r4887, %r4886;
	sub.s32 	%r4889, %r6387, %r4888;
	shl.b64 	%rd4932, %rd919, %r4888;
	setp.lt.s32 	%p2247, %r4889, 1;
	mov.u32 	%r4890, 1;
	sub.s32 	%r4891, %r4890, %r4889;
	shr.u64 	%rd4933, %rd4932, %r4891;
	add.s32 	%r4892, %r4889, -1;
	cvt.u64.u32 	%rd4934, %r4892;
	shl.b64 	%rd4935, %rd4934, 52;
	add.s64 	%rd4936, %rd4935, %rd4932;
	selp.b64 	%rd4937, %rd4933, %rd4936, %p2247;
	mov.b64 	%fd3114, %rd4937;

$L__BB0_1137:
	and.b32  	%r4893, %r1298, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4894}, %fd3114;
	}
	or.b32  	%r4895, %r4894, %r4893;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4896, %temp}, %fd3114;
	}
	mov.b64 	%fd3115, {%r4896, %r4895};
	bra.uni 	$L__BB0_1141;

$L__BB0_26:
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mov.f64 	%fd826, 0d3FF0000000000000;
	add.rn.f64 	%fd2897, %fd4, %fd826;

$L__BB0_28:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 71 5
	ld.local.u8 	%rs223, [%rd7];
	cvt.rn.f64.u16 	%fd15, %rs223;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mov.f64 	%fd827, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd828, %fd827, %fd2897;
	mul.f64 	%fd829, %fd828, %fd15;
	fma.rn.f64 	%fd16, %fd829, 0d400921FB54442D18, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd16;
	}
	and.b32  	%r1872, %r34, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1873, %temp}, %fd16;
	}
	mov.b64 	%fd2898, {%r1873, %r1872};
	setp.gt.u32 	%p59, %r1872, 2146435071;
	or.pred  	%p61, %p59, %p18;
	@%p61 bra 	$L__BB0_45;
	bra.uni 	$L__BB0_29;

$L__BB0_45:
	.loc	1 0 9
	setp.le.f64 	%p96, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p97, %fd2898, 0d7FF0000000000000;
	and.pred  	%p98, %p97, %p96;
	@%p98 bra 	$L__BB0_47;
	bra.uni 	$L__BB0_46;

$L__BB0_47:
	setp.eq.f64 	%p99, %fd2898, 0d7FF0000000000000;
	selp.f64 	%fd2901, 0dFFF8000000000000, %fd16, %p99;
	bra.uni 	$L__BB0_48;

$L__BB0_29:
	.loc	1 0 9
	setp.eq.f64 	%p62, %fd3160, 0d0000000000000000;
	mov.f64 	%fd2901, 0dFFF8000000000000;
	.loc	1 32 9
	@%p62 bra 	$L__BB0_48;

	setp.ltu.f64 	%p63, %fd2898, %fd3160;
	mov.f64 	%fd2901, %fd16;
	@%p63 bra 	$L__BB0_48;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1874}, %fd2898;
	}
	shr.u32 	%r5915, %r1874, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1875}, %fd3160;
	}
	shr.u32 	%r5916, %r1875, 20;
	setp.ne.s32 	%p64, %r5915, 0;
	@%p64 bra 	$L__BB0_33;

	mul.f64 	%fd2898, %fd2898, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1876}, %fd2898;
	}
	shr.u32 	%r1877, %r1876, 20;
	add.s32 	%r5915, %r1877, -54;

$L__BB0_33:
	setp.ne.s32 	%p65, %r5916, 0;
	mov.f64 	%fd2899, %fd3160;
	@%p65 bra 	$L__BB0_35;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1878}, %fd2;
	}
	shr.u32 	%r1879, %r1878, 20;
	add.s32 	%r5916, %r1879, -54;
	mov.f64 	%fd2899, %fd2;

$L__BB0_35:
	mov.b64 	%rd1336, %fd2898;
	and.b64  	%rd1337, %rd1336, 4503599627370495;
	or.b64  	%rd6129, %rd1337, 4503599627370496;
	mov.b64 	%rd1338, %fd2899;
	and.b64  	%rd1339, %rd1338, 4503599627370495;
	or.b64  	%rd29, %rd1339, 4503599627370496;
	sub.s32 	%r5922, %r5915, %r5916;
	not.b32 	%r1880, %r5915;
	add.s32 	%r1881, %r5916, %r1880;
	max.s32 	%r1882, %r1881, -1;
	add.s32 	%r42, %r1882, %r5915;
	mov.u32 	%r1883, 2;
	sub.s32 	%r1884, %r1883, %r5916;
	add.s32 	%r1885, %r1884, %r42;
	and.b32  	%r5918, %r1885, 3;
	setp.eq.s32 	%p66, %r5918, 0;
	@%p66 bra 	$L__BB0_37;

$L__BB0_36:
	.pragma "nounroll";
	sub.s64 	%rd1340, %rd6129, %rd29;
	mov.b64 	%fd831, %rd1340;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1886}, %fd831;
	}
	setp.lt.s32 	%p67, %r1886, 0;
	selp.b64 	%rd6132, %rd6129, %rd1340, %p67;
	shl.b64 	%rd6129, %rd6132, 1;
	add.s32 	%r5922, %r5922, -1;
	add.s32 	%r5918, %r5918, -1;
	setp.ne.s32 	%p68, %r5918, 0;
	@%p68 bra 	$L__BB0_36;

$L__BB0_37:
	mov.u32 	%r1887, 1;
	sub.s32 	%r1888, %r1887, %r5916;
	add.s32 	%r1889, %r1888, %r42;
	setp.lt.u32 	%p69, %r1889, 3;
	@%p69 bra 	$L__BB0_42;

	not.b32 	%r1890, %r5922;
	max.s32 	%r1891, %r1890, -4;
	add.s32 	%r1892, %r5922, %r1891;
	add.s32 	%r49, %r1892, 4;
	shr.u32 	%r1893, %r49, 2;
	add.s32 	%r1894, %r1893, 1;
	and.b32  	%r5921, %r1894, 3;
	setp.eq.s32 	%p70, %r5921, 0;
	@%p70 bra 	$L__BB0_40;

$L__BB0_39:
	.pragma "nounroll";
	sub.s64 	%rd1342, %rd6129, %rd29;
	mov.b64 	%fd832, %rd1342;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1895}, %fd832;
	}
	setp.lt.s32 	%p71, %r1895, 0;
	selp.b64 	%rd1343, %rd6129, %rd1342, %p71;
	shl.b64 	%rd1344, %rd1343, 1;
	sub.s64 	%rd1345, %rd1344, %rd29;
	mov.b64 	%fd833, %rd1345;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1896}, %fd833;
	}
	setp.lt.s32 	%p72, %r1896, 0;
	selp.b64 	%rd1346, %rd1344, %rd1345, %p72;
	shl.b64 	%rd1347, %rd1346, 1;
	sub.s64 	%rd1348, %rd1347, %rd29;
	mov.b64 	%fd834, %rd1348;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1897}, %fd834;
	}
	setp.lt.s32 	%p73, %r1897, 0;
	selp.b64 	%rd1349, %rd1347, %rd1348, %p73;
	shl.b64 	%rd1350, %rd1349, 1;
	sub.s64 	%rd1351, %rd1350, %rd29;
	mov.b64 	%fd835, %rd1351;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1898}, %fd835;
	}
	setp.lt.s32 	%p74, %r1898, 0;
	selp.b64 	%rd6132, %rd1350, %rd1351, %p74;
	shl.b64 	%rd6129, %rd6132, 1;
	add.s32 	%r5922, %r5922, -4;
	add.s32 	%r5921, %r5921, -1;
	setp.ne.s32 	%p75, %r5921, 0;
	@%p75 bra 	$L__BB0_39;

$L__BB0_40:
	setp.lt.u32 	%p76, %r49, 12;
	@%p76 bra 	$L__BB0_42;

$L__BB0_41:
	sub.s64 	%rd1352, %rd6129, %rd29;
	mov.b64 	%fd836, %rd1352;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1899}, %fd836;
	}
	setp.lt.s32 	%p77, %r1899, 0;
	selp.b64 	%rd1353, %rd6129, %rd1352, %p77;
	shl.b64 	%rd1354, %rd1353, 1;
	sub.s64 	%rd1355, %rd1354, %rd29;
	mov.b64 	%fd837, %rd1355;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1900}, %fd837;
	}
	setp.lt.s32 	%p78, %r1900, 0;
	selp.b64 	%rd1356, %rd1354, %rd1355, %p78;
	shl.b64 	%rd1357, %rd1356, 1;
	sub.s64 	%rd1358, %rd1357, %rd29;
	mov.b64 	%fd838, %rd1358;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1901}, %fd838;
	}
	setp.lt.s32 	%p79, %r1901, 0;
	selp.b64 	%rd1359, %rd1357, %rd1358, %p79;
	shl.b64 	%rd1360, %rd1359, 1;
	sub.s64 	%rd1361, %rd1360, %rd29;
	mov.b64 	%fd839, %rd1361;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1902}, %fd839;
	}
	setp.lt.s32 	%p80, %r1902, 0;
	selp.b64 	%rd1362, %rd1360, %rd1361, %p80;
	shl.b64 	%rd1363, %rd1362, 1;
	sub.s64 	%rd1364, %rd1363, %rd29;
	mov.b64 	%fd840, %rd1364;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1903}, %fd840;
	}
	setp.lt.s32 	%p81, %r1903, 0;
	selp.b64 	%rd1365, %rd1363, %rd1364, %p81;
	shl.b64 	%rd1366, %rd1365, 1;
	sub.s64 	%rd1367, %rd1366, %rd29;
	mov.b64 	%fd841, %rd1367;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1904}, %fd841;
	}
	setp.lt.s32 	%p82, %r1904, 0;
	selp.b64 	%rd1368, %rd1366, %rd1367, %p82;
	shl.b64 	%rd1369, %rd1368, 1;
	sub.s64 	%rd1370, %rd1369, %rd29;
	mov.b64 	%fd842, %rd1370;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1905}, %fd842;
	}
	setp.lt.s32 	%p83, %r1905, 0;
	selp.b64 	%rd1371, %rd1369, %rd1370, %p83;
	shl.b64 	%rd1372, %rd1371, 1;
	sub.s64 	%rd1373, %rd1372, %rd29;
	mov.b64 	%fd843, %rd1373;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1906}, %fd843;
	}
	setp.lt.s32 	%p84, %r1906, 0;
	selp.b64 	%rd1374, %rd1372, %rd1373, %p84;
	shl.b64 	%rd1375, %rd1374, 1;
	sub.s64 	%rd1376, %rd1375, %rd29;
	mov.b64 	%fd844, %rd1376;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1907}, %fd844;
	}
	setp.lt.s32 	%p85, %r1907, 0;
	selp.b64 	%rd1377, %rd1375, %rd1376, %p85;
	shl.b64 	%rd1378, %rd1377, 1;
	sub.s64 	%rd1379, %rd1378, %rd29;
	mov.b64 	%fd845, %rd1379;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1908}, %fd845;
	}
	setp.lt.s32 	%p86, %r1908, 0;
	selp.b64 	%rd1380, %rd1378, %rd1379, %p86;
	shl.b64 	%rd1381, %rd1380, 1;
	sub.s64 	%rd1382, %rd1381, %rd29;
	mov.b64 	%fd846, %rd1382;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1909}, %fd846;
	}
	setp.lt.s32 	%p87, %r1909, 0;
	selp.b64 	%rd1383, %rd1381, %rd1382, %p87;
	shl.b64 	%rd1384, %rd1383, 1;
	sub.s64 	%rd1385, %rd1384, %rd29;
	mov.b64 	%fd847, %rd1385;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1910}, %fd847;
	}
	setp.lt.s32 	%p88, %r1910, 0;
	selp.b64 	%rd1386, %rd1384, %rd1385, %p88;
	shl.b64 	%rd1387, %rd1386, 1;
	sub.s64 	%rd1388, %rd1387, %rd29;
	mov.b64 	%fd848, %rd1388;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1911}, %fd848;
	}
	setp.lt.s32 	%p89, %r1911, 0;
	selp.b64 	%rd1389, %rd1387, %rd1388, %p89;
	shl.b64 	%rd1390, %rd1389, 1;
	sub.s64 	%rd1391, %rd1390, %rd29;
	mov.b64 	%fd849, %rd1391;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1912}, %fd849;
	}
	setp.lt.s32 	%p90, %r1912, 0;
	selp.b64 	%rd1392, %rd1390, %rd1391, %p90;
	shl.b64 	%rd1393, %rd1392, 1;
	sub.s64 	%rd1394, %rd1393, %rd29;
	mov.b64 	%fd850, %rd1394;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1913}, %fd850;
	}
	setp.lt.s32 	%p91, %r1913, 0;
	selp.b64 	%rd1395, %rd1393, %rd1394, %p91;
	shl.b64 	%rd1396, %rd1395, 1;
	sub.s64 	%rd1397, %rd1396, %rd29;
	mov.b64 	%fd851, %rd1397;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1914}, %fd851;
	}
	setp.lt.s32 	%p92, %r1914, 0;
	selp.b64 	%rd6132, %rd1396, %rd1397, %p92;
	shl.b64 	%rd6129, %rd6132, 1;
	add.s32 	%r57, %r5922, -16;
	setp.gt.s32 	%p93, %r5922, 15;
	mov.u32 	%r5922, %r57;
	@%p93 bra 	$L__BB0_41;

$L__BB0_42:
	and.b64  	%rd44, %rd6132, 9223372036854775807;
	setp.eq.s64 	%p94, %rd44, 0;
	mov.f64 	%fd2900, 0d0000000000000000;
	@%p94 bra 	$L__BB0_44;

	mov.b64 	%fd853, %rd44;
	mul.f64 	%fd854, %fd853, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1915}, %fd854;
	}
	shr.u32 	%r1916, %r1915, 20;
	mov.u32 	%r1917, 55;
	sub.s32 	%r1918, %r1917, %r1916;
	sub.s32 	%r1919, %r5916, %r1918;
	shl.b64 	%rd1398, %rd44, %r1918;
	setp.lt.s32 	%p95, %r1919, 1;
	mov.u32 	%r1920, 1;
	sub.s32 	%r1921, %r1920, %r1919;
	shr.u64 	%rd1399, %rd1398, %r1921;
	add.s32 	%r1922, %r1919, -1;
	cvt.u64.u32 	%rd1400, %r1922;
	shl.b64 	%rd1401, %rd1400, 52;
	add.s64 	%rd1402, %rd1401, %rd1398;
	selp.b64 	%rd1403, %rd1399, %rd1402, %p95;
	mov.b64 	%fd2900, %rd1403;

$L__BB0_44:
	and.b32  	%r1923, %r34, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1924}, %fd2900;
	}
	or.b32  	%r1925, %r1924, %r1923;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1926, %temp}, %fd2900;
	}
	mov.b64 	%fd2901, {%r1926, %r1925};
	bra.uni 	$L__BB0_48;

$L__BB0_46:
	mov.f64 	%fd855, 0d3FF0000000000000;
	add.rn.f64 	%fd2901, %fd16, %fd855;

$L__BB0_48:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 71 5
	ld.local.u8 	%rs222, [%rd6];
	cvt.rn.f64.u16 	%fd27, %rs222;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mov.f64 	%fd856, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd857, %fd856, %fd2901;
	mul.f64 	%fd858, %fd857, %fd27;
	fma.rn.f64 	%fd28, %fd858, 0d400921FB54442D18, 0d4032D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r58}, %fd28;
	}
	and.b32  	%r1927, %r58, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1928, %temp}, %fd28;
	}
	mov.b64 	%fd2902, {%r1928, %r1927};
	setp.gt.u32 	%p100, %r1927, 2146435071;
	or.pred  	%p102, %p100, %p18;
	@%p102 bra 	$L__BB0_65;
	bra.uni 	$L__BB0_49;

$L__BB0_65:
	.loc	1 0 9
	setp.le.f64 	%p137, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p138, %fd2902, 0d7FF0000000000000;
	and.pred  	%p139, %p138, %p137;
	@%p139 bra 	$L__BB0_67;
	bra.uni 	$L__BB0_66;

$L__BB0_67:
	setp.eq.f64 	%p140, %fd2902, 0d7FF0000000000000;
	selp.f64 	%fd2905, 0dFFF8000000000000, %fd28, %p140;
	bra.uni 	$L__BB0_68;

$L__BB0_49:
	.loc	1 0 9
	setp.eq.f64 	%p103, %fd3160, 0d0000000000000000;
	mov.f64 	%fd2905, 0dFFF8000000000000;
	.loc	1 32 9
	@%p103 bra 	$L__BB0_68;

	setp.ltu.f64 	%p104, %fd2902, %fd3160;
	mov.f64 	%fd2905, %fd28;
	@%p104 bra 	$L__BB0_68;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1929}, %fd2902;
	}
	shr.u32 	%r5924, %r1929, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1930}, %fd3160;
	}
	shr.u32 	%r5925, %r1930, 20;
	setp.ne.s32 	%p105, %r5924, 0;
	@%p105 bra 	$L__BB0_53;

	mul.f64 	%fd2902, %fd2902, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1931}, %fd2902;
	}
	shr.u32 	%r1932, %r1931, 20;
	add.s32 	%r5924, %r1932, -54;

$L__BB0_53:
	setp.ne.s32 	%p106, %r5925, 0;
	mov.f64 	%fd2903, %fd3160;
	@%p106 bra 	$L__BB0_55;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1933}, %fd2;
	}
	shr.u32 	%r1934, %r1933, 20;
	add.s32 	%r5925, %r1934, -54;
	mov.f64 	%fd2903, %fd2;

$L__BB0_55:
	mov.b64 	%rd1405, %fd2902;
	and.b64  	%rd1406, %rd1405, 4503599627370495;
	or.b64  	%rd6137, %rd1406, 4503599627370496;
	mov.b64 	%rd1407, %fd2903;
	and.b64  	%rd1408, %rd1407, 4503599627370495;
	or.b64  	%rd46, %rd1408, 4503599627370496;
	sub.s32 	%r5931, %r5924, %r5925;
	not.b32 	%r1935, %r5924;
	add.s32 	%r1936, %r5925, %r1935;
	max.s32 	%r1937, %r1936, -1;
	add.s32 	%r66, %r1937, %r5924;
	mov.u32 	%r1938, 2;
	sub.s32 	%r1939, %r1938, %r5925;
	add.s32 	%r1940, %r1939, %r66;
	and.b32  	%r5927, %r1940, 3;
	setp.eq.s32 	%p107, %r5927, 0;
	@%p107 bra 	$L__BB0_57;

$L__BB0_56:
	.pragma "nounroll";
	sub.s64 	%rd1409, %rd6137, %rd46;
	mov.b64 	%fd860, %rd1409;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1941}, %fd860;
	}
	setp.lt.s32 	%p108, %r1941, 0;
	selp.b64 	%rd6140, %rd6137, %rd1409, %p108;
	shl.b64 	%rd6137, %rd6140, 1;
	add.s32 	%r5931, %r5931, -1;
	add.s32 	%r5927, %r5927, -1;
	setp.ne.s32 	%p109, %r5927, 0;
	@%p109 bra 	$L__BB0_56;

$L__BB0_57:
	mov.u32 	%r1942, 1;
	sub.s32 	%r1943, %r1942, %r5925;
	add.s32 	%r1944, %r1943, %r66;
	setp.lt.u32 	%p110, %r1944, 3;
	@%p110 bra 	$L__BB0_62;

	not.b32 	%r1945, %r5931;
	max.s32 	%r1946, %r1945, -4;
	add.s32 	%r1947, %r5931, %r1946;
	add.s32 	%r73, %r1947, 4;
	shr.u32 	%r1948, %r73, 2;
	add.s32 	%r1949, %r1948, 1;
	and.b32  	%r5930, %r1949, 3;
	setp.eq.s32 	%p111, %r5930, 0;
	@%p111 bra 	$L__BB0_60;

$L__BB0_59:
	.pragma "nounroll";
	sub.s64 	%rd1411, %rd6137, %rd46;
	mov.b64 	%fd861, %rd1411;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1950}, %fd861;
	}
	setp.lt.s32 	%p112, %r1950, 0;
	selp.b64 	%rd1412, %rd6137, %rd1411, %p112;
	shl.b64 	%rd1413, %rd1412, 1;
	sub.s64 	%rd1414, %rd1413, %rd46;
	mov.b64 	%fd862, %rd1414;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1951}, %fd862;
	}
	setp.lt.s32 	%p113, %r1951, 0;
	selp.b64 	%rd1415, %rd1413, %rd1414, %p113;
	shl.b64 	%rd1416, %rd1415, 1;
	sub.s64 	%rd1417, %rd1416, %rd46;
	mov.b64 	%fd863, %rd1417;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1952}, %fd863;
	}
	setp.lt.s32 	%p114, %r1952, 0;
	selp.b64 	%rd1418, %rd1416, %rd1417, %p114;
	shl.b64 	%rd1419, %rd1418, 1;
	sub.s64 	%rd1420, %rd1419, %rd46;
	mov.b64 	%fd864, %rd1420;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1953}, %fd864;
	}
	setp.lt.s32 	%p115, %r1953, 0;
	selp.b64 	%rd6140, %rd1419, %rd1420, %p115;
	shl.b64 	%rd6137, %rd6140, 1;
	add.s32 	%r5931, %r5931, -4;
	add.s32 	%r5930, %r5930, -1;
	setp.ne.s32 	%p116, %r5930, 0;
	@%p116 bra 	$L__BB0_59;

$L__BB0_60:
	setp.lt.u32 	%p117, %r73, 12;
	@%p117 bra 	$L__BB0_62;

$L__BB0_61:
	sub.s64 	%rd1421, %rd6137, %rd46;
	mov.b64 	%fd865, %rd1421;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1954}, %fd865;
	}
	setp.lt.s32 	%p118, %r1954, 0;
	selp.b64 	%rd1422, %rd6137, %rd1421, %p118;
	shl.b64 	%rd1423, %rd1422, 1;
	sub.s64 	%rd1424, %rd1423, %rd46;
	mov.b64 	%fd866, %rd1424;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1955}, %fd866;
	}
	setp.lt.s32 	%p119, %r1955, 0;
	selp.b64 	%rd1425, %rd1423, %rd1424, %p119;
	shl.b64 	%rd1426, %rd1425, 1;
	sub.s64 	%rd1427, %rd1426, %rd46;
	mov.b64 	%fd867, %rd1427;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1956}, %fd867;
	}
	setp.lt.s32 	%p120, %r1956, 0;
	selp.b64 	%rd1428, %rd1426, %rd1427, %p120;
	shl.b64 	%rd1429, %rd1428, 1;
	sub.s64 	%rd1430, %rd1429, %rd46;
	mov.b64 	%fd868, %rd1430;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1957}, %fd868;
	}
	setp.lt.s32 	%p121, %r1957, 0;
	selp.b64 	%rd1431, %rd1429, %rd1430, %p121;
	shl.b64 	%rd1432, %rd1431, 1;
	sub.s64 	%rd1433, %rd1432, %rd46;
	mov.b64 	%fd869, %rd1433;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1958}, %fd869;
	}
	setp.lt.s32 	%p122, %r1958, 0;
	selp.b64 	%rd1434, %rd1432, %rd1433, %p122;
	shl.b64 	%rd1435, %rd1434, 1;
	sub.s64 	%rd1436, %rd1435, %rd46;
	mov.b64 	%fd870, %rd1436;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1959}, %fd870;
	}
	setp.lt.s32 	%p123, %r1959, 0;
	selp.b64 	%rd1437, %rd1435, %rd1436, %p123;
	shl.b64 	%rd1438, %rd1437, 1;
	sub.s64 	%rd1439, %rd1438, %rd46;
	mov.b64 	%fd871, %rd1439;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1960}, %fd871;
	}
	setp.lt.s32 	%p124, %r1960, 0;
	selp.b64 	%rd1440, %rd1438, %rd1439, %p124;
	shl.b64 	%rd1441, %rd1440, 1;
	sub.s64 	%rd1442, %rd1441, %rd46;
	mov.b64 	%fd872, %rd1442;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1961}, %fd872;
	}
	setp.lt.s32 	%p125, %r1961, 0;
	selp.b64 	%rd1443, %rd1441, %rd1442, %p125;
	shl.b64 	%rd1444, %rd1443, 1;
	sub.s64 	%rd1445, %rd1444, %rd46;
	mov.b64 	%fd873, %rd1445;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1962}, %fd873;
	}
	setp.lt.s32 	%p126, %r1962, 0;
	selp.b64 	%rd1446, %rd1444, %rd1445, %p126;
	shl.b64 	%rd1447, %rd1446, 1;
	sub.s64 	%rd1448, %rd1447, %rd46;
	mov.b64 	%fd874, %rd1448;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1963}, %fd874;
	}
	setp.lt.s32 	%p127, %r1963, 0;
	selp.b64 	%rd1449, %rd1447, %rd1448, %p127;
	shl.b64 	%rd1450, %rd1449, 1;
	sub.s64 	%rd1451, %rd1450, %rd46;
	mov.b64 	%fd875, %rd1451;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1964}, %fd875;
	}
	setp.lt.s32 	%p128, %r1964, 0;
	selp.b64 	%rd1452, %rd1450, %rd1451, %p128;
	shl.b64 	%rd1453, %rd1452, 1;
	sub.s64 	%rd1454, %rd1453, %rd46;
	mov.b64 	%fd876, %rd1454;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1965}, %fd876;
	}
	setp.lt.s32 	%p129, %r1965, 0;
	selp.b64 	%rd1455, %rd1453, %rd1454, %p129;
	shl.b64 	%rd1456, %rd1455, 1;
	sub.s64 	%rd1457, %rd1456, %rd46;
	mov.b64 	%fd877, %rd1457;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1966}, %fd877;
	}
	setp.lt.s32 	%p130, %r1966, 0;
	selp.b64 	%rd1458, %rd1456, %rd1457, %p130;
	shl.b64 	%rd1459, %rd1458, 1;
	sub.s64 	%rd1460, %rd1459, %rd46;
	mov.b64 	%fd878, %rd1460;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1967}, %fd878;
	}
	setp.lt.s32 	%p131, %r1967, 0;
	selp.b64 	%rd1461, %rd1459, %rd1460, %p131;
	shl.b64 	%rd1462, %rd1461, 1;
	sub.s64 	%rd1463, %rd1462, %rd46;
	mov.b64 	%fd879, %rd1463;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1968}, %fd879;
	}
	setp.lt.s32 	%p132, %r1968, 0;
	selp.b64 	%rd1464, %rd1462, %rd1463, %p132;
	shl.b64 	%rd1465, %rd1464, 1;
	sub.s64 	%rd1466, %rd1465, %rd46;
	mov.b64 	%fd880, %rd1466;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1969}, %fd880;
	}
	setp.lt.s32 	%p133, %r1969, 0;
	selp.b64 	%rd6140, %rd1465, %rd1466, %p133;
	shl.b64 	%rd6137, %rd6140, 1;
	add.s32 	%r81, %r5931, -16;
	setp.gt.s32 	%p134, %r5931, 15;
	mov.u32 	%r5931, %r81;
	@%p134 bra 	$L__BB0_61;

$L__BB0_62:
	and.b64  	%rd61, %rd6140, 9223372036854775807;
	setp.eq.s64 	%p135, %rd61, 0;
	mov.f64 	%fd2904, 0d0000000000000000;
	@%p135 bra 	$L__BB0_64;

	mov.b64 	%fd882, %rd61;
	mul.f64 	%fd883, %fd882, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1970}, %fd883;
	}
	shr.u32 	%r1971, %r1970, 20;
	mov.u32 	%r1972, 55;
	sub.s32 	%r1973, %r1972, %r1971;
	sub.s32 	%r1974, %r5925, %r1973;
	shl.b64 	%rd1467, %rd61, %r1973;
	setp.lt.s32 	%p136, %r1974, 1;
	mov.u32 	%r1975, 1;
	sub.s32 	%r1976, %r1975, %r1974;
	shr.u64 	%rd1468, %rd1467, %r1976;
	add.s32 	%r1977, %r1974, -1;
	cvt.u64.u32 	%rd1469, %r1977;
	shl.b64 	%rd1470, %rd1469, 52;
	add.s64 	%rd1471, %rd1470, %rd1467;
	selp.b64 	%rd1472, %rd1468, %rd1471, %p136;
	mov.b64 	%fd2904, %rd1472;

$L__BB0_64:
	and.b32  	%r1978, %r58, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1979}, %fd2904;
	}
	or.b32  	%r1980, %r1979, %r1978;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1981, %temp}, %fd2904;
	}
	mov.b64 	%fd2905, {%r1981, %r1980};
	bra.uni 	$L__BB0_68;

$L__BB0_66:
	mov.f64 	%fd884, 0d3FF0000000000000;
	add.rn.f64 	%fd2905, %fd28, %fd884;

$L__BB0_68:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 71 5
	ld.local.u8 	%rs221, [%rd5];
	cvt.rn.f64.u16 	%fd39, %rs221;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mov.f64 	%fd885, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd886, %fd885, %fd2905;
	mul.f64 	%fd887, %fd886, %fd39;
	fma.rn.f64 	%fd40, %fd887, 0d400921FB54442D18, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd40;
	}
	and.b32  	%r1982, %r82, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1983, %temp}, %fd40;
	}
	mov.b64 	%fd2906, {%r1983, %r1982};
	setp.gt.u32 	%p141, %r1982, 2146435071;
	or.pred  	%p143, %p141, %p18;
	@%p143 bra 	$L__BB0_85;
	bra.uni 	$L__BB0_69;

$L__BB0_85:
	.loc	1 0 9
	setp.le.f64 	%p178, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p179, %fd2906, 0d7FF0000000000000;
	and.pred  	%p180, %p179, %p178;
	@%p180 bra 	$L__BB0_87;
	bra.uni 	$L__BB0_86;

$L__BB0_87:
	setp.eq.f64 	%p181, %fd2906, 0d7FF0000000000000;
	selp.f64 	%fd2909, 0dFFF8000000000000, %fd40, %p181;
	bra.uni 	$L__BB0_88;

$L__BB0_69:
	.loc	1 0 9
	setp.eq.f64 	%p144, %fd3160, 0d0000000000000000;
	mov.f64 	%fd2909, 0dFFF8000000000000;
	.loc	1 32 9
	@%p144 bra 	$L__BB0_88;

	setp.ltu.f64 	%p145, %fd2906, %fd3160;
	mov.f64 	%fd2909, %fd40;
	@%p145 bra 	$L__BB0_88;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1984}, %fd2906;
	}
	shr.u32 	%r5933, %r1984, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1985}, %fd3160;
	}
	shr.u32 	%r5934, %r1985, 20;
	setp.ne.s32 	%p146, %r5933, 0;
	@%p146 bra 	$L__BB0_73;

	mul.f64 	%fd2906, %fd2906, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1986}, %fd2906;
	}
	shr.u32 	%r1987, %r1986, 20;
	add.s32 	%r5933, %r1987, -54;

$L__BB0_73:
	setp.ne.s32 	%p147, %r5934, 0;
	mov.f64 	%fd2907, %fd3160;
	@%p147 bra 	$L__BB0_75;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1988}, %fd2;
	}
	shr.u32 	%r1989, %r1988, 20;
	add.s32 	%r5934, %r1989, -54;
	mov.f64 	%fd2907, %fd2;

$L__BB0_75:
	mov.b64 	%rd1474, %fd2906;
	and.b64  	%rd1475, %rd1474, 4503599627370495;
	or.b64  	%rd6145, %rd1475, 4503599627370496;
	mov.b64 	%rd1476, %fd2907;
	and.b64  	%rd1477, %rd1476, 4503599627370495;
	or.b64  	%rd63, %rd1477, 4503599627370496;
	sub.s32 	%r5940, %r5933, %r5934;
	not.b32 	%r1990, %r5933;
	add.s32 	%r1991, %r5934, %r1990;
	max.s32 	%r1992, %r1991, -1;
	add.s32 	%r90, %r1992, %r5933;
	mov.u32 	%r1993, 2;
	sub.s32 	%r1994, %r1993, %r5934;
	add.s32 	%r1995, %r1994, %r90;
	and.b32  	%r5936, %r1995, 3;
	setp.eq.s32 	%p148, %r5936, 0;
	@%p148 bra 	$L__BB0_77;

$L__BB0_76:
	.pragma "nounroll";
	sub.s64 	%rd1478, %rd6145, %rd63;
	mov.b64 	%fd889, %rd1478;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1996}, %fd889;
	}
	setp.lt.s32 	%p149, %r1996, 0;
	selp.b64 	%rd6148, %rd6145, %rd1478, %p149;
	shl.b64 	%rd6145, %rd6148, 1;
	add.s32 	%r5940, %r5940, -1;
	add.s32 	%r5936, %r5936, -1;
	setp.ne.s32 	%p150, %r5936, 0;
	@%p150 bra 	$L__BB0_76;

$L__BB0_77:
	mov.u32 	%r1997, 1;
	sub.s32 	%r1998, %r1997, %r5934;
	add.s32 	%r1999, %r1998, %r90;
	setp.lt.u32 	%p151, %r1999, 3;
	@%p151 bra 	$L__BB0_82;

	not.b32 	%r2000, %r5940;
	max.s32 	%r2001, %r2000, -4;
	add.s32 	%r2002, %r5940, %r2001;
	add.s32 	%r97, %r2002, 4;
	shr.u32 	%r2003, %r97, 2;
	add.s32 	%r2004, %r2003, 1;
	and.b32  	%r5939, %r2004, 3;
	setp.eq.s32 	%p152, %r5939, 0;
	@%p152 bra 	$L__BB0_80;

$L__BB0_79:
	.pragma "nounroll";
	sub.s64 	%rd1480, %rd6145, %rd63;
	mov.b64 	%fd890, %rd1480;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2005}, %fd890;
	}
	setp.lt.s32 	%p153, %r2005, 0;
	selp.b64 	%rd1481, %rd6145, %rd1480, %p153;
	shl.b64 	%rd1482, %rd1481, 1;
	sub.s64 	%rd1483, %rd1482, %rd63;
	mov.b64 	%fd891, %rd1483;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2006}, %fd891;
	}
	setp.lt.s32 	%p154, %r2006, 0;
	selp.b64 	%rd1484, %rd1482, %rd1483, %p154;
	shl.b64 	%rd1485, %rd1484, 1;
	sub.s64 	%rd1486, %rd1485, %rd63;
	mov.b64 	%fd892, %rd1486;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2007}, %fd892;
	}
	setp.lt.s32 	%p155, %r2007, 0;
	selp.b64 	%rd1487, %rd1485, %rd1486, %p155;
	shl.b64 	%rd1488, %rd1487, 1;
	sub.s64 	%rd1489, %rd1488, %rd63;
	mov.b64 	%fd893, %rd1489;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2008}, %fd893;
	}
	setp.lt.s32 	%p156, %r2008, 0;
	selp.b64 	%rd6148, %rd1488, %rd1489, %p156;
	shl.b64 	%rd6145, %rd6148, 1;
	add.s32 	%r5940, %r5940, -4;
	add.s32 	%r5939, %r5939, -1;
	setp.ne.s32 	%p157, %r5939, 0;
	@%p157 bra 	$L__BB0_79;

$L__BB0_80:
	setp.lt.u32 	%p158, %r97, 12;
	@%p158 bra 	$L__BB0_82;

$L__BB0_81:
	sub.s64 	%rd1490, %rd6145, %rd63;
	mov.b64 	%fd894, %rd1490;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2009}, %fd894;
	}
	setp.lt.s32 	%p159, %r2009, 0;
	selp.b64 	%rd1491, %rd6145, %rd1490, %p159;
	shl.b64 	%rd1492, %rd1491, 1;
	sub.s64 	%rd1493, %rd1492, %rd63;
	mov.b64 	%fd895, %rd1493;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2010}, %fd895;
	}
	setp.lt.s32 	%p160, %r2010, 0;
	selp.b64 	%rd1494, %rd1492, %rd1493, %p160;
	shl.b64 	%rd1495, %rd1494, 1;
	sub.s64 	%rd1496, %rd1495, %rd63;
	mov.b64 	%fd896, %rd1496;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2011}, %fd896;
	}
	setp.lt.s32 	%p161, %r2011, 0;
	selp.b64 	%rd1497, %rd1495, %rd1496, %p161;
	shl.b64 	%rd1498, %rd1497, 1;
	sub.s64 	%rd1499, %rd1498, %rd63;
	mov.b64 	%fd897, %rd1499;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2012}, %fd897;
	}
	setp.lt.s32 	%p162, %r2012, 0;
	selp.b64 	%rd1500, %rd1498, %rd1499, %p162;
	shl.b64 	%rd1501, %rd1500, 1;
	sub.s64 	%rd1502, %rd1501, %rd63;
	mov.b64 	%fd898, %rd1502;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2013}, %fd898;
	}
	setp.lt.s32 	%p163, %r2013, 0;
	selp.b64 	%rd1503, %rd1501, %rd1502, %p163;
	shl.b64 	%rd1504, %rd1503, 1;
	sub.s64 	%rd1505, %rd1504, %rd63;
	mov.b64 	%fd899, %rd1505;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2014}, %fd899;
	}
	setp.lt.s32 	%p164, %r2014, 0;
	selp.b64 	%rd1506, %rd1504, %rd1505, %p164;
	shl.b64 	%rd1507, %rd1506, 1;
	sub.s64 	%rd1508, %rd1507, %rd63;
	mov.b64 	%fd900, %rd1508;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2015}, %fd900;
	}
	setp.lt.s32 	%p165, %r2015, 0;
	selp.b64 	%rd1509, %rd1507, %rd1508, %p165;
	shl.b64 	%rd1510, %rd1509, 1;
	sub.s64 	%rd1511, %rd1510, %rd63;
	mov.b64 	%fd901, %rd1511;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2016}, %fd901;
	}
	setp.lt.s32 	%p166, %r2016, 0;
	selp.b64 	%rd1512, %rd1510, %rd1511, %p166;
	shl.b64 	%rd1513, %rd1512, 1;
	sub.s64 	%rd1514, %rd1513, %rd63;
	mov.b64 	%fd902, %rd1514;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2017}, %fd902;
	}
	setp.lt.s32 	%p167, %r2017, 0;
	selp.b64 	%rd1515, %rd1513, %rd1514, %p167;
	shl.b64 	%rd1516, %rd1515, 1;
	sub.s64 	%rd1517, %rd1516, %rd63;
	mov.b64 	%fd903, %rd1517;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2018}, %fd903;
	}
	setp.lt.s32 	%p168, %r2018, 0;
	selp.b64 	%rd1518, %rd1516, %rd1517, %p168;
	shl.b64 	%rd1519, %rd1518, 1;
	sub.s64 	%rd1520, %rd1519, %rd63;
	mov.b64 	%fd904, %rd1520;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2019}, %fd904;
	}
	setp.lt.s32 	%p169, %r2019, 0;
	selp.b64 	%rd1521, %rd1519, %rd1520, %p169;
	shl.b64 	%rd1522, %rd1521, 1;
	sub.s64 	%rd1523, %rd1522, %rd63;
	mov.b64 	%fd905, %rd1523;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2020}, %fd905;
	}
	setp.lt.s32 	%p170, %r2020, 0;
	selp.b64 	%rd1524, %rd1522, %rd1523, %p170;
	shl.b64 	%rd1525, %rd1524, 1;
	sub.s64 	%rd1526, %rd1525, %rd63;
	mov.b64 	%fd906, %rd1526;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2021}, %fd906;
	}
	setp.lt.s32 	%p171, %r2021, 0;
	selp.b64 	%rd1527, %rd1525, %rd1526, %p171;
	shl.b64 	%rd1528, %rd1527, 1;
	sub.s64 	%rd1529, %rd1528, %rd63;
	mov.b64 	%fd907, %rd1529;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2022}, %fd907;
	}
	setp.lt.s32 	%p172, %r2022, 0;
	selp.b64 	%rd1530, %rd1528, %rd1529, %p172;
	shl.b64 	%rd1531, %rd1530, 1;
	sub.s64 	%rd1532, %rd1531, %rd63;
	mov.b64 	%fd908, %rd1532;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2023}, %fd908;
	}
	setp.lt.s32 	%p173, %r2023, 0;
	selp.b64 	%rd1533, %rd1531, %rd1532, %p173;
	shl.b64 	%rd1534, %rd1533, 1;
	sub.s64 	%rd1535, %rd1534, %rd63;
	mov.b64 	%fd909, %rd1535;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2024}, %fd909;
	}
	setp.lt.s32 	%p174, %r2024, 0;
	selp.b64 	%rd6148, %rd1534, %rd1535, %p174;
	shl.b64 	%rd6145, %rd6148, 1;
	add.s32 	%r105, %r5940, -16;
	setp.gt.s32 	%p175, %r5940, 15;
	mov.u32 	%r5940, %r105;
	@%p175 bra 	$L__BB0_81;

$L__BB0_82:
	and.b64  	%rd78, %rd6148, 9223372036854775807;
	setp.eq.s64 	%p176, %rd78, 0;
	mov.f64 	%fd2908, 0d0000000000000000;
	@%p176 bra 	$L__BB0_84;

	mov.b64 	%fd911, %rd78;
	mul.f64 	%fd912, %fd911, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2025}, %fd912;
	}
	shr.u32 	%r2026, %r2025, 20;
	mov.u32 	%r2027, 55;
	sub.s32 	%r2028, %r2027, %r2026;
	sub.s32 	%r2029, %r5934, %r2028;
	shl.b64 	%rd1536, %rd78, %r2028;
	setp.lt.s32 	%p177, %r2029, 1;
	mov.u32 	%r2030, 1;
	sub.s32 	%r2031, %r2030, %r2029;
	shr.u64 	%rd1537, %rd1536, %r2031;
	add.s32 	%r2032, %r2029, -1;
	cvt.u64.u32 	%rd1538, %r2032;
	shl.b64 	%rd1539, %rd1538, 52;
	add.s64 	%rd1540, %rd1539, %rd1536;
	selp.b64 	%rd1541, %rd1537, %rd1540, %p177;
	mov.b64 	%fd2908, %rd1541;

$L__BB0_84:
	and.b32  	%r2033, %r82, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2034}, %fd2908;
	}
	or.b32  	%r2035, %r2034, %r2033;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2036, %temp}, %fd2908;
	}
	mov.b64 	%fd2909, {%r2036, %r2035};
	bra.uni 	$L__BB0_88;

$L__BB0_86:
	mov.f64 	%fd913, 0d3FF0000000000000;
	add.rn.f64 	%fd2909, %fd40, %fd913;

$L__BB0_88:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 71 5
	ld.local.u8 	%rs220, [%rd4];
	cvt.rn.f64.u16 	%fd51, %rs220;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mov.f64 	%fd914, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd915, %fd914, %fd2909;
	mul.f64 	%fd916, %fd915, %fd51;
	fma.rn.f64 	%fd52, %fd916, 0d400921FB54442D18, 0d402921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd52;
	}
	and.b32  	%r2037, %r106, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2038, %temp}, %fd52;
	}
	mov.b64 	%fd2910, {%r2038, %r2037};
	setp.gt.u32 	%p182, %r2037, 2146435071;
	or.pred  	%p184, %p182, %p18;
	@%p184 bra 	$L__BB0_105;
	bra.uni 	$L__BB0_89;

$L__BB0_105:
	.loc	1 0 9
	setp.le.f64 	%p219, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p220, %fd2910, 0d7FF0000000000000;
	and.pred  	%p221, %p220, %p219;
	@%p221 bra 	$L__BB0_107;
	bra.uni 	$L__BB0_106;

$L__BB0_107:
	setp.eq.f64 	%p222, %fd2910, 0d7FF0000000000000;
	selp.f64 	%fd2913, 0dFFF8000000000000, %fd52, %p222;
	bra.uni 	$L__BB0_108;

$L__BB0_89:
	.loc	1 0 9
	setp.eq.f64 	%p185, %fd3160, 0d0000000000000000;
	mov.f64 	%fd2913, 0dFFF8000000000000;
	.loc	1 32 9
	@%p185 bra 	$L__BB0_108;

	setp.ltu.f64 	%p186, %fd2910, %fd3160;
	mov.f64 	%fd2913, %fd52;
	@%p186 bra 	$L__BB0_108;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2039}, %fd2910;
	}
	shr.u32 	%r5942, %r2039, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2040}, %fd3160;
	}
	shr.u32 	%r5943, %r2040, 20;
	setp.ne.s32 	%p187, %r5942, 0;
	@%p187 bra 	$L__BB0_93;

	mul.f64 	%fd2910, %fd2910, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2041}, %fd2910;
	}
	shr.u32 	%r2042, %r2041, 20;
	add.s32 	%r5942, %r2042, -54;

$L__BB0_93:
	setp.ne.s32 	%p188, %r5943, 0;
	mov.f64 	%fd2911, %fd3160;
	@%p188 bra 	$L__BB0_95;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2043}, %fd2;
	}
	shr.u32 	%r2044, %r2043, 20;
	add.s32 	%r5943, %r2044, -54;
	mov.f64 	%fd2911, %fd2;

$L__BB0_95:
	mov.b64 	%rd1543, %fd2910;
	and.b64  	%rd1544, %rd1543, 4503599627370495;
	or.b64  	%rd6153, %rd1544, 4503599627370496;
	mov.b64 	%rd1545, %fd2911;
	and.b64  	%rd1546, %rd1545, 4503599627370495;
	or.b64  	%rd80, %rd1546, 4503599627370496;
	sub.s32 	%r5949, %r5942, %r5943;
	not.b32 	%r2045, %r5942;
	add.s32 	%r2046, %r5943, %r2045;
	max.s32 	%r2047, %r2046, -1;
	add.s32 	%r114, %r2047, %r5942;
	mov.u32 	%r2048, 2;
	sub.s32 	%r2049, %r2048, %r5943;
	add.s32 	%r2050, %r2049, %r114;
	and.b32  	%r5945, %r2050, 3;
	setp.eq.s32 	%p189, %r5945, 0;
	@%p189 bra 	$L__BB0_97;

$L__BB0_96:
	.pragma "nounroll";
	sub.s64 	%rd1547, %rd6153, %rd80;
	mov.b64 	%fd918, %rd1547;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2051}, %fd918;
	}
	setp.lt.s32 	%p190, %r2051, 0;
	selp.b64 	%rd6156, %rd6153, %rd1547, %p190;
	shl.b64 	%rd6153, %rd6156, 1;
	add.s32 	%r5949, %r5949, -1;
	add.s32 	%r5945, %r5945, -1;
	setp.ne.s32 	%p191, %r5945, 0;
	@%p191 bra 	$L__BB0_96;

$L__BB0_97:
	mov.u32 	%r2052, 1;
	sub.s32 	%r2053, %r2052, %r5943;
	add.s32 	%r2054, %r2053, %r114;
	setp.lt.u32 	%p192, %r2054, 3;
	@%p192 bra 	$L__BB0_102;

	not.b32 	%r2055, %r5949;
	max.s32 	%r2056, %r2055, -4;
	add.s32 	%r2057, %r5949, %r2056;
	add.s32 	%r121, %r2057, 4;
	shr.u32 	%r2058, %r121, 2;
	add.s32 	%r2059, %r2058, 1;
	and.b32  	%r5948, %r2059, 3;
	setp.eq.s32 	%p193, %r5948, 0;
	@%p193 bra 	$L__BB0_100;

$L__BB0_99:
	.pragma "nounroll";
	sub.s64 	%rd1549, %rd6153, %rd80;
	mov.b64 	%fd919, %rd1549;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2060}, %fd919;
	}
	setp.lt.s32 	%p194, %r2060, 0;
	selp.b64 	%rd1550, %rd6153, %rd1549, %p194;
	shl.b64 	%rd1551, %rd1550, 1;
	sub.s64 	%rd1552, %rd1551, %rd80;
	mov.b64 	%fd920, %rd1552;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2061}, %fd920;
	}
	setp.lt.s32 	%p195, %r2061, 0;
	selp.b64 	%rd1553, %rd1551, %rd1552, %p195;
	shl.b64 	%rd1554, %rd1553, 1;
	sub.s64 	%rd1555, %rd1554, %rd80;
	mov.b64 	%fd921, %rd1555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2062}, %fd921;
	}
	setp.lt.s32 	%p196, %r2062, 0;
	selp.b64 	%rd1556, %rd1554, %rd1555, %p196;
	shl.b64 	%rd1557, %rd1556, 1;
	sub.s64 	%rd1558, %rd1557, %rd80;
	mov.b64 	%fd922, %rd1558;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2063}, %fd922;
	}
	setp.lt.s32 	%p197, %r2063, 0;
	selp.b64 	%rd6156, %rd1557, %rd1558, %p197;
	shl.b64 	%rd6153, %rd6156, 1;
	add.s32 	%r5949, %r5949, -4;
	add.s32 	%r5948, %r5948, -1;
	setp.ne.s32 	%p198, %r5948, 0;
	@%p198 bra 	$L__BB0_99;

$L__BB0_100:
	setp.lt.u32 	%p199, %r121, 12;
	@%p199 bra 	$L__BB0_102;

$L__BB0_101:
	sub.s64 	%rd1559, %rd6153, %rd80;
	mov.b64 	%fd923, %rd1559;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2064}, %fd923;
	}
	setp.lt.s32 	%p200, %r2064, 0;
	selp.b64 	%rd1560, %rd6153, %rd1559, %p200;
	shl.b64 	%rd1561, %rd1560, 1;
	sub.s64 	%rd1562, %rd1561, %rd80;
	mov.b64 	%fd924, %rd1562;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2065}, %fd924;
	}
	setp.lt.s32 	%p201, %r2065, 0;
	selp.b64 	%rd1563, %rd1561, %rd1562, %p201;
	shl.b64 	%rd1564, %rd1563, 1;
	sub.s64 	%rd1565, %rd1564, %rd80;
	mov.b64 	%fd925, %rd1565;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2066}, %fd925;
	}
	setp.lt.s32 	%p202, %r2066, 0;
	selp.b64 	%rd1566, %rd1564, %rd1565, %p202;
	shl.b64 	%rd1567, %rd1566, 1;
	sub.s64 	%rd1568, %rd1567, %rd80;
	mov.b64 	%fd926, %rd1568;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2067}, %fd926;
	}
	setp.lt.s32 	%p203, %r2067, 0;
	selp.b64 	%rd1569, %rd1567, %rd1568, %p203;
	shl.b64 	%rd1570, %rd1569, 1;
	sub.s64 	%rd1571, %rd1570, %rd80;
	mov.b64 	%fd927, %rd1571;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2068}, %fd927;
	}
	setp.lt.s32 	%p204, %r2068, 0;
	selp.b64 	%rd1572, %rd1570, %rd1571, %p204;
	shl.b64 	%rd1573, %rd1572, 1;
	sub.s64 	%rd1574, %rd1573, %rd80;
	mov.b64 	%fd928, %rd1574;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2069}, %fd928;
	}
	setp.lt.s32 	%p205, %r2069, 0;
	selp.b64 	%rd1575, %rd1573, %rd1574, %p205;
	shl.b64 	%rd1576, %rd1575, 1;
	sub.s64 	%rd1577, %rd1576, %rd80;
	mov.b64 	%fd929, %rd1577;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2070}, %fd929;
	}
	setp.lt.s32 	%p206, %r2070, 0;
	selp.b64 	%rd1578, %rd1576, %rd1577, %p206;
	shl.b64 	%rd1579, %rd1578, 1;
	sub.s64 	%rd1580, %rd1579, %rd80;
	mov.b64 	%fd930, %rd1580;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2071}, %fd930;
	}
	setp.lt.s32 	%p207, %r2071, 0;
	selp.b64 	%rd1581, %rd1579, %rd1580, %p207;
	shl.b64 	%rd1582, %rd1581, 1;
	sub.s64 	%rd1583, %rd1582, %rd80;
	mov.b64 	%fd931, %rd1583;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2072}, %fd931;
	}
	setp.lt.s32 	%p208, %r2072, 0;
	selp.b64 	%rd1584, %rd1582, %rd1583, %p208;
	shl.b64 	%rd1585, %rd1584, 1;
	sub.s64 	%rd1586, %rd1585, %rd80;
	mov.b64 	%fd932, %rd1586;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2073}, %fd932;
	}
	setp.lt.s32 	%p209, %r2073, 0;
	selp.b64 	%rd1587, %rd1585, %rd1586, %p209;
	shl.b64 	%rd1588, %rd1587, 1;
	sub.s64 	%rd1589, %rd1588, %rd80;
	mov.b64 	%fd933, %rd1589;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2074}, %fd933;
	}
	setp.lt.s32 	%p210, %r2074, 0;
	selp.b64 	%rd1590, %rd1588, %rd1589, %p210;
	shl.b64 	%rd1591, %rd1590, 1;
	sub.s64 	%rd1592, %rd1591, %rd80;
	mov.b64 	%fd934, %rd1592;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2075}, %fd934;
	}
	setp.lt.s32 	%p211, %r2075, 0;
	selp.b64 	%rd1593, %rd1591, %rd1592, %p211;
	shl.b64 	%rd1594, %rd1593, 1;
	sub.s64 	%rd1595, %rd1594, %rd80;
	mov.b64 	%fd935, %rd1595;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2076}, %fd935;
	}
	setp.lt.s32 	%p212, %r2076, 0;
	selp.b64 	%rd1596, %rd1594, %rd1595, %p212;
	shl.b64 	%rd1597, %rd1596, 1;
	sub.s64 	%rd1598, %rd1597, %rd80;
	mov.b64 	%fd936, %rd1598;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2077}, %fd936;
	}
	setp.lt.s32 	%p213, %r2077, 0;
	selp.b64 	%rd1599, %rd1597, %rd1598, %p213;
	shl.b64 	%rd1600, %rd1599, 1;
	sub.s64 	%rd1601, %rd1600, %rd80;
	mov.b64 	%fd937, %rd1601;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2078}, %fd937;
	}
	setp.lt.s32 	%p214, %r2078, 0;
	selp.b64 	%rd1602, %rd1600, %rd1601, %p214;
	shl.b64 	%rd1603, %rd1602, 1;
	sub.s64 	%rd1604, %rd1603, %rd80;
	mov.b64 	%fd938, %rd1604;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2079}, %fd938;
	}
	setp.lt.s32 	%p215, %r2079, 0;
	selp.b64 	%rd6156, %rd1603, %rd1604, %p215;
	shl.b64 	%rd6153, %rd6156, 1;
	add.s32 	%r129, %r5949, -16;
	setp.gt.s32 	%p216, %r5949, 15;
	mov.u32 	%r5949, %r129;
	@%p216 bra 	$L__BB0_101;

$L__BB0_102:
	and.b64  	%rd95, %rd6156, 9223372036854775807;
	setp.eq.s64 	%p217, %rd95, 0;
	mov.f64 	%fd2912, 0d0000000000000000;
	@%p217 bra 	$L__BB0_104;

	mov.b64 	%fd940, %rd95;
	mul.f64 	%fd941, %fd940, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2080}, %fd941;
	}
	shr.u32 	%r2081, %r2080, 20;
	mov.u32 	%r2082, 55;
	sub.s32 	%r2083, %r2082, %r2081;
	sub.s32 	%r2084, %r5943, %r2083;
	shl.b64 	%rd1605, %rd95, %r2083;
	setp.lt.s32 	%p218, %r2084, 1;
	mov.u32 	%r2085, 1;
	sub.s32 	%r2086, %r2085, %r2084;
	shr.u64 	%rd1606, %rd1605, %r2086;
	add.s32 	%r2087, %r2084, -1;
	cvt.u64.u32 	%rd1607, %r2087;
	shl.b64 	%rd1608, %rd1607, 52;
	add.s64 	%rd1609, %rd1608, %rd1605;
	selp.b64 	%rd1610, %rd1606, %rd1609, %p218;
	mov.b64 	%fd2912, %rd1610;

$L__BB0_104:
	and.b32  	%r2088, %r106, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2089}, %fd2912;
	}
	or.b32  	%r2090, %r2089, %r2088;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2091, %temp}, %fd2912;
	}
	mov.b64 	%fd2913, {%r2091, %r2090};
	bra.uni 	$L__BB0_108;

$L__BB0_106:
	mov.f64 	%fd942, 0d3FF0000000000000;
	add.rn.f64 	%fd2913, %fd52, %fd942;

$L__BB0_108:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 71 5
	ld.local.u8 	%rs219, [%rd3];
	cvt.rn.f64.u16 	%fd63, %rs219;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mov.f64 	%fd943, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd944, %fd943, %fd2913;
	mul.f64 	%fd945, %fd944, %fd63;
	fma.rn.f64 	%fd64, %fd945, 0d400921FB54442D18, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r130}, %fd64;
	}
	and.b32  	%r2092, %r130, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2093, %temp}, %fd64;
	}
	mov.b64 	%fd2914, {%r2093, %r2092};
	setp.gt.u32 	%p223, %r2092, 2146435071;
	or.pred  	%p225, %p223, %p18;
	@%p225 bra 	$L__BB0_125;
	bra.uni 	$L__BB0_109;

$L__BB0_125:
	.loc	1 0 9
	setp.le.f64 	%p260, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p261, %fd2914, 0d7FF0000000000000;
	and.pred  	%p262, %p261, %p260;
	@%p262 bra 	$L__BB0_127;
	bra.uni 	$L__BB0_126;

$L__BB0_127:
	setp.eq.f64 	%p263, %fd2914, 0d7FF0000000000000;
	selp.f64 	%fd2917, 0dFFF8000000000000, %fd64, %p263;
	bra.uni 	$L__BB0_128;

$L__BB0_109:
	.loc	1 0 9
	setp.eq.f64 	%p226, %fd3160, 0d0000000000000000;
	mov.f64 	%fd2917, 0dFFF8000000000000;
	.loc	1 32 9
	@%p226 bra 	$L__BB0_128;

	setp.ltu.f64 	%p227, %fd2914, %fd3160;
	mov.f64 	%fd2917, %fd64;
	@%p227 bra 	$L__BB0_128;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2094}, %fd2914;
	}
	shr.u32 	%r5951, %r2094, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2095}, %fd3160;
	}
	shr.u32 	%r5952, %r2095, 20;
	setp.ne.s32 	%p228, %r5951, 0;
	@%p228 bra 	$L__BB0_113;

	mul.f64 	%fd2914, %fd2914, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2096}, %fd2914;
	}
	shr.u32 	%r2097, %r2096, 20;
	add.s32 	%r5951, %r2097, -54;

$L__BB0_113:
	setp.ne.s32 	%p229, %r5952, 0;
	mov.f64 	%fd2915, %fd3160;
	@%p229 bra 	$L__BB0_115;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2098}, %fd2;
	}
	shr.u32 	%r2099, %r2098, 20;
	add.s32 	%r5952, %r2099, -54;
	mov.f64 	%fd2915, %fd2;

$L__BB0_115:
	mov.b64 	%rd1612, %fd2914;
	and.b64  	%rd1613, %rd1612, 4503599627370495;
	or.b64  	%rd6161, %rd1613, 4503599627370496;
	mov.b64 	%rd1614, %fd2915;
	and.b64  	%rd1615, %rd1614, 4503599627370495;
	or.b64  	%rd97, %rd1615, 4503599627370496;
	sub.s32 	%r5958, %r5951, %r5952;
	not.b32 	%r2100, %r5951;
	add.s32 	%r2101, %r5952, %r2100;
	max.s32 	%r2102, %r2101, -1;
	add.s32 	%r138, %r2102, %r5951;
	mov.u32 	%r2103, 2;
	sub.s32 	%r2104, %r2103, %r5952;
	add.s32 	%r2105, %r2104, %r138;
	and.b32  	%r5954, %r2105, 3;
	setp.eq.s32 	%p230, %r5954, 0;
	@%p230 bra 	$L__BB0_117;

$L__BB0_116:
	.pragma "nounroll";
	sub.s64 	%rd1616, %rd6161, %rd97;
	mov.b64 	%fd947, %rd1616;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2106}, %fd947;
	}
	setp.lt.s32 	%p231, %r2106, 0;
	selp.b64 	%rd6164, %rd6161, %rd1616, %p231;
	shl.b64 	%rd6161, %rd6164, 1;
	add.s32 	%r5958, %r5958, -1;
	add.s32 	%r5954, %r5954, -1;
	setp.ne.s32 	%p232, %r5954, 0;
	@%p232 bra 	$L__BB0_116;

$L__BB0_117:
	mov.u32 	%r2107, 1;
	sub.s32 	%r2108, %r2107, %r5952;
	add.s32 	%r2109, %r2108, %r138;
	setp.lt.u32 	%p233, %r2109, 3;
	@%p233 bra 	$L__BB0_122;

	not.b32 	%r2110, %r5958;
	max.s32 	%r2111, %r2110, -4;
	add.s32 	%r2112, %r5958, %r2111;
	add.s32 	%r145, %r2112, 4;
	shr.u32 	%r2113, %r145, 2;
	add.s32 	%r2114, %r2113, 1;
	and.b32  	%r5957, %r2114, 3;
	setp.eq.s32 	%p234, %r5957, 0;
	@%p234 bra 	$L__BB0_120;

$L__BB0_119:
	.pragma "nounroll";
	sub.s64 	%rd1618, %rd6161, %rd97;
	mov.b64 	%fd948, %rd1618;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2115}, %fd948;
	}
	setp.lt.s32 	%p235, %r2115, 0;
	selp.b64 	%rd1619, %rd6161, %rd1618, %p235;
	shl.b64 	%rd1620, %rd1619, 1;
	sub.s64 	%rd1621, %rd1620, %rd97;
	mov.b64 	%fd949, %rd1621;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2116}, %fd949;
	}
	setp.lt.s32 	%p236, %r2116, 0;
	selp.b64 	%rd1622, %rd1620, %rd1621, %p236;
	shl.b64 	%rd1623, %rd1622, 1;
	sub.s64 	%rd1624, %rd1623, %rd97;
	mov.b64 	%fd950, %rd1624;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2117}, %fd950;
	}
	setp.lt.s32 	%p237, %r2117, 0;
	selp.b64 	%rd1625, %rd1623, %rd1624, %p237;
	shl.b64 	%rd1626, %rd1625, 1;
	sub.s64 	%rd1627, %rd1626, %rd97;
	mov.b64 	%fd951, %rd1627;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2118}, %fd951;
	}
	setp.lt.s32 	%p238, %r2118, 0;
	selp.b64 	%rd6164, %rd1626, %rd1627, %p238;
	shl.b64 	%rd6161, %rd6164, 1;
	add.s32 	%r5958, %r5958, -4;
	add.s32 	%r5957, %r5957, -1;
	setp.ne.s32 	%p239, %r5957, 0;
	@%p239 bra 	$L__BB0_119;

$L__BB0_120:
	setp.lt.u32 	%p240, %r145, 12;
	@%p240 bra 	$L__BB0_122;

$L__BB0_121:
	sub.s64 	%rd1628, %rd6161, %rd97;
	mov.b64 	%fd952, %rd1628;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2119}, %fd952;
	}
	setp.lt.s32 	%p241, %r2119, 0;
	selp.b64 	%rd1629, %rd6161, %rd1628, %p241;
	shl.b64 	%rd1630, %rd1629, 1;
	sub.s64 	%rd1631, %rd1630, %rd97;
	mov.b64 	%fd953, %rd1631;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2120}, %fd953;
	}
	setp.lt.s32 	%p242, %r2120, 0;
	selp.b64 	%rd1632, %rd1630, %rd1631, %p242;
	shl.b64 	%rd1633, %rd1632, 1;
	sub.s64 	%rd1634, %rd1633, %rd97;
	mov.b64 	%fd954, %rd1634;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2121}, %fd954;
	}
	setp.lt.s32 	%p243, %r2121, 0;
	selp.b64 	%rd1635, %rd1633, %rd1634, %p243;
	shl.b64 	%rd1636, %rd1635, 1;
	sub.s64 	%rd1637, %rd1636, %rd97;
	mov.b64 	%fd955, %rd1637;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2122}, %fd955;
	}
	setp.lt.s32 	%p244, %r2122, 0;
	selp.b64 	%rd1638, %rd1636, %rd1637, %p244;
	shl.b64 	%rd1639, %rd1638, 1;
	sub.s64 	%rd1640, %rd1639, %rd97;
	mov.b64 	%fd956, %rd1640;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2123}, %fd956;
	}
	setp.lt.s32 	%p245, %r2123, 0;
	selp.b64 	%rd1641, %rd1639, %rd1640, %p245;
	shl.b64 	%rd1642, %rd1641, 1;
	sub.s64 	%rd1643, %rd1642, %rd97;
	mov.b64 	%fd957, %rd1643;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2124}, %fd957;
	}
	setp.lt.s32 	%p246, %r2124, 0;
	selp.b64 	%rd1644, %rd1642, %rd1643, %p246;
	shl.b64 	%rd1645, %rd1644, 1;
	sub.s64 	%rd1646, %rd1645, %rd97;
	mov.b64 	%fd958, %rd1646;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2125}, %fd958;
	}
	setp.lt.s32 	%p247, %r2125, 0;
	selp.b64 	%rd1647, %rd1645, %rd1646, %p247;
	shl.b64 	%rd1648, %rd1647, 1;
	sub.s64 	%rd1649, %rd1648, %rd97;
	mov.b64 	%fd959, %rd1649;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2126}, %fd959;
	}
	setp.lt.s32 	%p248, %r2126, 0;
	selp.b64 	%rd1650, %rd1648, %rd1649, %p248;
	shl.b64 	%rd1651, %rd1650, 1;
	sub.s64 	%rd1652, %rd1651, %rd97;
	mov.b64 	%fd960, %rd1652;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2127}, %fd960;
	}
	setp.lt.s32 	%p249, %r2127, 0;
	selp.b64 	%rd1653, %rd1651, %rd1652, %p249;
	shl.b64 	%rd1654, %rd1653, 1;
	sub.s64 	%rd1655, %rd1654, %rd97;
	mov.b64 	%fd961, %rd1655;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2128}, %fd961;
	}
	setp.lt.s32 	%p250, %r2128, 0;
	selp.b64 	%rd1656, %rd1654, %rd1655, %p250;
	shl.b64 	%rd1657, %rd1656, 1;
	sub.s64 	%rd1658, %rd1657, %rd97;
	mov.b64 	%fd962, %rd1658;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2129}, %fd962;
	}
	setp.lt.s32 	%p251, %r2129, 0;
	selp.b64 	%rd1659, %rd1657, %rd1658, %p251;
	shl.b64 	%rd1660, %rd1659, 1;
	sub.s64 	%rd1661, %rd1660, %rd97;
	mov.b64 	%fd963, %rd1661;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2130}, %fd963;
	}
	setp.lt.s32 	%p252, %r2130, 0;
	selp.b64 	%rd1662, %rd1660, %rd1661, %p252;
	shl.b64 	%rd1663, %rd1662, 1;
	sub.s64 	%rd1664, %rd1663, %rd97;
	mov.b64 	%fd964, %rd1664;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2131}, %fd964;
	}
	setp.lt.s32 	%p253, %r2131, 0;
	selp.b64 	%rd1665, %rd1663, %rd1664, %p253;
	shl.b64 	%rd1666, %rd1665, 1;
	sub.s64 	%rd1667, %rd1666, %rd97;
	mov.b64 	%fd965, %rd1667;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2132}, %fd965;
	}
	setp.lt.s32 	%p254, %r2132, 0;
	selp.b64 	%rd1668, %rd1666, %rd1667, %p254;
	shl.b64 	%rd1669, %rd1668, 1;
	sub.s64 	%rd1670, %rd1669, %rd97;
	mov.b64 	%fd966, %rd1670;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2133}, %fd966;
	}
	setp.lt.s32 	%p255, %r2133, 0;
	selp.b64 	%rd1671, %rd1669, %rd1670, %p255;
	shl.b64 	%rd1672, %rd1671, 1;
	sub.s64 	%rd1673, %rd1672, %rd97;
	mov.b64 	%fd967, %rd1673;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2134}, %fd967;
	}
	setp.lt.s32 	%p256, %r2134, 0;
	selp.b64 	%rd6164, %rd1672, %rd1673, %p256;
	shl.b64 	%rd6161, %rd6164, 1;
	add.s32 	%r153, %r5958, -16;
	setp.gt.s32 	%p257, %r5958, 15;
	mov.u32 	%r5958, %r153;
	@%p257 bra 	$L__BB0_121;

$L__BB0_122:
	and.b64  	%rd112, %rd6164, 9223372036854775807;
	setp.eq.s64 	%p258, %rd112, 0;
	mov.f64 	%fd2916, 0d0000000000000000;
	@%p258 bra 	$L__BB0_124;

	mov.b64 	%fd969, %rd112;
	mul.f64 	%fd970, %fd969, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2135}, %fd970;
	}
	shr.u32 	%r2136, %r2135, 20;
	mov.u32 	%r2137, 55;
	sub.s32 	%r2138, %r2137, %r2136;
	sub.s32 	%r2139, %r5952, %r2138;
	shl.b64 	%rd1674, %rd112, %r2138;
	setp.lt.s32 	%p259, %r2139, 1;
	mov.u32 	%r2140, 1;
	sub.s32 	%r2141, %r2140, %r2139;
	shr.u64 	%rd1675, %rd1674, %r2141;
	add.s32 	%r2142, %r2139, -1;
	cvt.u64.u32 	%rd1676, %r2142;
	shl.b64 	%rd1677, %rd1676, 52;
	add.s64 	%rd1678, %rd1677, %rd1674;
	selp.b64 	%rd1679, %rd1675, %rd1678, %p259;
	mov.b64 	%fd2916, %rd1679;

$L__BB0_124:
	and.b32  	%r2143, %r130, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2144}, %fd2916;
	}
	or.b32  	%r2145, %r2144, %r2143;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2146, %temp}, %fd2916;
	}
	mov.b64 	%fd2917, {%r2146, %r2145};
	bra.uni 	$L__BB0_128;

$L__BB0_126:
	mov.f64 	%fd971, 0d3FF0000000000000;
	add.rn.f64 	%fd2917, %fd64, %fd971;

$L__BB0_128:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 71 5
	ld.local.u8 	%rs218, [%rd2];
	cvt.rn.f64.u16 	%fd75, %rs218;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mov.f64 	%fd972, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd973, %fd972, %fd2917;
	mul.f64 	%fd974, %fd973, %fd75;
	fma.rn.f64 	%fd76, %fd974, 0d400921FB54442D18, 0d401921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r154}, %fd76;
	}
	and.b32  	%r2147, %r154, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2148, %temp}, %fd76;
	}
	mov.b64 	%fd2918, {%r2148, %r2147};
	setp.gt.u32 	%p264, %r2147, 2146435071;
	or.pred  	%p266, %p264, %p18;
	@%p266 bra 	$L__BB0_145;
	bra.uni 	$L__BB0_129;

$L__BB0_145:
	.loc	1 0 9
	setp.le.f64 	%p301, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p302, %fd2918, 0d7FF0000000000000;
	and.pred  	%p303, %p302, %p301;
	@%p303 bra 	$L__BB0_147;
	bra.uni 	$L__BB0_146;

$L__BB0_147:
	setp.eq.f64 	%p304, %fd2918, 0d7FF0000000000000;
	selp.f64 	%fd2921, 0dFFF8000000000000, %fd76, %p304;
	bra.uni 	$L__BB0_148;

$L__BB0_129:
	.loc	1 0 9
	setp.eq.f64 	%p267, %fd3160, 0d0000000000000000;
	mov.f64 	%fd2921, 0dFFF8000000000000;
	.loc	1 32 9
	@%p267 bra 	$L__BB0_148;

	setp.ltu.f64 	%p268, %fd2918, %fd3160;
	mov.f64 	%fd2921, %fd76;
	@%p268 bra 	$L__BB0_148;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2149}, %fd2918;
	}
	shr.u32 	%r5960, %r2149, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2150}, %fd3160;
	}
	shr.u32 	%r5961, %r2150, 20;
	setp.ne.s32 	%p269, %r5960, 0;
	@%p269 bra 	$L__BB0_133;

	mul.f64 	%fd2918, %fd2918, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2151}, %fd2918;
	}
	shr.u32 	%r2152, %r2151, 20;
	add.s32 	%r5960, %r2152, -54;

$L__BB0_133:
	setp.ne.s32 	%p270, %r5961, 0;
	mov.f64 	%fd2919, %fd3160;
	@%p270 bra 	$L__BB0_135;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2153}, %fd2;
	}
	shr.u32 	%r2154, %r2153, 20;
	add.s32 	%r5961, %r2154, -54;
	mov.f64 	%fd2919, %fd2;

$L__BB0_135:
	mov.b64 	%rd1681, %fd2918;
	and.b64  	%rd1682, %rd1681, 4503599627370495;
	or.b64  	%rd6169, %rd1682, 4503599627370496;
	mov.b64 	%rd1683, %fd2919;
	and.b64  	%rd1684, %rd1683, 4503599627370495;
	or.b64  	%rd114, %rd1684, 4503599627370496;
	sub.s32 	%r5967, %r5960, %r5961;
	not.b32 	%r2155, %r5960;
	add.s32 	%r2156, %r5961, %r2155;
	max.s32 	%r2157, %r2156, -1;
	add.s32 	%r162, %r2157, %r5960;
	mov.u32 	%r2158, 2;
	sub.s32 	%r2159, %r2158, %r5961;
	add.s32 	%r2160, %r2159, %r162;
	and.b32  	%r5963, %r2160, 3;
	setp.eq.s32 	%p271, %r5963, 0;
	@%p271 bra 	$L__BB0_137;

$L__BB0_136:
	.pragma "nounroll";
	sub.s64 	%rd1685, %rd6169, %rd114;
	mov.b64 	%fd976, %rd1685;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2161}, %fd976;
	}
	setp.lt.s32 	%p272, %r2161, 0;
	selp.b64 	%rd6172, %rd6169, %rd1685, %p272;
	shl.b64 	%rd6169, %rd6172, 1;
	add.s32 	%r5967, %r5967, -1;
	add.s32 	%r5963, %r5963, -1;
	setp.ne.s32 	%p273, %r5963, 0;
	@%p273 bra 	$L__BB0_136;

$L__BB0_137:
	mov.u32 	%r2162, 1;
	sub.s32 	%r2163, %r2162, %r5961;
	add.s32 	%r2164, %r2163, %r162;
	setp.lt.u32 	%p274, %r2164, 3;
	@%p274 bra 	$L__BB0_142;

	not.b32 	%r2165, %r5967;
	max.s32 	%r2166, %r2165, -4;
	add.s32 	%r2167, %r5967, %r2166;
	add.s32 	%r169, %r2167, 4;
	shr.u32 	%r2168, %r169, 2;
	add.s32 	%r2169, %r2168, 1;
	and.b32  	%r5966, %r2169, 3;
	setp.eq.s32 	%p275, %r5966, 0;
	@%p275 bra 	$L__BB0_140;

$L__BB0_139:
	.pragma "nounroll";
	sub.s64 	%rd1687, %rd6169, %rd114;
	mov.b64 	%fd977, %rd1687;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2170}, %fd977;
	}
	setp.lt.s32 	%p276, %r2170, 0;
	selp.b64 	%rd1688, %rd6169, %rd1687, %p276;
	shl.b64 	%rd1689, %rd1688, 1;
	sub.s64 	%rd1690, %rd1689, %rd114;
	mov.b64 	%fd978, %rd1690;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2171}, %fd978;
	}
	setp.lt.s32 	%p277, %r2171, 0;
	selp.b64 	%rd1691, %rd1689, %rd1690, %p277;
	shl.b64 	%rd1692, %rd1691, 1;
	sub.s64 	%rd1693, %rd1692, %rd114;
	mov.b64 	%fd979, %rd1693;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2172}, %fd979;
	}
	setp.lt.s32 	%p278, %r2172, 0;
	selp.b64 	%rd1694, %rd1692, %rd1693, %p278;
	shl.b64 	%rd1695, %rd1694, 1;
	sub.s64 	%rd1696, %rd1695, %rd114;
	mov.b64 	%fd980, %rd1696;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2173}, %fd980;
	}
	setp.lt.s32 	%p279, %r2173, 0;
	selp.b64 	%rd6172, %rd1695, %rd1696, %p279;
	shl.b64 	%rd6169, %rd6172, 1;
	add.s32 	%r5967, %r5967, -4;
	add.s32 	%r5966, %r5966, -1;
	setp.ne.s32 	%p280, %r5966, 0;
	@%p280 bra 	$L__BB0_139;

$L__BB0_140:
	setp.lt.u32 	%p281, %r169, 12;
	@%p281 bra 	$L__BB0_142;

$L__BB0_141:
	sub.s64 	%rd1697, %rd6169, %rd114;
	mov.b64 	%fd981, %rd1697;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2174}, %fd981;
	}
	setp.lt.s32 	%p282, %r2174, 0;
	selp.b64 	%rd1698, %rd6169, %rd1697, %p282;
	shl.b64 	%rd1699, %rd1698, 1;
	sub.s64 	%rd1700, %rd1699, %rd114;
	mov.b64 	%fd982, %rd1700;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2175}, %fd982;
	}
	setp.lt.s32 	%p283, %r2175, 0;
	selp.b64 	%rd1701, %rd1699, %rd1700, %p283;
	shl.b64 	%rd1702, %rd1701, 1;
	sub.s64 	%rd1703, %rd1702, %rd114;
	mov.b64 	%fd983, %rd1703;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2176}, %fd983;
	}
	setp.lt.s32 	%p284, %r2176, 0;
	selp.b64 	%rd1704, %rd1702, %rd1703, %p284;
	shl.b64 	%rd1705, %rd1704, 1;
	sub.s64 	%rd1706, %rd1705, %rd114;
	mov.b64 	%fd984, %rd1706;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2177}, %fd984;
	}
	setp.lt.s32 	%p285, %r2177, 0;
	selp.b64 	%rd1707, %rd1705, %rd1706, %p285;
	shl.b64 	%rd1708, %rd1707, 1;
	sub.s64 	%rd1709, %rd1708, %rd114;
	mov.b64 	%fd985, %rd1709;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2178}, %fd985;
	}
	setp.lt.s32 	%p286, %r2178, 0;
	selp.b64 	%rd1710, %rd1708, %rd1709, %p286;
	shl.b64 	%rd1711, %rd1710, 1;
	sub.s64 	%rd1712, %rd1711, %rd114;
	mov.b64 	%fd986, %rd1712;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2179}, %fd986;
	}
	setp.lt.s32 	%p287, %r2179, 0;
	selp.b64 	%rd1713, %rd1711, %rd1712, %p287;
	shl.b64 	%rd1714, %rd1713, 1;
	sub.s64 	%rd1715, %rd1714, %rd114;
	mov.b64 	%fd987, %rd1715;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2180}, %fd987;
	}
	setp.lt.s32 	%p288, %r2180, 0;
	selp.b64 	%rd1716, %rd1714, %rd1715, %p288;
	shl.b64 	%rd1717, %rd1716, 1;
	sub.s64 	%rd1718, %rd1717, %rd114;
	mov.b64 	%fd988, %rd1718;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2181}, %fd988;
	}
	setp.lt.s32 	%p289, %r2181, 0;
	selp.b64 	%rd1719, %rd1717, %rd1718, %p289;
	shl.b64 	%rd1720, %rd1719, 1;
	sub.s64 	%rd1721, %rd1720, %rd114;
	mov.b64 	%fd989, %rd1721;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2182}, %fd989;
	}
	setp.lt.s32 	%p290, %r2182, 0;
	selp.b64 	%rd1722, %rd1720, %rd1721, %p290;
	shl.b64 	%rd1723, %rd1722, 1;
	sub.s64 	%rd1724, %rd1723, %rd114;
	mov.b64 	%fd990, %rd1724;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2183}, %fd990;
	}
	setp.lt.s32 	%p291, %r2183, 0;
	selp.b64 	%rd1725, %rd1723, %rd1724, %p291;
	shl.b64 	%rd1726, %rd1725, 1;
	sub.s64 	%rd1727, %rd1726, %rd114;
	mov.b64 	%fd991, %rd1727;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2184}, %fd991;
	}
	setp.lt.s32 	%p292, %r2184, 0;
	selp.b64 	%rd1728, %rd1726, %rd1727, %p292;
	shl.b64 	%rd1729, %rd1728, 1;
	sub.s64 	%rd1730, %rd1729, %rd114;
	mov.b64 	%fd992, %rd1730;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2185}, %fd992;
	}
	setp.lt.s32 	%p293, %r2185, 0;
	selp.b64 	%rd1731, %rd1729, %rd1730, %p293;
	shl.b64 	%rd1732, %rd1731, 1;
	sub.s64 	%rd1733, %rd1732, %rd114;
	mov.b64 	%fd993, %rd1733;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2186}, %fd993;
	}
	setp.lt.s32 	%p294, %r2186, 0;
	selp.b64 	%rd1734, %rd1732, %rd1733, %p294;
	shl.b64 	%rd1735, %rd1734, 1;
	sub.s64 	%rd1736, %rd1735, %rd114;
	mov.b64 	%fd994, %rd1736;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2187}, %fd994;
	}
	setp.lt.s32 	%p295, %r2187, 0;
	selp.b64 	%rd1737, %rd1735, %rd1736, %p295;
	shl.b64 	%rd1738, %rd1737, 1;
	sub.s64 	%rd1739, %rd1738, %rd114;
	mov.b64 	%fd995, %rd1739;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2188}, %fd995;
	}
	setp.lt.s32 	%p296, %r2188, 0;
	selp.b64 	%rd1740, %rd1738, %rd1739, %p296;
	shl.b64 	%rd1741, %rd1740, 1;
	sub.s64 	%rd1742, %rd1741, %rd114;
	mov.b64 	%fd996, %rd1742;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2189}, %fd996;
	}
	setp.lt.s32 	%p297, %r2189, 0;
	selp.b64 	%rd6172, %rd1741, %rd1742, %p297;
	shl.b64 	%rd6169, %rd6172, 1;
	add.s32 	%r177, %r5967, -16;
	setp.gt.s32 	%p298, %r5967, 15;
	mov.u32 	%r5967, %r177;
	@%p298 bra 	$L__BB0_141;

$L__BB0_142:
	and.b64  	%rd129, %rd6172, 9223372036854775807;
	setp.eq.s64 	%p299, %rd129, 0;
	mov.f64 	%fd2920, 0d0000000000000000;
	@%p299 bra 	$L__BB0_144;

	mov.b64 	%fd998, %rd129;
	mul.f64 	%fd999, %fd998, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2190}, %fd999;
	}
	shr.u32 	%r2191, %r2190, 20;
	mov.u32 	%r2192, 55;
	sub.s32 	%r2193, %r2192, %r2191;
	sub.s32 	%r2194, %r5961, %r2193;
	shl.b64 	%rd1743, %rd129, %r2193;
	setp.lt.s32 	%p300, %r2194, 1;
	mov.u32 	%r2195, 1;
	sub.s32 	%r2196, %r2195, %r2194;
	shr.u64 	%rd1744, %rd1743, %r2196;
	add.s32 	%r2197, %r2194, -1;
	cvt.u64.u32 	%rd1745, %r2197;
	shl.b64 	%rd1746, %rd1745, 52;
	add.s64 	%rd1747, %rd1746, %rd1743;
	selp.b64 	%rd1748, %rd1744, %rd1747, %p300;
	mov.b64 	%fd2920, %rd1748;

$L__BB0_144:
	and.b32  	%r2198, %r154, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2199}, %fd2920;
	}
	or.b32  	%r2200, %r2199, %r2198;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2201, %temp}, %fd2920;
	}
	mov.b64 	%fd2921, {%r2201, %r2200};
	bra.uni 	$L__BB0_148;

$L__BB0_146:
	mov.f64 	%fd1000, 0d3FF0000000000000;
	add.rn.f64 	%fd2921, %fd76, %fd1000;

$L__BB0_148:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 71 5
	ld.local.u8 	%rs217, [%rd1];
	cvt.rn.f64.u16 	%fd87, %rs217;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mov.f64 	%fd1001, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1002, %fd1001, %fd2921;
	mul.f64 	%fd1003, %fd1002, %fd87;
	fma.rn.f64 	%fd1004, %fd1003, 0d400921FB54442D18, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2202}, %fd1004;
	}
	and.b32  	%r2203, %r2202, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2204, %temp}, %fd1004;
	}
	mov.b64 	%fd88, {%r2204, %r2203};
	setp.gt.u32 	%p305, %r2203, 2146435071;
	or.pred  	%p307, %p305, %p18;
	setp.ltu.f64 	%p308, %fd88, %fd3160;
	setp.eq.f64 	%p309, %fd3160, 0d0000000000000000;
	or.pred  	%p310, %p309, %p308;
	or.pred  	%p311, %p307, %p310;
	@%p311 bra 	$L__BB0_158;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2205}, %fd88;
	}
	shr.u32 	%r5969, %r2205, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2206}, %fd3160;
	}
	shr.u32 	%r5970, %r2206, 20;
	setp.ne.s32 	%p312, %r5969, 0;
	@%p312 bra 	$L__BB0_151;

	mul.f64 	%fd1005, %fd88, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2207}, %fd1005;
	}
	shr.u32 	%r2208, %r2207, 20;
	add.s32 	%r5969, %r2208, -54;

$L__BB0_151:
	setp.ne.s32 	%p313, %r5970, 0;
	@%p313 bra 	$L__BB0_153;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2209}, %fd2;
	}
	shr.u32 	%r2210, %r2209, 20;
	add.s32 	%r5970, %r2210, -54;

$L__BB0_153:
	sub.s32 	%r5973, %r5969, %r5970;
	not.b32 	%r2211, %r5969;
	add.s32 	%r2212, %r5970, %r2211;
	max.s32 	%r2213, %r2212, -1;
	add.s32 	%r2214, %r2213, %r5969;
	mov.u32 	%r2215, 2;
	sub.s32 	%r2216, %r2215, %r5970;
	add.s32 	%r2217, %r2216, %r2214;
	mov.u32 	%r2218, 1;
	sub.s32 	%r2219, %r2218, %r5970;
	add.s32 	%r185, %r2219, %r2214;
	and.b32  	%r5972, %r2217, 3;
	setp.eq.s32 	%p314, %r5972, 0;
	@%p314 bra 	$L__BB0_155;

$L__BB0_154:
	.pragma "nounroll";
	add.s32 	%r5973, %r5973, -1;
	add.s32 	%r5972, %r5972, -1;
	setp.ne.s32 	%p315, %r5972, 0;
	@%p315 bra 	$L__BB0_154;

$L__BB0_155:
	setp.lt.u32 	%p316, %r185, 3;
	@%p316 bra 	$L__BB0_158;

	not.b32 	%r2220, %r5973;
	max.s32 	%r2221, %r2220, -4;
	add.s32 	%r2222, %r5973, %r2221;
	add.s32 	%r2223, %r2222, 4;
	shr.u32 	%r2224, %r2223, 2;
	add.s32 	%r2225, %r2224, 1;
	and.b32  	%r5974, %r2225, 3;
	setp.eq.s32 	%p317, %r5974, 0;
	@%p317 bra 	$L__BB0_158;

$L__BB0_157:
	.pragma "nounroll";
	add.s32 	%r5974, %r5974, -1;
	setp.ne.s32 	%p318, %r5974, 0;
	@%p318 bra 	$L__BB0_157;

$L__BB0_158:
	.loc	1 80 9, function_name $L__info_string3, inlined_at 1 249 17
	ld.global.u8 	%r2226, [%rd1206];
	ld.global.u8 	%r2227, [%rd1206+1];
	prmt.b32 	%r2228, %r2227, %r2226, 30212;
	ld.global.u8 	%r2229, [%rd1206+2];
	ld.global.u8 	%r2230, [%rd1206+3];
	prmt.b32 	%r2231, %r2230, %r2229, 30212;
	prmt.b32 	%r195, %r2231, %r2228, 4180;
	.loc	1 81 9, function_name $L__info_string3, inlined_at 1 249 17
	ld.global.u8 	%r2232, [%rd1206+4];
	ld.global.u8 	%r2233, [%rd1206+5];
	prmt.b32 	%r2234, %r2233, %r2232, 30212;
	ld.global.u8 	%r2235, [%rd1206+6];
	ld.global.u8 	%r2236, [%rd1206+7];
	prmt.b32 	%r2237, %r2236, %r2235, 30212;
	prmt.b32 	%r6047, %r2237, %r2234, 4180;
	.loc	1 79 28, function_name $L__info_string3, inlined_at 1 249 17
	.loc	1 53 5, function_name $L__info_string6, inlined_at 1 79 28
	add.s32 	%r2238, %r6047, 8;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 79 28
	cvt.rn.f64.s32 	%fd1006, %r2238;
	fma.rn.f64 	%fd89, %fd1006, 0d400921FB54442D18, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r197}, %fd89;
	}
	and.b32  	%r2239, %r197, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2240, %temp}, %fd89;
	}
	mov.b64 	%fd2922, {%r2240, %r2239};
	setp.gt.u32 	%p320, %r2239, 2146435071;
	or.pred  	%p321, %p320, %p18;
	@%p321 bra 	$L__BB0_175;
	bra.uni 	$L__BB0_159;

$L__BB0_175:
	.loc	1 0 9
	setp.le.f64 	%p356, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p357, %fd2922, 0d7FF0000000000000;
	and.pred  	%p358, %p357, %p356;
	@%p358 bra 	$L__BB0_177;
	bra.uni 	$L__BB0_176;

$L__BB0_177:
	setp.eq.f64 	%p359, %fd2922, 0d7FF0000000000000;
	selp.f64 	%fd2925, 0dFFF8000000000000, %fd89, %p359;
	bra.uni 	$L__BB0_178;

$L__BB0_159:
	.loc	1 0 9
	mov.f64 	%fd2925, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_178;

	setp.ltu.f64 	%p323, %fd2922, %fd3160;
	mov.f64 	%fd2925, %fd89;
	@%p323 bra 	$L__BB0_178;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2241}, %fd2922;
	}
	shr.u32 	%r5975, %r2241, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2242}, %fd3160;
	}
	shr.u32 	%r5976, %r2242, 20;
	setp.ne.s32 	%p324, %r5975, 0;
	@%p324 bra 	$L__BB0_163;

	mul.f64 	%fd2922, %fd2922, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2243}, %fd2922;
	}
	shr.u32 	%r2244, %r2243, 20;
	add.s32 	%r5975, %r2244, -54;

$L__BB0_163:
	setp.ne.s32 	%p325, %r5976, 0;
	mov.f64 	%fd2923, %fd3160;
	@%p325 bra 	$L__BB0_165;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2245}, %fd2;
	}
	shr.u32 	%r2246, %r2245, 20;
	add.s32 	%r5976, %r2246, -54;
	mov.f64 	%fd2923, %fd2;

$L__BB0_165:
	mov.b64 	%rd1750, %fd2922;
	and.b64  	%rd1751, %rd1750, 4503599627370495;
	or.b64  	%rd6177, %rd1751, 4503599627370496;
	mov.b64 	%rd1752, %fd2923;
	and.b64  	%rd1753, %rd1752, 4503599627370495;
	or.b64  	%rd131, %rd1753, 4503599627370496;
	sub.s32 	%r5982, %r5975, %r5976;
	not.b32 	%r2247, %r5975;
	add.s32 	%r2248, %r5976, %r2247;
	max.s32 	%r2249, %r2248, -1;
	add.s32 	%r205, %r2249, %r5975;
	mov.u32 	%r2250, 2;
	sub.s32 	%r2251, %r2250, %r5976;
	add.s32 	%r2252, %r2251, %r205;
	and.b32  	%r5978, %r2252, 3;
	setp.eq.s32 	%p326, %r5978, 0;
	@%p326 bra 	$L__BB0_167;

$L__BB0_166:
	.pragma "nounroll";
	sub.s64 	%rd1754, %rd6177, %rd131;
	mov.b64 	%fd1008, %rd1754;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2253}, %fd1008;
	}
	setp.lt.s32 	%p327, %r2253, 0;
	selp.b64 	%rd6180, %rd6177, %rd1754, %p327;
	shl.b64 	%rd6177, %rd6180, 1;
	add.s32 	%r5982, %r5982, -1;
	add.s32 	%r5978, %r5978, -1;
	setp.ne.s32 	%p328, %r5978, 0;
	@%p328 bra 	$L__BB0_166;

$L__BB0_167:
	mov.u32 	%r2254, 1;
	sub.s32 	%r2255, %r2254, %r5976;
	add.s32 	%r2256, %r2255, %r205;
	setp.lt.u32 	%p329, %r2256, 3;
	@%p329 bra 	$L__BB0_172;

	not.b32 	%r2257, %r5982;
	max.s32 	%r2258, %r2257, -4;
	add.s32 	%r2259, %r5982, %r2258;
	add.s32 	%r212, %r2259, 4;
	shr.u32 	%r2260, %r212, 2;
	add.s32 	%r2261, %r2260, 1;
	and.b32  	%r5981, %r2261, 3;
	setp.eq.s32 	%p330, %r5981, 0;
	@%p330 bra 	$L__BB0_170;

$L__BB0_169:
	.pragma "nounroll";
	sub.s64 	%rd1756, %rd6177, %rd131;
	mov.b64 	%fd1009, %rd1756;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2262}, %fd1009;
	}
	setp.lt.s32 	%p331, %r2262, 0;
	selp.b64 	%rd1757, %rd6177, %rd1756, %p331;
	shl.b64 	%rd1758, %rd1757, 1;
	sub.s64 	%rd1759, %rd1758, %rd131;
	mov.b64 	%fd1010, %rd1759;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2263}, %fd1010;
	}
	setp.lt.s32 	%p332, %r2263, 0;
	selp.b64 	%rd1760, %rd1758, %rd1759, %p332;
	shl.b64 	%rd1761, %rd1760, 1;
	sub.s64 	%rd1762, %rd1761, %rd131;
	mov.b64 	%fd1011, %rd1762;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2264}, %fd1011;
	}
	setp.lt.s32 	%p333, %r2264, 0;
	selp.b64 	%rd1763, %rd1761, %rd1762, %p333;
	shl.b64 	%rd1764, %rd1763, 1;
	sub.s64 	%rd1765, %rd1764, %rd131;
	mov.b64 	%fd1012, %rd1765;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2265}, %fd1012;
	}
	setp.lt.s32 	%p334, %r2265, 0;
	selp.b64 	%rd6180, %rd1764, %rd1765, %p334;
	shl.b64 	%rd6177, %rd6180, 1;
	add.s32 	%r5982, %r5982, -4;
	add.s32 	%r5981, %r5981, -1;
	setp.ne.s32 	%p335, %r5981, 0;
	@%p335 bra 	$L__BB0_169;

$L__BB0_170:
	setp.lt.u32 	%p336, %r212, 12;
	@%p336 bra 	$L__BB0_172;

$L__BB0_171:
	sub.s64 	%rd1766, %rd6177, %rd131;
	mov.b64 	%fd1013, %rd1766;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2266}, %fd1013;
	}
	setp.lt.s32 	%p337, %r2266, 0;
	selp.b64 	%rd1767, %rd6177, %rd1766, %p337;
	shl.b64 	%rd1768, %rd1767, 1;
	sub.s64 	%rd1769, %rd1768, %rd131;
	mov.b64 	%fd1014, %rd1769;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2267}, %fd1014;
	}
	setp.lt.s32 	%p338, %r2267, 0;
	selp.b64 	%rd1770, %rd1768, %rd1769, %p338;
	shl.b64 	%rd1771, %rd1770, 1;
	sub.s64 	%rd1772, %rd1771, %rd131;
	mov.b64 	%fd1015, %rd1772;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2268}, %fd1015;
	}
	setp.lt.s32 	%p339, %r2268, 0;
	selp.b64 	%rd1773, %rd1771, %rd1772, %p339;
	shl.b64 	%rd1774, %rd1773, 1;
	sub.s64 	%rd1775, %rd1774, %rd131;
	mov.b64 	%fd1016, %rd1775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2269}, %fd1016;
	}
	setp.lt.s32 	%p340, %r2269, 0;
	selp.b64 	%rd1776, %rd1774, %rd1775, %p340;
	shl.b64 	%rd1777, %rd1776, 1;
	sub.s64 	%rd1778, %rd1777, %rd131;
	mov.b64 	%fd1017, %rd1778;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2270}, %fd1017;
	}
	setp.lt.s32 	%p341, %r2270, 0;
	selp.b64 	%rd1779, %rd1777, %rd1778, %p341;
	shl.b64 	%rd1780, %rd1779, 1;
	sub.s64 	%rd1781, %rd1780, %rd131;
	mov.b64 	%fd1018, %rd1781;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2271}, %fd1018;
	}
	setp.lt.s32 	%p342, %r2271, 0;
	selp.b64 	%rd1782, %rd1780, %rd1781, %p342;
	shl.b64 	%rd1783, %rd1782, 1;
	sub.s64 	%rd1784, %rd1783, %rd131;
	mov.b64 	%fd1019, %rd1784;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2272}, %fd1019;
	}
	setp.lt.s32 	%p343, %r2272, 0;
	selp.b64 	%rd1785, %rd1783, %rd1784, %p343;
	shl.b64 	%rd1786, %rd1785, 1;
	sub.s64 	%rd1787, %rd1786, %rd131;
	mov.b64 	%fd1020, %rd1787;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2273}, %fd1020;
	}
	setp.lt.s32 	%p344, %r2273, 0;
	selp.b64 	%rd1788, %rd1786, %rd1787, %p344;
	shl.b64 	%rd1789, %rd1788, 1;
	sub.s64 	%rd1790, %rd1789, %rd131;
	mov.b64 	%fd1021, %rd1790;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2274}, %fd1021;
	}
	setp.lt.s32 	%p345, %r2274, 0;
	selp.b64 	%rd1791, %rd1789, %rd1790, %p345;
	shl.b64 	%rd1792, %rd1791, 1;
	sub.s64 	%rd1793, %rd1792, %rd131;
	mov.b64 	%fd1022, %rd1793;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2275}, %fd1022;
	}
	setp.lt.s32 	%p346, %r2275, 0;
	selp.b64 	%rd1794, %rd1792, %rd1793, %p346;
	shl.b64 	%rd1795, %rd1794, 1;
	sub.s64 	%rd1796, %rd1795, %rd131;
	mov.b64 	%fd1023, %rd1796;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2276}, %fd1023;
	}
	setp.lt.s32 	%p347, %r2276, 0;
	selp.b64 	%rd1797, %rd1795, %rd1796, %p347;
	shl.b64 	%rd1798, %rd1797, 1;
	sub.s64 	%rd1799, %rd1798, %rd131;
	mov.b64 	%fd1024, %rd1799;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2277}, %fd1024;
	}
	setp.lt.s32 	%p348, %r2277, 0;
	selp.b64 	%rd1800, %rd1798, %rd1799, %p348;
	shl.b64 	%rd1801, %rd1800, 1;
	sub.s64 	%rd1802, %rd1801, %rd131;
	mov.b64 	%fd1025, %rd1802;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2278}, %fd1025;
	}
	setp.lt.s32 	%p349, %r2278, 0;
	selp.b64 	%rd1803, %rd1801, %rd1802, %p349;
	shl.b64 	%rd1804, %rd1803, 1;
	sub.s64 	%rd1805, %rd1804, %rd131;
	mov.b64 	%fd1026, %rd1805;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2279}, %fd1026;
	}
	setp.lt.s32 	%p350, %r2279, 0;
	selp.b64 	%rd1806, %rd1804, %rd1805, %p350;
	shl.b64 	%rd1807, %rd1806, 1;
	sub.s64 	%rd1808, %rd1807, %rd131;
	mov.b64 	%fd1027, %rd1808;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2280}, %fd1027;
	}
	setp.lt.s32 	%p351, %r2280, 0;
	selp.b64 	%rd1809, %rd1807, %rd1808, %p351;
	shl.b64 	%rd1810, %rd1809, 1;
	sub.s64 	%rd1811, %rd1810, %rd131;
	mov.b64 	%fd1028, %rd1811;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2281}, %fd1028;
	}
	setp.lt.s32 	%p352, %r2281, 0;
	selp.b64 	%rd6180, %rd1810, %rd1811, %p352;
	shl.b64 	%rd6177, %rd6180, 1;
	add.s32 	%r220, %r5982, -16;
	setp.gt.s32 	%p353, %r5982, 15;
	mov.u32 	%r5982, %r220;
	@%p353 bra 	$L__BB0_171;

$L__BB0_172:
	and.b64  	%rd146, %rd6180, 9223372036854775807;
	setp.eq.s64 	%p354, %rd146, 0;
	mov.f64 	%fd2924, 0d0000000000000000;
	@%p354 bra 	$L__BB0_174;

	mov.b64 	%fd1030, %rd146;
	mul.f64 	%fd1031, %fd1030, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2282}, %fd1031;
	}
	shr.u32 	%r2283, %r2282, 20;
	mov.u32 	%r2284, 55;
	sub.s32 	%r2285, %r2284, %r2283;
	sub.s32 	%r2286, %r5976, %r2285;
	shl.b64 	%rd1812, %rd146, %r2285;
	setp.lt.s32 	%p355, %r2286, 1;
	mov.u32 	%r2287, 1;
	sub.s32 	%r2288, %r2287, %r2286;
	shr.u64 	%rd1813, %rd1812, %r2288;
	add.s32 	%r2289, %r2286, -1;
	cvt.u64.u32 	%rd1814, %r2289;
	shl.b64 	%rd1815, %rd1814, 52;
	add.s64 	%rd1816, %rd1815, %rd1812;
	selp.b64 	%rd1817, %rd1813, %rd1816, %p355;
	mov.b64 	%fd2924, %rd1817;

$L__BB0_174:
	and.b32  	%r2290, %r197, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2291}, %fd2924;
	}
	or.b32  	%r2292, %r2291, %r2290;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2293, %temp}, %fd2924;
	}
	mov.b64 	%fd2925, {%r2293, %r2292};
	bra.uni 	$L__BB0_178;

$L__BB0_176:
	mov.f64 	%fd1032, 0d3FF0000000000000;
	add.rn.f64 	%fd2925, %fd89, %fd1032;

$L__BB0_178:
	mov.f64 	%fd1033, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1034, %fd1033, %fd2925;
	mul.f64 	%fd1035, %fd1034, %fd15;
	mul.f64 	%fd1036, %fd1035, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 79 28
	add.s32 	%r2294, %r6047, 7;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 79 28
	cvt.rn.f64.s32 	%fd1037, %r2294;
	fma.rn.f64 	%fd100, %fd1037, 0d400921FB54442D18, %fd1036;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r221}, %fd100;
	}
	and.b32  	%r2295, %r221, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2296, %temp}, %fd100;
	}
	mov.b64 	%fd2926, {%r2296, %r2295};
	setp.gt.u32 	%p360, %r2295, 2146435071;
	or.pred  	%p362, %p360, %p18;
	@%p362 bra 	$L__BB0_195;
	bra.uni 	$L__BB0_179;

$L__BB0_195:
	.loc	1 0 9
	setp.le.f64 	%p397, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p398, %fd2926, 0d7FF0000000000000;
	and.pred  	%p399, %p398, %p397;
	@%p399 bra 	$L__BB0_197;
	bra.uni 	$L__BB0_196;

$L__BB0_197:
	setp.eq.f64 	%p400, %fd2926, 0d7FF0000000000000;
	selp.f64 	%fd2929, 0dFFF8000000000000, %fd100, %p400;
	bra.uni 	$L__BB0_198;

$L__BB0_179:
	.loc	1 0 9
	mov.f64 	%fd2929, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_198;

	setp.ltu.f64 	%p364, %fd2926, %fd3160;
	mov.f64 	%fd2929, %fd100;
	@%p364 bra 	$L__BB0_198;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2297}, %fd2926;
	}
	shr.u32 	%r5984, %r2297, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2298}, %fd3160;
	}
	shr.u32 	%r5985, %r2298, 20;
	setp.ne.s32 	%p365, %r5984, 0;
	@%p365 bra 	$L__BB0_183;

	mul.f64 	%fd2926, %fd2926, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2299}, %fd2926;
	}
	shr.u32 	%r2300, %r2299, 20;
	add.s32 	%r5984, %r2300, -54;

$L__BB0_183:
	setp.ne.s32 	%p366, %r5985, 0;
	mov.f64 	%fd2927, %fd3160;
	@%p366 bra 	$L__BB0_185;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2301}, %fd2;
	}
	shr.u32 	%r2302, %r2301, 20;
	add.s32 	%r5985, %r2302, -54;
	mov.f64 	%fd2927, %fd2;

$L__BB0_185:
	mov.b64 	%rd1819, %fd2926;
	and.b64  	%rd1820, %rd1819, 4503599627370495;
	or.b64  	%rd6185, %rd1820, 4503599627370496;
	mov.b64 	%rd1821, %fd2927;
	and.b64  	%rd1822, %rd1821, 4503599627370495;
	or.b64  	%rd148, %rd1822, 4503599627370496;
	sub.s32 	%r5991, %r5984, %r5985;
	not.b32 	%r2303, %r5984;
	add.s32 	%r2304, %r5985, %r2303;
	max.s32 	%r2305, %r2304, -1;
	add.s32 	%r229, %r2305, %r5984;
	mov.u32 	%r2306, 2;
	sub.s32 	%r2307, %r2306, %r5985;
	add.s32 	%r2308, %r2307, %r229;
	and.b32  	%r5987, %r2308, 3;
	setp.eq.s32 	%p367, %r5987, 0;
	@%p367 bra 	$L__BB0_187;

$L__BB0_186:
	.pragma "nounroll";
	sub.s64 	%rd1823, %rd6185, %rd148;
	mov.b64 	%fd1039, %rd1823;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2309}, %fd1039;
	}
	setp.lt.s32 	%p368, %r2309, 0;
	selp.b64 	%rd6188, %rd6185, %rd1823, %p368;
	shl.b64 	%rd6185, %rd6188, 1;
	add.s32 	%r5991, %r5991, -1;
	add.s32 	%r5987, %r5987, -1;
	setp.ne.s32 	%p369, %r5987, 0;
	@%p369 bra 	$L__BB0_186;

$L__BB0_187:
	mov.u32 	%r2310, 1;
	sub.s32 	%r2311, %r2310, %r5985;
	add.s32 	%r2312, %r2311, %r229;
	setp.lt.u32 	%p370, %r2312, 3;
	@%p370 bra 	$L__BB0_192;

	not.b32 	%r2313, %r5991;
	max.s32 	%r2314, %r2313, -4;
	add.s32 	%r2315, %r5991, %r2314;
	add.s32 	%r236, %r2315, 4;
	shr.u32 	%r2316, %r236, 2;
	add.s32 	%r2317, %r2316, 1;
	and.b32  	%r5990, %r2317, 3;
	setp.eq.s32 	%p371, %r5990, 0;
	@%p371 bra 	$L__BB0_190;

$L__BB0_189:
	.pragma "nounroll";
	sub.s64 	%rd1825, %rd6185, %rd148;
	mov.b64 	%fd1040, %rd1825;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2318}, %fd1040;
	}
	setp.lt.s32 	%p372, %r2318, 0;
	selp.b64 	%rd1826, %rd6185, %rd1825, %p372;
	shl.b64 	%rd1827, %rd1826, 1;
	sub.s64 	%rd1828, %rd1827, %rd148;
	mov.b64 	%fd1041, %rd1828;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2319}, %fd1041;
	}
	setp.lt.s32 	%p373, %r2319, 0;
	selp.b64 	%rd1829, %rd1827, %rd1828, %p373;
	shl.b64 	%rd1830, %rd1829, 1;
	sub.s64 	%rd1831, %rd1830, %rd148;
	mov.b64 	%fd1042, %rd1831;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2320}, %fd1042;
	}
	setp.lt.s32 	%p374, %r2320, 0;
	selp.b64 	%rd1832, %rd1830, %rd1831, %p374;
	shl.b64 	%rd1833, %rd1832, 1;
	sub.s64 	%rd1834, %rd1833, %rd148;
	mov.b64 	%fd1043, %rd1834;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2321}, %fd1043;
	}
	setp.lt.s32 	%p375, %r2321, 0;
	selp.b64 	%rd6188, %rd1833, %rd1834, %p375;
	shl.b64 	%rd6185, %rd6188, 1;
	add.s32 	%r5991, %r5991, -4;
	add.s32 	%r5990, %r5990, -1;
	setp.ne.s32 	%p376, %r5990, 0;
	@%p376 bra 	$L__BB0_189;

$L__BB0_190:
	setp.lt.u32 	%p377, %r236, 12;
	@%p377 bra 	$L__BB0_192;

$L__BB0_191:
	sub.s64 	%rd1835, %rd6185, %rd148;
	mov.b64 	%fd1044, %rd1835;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2322}, %fd1044;
	}
	setp.lt.s32 	%p378, %r2322, 0;
	selp.b64 	%rd1836, %rd6185, %rd1835, %p378;
	shl.b64 	%rd1837, %rd1836, 1;
	sub.s64 	%rd1838, %rd1837, %rd148;
	mov.b64 	%fd1045, %rd1838;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2323}, %fd1045;
	}
	setp.lt.s32 	%p379, %r2323, 0;
	selp.b64 	%rd1839, %rd1837, %rd1838, %p379;
	shl.b64 	%rd1840, %rd1839, 1;
	sub.s64 	%rd1841, %rd1840, %rd148;
	mov.b64 	%fd1046, %rd1841;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2324}, %fd1046;
	}
	setp.lt.s32 	%p380, %r2324, 0;
	selp.b64 	%rd1842, %rd1840, %rd1841, %p380;
	shl.b64 	%rd1843, %rd1842, 1;
	sub.s64 	%rd1844, %rd1843, %rd148;
	mov.b64 	%fd1047, %rd1844;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2325}, %fd1047;
	}
	setp.lt.s32 	%p381, %r2325, 0;
	selp.b64 	%rd1845, %rd1843, %rd1844, %p381;
	shl.b64 	%rd1846, %rd1845, 1;
	sub.s64 	%rd1847, %rd1846, %rd148;
	mov.b64 	%fd1048, %rd1847;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2326}, %fd1048;
	}
	setp.lt.s32 	%p382, %r2326, 0;
	selp.b64 	%rd1848, %rd1846, %rd1847, %p382;
	shl.b64 	%rd1849, %rd1848, 1;
	sub.s64 	%rd1850, %rd1849, %rd148;
	mov.b64 	%fd1049, %rd1850;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2327}, %fd1049;
	}
	setp.lt.s32 	%p383, %r2327, 0;
	selp.b64 	%rd1851, %rd1849, %rd1850, %p383;
	shl.b64 	%rd1852, %rd1851, 1;
	sub.s64 	%rd1853, %rd1852, %rd148;
	mov.b64 	%fd1050, %rd1853;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2328}, %fd1050;
	}
	setp.lt.s32 	%p384, %r2328, 0;
	selp.b64 	%rd1854, %rd1852, %rd1853, %p384;
	shl.b64 	%rd1855, %rd1854, 1;
	sub.s64 	%rd1856, %rd1855, %rd148;
	mov.b64 	%fd1051, %rd1856;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2329}, %fd1051;
	}
	setp.lt.s32 	%p385, %r2329, 0;
	selp.b64 	%rd1857, %rd1855, %rd1856, %p385;
	shl.b64 	%rd1858, %rd1857, 1;
	sub.s64 	%rd1859, %rd1858, %rd148;
	mov.b64 	%fd1052, %rd1859;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2330}, %fd1052;
	}
	setp.lt.s32 	%p386, %r2330, 0;
	selp.b64 	%rd1860, %rd1858, %rd1859, %p386;
	shl.b64 	%rd1861, %rd1860, 1;
	sub.s64 	%rd1862, %rd1861, %rd148;
	mov.b64 	%fd1053, %rd1862;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2331}, %fd1053;
	}
	setp.lt.s32 	%p387, %r2331, 0;
	selp.b64 	%rd1863, %rd1861, %rd1862, %p387;
	shl.b64 	%rd1864, %rd1863, 1;
	sub.s64 	%rd1865, %rd1864, %rd148;
	mov.b64 	%fd1054, %rd1865;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2332}, %fd1054;
	}
	setp.lt.s32 	%p388, %r2332, 0;
	selp.b64 	%rd1866, %rd1864, %rd1865, %p388;
	shl.b64 	%rd1867, %rd1866, 1;
	sub.s64 	%rd1868, %rd1867, %rd148;
	mov.b64 	%fd1055, %rd1868;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2333}, %fd1055;
	}
	setp.lt.s32 	%p389, %r2333, 0;
	selp.b64 	%rd1869, %rd1867, %rd1868, %p389;
	shl.b64 	%rd1870, %rd1869, 1;
	sub.s64 	%rd1871, %rd1870, %rd148;
	mov.b64 	%fd1056, %rd1871;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2334}, %fd1056;
	}
	setp.lt.s32 	%p390, %r2334, 0;
	selp.b64 	%rd1872, %rd1870, %rd1871, %p390;
	shl.b64 	%rd1873, %rd1872, 1;
	sub.s64 	%rd1874, %rd1873, %rd148;
	mov.b64 	%fd1057, %rd1874;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2335}, %fd1057;
	}
	setp.lt.s32 	%p391, %r2335, 0;
	selp.b64 	%rd1875, %rd1873, %rd1874, %p391;
	shl.b64 	%rd1876, %rd1875, 1;
	sub.s64 	%rd1877, %rd1876, %rd148;
	mov.b64 	%fd1058, %rd1877;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2336}, %fd1058;
	}
	setp.lt.s32 	%p392, %r2336, 0;
	selp.b64 	%rd1878, %rd1876, %rd1877, %p392;
	shl.b64 	%rd1879, %rd1878, 1;
	sub.s64 	%rd1880, %rd1879, %rd148;
	mov.b64 	%fd1059, %rd1880;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2337}, %fd1059;
	}
	setp.lt.s32 	%p393, %r2337, 0;
	selp.b64 	%rd6188, %rd1879, %rd1880, %p393;
	shl.b64 	%rd6185, %rd6188, 1;
	add.s32 	%r244, %r5991, -16;
	setp.gt.s32 	%p394, %r5991, 15;
	mov.u32 	%r5991, %r244;
	@%p394 bra 	$L__BB0_191;

$L__BB0_192:
	and.b64  	%rd163, %rd6188, 9223372036854775807;
	setp.eq.s64 	%p395, %rd163, 0;
	mov.f64 	%fd2928, 0d0000000000000000;
	@%p395 bra 	$L__BB0_194;

	mov.b64 	%fd1061, %rd163;
	mul.f64 	%fd1062, %fd1061, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2338}, %fd1062;
	}
	shr.u32 	%r2339, %r2338, 20;
	mov.u32 	%r2340, 55;
	sub.s32 	%r2341, %r2340, %r2339;
	sub.s32 	%r2342, %r5985, %r2341;
	shl.b64 	%rd1881, %rd163, %r2341;
	setp.lt.s32 	%p396, %r2342, 1;
	mov.u32 	%r2343, 1;
	sub.s32 	%r2344, %r2343, %r2342;
	shr.u64 	%rd1882, %rd1881, %r2344;
	add.s32 	%r2345, %r2342, -1;
	cvt.u64.u32 	%rd1883, %r2345;
	shl.b64 	%rd1884, %rd1883, 52;
	add.s64 	%rd1885, %rd1884, %rd1881;
	selp.b64 	%rd1886, %rd1882, %rd1885, %p396;
	mov.b64 	%fd2928, %rd1886;

$L__BB0_194:
	and.b32  	%r2346, %r221, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2347}, %fd2928;
	}
	or.b32  	%r2348, %r2347, %r2346;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2349, %temp}, %fd2928;
	}
	mov.b64 	%fd2929, {%r2349, %r2348};
	bra.uni 	$L__BB0_198;

$L__BB0_196:
	mov.f64 	%fd1063, 0d3FF0000000000000;
	add.rn.f64 	%fd2929, %fd100, %fd1063;

$L__BB0_198:
	mov.f64 	%fd1064, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1065, %fd1064, %fd2929;
	mul.f64 	%fd1066, %fd1065, %fd27;
	mul.f64 	%fd1067, %fd1066, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 79 28
	add.s32 	%r2350, %r6047, 6;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 79 28
	cvt.rn.f64.s32 	%fd1068, %r2350;
	fma.rn.f64 	%fd111, %fd1068, 0d400921FB54442D18, %fd1067;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r245}, %fd111;
	}
	and.b32  	%r2351, %r245, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2352, %temp}, %fd111;
	}
	mov.b64 	%fd2930, {%r2352, %r2351};
	setp.gt.u32 	%p401, %r2351, 2146435071;
	or.pred  	%p403, %p401, %p18;
	@%p403 bra 	$L__BB0_215;
	bra.uni 	$L__BB0_199;

$L__BB0_215:
	.loc	1 0 9
	setp.le.f64 	%p438, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p439, %fd2930, 0d7FF0000000000000;
	and.pred  	%p440, %p439, %p438;
	@%p440 bra 	$L__BB0_217;
	bra.uni 	$L__BB0_216;

$L__BB0_217:
	setp.eq.f64 	%p441, %fd2930, 0d7FF0000000000000;
	selp.f64 	%fd2933, 0dFFF8000000000000, %fd111, %p441;
	bra.uni 	$L__BB0_218;

$L__BB0_199:
	.loc	1 0 9
	mov.f64 	%fd2933, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_218;

	setp.ltu.f64 	%p405, %fd2930, %fd3160;
	mov.f64 	%fd2933, %fd111;
	@%p405 bra 	$L__BB0_218;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2353}, %fd2930;
	}
	shr.u32 	%r5993, %r2353, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2354}, %fd3160;
	}
	shr.u32 	%r5994, %r2354, 20;
	setp.ne.s32 	%p406, %r5993, 0;
	@%p406 bra 	$L__BB0_203;

	mul.f64 	%fd2930, %fd2930, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2355}, %fd2930;
	}
	shr.u32 	%r2356, %r2355, 20;
	add.s32 	%r5993, %r2356, -54;

$L__BB0_203:
	setp.ne.s32 	%p407, %r5994, 0;
	mov.f64 	%fd2931, %fd3160;
	@%p407 bra 	$L__BB0_205;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2357}, %fd2;
	}
	shr.u32 	%r2358, %r2357, 20;
	add.s32 	%r5994, %r2358, -54;
	mov.f64 	%fd2931, %fd2;

$L__BB0_205:
	mov.b64 	%rd1888, %fd2930;
	and.b64  	%rd1889, %rd1888, 4503599627370495;
	or.b64  	%rd6193, %rd1889, 4503599627370496;
	mov.b64 	%rd1890, %fd2931;
	and.b64  	%rd1891, %rd1890, 4503599627370495;
	or.b64  	%rd165, %rd1891, 4503599627370496;
	sub.s32 	%r6000, %r5993, %r5994;
	not.b32 	%r2359, %r5993;
	add.s32 	%r2360, %r5994, %r2359;
	max.s32 	%r2361, %r2360, -1;
	add.s32 	%r253, %r2361, %r5993;
	mov.u32 	%r2362, 2;
	sub.s32 	%r2363, %r2362, %r5994;
	add.s32 	%r2364, %r2363, %r253;
	and.b32  	%r5996, %r2364, 3;
	setp.eq.s32 	%p408, %r5996, 0;
	@%p408 bra 	$L__BB0_207;

$L__BB0_206:
	.pragma "nounroll";
	sub.s64 	%rd1892, %rd6193, %rd165;
	mov.b64 	%fd1070, %rd1892;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2365}, %fd1070;
	}
	setp.lt.s32 	%p409, %r2365, 0;
	selp.b64 	%rd6196, %rd6193, %rd1892, %p409;
	shl.b64 	%rd6193, %rd6196, 1;
	add.s32 	%r6000, %r6000, -1;
	add.s32 	%r5996, %r5996, -1;
	setp.ne.s32 	%p410, %r5996, 0;
	@%p410 bra 	$L__BB0_206;

$L__BB0_207:
	mov.u32 	%r2366, 1;
	sub.s32 	%r2367, %r2366, %r5994;
	add.s32 	%r2368, %r2367, %r253;
	setp.lt.u32 	%p411, %r2368, 3;
	@%p411 bra 	$L__BB0_212;

	not.b32 	%r2369, %r6000;
	max.s32 	%r2370, %r2369, -4;
	add.s32 	%r2371, %r6000, %r2370;
	add.s32 	%r260, %r2371, 4;
	shr.u32 	%r2372, %r260, 2;
	add.s32 	%r2373, %r2372, 1;
	and.b32  	%r5999, %r2373, 3;
	setp.eq.s32 	%p412, %r5999, 0;
	@%p412 bra 	$L__BB0_210;

$L__BB0_209:
	.pragma "nounroll";
	sub.s64 	%rd1894, %rd6193, %rd165;
	mov.b64 	%fd1071, %rd1894;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2374}, %fd1071;
	}
	setp.lt.s32 	%p413, %r2374, 0;
	selp.b64 	%rd1895, %rd6193, %rd1894, %p413;
	shl.b64 	%rd1896, %rd1895, 1;
	sub.s64 	%rd1897, %rd1896, %rd165;
	mov.b64 	%fd1072, %rd1897;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2375}, %fd1072;
	}
	setp.lt.s32 	%p414, %r2375, 0;
	selp.b64 	%rd1898, %rd1896, %rd1897, %p414;
	shl.b64 	%rd1899, %rd1898, 1;
	sub.s64 	%rd1900, %rd1899, %rd165;
	mov.b64 	%fd1073, %rd1900;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2376}, %fd1073;
	}
	setp.lt.s32 	%p415, %r2376, 0;
	selp.b64 	%rd1901, %rd1899, %rd1900, %p415;
	shl.b64 	%rd1902, %rd1901, 1;
	sub.s64 	%rd1903, %rd1902, %rd165;
	mov.b64 	%fd1074, %rd1903;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2377}, %fd1074;
	}
	setp.lt.s32 	%p416, %r2377, 0;
	selp.b64 	%rd6196, %rd1902, %rd1903, %p416;
	shl.b64 	%rd6193, %rd6196, 1;
	add.s32 	%r6000, %r6000, -4;
	add.s32 	%r5999, %r5999, -1;
	setp.ne.s32 	%p417, %r5999, 0;
	@%p417 bra 	$L__BB0_209;

$L__BB0_210:
	setp.lt.u32 	%p418, %r260, 12;
	@%p418 bra 	$L__BB0_212;

$L__BB0_211:
	sub.s64 	%rd1904, %rd6193, %rd165;
	mov.b64 	%fd1075, %rd1904;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2378}, %fd1075;
	}
	setp.lt.s32 	%p419, %r2378, 0;
	selp.b64 	%rd1905, %rd6193, %rd1904, %p419;
	shl.b64 	%rd1906, %rd1905, 1;
	sub.s64 	%rd1907, %rd1906, %rd165;
	mov.b64 	%fd1076, %rd1907;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2379}, %fd1076;
	}
	setp.lt.s32 	%p420, %r2379, 0;
	selp.b64 	%rd1908, %rd1906, %rd1907, %p420;
	shl.b64 	%rd1909, %rd1908, 1;
	sub.s64 	%rd1910, %rd1909, %rd165;
	mov.b64 	%fd1077, %rd1910;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2380}, %fd1077;
	}
	setp.lt.s32 	%p421, %r2380, 0;
	selp.b64 	%rd1911, %rd1909, %rd1910, %p421;
	shl.b64 	%rd1912, %rd1911, 1;
	sub.s64 	%rd1913, %rd1912, %rd165;
	mov.b64 	%fd1078, %rd1913;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2381}, %fd1078;
	}
	setp.lt.s32 	%p422, %r2381, 0;
	selp.b64 	%rd1914, %rd1912, %rd1913, %p422;
	shl.b64 	%rd1915, %rd1914, 1;
	sub.s64 	%rd1916, %rd1915, %rd165;
	mov.b64 	%fd1079, %rd1916;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2382}, %fd1079;
	}
	setp.lt.s32 	%p423, %r2382, 0;
	selp.b64 	%rd1917, %rd1915, %rd1916, %p423;
	shl.b64 	%rd1918, %rd1917, 1;
	sub.s64 	%rd1919, %rd1918, %rd165;
	mov.b64 	%fd1080, %rd1919;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2383}, %fd1080;
	}
	setp.lt.s32 	%p424, %r2383, 0;
	selp.b64 	%rd1920, %rd1918, %rd1919, %p424;
	shl.b64 	%rd1921, %rd1920, 1;
	sub.s64 	%rd1922, %rd1921, %rd165;
	mov.b64 	%fd1081, %rd1922;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2384}, %fd1081;
	}
	setp.lt.s32 	%p425, %r2384, 0;
	selp.b64 	%rd1923, %rd1921, %rd1922, %p425;
	shl.b64 	%rd1924, %rd1923, 1;
	sub.s64 	%rd1925, %rd1924, %rd165;
	mov.b64 	%fd1082, %rd1925;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2385}, %fd1082;
	}
	setp.lt.s32 	%p426, %r2385, 0;
	selp.b64 	%rd1926, %rd1924, %rd1925, %p426;
	shl.b64 	%rd1927, %rd1926, 1;
	sub.s64 	%rd1928, %rd1927, %rd165;
	mov.b64 	%fd1083, %rd1928;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2386}, %fd1083;
	}
	setp.lt.s32 	%p427, %r2386, 0;
	selp.b64 	%rd1929, %rd1927, %rd1928, %p427;
	shl.b64 	%rd1930, %rd1929, 1;
	sub.s64 	%rd1931, %rd1930, %rd165;
	mov.b64 	%fd1084, %rd1931;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2387}, %fd1084;
	}
	setp.lt.s32 	%p428, %r2387, 0;
	selp.b64 	%rd1932, %rd1930, %rd1931, %p428;
	shl.b64 	%rd1933, %rd1932, 1;
	sub.s64 	%rd1934, %rd1933, %rd165;
	mov.b64 	%fd1085, %rd1934;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2388}, %fd1085;
	}
	setp.lt.s32 	%p429, %r2388, 0;
	selp.b64 	%rd1935, %rd1933, %rd1934, %p429;
	shl.b64 	%rd1936, %rd1935, 1;
	sub.s64 	%rd1937, %rd1936, %rd165;
	mov.b64 	%fd1086, %rd1937;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2389}, %fd1086;
	}
	setp.lt.s32 	%p430, %r2389, 0;
	selp.b64 	%rd1938, %rd1936, %rd1937, %p430;
	shl.b64 	%rd1939, %rd1938, 1;
	sub.s64 	%rd1940, %rd1939, %rd165;
	mov.b64 	%fd1087, %rd1940;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2390}, %fd1087;
	}
	setp.lt.s32 	%p431, %r2390, 0;
	selp.b64 	%rd1941, %rd1939, %rd1940, %p431;
	shl.b64 	%rd1942, %rd1941, 1;
	sub.s64 	%rd1943, %rd1942, %rd165;
	mov.b64 	%fd1088, %rd1943;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2391}, %fd1088;
	}
	setp.lt.s32 	%p432, %r2391, 0;
	selp.b64 	%rd1944, %rd1942, %rd1943, %p432;
	shl.b64 	%rd1945, %rd1944, 1;
	sub.s64 	%rd1946, %rd1945, %rd165;
	mov.b64 	%fd1089, %rd1946;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2392}, %fd1089;
	}
	setp.lt.s32 	%p433, %r2392, 0;
	selp.b64 	%rd1947, %rd1945, %rd1946, %p433;
	shl.b64 	%rd1948, %rd1947, 1;
	sub.s64 	%rd1949, %rd1948, %rd165;
	mov.b64 	%fd1090, %rd1949;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2393}, %fd1090;
	}
	setp.lt.s32 	%p434, %r2393, 0;
	selp.b64 	%rd6196, %rd1948, %rd1949, %p434;
	shl.b64 	%rd6193, %rd6196, 1;
	add.s32 	%r268, %r6000, -16;
	setp.gt.s32 	%p435, %r6000, 15;
	mov.u32 	%r6000, %r268;
	@%p435 bra 	$L__BB0_211;

$L__BB0_212:
	and.b64  	%rd180, %rd6196, 9223372036854775807;
	setp.eq.s64 	%p436, %rd180, 0;
	mov.f64 	%fd2932, 0d0000000000000000;
	@%p436 bra 	$L__BB0_214;

	mov.b64 	%fd1092, %rd180;
	mul.f64 	%fd1093, %fd1092, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2394}, %fd1093;
	}
	shr.u32 	%r2395, %r2394, 20;
	mov.u32 	%r2396, 55;
	sub.s32 	%r2397, %r2396, %r2395;
	sub.s32 	%r2398, %r5994, %r2397;
	shl.b64 	%rd1950, %rd180, %r2397;
	setp.lt.s32 	%p437, %r2398, 1;
	mov.u32 	%r2399, 1;
	sub.s32 	%r2400, %r2399, %r2398;
	shr.u64 	%rd1951, %rd1950, %r2400;
	add.s32 	%r2401, %r2398, -1;
	cvt.u64.u32 	%rd1952, %r2401;
	shl.b64 	%rd1953, %rd1952, 52;
	add.s64 	%rd1954, %rd1953, %rd1950;
	selp.b64 	%rd1955, %rd1951, %rd1954, %p437;
	mov.b64 	%fd2932, %rd1955;

$L__BB0_214:
	and.b32  	%r2402, %r245, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2403}, %fd2932;
	}
	or.b32  	%r2404, %r2403, %r2402;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2405, %temp}, %fd2932;
	}
	mov.b64 	%fd2933, {%r2405, %r2404};
	bra.uni 	$L__BB0_218;

$L__BB0_216:
	mov.f64 	%fd1094, 0d3FF0000000000000;
	add.rn.f64 	%fd2933, %fd111, %fd1094;

$L__BB0_218:
	mov.f64 	%fd1095, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1096, %fd1095, %fd2933;
	mul.f64 	%fd1097, %fd1096, %fd39;
	mul.f64 	%fd1098, %fd1097, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 79 28
	add.s32 	%r2406, %r6047, 5;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 79 28
	cvt.rn.f64.s32 	%fd1099, %r2406;
	fma.rn.f64 	%fd122, %fd1099, 0d400921FB54442D18, %fd1098;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r269}, %fd122;
	}
	and.b32  	%r2407, %r269, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2408, %temp}, %fd122;
	}
	mov.b64 	%fd2934, {%r2408, %r2407};
	setp.gt.u32 	%p442, %r2407, 2146435071;
	or.pred  	%p444, %p442, %p18;
	@%p444 bra 	$L__BB0_235;
	bra.uni 	$L__BB0_219;

$L__BB0_235:
	.loc	1 0 9
	setp.le.f64 	%p479, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p480, %fd2934, 0d7FF0000000000000;
	and.pred  	%p481, %p480, %p479;
	@%p481 bra 	$L__BB0_237;
	bra.uni 	$L__BB0_236;

$L__BB0_237:
	setp.eq.f64 	%p482, %fd2934, 0d7FF0000000000000;
	selp.f64 	%fd2937, 0dFFF8000000000000, %fd122, %p482;
	bra.uni 	$L__BB0_238;

$L__BB0_219:
	.loc	1 0 9
	mov.f64 	%fd2937, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_238;

	setp.ltu.f64 	%p446, %fd2934, %fd3160;
	mov.f64 	%fd2937, %fd122;
	@%p446 bra 	$L__BB0_238;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2409}, %fd2934;
	}
	shr.u32 	%r6002, %r2409, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2410}, %fd3160;
	}
	shr.u32 	%r6003, %r2410, 20;
	setp.ne.s32 	%p447, %r6002, 0;
	@%p447 bra 	$L__BB0_223;

	mul.f64 	%fd2934, %fd2934, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2411}, %fd2934;
	}
	shr.u32 	%r2412, %r2411, 20;
	add.s32 	%r6002, %r2412, -54;

$L__BB0_223:
	setp.ne.s32 	%p448, %r6003, 0;
	mov.f64 	%fd2935, %fd3160;
	@%p448 bra 	$L__BB0_225;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2413}, %fd2;
	}
	shr.u32 	%r2414, %r2413, 20;
	add.s32 	%r6003, %r2414, -54;
	mov.f64 	%fd2935, %fd2;

$L__BB0_225:
	mov.b64 	%rd1957, %fd2934;
	and.b64  	%rd1958, %rd1957, 4503599627370495;
	or.b64  	%rd6201, %rd1958, 4503599627370496;
	mov.b64 	%rd1959, %fd2935;
	and.b64  	%rd1960, %rd1959, 4503599627370495;
	or.b64  	%rd182, %rd1960, 4503599627370496;
	sub.s32 	%r6009, %r6002, %r6003;
	not.b32 	%r2415, %r6002;
	add.s32 	%r2416, %r6003, %r2415;
	max.s32 	%r2417, %r2416, -1;
	add.s32 	%r277, %r2417, %r6002;
	mov.u32 	%r2418, 2;
	sub.s32 	%r2419, %r2418, %r6003;
	add.s32 	%r2420, %r2419, %r277;
	and.b32  	%r6005, %r2420, 3;
	setp.eq.s32 	%p449, %r6005, 0;
	@%p449 bra 	$L__BB0_227;

$L__BB0_226:
	.pragma "nounroll";
	sub.s64 	%rd1961, %rd6201, %rd182;
	mov.b64 	%fd1101, %rd1961;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2421}, %fd1101;
	}
	setp.lt.s32 	%p450, %r2421, 0;
	selp.b64 	%rd6204, %rd6201, %rd1961, %p450;
	shl.b64 	%rd6201, %rd6204, 1;
	add.s32 	%r6009, %r6009, -1;
	add.s32 	%r6005, %r6005, -1;
	setp.ne.s32 	%p451, %r6005, 0;
	@%p451 bra 	$L__BB0_226;

$L__BB0_227:
	mov.u32 	%r2422, 1;
	sub.s32 	%r2423, %r2422, %r6003;
	add.s32 	%r2424, %r2423, %r277;
	setp.lt.u32 	%p452, %r2424, 3;
	@%p452 bra 	$L__BB0_232;

	not.b32 	%r2425, %r6009;
	max.s32 	%r2426, %r2425, -4;
	add.s32 	%r2427, %r6009, %r2426;
	add.s32 	%r284, %r2427, 4;
	shr.u32 	%r2428, %r284, 2;
	add.s32 	%r2429, %r2428, 1;
	and.b32  	%r6008, %r2429, 3;
	setp.eq.s32 	%p453, %r6008, 0;
	@%p453 bra 	$L__BB0_230;

$L__BB0_229:
	.pragma "nounroll";
	sub.s64 	%rd1963, %rd6201, %rd182;
	mov.b64 	%fd1102, %rd1963;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2430}, %fd1102;
	}
	setp.lt.s32 	%p454, %r2430, 0;
	selp.b64 	%rd1964, %rd6201, %rd1963, %p454;
	shl.b64 	%rd1965, %rd1964, 1;
	sub.s64 	%rd1966, %rd1965, %rd182;
	mov.b64 	%fd1103, %rd1966;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2431}, %fd1103;
	}
	setp.lt.s32 	%p455, %r2431, 0;
	selp.b64 	%rd1967, %rd1965, %rd1966, %p455;
	shl.b64 	%rd1968, %rd1967, 1;
	sub.s64 	%rd1969, %rd1968, %rd182;
	mov.b64 	%fd1104, %rd1969;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2432}, %fd1104;
	}
	setp.lt.s32 	%p456, %r2432, 0;
	selp.b64 	%rd1970, %rd1968, %rd1969, %p456;
	shl.b64 	%rd1971, %rd1970, 1;
	sub.s64 	%rd1972, %rd1971, %rd182;
	mov.b64 	%fd1105, %rd1972;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2433}, %fd1105;
	}
	setp.lt.s32 	%p457, %r2433, 0;
	selp.b64 	%rd6204, %rd1971, %rd1972, %p457;
	shl.b64 	%rd6201, %rd6204, 1;
	add.s32 	%r6009, %r6009, -4;
	add.s32 	%r6008, %r6008, -1;
	setp.ne.s32 	%p458, %r6008, 0;
	@%p458 bra 	$L__BB0_229;

$L__BB0_230:
	setp.lt.u32 	%p459, %r284, 12;
	@%p459 bra 	$L__BB0_232;

$L__BB0_231:
	sub.s64 	%rd1973, %rd6201, %rd182;
	mov.b64 	%fd1106, %rd1973;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2434}, %fd1106;
	}
	setp.lt.s32 	%p460, %r2434, 0;
	selp.b64 	%rd1974, %rd6201, %rd1973, %p460;
	shl.b64 	%rd1975, %rd1974, 1;
	sub.s64 	%rd1976, %rd1975, %rd182;
	mov.b64 	%fd1107, %rd1976;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2435}, %fd1107;
	}
	setp.lt.s32 	%p461, %r2435, 0;
	selp.b64 	%rd1977, %rd1975, %rd1976, %p461;
	shl.b64 	%rd1978, %rd1977, 1;
	sub.s64 	%rd1979, %rd1978, %rd182;
	mov.b64 	%fd1108, %rd1979;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2436}, %fd1108;
	}
	setp.lt.s32 	%p462, %r2436, 0;
	selp.b64 	%rd1980, %rd1978, %rd1979, %p462;
	shl.b64 	%rd1981, %rd1980, 1;
	sub.s64 	%rd1982, %rd1981, %rd182;
	mov.b64 	%fd1109, %rd1982;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2437}, %fd1109;
	}
	setp.lt.s32 	%p463, %r2437, 0;
	selp.b64 	%rd1983, %rd1981, %rd1982, %p463;
	shl.b64 	%rd1984, %rd1983, 1;
	sub.s64 	%rd1985, %rd1984, %rd182;
	mov.b64 	%fd1110, %rd1985;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2438}, %fd1110;
	}
	setp.lt.s32 	%p464, %r2438, 0;
	selp.b64 	%rd1986, %rd1984, %rd1985, %p464;
	shl.b64 	%rd1987, %rd1986, 1;
	sub.s64 	%rd1988, %rd1987, %rd182;
	mov.b64 	%fd1111, %rd1988;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2439}, %fd1111;
	}
	setp.lt.s32 	%p465, %r2439, 0;
	selp.b64 	%rd1989, %rd1987, %rd1988, %p465;
	shl.b64 	%rd1990, %rd1989, 1;
	sub.s64 	%rd1991, %rd1990, %rd182;
	mov.b64 	%fd1112, %rd1991;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2440}, %fd1112;
	}
	setp.lt.s32 	%p466, %r2440, 0;
	selp.b64 	%rd1992, %rd1990, %rd1991, %p466;
	shl.b64 	%rd1993, %rd1992, 1;
	sub.s64 	%rd1994, %rd1993, %rd182;
	mov.b64 	%fd1113, %rd1994;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2441}, %fd1113;
	}
	setp.lt.s32 	%p467, %r2441, 0;
	selp.b64 	%rd1995, %rd1993, %rd1994, %p467;
	shl.b64 	%rd1996, %rd1995, 1;
	sub.s64 	%rd1997, %rd1996, %rd182;
	mov.b64 	%fd1114, %rd1997;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2442}, %fd1114;
	}
	setp.lt.s32 	%p468, %r2442, 0;
	selp.b64 	%rd1998, %rd1996, %rd1997, %p468;
	shl.b64 	%rd1999, %rd1998, 1;
	sub.s64 	%rd2000, %rd1999, %rd182;
	mov.b64 	%fd1115, %rd2000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2443}, %fd1115;
	}
	setp.lt.s32 	%p469, %r2443, 0;
	selp.b64 	%rd2001, %rd1999, %rd2000, %p469;
	shl.b64 	%rd2002, %rd2001, 1;
	sub.s64 	%rd2003, %rd2002, %rd182;
	mov.b64 	%fd1116, %rd2003;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2444}, %fd1116;
	}
	setp.lt.s32 	%p470, %r2444, 0;
	selp.b64 	%rd2004, %rd2002, %rd2003, %p470;
	shl.b64 	%rd2005, %rd2004, 1;
	sub.s64 	%rd2006, %rd2005, %rd182;
	mov.b64 	%fd1117, %rd2006;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2445}, %fd1117;
	}
	setp.lt.s32 	%p471, %r2445, 0;
	selp.b64 	%rd2007, %rd2005, %rd2006, %p471;
	shl.b64 	%rd2008, %rd2007, 1;
	sub.s64 	%rd2009, %rd2008, %rd182;
	mov.b64 	%fd1118, %rd2009;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2446}, %fd1118;
	}
	setp.lt.s32 	%p472, %r2446, 0;
	selp.b64 	%rd2010, %rd2008, %rd2009, %p472;
	shl.b64 	%rd2011, %rd2010, 1;
	sub.s64 	%rd2012, %rd2011, %rd182;
	mov.b64 	%fd1119, %rd2012;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2447}, %fd1119;
	}
	setp.lt.s32 	%p473, %r2447, 0;
	selp.b64 	%rd2013, %rd2011, %rd2012, %p473;
	shl.b64 	%rd2014, %rd2013, 1;
	sub.s64 	%rd2015, %rd2014, %rd182;
	mov.b64 	%fd1120, %rd2015;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2448}, %fd1120;
	}
	setp.lt.s32 	%p474, %r2448, 0;
	selp.b64 	%rd2016, %rd2014, %rd2015, %p474;
	shl.b64 	%rd2017, %rd2016, 1;
	sub.s64 	%rd2018, %rd2017, %rd182;
	mov.b64 	%fd1121, %rd2018;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2449}, %fd1121;
	}
	setp.lt.s32 	%p475, %r2449, 0;
	selp.b64 	%rd6204, %rd2017, %rd2018, %p475;
	shl.b64 	%rd6201, %rd6204, 1;
	add.s32 	%r292, %r6009, -16;
	setp.gt.s32 	%p476, %r6009, 15;
	mov.u32 	%r6009, %r292;
	@%p476 bra 	$L__BB0_231;

$L__BB0_232:
	and.b64  	%rd197, %rd6204, 9223372036854775807;
	setp.eq.s64 	%p477, %rd197, 0;
	mov.f64 	%fd2936, 0d0000000000000000;
	@%p477 bra 	$L__BB0_234;

	mov.b64 	%fd1123, %rd197;
	mul.f64 	%fd1124, %fd1123, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2450}, %fd1124;
	}
	shr.u32 	%r2451, %r2450, 20;
	mov.u32 	%r2452, 55;
	sub.s32 	%r2453, %r2452, %r2451;
	sub.s32 	%r2454, %r6003, %r2453;
	shl.b64 	%rd2019, %rd197, %r2453;
	setp.lt.s32 	%p478, %r2454, 1;
	mov.u32 	%r2455, 1;
	sub.s32 	%r2456, %r2455, %r2454;
	shr.u64 	%rd2020, %rd2019, %r2456;
	add.s32 	%r2457, %r2454, -1;
	cvt.u64.u32 	%rd2021, %r2457;
	shl.b64 	%rd2022, %rd2021, 52;
	add.s64 	%rd2023, %rd2022, %rd2019;
	selp.b64 	%rd2024, %rd2020, %rd2023, %p478;
	mov.b64 	%fd2936, %rd2024;

$L__BB0_234:
	and.b32  	%r2458, %r269, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2459}, %fd2936;
	}
	or.b32  	%r2460, %r2459, %r2458;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2461, %temp}, %fd2936;
	}
	mov.b64 	%fd2937, {%r2461, %r2460};
	bra.uni 	$L__BB0_238;

$L__BB0_236:
	mov.f64 	%fd1125, 0d3FF0000000000000;
	add.rn.f64 	%fd2937, %fd122, %fd1125;

$L__BB0_238:
	mov.f64 	%fd1126, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1127, %fd1126, %fd2937;
	mul.f64 	%fd1128, %fd1127, %fd51;
	mul.f64 	%fd1129, %fd1128, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 79 28
	add.s32 	%r2462, %r6047, 4;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 79 28
	cvt.rn.f64.s32 	%fd1130, %r2462;
	fma.rn.f64 	%fd133, %fd1130, 0d400921FB54442D18, %fd1129;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r293}, %fd133;
	}
	and.b32  	%r2463, %r293, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2464, %temp}, %fd133;
	}
	mov.b64 	%fd2938, {%r2464, %r2463};
	setp.gt.u32 	%p483, %r2463, 2146435071;
	or.pred  	%p485, %p483, %p18;
	@%p485 bra 	$L__BB0_255;
	bra.uni 	$L__BB0_239;

$L__BB0_255:
	.loc	1 0 9
	setp.le.f64 	%p520, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p521, %fd2938, 0d7FF0000000000000;
	and.pred  	%p522, %p521, %p520;
	@%p522 bra 	$L__BB0_257;
	bra.uni 	$L__BB0_256;

$L__BB0_257:
	setp.eq.f64 	%p523, %fd2938, 0d7FF0000000000000;
	selp.f64 	%fd2941, 0dFFF8000000000000, %fd133, %p523;
	bra.uni 	$L__BB0_258;

$L__BB0_239:
	.loc	1 0 9
	mov.f64 	%fd2941, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_258;

	setp.ltu.f64 	%p487, %fd2938, %fd3160;
	mov.f64 	%fd2941, %fd133;
	@%p487 bra 	$L__BB0_258;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2465}, %fd2938;
	}
	shr.u32 	%r6011, %r2465, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2466}, %fd3160;
	}
	shr.u32 	%r6012, %r2466, 20;
	setp.ne.s32 	%p488, %r6011, 0;
	@%p488 bra 	$L__BB0_243;

	mul.f64 	%fd2938, %fd2938, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2467}, %fd2938;
	}
	shr.u32 	%r2468, %r2467, 20;
	add.s32 	%r6011, %r2468, -54;

$L__BB0_243:
	setp.ne.s32 	%p489, %r6012, 0;
	mov.f64 	%fd2939, %fd3160;
	@%p489 bra 	$L__BB0_245;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2469}, %fd2;
	}
	shr.u32 	%r2470, %r2469, 20;
	add.s32 	%r6012, %r2470, -54;
	mov.f64 	%fd2939, %fd2;

$L__BB0_245:
	mov.b64 	%rd2026, %fd2938;
	and.b64  	%rd2027, %rd2026, 4503599627370495;
	or.b64  	%rd6209, %rd2027, 4503599627370496;
	mov.b64 	%rd2028, %fd2939;
	and.b64  	%rd2029, %rd2028, 4503599627370495;
	or.b64  	%rd199, %rd2029, 4503599627370496;
	sub.s32 	%r6018, %r6011, %r6012;
	not.b32 	%r2471, %r6011;
	add.s32 	%r2472, %r6012, %r2471;
	max.s32 	%r2473, %r2472, -1;
	add.s32 	%r301, %r2473, %r6011;
	mov.u32 	%r2474, 2;
	sub.s32 	%r2475, %r2474, %r6012;
	add.s32 	%r2476, %r2475, %r301;
	and.b32  	%r6014, %r2476, 3;
	setp.eq.s32 	%p490, %r6014, 0;
	@%p490 bra 	$L__BB0_247;

$L__BB0_246:
	.pragma "nounroll";
	sub.s64 	%rd2030, %rd6209, %rd199;
	mov.b64 	%fd1132, %rd2030;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2477}, %fd1132;
	}
	setp.lt.s32 	%p491, %r2477, 0;
	selp.b64 	%rd6212, %rd6209, %rd2030, %p491;
	shl.b64 	%rd6209, %rd6212, 1;
	add.s32 	%r6018, %r6018, -1;
	add.s32 	%r6014, %r6014, -1;
	setp.ne.s32 	%p492, %r6014, 0;
	@%p492 bra 	$L__BB0_246;

$L__BB0_247:
	mov.u32 	%r2478, 1;
	sub.s32 	%r2479, %r2478, %r6012;
	add.s32 	%r2480, %r2479, %r301;
	setp.lt.u32 	%p493, %r2480, 3;
	@%p493 bra 	$L__BB0_252;

	not.b32 	%r2481, %r6018;
	max.s32 	%r2482, %r2481, -4;
	add.s32 	%r2483, %r6018, %r2482;
	add.s32 	%r308, %r2483, 4;
	shr.u32 	%r2484, %r308, 2;
	add.s32 	%r2485, %r2484, 1;
	and.b32  	%r6017, %r2485, 3;
	setp.eq.s32 	%p494, %r6017, 0;
	@%p494 bra 	$L__BB0_250;

$L__BB0_249:
	.pragma "nounroll";
	sub.s64 	%rd2032, %rd6209, %rd199;
	mov.b64 	%fd1133, %rd2032;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2486}, %fd1133;
	}
	setp.lt.s32 	%p495, %r2486, 0;
	selp.b64 	%rd2033, %rd6209, %rd2032, %p495;
	shl.b64 	%rd2034, %rd2033, 1;
	sub.s64 	%rd2035, %rd2034, %rd199;
	mov.b64 	%fd1134, %rd2035;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2487}, %fd1134;
	}
	setp.lt.s32 	%p496, %r2487, 0;
	selp.b64 	%rd2036, %rd2034, %rd2035, %p496;
	shl.b64 	%rd2037, %rd2036, 1;
	sub.s64 	%rd2038, %rd2037, %rd199;
	mov.b64 	%fd1135, %rd2038;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2488}, %fd1135;
	}
	setp.lt.s32 	%p497, %r2488, 0;
	selp.b64 	%rd2039, %rd2037, %rd2038, %p497;
	shl.b64 	%rd2040, %rd2039, 1;
	sub.s64 	%rd2041, %rd2040, %rd199;
	mov.b64 	%fd1136, %rd2041;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2489}, %fd1136;
	}
	setp.lt.s32 	%p498, %r2489, 0;
	selp.b64 	%rd6212, %rd2040, %rd2041, %p498;
	shl.b64 	%rd6209, %rd6212, 1;
	add.s32 	%r6018, %r6018, -4;
	add.s32 	%r6017, %r6017, -1;
	setp.ne.s32 	%p499, %r6017, 0;
	@%p499 bra 	$L__BB0_249;

$L__BB0_250:
	setp.lt.u32 	%p500, %r308, 12;
	@%p500 bra 	$L__BB0_252;

$L__BB0_251:
	sub.s64 	%rd2042, %rd6209, %rd199;
	mov.b64 	%fd1137, %rd2042;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2490}, %fd1137;
	}
	setp.lt.s32 	%p501, %r2490, 0;
	selp.b64 	%rd2043, %rd6209, %rd2042, %p501;
	shl.b64 	%rd2044, %rd2043, 1;
	sub.s64 	%rd2045, %rd2044, %rd199;
	mov.b64 	%fd1138, %rd2045;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2491}, %fd1138;
	}
	setp.lt.s32 	%p502, %r2491, 0;
	selp.b64 	%rd2046, %rd2044, %rd2045, %p502;
	shl.b64 	%rd2047, %rd2046, 1;
	sub.s64 	%rd2048, %rd2047, %rd199;
	mov.b64 	%fd1139, %rd2048;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2492}, %fd1139;
	}
	setp.lt.s32 	%p503, %r2492, 0;
	selp.b64 	%rd2049, %rd2047, %rd2048, %p503;
	shl.b64 	%rd2050, %rd2049, 1;
	sub.s64 	%rd2051, %rd2050, %rd199;
	mov.b64 	%fd1140, %rd2051;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2493}, %fd1140;
	}
	setp.lt.s32 	%p504, %r2493, 0;
	selp.b64 	%rd2052, %rd2050, %rd2051, %p504;
	shl.b64 	%rd2053, %rd2052, 1;
	sub.s64 	%rd2054, %rd2053, %rd199;
	mov.b64 	%fd1141, %rd2054;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2494}, %fd1141;
	}
	setp.lt.s32 	%p505, %r2494, 0;
	selp.b64 	%rd2055, %rd2053, %rd2054, %p505;
	shl.b64 	%rd2056, %rd2055, 1;
	sub.s64 	%rd2057, %rd2056, %rd199;
	mov.b64 	%fd1142, %rd2057;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2495}, %fd1142;
	}
	setp.lt.s32 	%p506, %r2495, 0;
	selp.b64 	%rd2058, %rd2056, %rd2057, %p506;
	shl.b64 	%rd2059, %rd2058, 1;
	sub.s64 	%rd2060, %rd2059, %rd199;
	mov.b64 	%fd1143, %rd2060;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2496}, %fd1143;
	}
	setp.lt.s32 	%p507, %r2496, 0;
	selp.b64 	%rd2061, %rd2059, %rd2060, %p507;
	shl.b64 	%rd2062, %rd2061, 1;
	sub.s64 	%rd2063, %rd2062, %rd199;
	mov.b64 	%fd1144, %rd2063;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2497}, %fd1144;
	}
	setp.lt.s32 	%p508, %r2497, 0;
	selp.b64 	%rd2064, %rd2062, %rd2063, %p508;
	shl.b64 	%rd2065, %rd2064, 1;
	sub.s64 	%rd2066, %rd2065, %rd199;
	mov.b64 	%fd1145, %rd2066;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2498}, %fd1145;
	}
	setp.lt.s32 	%p509, %r2498, 0;
	selp.b64 	%rd2067, %rd2065, %rd2066, %p509;
	shl.b64 	%rd2068, %rd2067, 1;
	sub.s64 	%rd2069, %rd2068, %rd199;
	mov.b64 	%fd1146, %rd2069;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2499}, %fd1146;
	}
	setp.lt.s32 	%p510, %r2499, 0;
	selp.b64 	%rd2070, %rd2068, %rd2069, %p510;
	shl.b64 	%rd2071, %rd2070, 1;
	sub.s64 	%rd2072, %rd2071, %rd199;
	mov.b64 	%fd1147, %rd2072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2500}, %fd1147;
	}
	setp.lt.s32 	%p511, %r2500, 0;
	selp.b64 	%rd2073, %rd2071, %rd2072, %p511;
	shl.b64 	%rd2074, %rd2073, 1;
	sub.s64 	%rd2075, %rd2074, %rd199;
	mov.b64 	%fd1148, %rd2075;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2501}, %fd1148;
	}
	setp.lt.s32 	%p512, %r2501, 0;
	selp.b64 	%rd2076, %rd2074, %rd2075, %p512;
	shl.b64 	%rd2077, %rd2076, 1;
	sub.s64 	%rd2078, %rd2077, %rd199;
	mov.b64 	%fd1149, %rd2078;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2502}, %fd1149;
	}
	setp.lt.s32 	%p513, %r2502, 0;
	selp.b64 	%rd2079, %rd2077, %rd2078, %p513;
	shl.b64 	%rd2080, %rd2079, 1;
	sub.s64 	%rd2081, %rd2080, %rd199;
	mov.b64 	%fd1150, %rd2081;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2503}, %fd1150;
	}
	setp.lt.s32 	%p514, %r2503, 0;
	selp.b64 	%rd2082, %rd2080, %rd2081, %p514;
	shl.b64 	%rd2083, %rd2082, 1;
	sub.s64 	%rd2084, %rd2083, %rd199;
	mov.b64 	%fd1151, %rd2084;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2504}, %fd1151;
	}
	setp.lt.s32 	%p515, %r2504, 0;
	selp.b64 	%rd2085, %rd2083, %rd2084, %p515;
	shl.b64 	%rd2086, %rd2085, 1;
	sub.s64 	%rd2087, %rd2086, %rd199;
	mov.b64 	%fd1152, %rd2087;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2505}, %fd1152;
	}
	setp.lt.s32 	%p516, %r2505, 0;
	selp.b64 	%rd6212, %rd2086, %rd2087, %p516;
	shl.b64 	%rd6209, %rd6212, 1;
	add.s32 	%r316, %r6018, -16;
	setp.gt.s32 	%p517, %r6018, 15;
	mov.u32 	%r6018, %r316;
	@%p517 bra 	$L__BB0_251;

$L__BB0_252:
	and.b64  	%rd214, %rd6212, 9223372036854775807;
	setp.eq.s64 	%p518, %rd214, 0;
	mov.f64 	%fd2940, 0d0000000000000000;
	@%p518 bra 	$L__BB0_254;

	mov.b64 	%fd1154, %rd214;
	mul.f64 	%fd1155, %fd1154, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2506}, %fd1155;
	}
	shr.u32 	%r2507, %r2506, 20;
	mov.u32 	%r2508, 55;
	sub.s32 	%r2509, %r2508, %r2507;
	sub.s32 	%r2510, %r6012, %r2509;
	shl.b64 	%rd2088, %rd214, %r2509;
	setp.lt.s32 	%p519, %r2510, 1;
	mov.u32 	%r2511, 1;
	sub.s32 	%r2512, %r2511, %r2510;
	shr.u64 	%rd2089, %rd2088, %r2512;
	add.s32 	%r2513, %r2510, -1;
	cvt.u64.u32 	%rd2090, %r2513;
	shl.b64 	%rd2091, %rd2090, 52;
	add.s64 	%rd2092, %rd2091, %rd2088;
	selp.b64 	%rd2093, %rd2089, %rd2092, %p519;
	mov.b64 	%fd2940, %rd2093;

$L__BB0_254:
	and.b32  	%r2514, %r293, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2515}, %fd2940;
	}
	or.b32  	%r2516, %r2515, %r2514;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2517, %temp}, %fd2940;
	}
	mov.b64 	%fd2941, {%r2517, %r2516};
	bra.uni 	$L__BB0_258;

$L__BB0_256:
	mov.f64 	%fd1156, 0d3FF0000000000000;
	add.rn.f64 	%fd2941, %fd133, %fd1156;

$L__BB0_258:
	mov.f64 	%fd1157, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1158, %fd1157, %fd2941;
	mul.f64 	%fd1159, %fd1158, %fd63;
	mul.f64 	%fd1160, %fd1159, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 79 28
	add.s32 	%r2518, %r6047, 3;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 79 28
	cvt.rn.f64.s32 	%fd1161, %r2518;
	fma.rn.f64 	%fd144, %fd1161, 0d400921FB54442D18, %fd1160;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r317}, %fd144;
	}
	and.b32  	%r2519, %r317, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2520, %temp}, %fd144;
	}
	mov.b64 	%fd2942, {%r2520, %r2519};
	setp.gt.u32 	%p524, %r2519, 2146435071;
	or.pred  	%p526, %p524, %p18;
	@%p526 bra 	$L__BB0_275;
	bra.uni 	$L__BB0_259;

$L__BB0_275:
	.loc	1 0 9
	setp.le.f64 	%p561, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p562, %fd2942, 0d7FF0000000000000;
	and.pred  	%p563, %p562, %p561;
	@%p563 bra 	$L__BB0_277;
	bra.uni 	$L__BB0_276;

$L__BB0_277:
	setp.eq.f64 	%p564, %fd2942, 0d7FF0000000000000;
	selp.f64 	%fd2945, 0dFFF8000000000000, %fd144, %p564;
	bra.uni 	$L__BB0_278;

$L__BB0_259:
	.loc	1 0 9
	mov.f64 	%fd2945, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_278;

	setp.ltu.f64 	%p528, %fd2942, %fd3160;
	mov.f64 	%fd2945, %fd144;
	@%p528 bra 	$L__BB0_278;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2521}, %fd2942;
	}
	shr.u32 	%r6020, %r2521, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2522}, %fd3160;
	}
	shr.u32 	%r6021, %r2522, 20;
	setp.ne.s32 	%p529, %r6020, 0;
	@%p529 bra 	$L__BB0_263;

	mul.f64 	%fd2942, %fd2942, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2523}, %fd2942;
	}
	shr.u32 	%r2524, %r2523, 20;
	add.s32 	%r6020, %r2524, -54;

$L__BB0_263:
	setp.ne.s32 	%p530, %r6021, 0;
	mov.f64 	%fd2943, %fd3160;
	@%p530 bra 	$L__BB0_265;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2525}, %fd2;
	}
	shr.u32 	%r2526, %r2525, 20;
	add.s32 	%r6021, %r2526, -54;
	mov.f64 	%fd2943, %fd2;

$L__BB0_265:
	mov.b64 	%rd2095, %fd2942;
	and.b64  	%rd2096, %rd2095, 4503599627370495;
	or.b64  	%rd6217, %rd2096, 4503599627370496;
	mov.b64 	%rd2097, %fd2943;
	and.b64  	%rd2098, %rd2097, 4503599627370495;
	or.b64  	%rd216, %rd2098, 4503599627370496;
	sub.s32 	%r6027, %r6020, %r6021;
	not.b32 	%r2527, %r6020;
	add.s32 	%r2528, %r6021, %r2527;
	max.s32 	%r2529, %r2528, -1;
	add.s32 	%r325, %r2529, %r6020;
	mov.u32 	%r2530, 2;
	sub.s32 	%r2531, %r2530, %r6021;
	add.s32 	%r2532, %r2531, %r325;
	and.b32  	%r6023, %r2532, 3;
	setp.eq.s32 	%p531, %r6023, 0;
	@%p531 bra 	$L__BB0_267;

$L__BB0_266:
	.pragma "nounroll";
	sub.s64 	%rd2099, %rd6217, %rd216;
	mov.b64 	%fd1163, %rd2099;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2533}, %fd1163;
	}
	setp.lt.s32 	%p532, %r2533, 0;
	selp.b64 	%rd6220, %rd6217, %rd2099, %p532;
	shl.b64 	%rd6217, %rd6220, 1;
	add.s32 	%r6027, %r6027, -1;
	add.s32 	%r6023, %r6023, -1;
	setp.ne.s32 	%p533, %r6023, 0;
	@%p533 bra 	$L__BB0_266;

$L__BB0_267:
	mov.u32 	%r2534, 1;
	sub.s32 	%r2535, %r2534, %r6021;
	add.s32 	%r2536, %r2535, %r325;
	setp.lt.u32 	%p534, %r2536, 3;
	@%p534 bra 	$L__BB0_272;

	not.b32 	%r2537, %r6027;
	max.s32 	%r2538, %r2537, -4;
	add.s32 	%r2539, %r6027, %r2538;
	add.s32 	%r332, %r2539, 4;
	shr.u32 	%r2540, %r332, 2;
	add.s32 	%r2541, %r2540, 1;
	and.b32  	%r6026, %r2541, 3;
	setp.eq.s32 	%p535, %r6026, 0;
	@%p535 bra 	$L__BB0_270;

$L__BB0_269:
	.pragma "nounroll";
	sub.s64 	%rd2101, %rd6217, %rd216;
	mov.b64 	%fd1164, %rd2101;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2542}, %fd1164;
	}
	setp.lt.s32 	%p536, %r2542, 0;
	selp.b64 	%rd2102, %rd6217, %rd2101, %p536;
	shl.b64 	%rd2103, %rd2102, 1;
	sub.s64 	%rd2104, %rd2103, %rd216;
	mov.b64 	%fd1165, %rd2104;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2543}, %fd1165;
	}
	setp.lt.s32 	%p537, %r2543, 0;
	selp.b64 	%rd2105, %rd2103, %rd2104, %p537;
	shl.b64 	%rd2106, %rd2105, 1;
	sub.s64 	%rd2107, %rd2106, %rd216;
	mov.b64 	%fd1166, %rd2107;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2544}, %fd1166;
	}
	setp.lt.s32 	%p538, %r2544, 0;
	selp.b64 	%rd2108, %rd2106, %rd2107, %p538;
	shl.b64 	%rd2109, %rd2108, 1;
	sub.s64 	%rd2110, %rd2109, %rd216;
	mov.b64 	%fd1167, %rd2110;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2545}, %fd1167;
	}
	setp.lt.s32 	%p539, %r2545, 0;
	selp.b64 	%rd6220, %rd2109, %rd2110, %p539;
	shl.b64 	%rd6217, %rd6220, 1;
	add.s32 	%r6027, %r6027, -4;
	add.s32 	%r6026, %r6026, -1;
	setp.ne.s32 	%p540, %r6026, 0;
	@%p540 bra 	$L__BB0_269;

$L__BB0_270:
	setp.lt.u32 	%p541, %r332, 12;
	@%p541 bra 	$L__BB0_272;

$L__BB0_271:
	sub.s64 	%rd2111, %rd6217, %rd216;
	mov.b64 	%fd1168, %rd2111;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2546}, %fd1168;
	}
	setp.lt.s32 	%p542, %r2546, 0;
	selp.b64 	%rd2112, %rd6217, %rd2111, %p542;
	shl.b64 	%rd2113, %rd2112, 1;
	sub.s64 	%rd2114, %rd2113, %rd216;
	mov.b64 	%fd1169, %rd2114;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2547}, %fd1169;
	}
	setp.lt.s32 	%p543, %r2547, 0;
	selp.b64 	%rd2115, %rd2113, %rd2114, %p543;
	shl.b64 	%rd2116, %rd2115, 1;
	sub.s64 	%rd2117, %rd2116, %rd216;
	mov.b64 	%fd1170, %rd2117;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2548}, %fd1170;
	}
	setp.lt.s32 	%p544, %r2548, 0;
	selp.b64 	%rd2118, %rd2116, %rd2117, %p544;
	shl.b64 	%rd2119, %rd2118, 1;
	sub.s64 	%rd2120, %rd2119, %rd216;
	mov.b64 	%fd1171, %rd2120;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2549}, %fd1171;
	}
	setp.lt.s32 	%p545, %r2549, 0;
	selp.b64 	%rd2121, %rd2119, %rd2120, %p545;
	shl.b64 	%rd2122, %rd2121, 1;
	sub.s64 	%rd2123, %rd2122, %rd216;
	mov.b64 	%fd1172, %rd2123;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2550}, %fd1172;
	}
	setp.lt.s32 	%p546, %r2550, 0;
	selp.b64 	%rd2124, %rd2122, %rd2123, %p546;
	shl.b64 	%rd2125, %rd2124, 1;
	sub.s64 	%rd2126, %rd2125, %rd216;
	mov.b64 	%fd1173, %rd2126;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2551}, %fd1173;
	}
	setp.lt.s32 	%p547, %r2551, 0;
	selp.b64 	%rd2127, %rd2125, %rd2126, %p547;
	shl.b64 	%rd2128, %rd2127, 1;
	sub.s64 	%rd2129, %rd2128, %rd216;
	mov.b64 	%fd1174, %rd2129;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2552}, %fd1174;
	}
	setp.lt.s32 	%p548, %r2552, 0;
	selp.b64 	%rd2130, %rd2128, %rd2129, %p548;
	shl.b64 	%rd2131, %rd2130, 1;
	sub.s64 	%rd2132, %rd2131, %rd216;
	mov.b64 	%fd1175, %rd2132;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2553}, %fd1175;
	}
	setp.lt.s32 	%p549, %r2553, 0;
	selp.b64 	%rd2133, %rd2131, %rd2132, %p549;
	shl.b64 	%rd2134, %rd2133, 1;
	sub.s64 	%rd2135, %rd2134, %rd216;
	mov.b64 	%fd1176, %rd2135;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2554}, %fd1176;
	}
	setp.lt.s32 	%p550, %r2554, 0;
	selp.b64 	%rd2136, %rd2134, %rd2135, %p550;
	shl.b64 	%rd2137, %rd2136, 1;
	sub.s64 	%rd2138, %rd2137, %rd216;
	mov.b64 	%fd1177, %rd2138;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2555}, %fd1177;
	}
	setp.lt.s32 	%p551, %r2555, 0;
	selp.b64 	%rd2139, %rd2137, %rd2138, %p551;
	shl.b64 	%rd2140, %rd2139, 1;
	sub.s64 	%rd2141, %rd2140, %rd216;
	mov.b64 	%fd1178, %rd2141;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2556}, %fd1178;
	}
	setp.lt.s32 	%p552, %r2556, 0;
	selp.b64 	%rd2142, %rd2140, %rd2141, %p552;
	shl.b64 	%rd2143, %rd2142, 1;
	sub.s64 	%rd2144, %rd2143, %rd216;
	mov.b64 	%fd1179, %rd2144;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2557}, %fd1179;
	}
	setp.lt.s32 	%p553, %r2557, 0;
	selp.b64 	%rd2145, %rd2143, %rd2144, %p553;
	shl.b64 	%rd2146, %rd2145, 1;
	sub.s64 	%rd2147, %rd2146, %rd216;
	mov.b64 	%fd1180, %rd2147;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2558}, %fd1180;
	}
	setp.lt.s32 	%p554, %r2558, 0;
	selp.b64 	%rd2148, %rd2146, %rd2147, %p554;
	shl.b64 	%rd2149, %rd2148, 1;
	sub.s64 	%rd2150, %rd2149, %rd216;
	mov.b64 	%fd1181, %rd2150;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2559}, %fd1181;
	}
	setp.lt.s32 	%p555, %r2559, 0;
	selp.b64 	%rd2151, %rd2149, %rd2150, %p555;
	shl.b64 	%rd2152, %rd2151, 1;
	sub.s64 	%rd2153, %rd2152, %rd216;
	mov.b64 	%fd1182, %rd2153;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2560}, %fd1182;
	}
	setp.lt.s32 	%p556, %r2560, 0;
	selp.b64 	%rd2154, %rd2152, %rd2153, %p556;
	shl.b64 	%rd2155, %rd2154, 1;
	sub.s64 	%rd2156, %rd2155, %rd216;
	mov.b64 	%fd1183, %rd2156;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2561}, %fd1183;
	}
	setp.lt.s32 	%p557, %r2561, 0;
	selp.b64 	%rd6220, %rd2155, %rd2156, %p557;
	shl.b64 	%rd6217, %rd6220, 1;
	add.s32 	%r340, %r6027, -16;
	setp.gt.s32 	%p558, %r6027, 15;
	mov.u32 	%r6027, %r340;
	@%p558 bra 	$L__BB0_271;

$L__BB0_272:
	and.b64  	%rd231, %rd6220, 9223372036854775807;
	setp.eq.s64 	%p559, %rd231, 0;
	mov.f64 	%fd2944, 0d0000000000000000;
	@%p559 bra 	$L__BB0_274;

	mov.b64 	%fd1185, %rd231;
	mul.f64 	%fd1186, %fd1185, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2562}, %fd1186;
	}
	shr.u32 	%r2563, %r2562, 20;
	mov.u32 	%r2564, 55;
	sub.s32 	%r2565, %r2564, %r2563;
	sub.s32 	%r2566, %r6021, %r2565;
	shl.b64 	%rd2157, %rd231, %r2565;
	setp.lt.s32 	%p560, %r2566, 1;
	mov.u32 	%r2567, 1;
	sub.s32 	%r2568, %r2567, %r2566;
	shr.u64 	%rd2158, %rd2157, %r2568;
	add.s32 	%r2569, %r2566, -1;
	cvt.u64.u32 	%rd2159, %r2569;
	shl.b64 	%rd2160, %rd2159, 52;
	add.s64 	%rd2161, %rd2160, %rd2157;
	selp.b64 	%rd2162, %rd2158, %rd2161, %p560;
	mov.b64 	%fd2944, %rd2162;

$L__BB0_274:
	and.b32  	%r2570, %r317, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2571}, %fd2944;
	}
	or.b32  	%r2572, %r2571, %r2570;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2573, %temp}, %fd2944;
	}
	mov.b64 	%fd2945, {%r2573, %r2572};
	bra.uni 	$L__BB0_278;

$L__BB0_276:
	mov.f64 	%fd1187, 0d3FF0000000000000;
	add.rn.f64 	%fd2945, %fd144, %fd1187;

$L__BB0_278:
	mov.f64 	%fd1188, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1189, %fd1188, %fd2945;
	mul.f64 	%fd1190, %fd1189, %fd75;
	mul.f64 	%fd1191, %fd1190, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 79 28
	add.s32 	%r2574, %r6047, 2;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 79 28
	cvt.rn.f64.s32 	%fd1192, %r2574;
	fma.rn.f64 	%fd155, %fd1192, 0d400921FB54442D18, %fd1191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r341}, %fd155;
	}
	and.b32  	%r2575, %r341, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2576, %temp}, %fd155;
	}
	mov.b64 	%fd2946, {%r2576, %r2575};
	setp.gt.u32 	%p565, %r2575, 2146435071;
	or.pred  	%p567, %p565, %p18;
	@%p567 bra 	$L__BB0_295;
	bra.uni 	$L__BB0_279;

$L__BB0_295:
	.loc	1 0 9
	setp.le.f64 	%p602, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p603, %fd2946, 0d7FF0000000000000;
	and.pred  	%p604, %p603, %p602;
	@%p604 bra 	$L__BB0_297;
	bra.uni 	$L__BB0_296;

$L__BB0_297:
	setp.eq.f64 	%p605, %fd2946, 0d7FF0000000000000;
	selp.f64 	%fd2949, 0dFFF8000000000000, %fd155, %p605;
	bra.uni 	$L__BB0_298;

$L__BB0_279:
	.loc	1 0 9
	mov.f64 	%fd2949, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_298;

	setp.ltu.f64 	%p569, %fd2946, %fd3160;
	mov.f64 	%fd2949, %fd155;
	@%p569 bra 	$L__BB0_298;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2577}, %fd2946;
	}
	shr.u32 	%r6029, %r2577, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2578}, %fd3160;
	}
	shr.u32 	%r6030, %r2578, 20;
	setp.ne.s32 	%p570, %r6029, 0;
	@%p570 bra 	$L__BB0_283;

	mul.f64 	%fd2946, %fd2946, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2579}, %fd2946;
	}
	shr.u32 	%r2580, %r2579, 20;
	add.s32 	%r6029, %r2580, -54;

$L__BB0_283:
	setp.ne.s32 	%p571, %r6030, 0;
	mov.f64 	%fd2947, %fd3160;
	@%p571 bra 	$L__BB0_285;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2581}, %fd2;
	}
	shr.u32 	%r2582, %r2581, 20;
	add.s32 	%r6030, %r2582, -54;
	mov.f64 	%fd2947, %fd2;

$L__BB0_285:
	mov.b64 	%rd2164, %fd2946;
	and.b64  	%rd2165, %rd2164, 4503599627370495;
	or.b64  	%rd6225, %rd2165, 4503599627370496;
	mov.b64 	%rd2166, %fd2947;
	and.b64  	%rd2167, %rd2166, 4503599627370495;
	or.b64  	%rd233, %rd2167, 4503599627370496;
	sub.s32 	%r6036, %r6029, %r6030;
	not.b32 	%r2583, %r6029;
	add.s32 	%r2584, %r6030, %r2583;
	max.s32 	%r2585, %r2584, -1;
	add.s32 	%r349, %r2585, %r6029;
	mov.u32 	%r2586, 2;
	sub.s32 	%r2587, %r2586, %r6030;
	add.s32 	%r2588, %r2587, %r349;
	and.b32  	%r6032, %r2588, 3;
	setp.eq.s32 	%p572, %r6032, 0;
	@%p572 bra 	$L__BB0_287;

$L__BB0_286:
	.pragma "nounroll";
	sub.s64 	%rd2168, %rd6225, %rd233;
	mov.b64 	%fd1194, %rd2168;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2589}, %fd1194;
	}
	setp.lt.s32 	%p573, %r2589, 0;
	selp.b64 	%rd6228, %rd6225, %rd2168, %p573;
	shl.b64 	%rd6225, %rd6228, 1;
	add.s32 	%r6036, %r6036, -1;
	add.s32 	%r6032, %r6032, -1;
	setp.ne.s32 	%p574, %r6032, 0;
	@%p574 bra 	$L__BB0_286;

$L__BB0_287:
	mov.u32 	%r2590, 1;
	sub.s32 	%r2591, %r2590, %r6030;
	add.s32 	%r2592, %r2591, %r349;
	setp.lt.u32 	%p575, %r2592, 3;
	@%p575 bra 	$L__BB0_292;

	not.b32 	%r2593, %r6036;
	max.s32 	%r2594, %r2593, -4;
	add.s32 	%r2595, %r6036, %r2594;
	add.s32 	%r356, %r2595, 4;
	shr.u32 	%r2596, %r356, 2;
	add.s32 	%r2597, %r2596, 1;
	and.b32  	%r6035, %r2597, 3;
	setp.eq.s32 	%p576, %r6035, 0;
	@%p576 bra 	$L__BB0_290;

$L__BB0_289:
	.pragma "nounroll";
	sub.s64 	%rd2170, %rd6225, %rd233;
	mov.b64 	%fd1195, %rd2170;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2598}, %fd1195;
	}
	setp.lt.s32 	%p577, %r2598, 0;
	selp.b64 	%rd2171, %rd6225, %rd2170, %p577;
	shl.b64 	%rd2172, %rd2171, 1;
	sub.s64 	%rd2173, %rd2172, %rd233;
	mov.b64 	%fd1196, %rd2173;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2599}, %fd1196;
	}
	setp.lt.s32 	%p578, %r2599, 0;
	selp.b64 	%rd2174, %rd2172, %rd2173, %p578;
	shl.b64 	%rd2175, %rd2174, 1;
	sub.s64 	%rd2176, %rd2175, %rd233;
	mov.b64 	%fd1197, %rd2176;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2600}, %fd1197;
	}
	setp.lt.s32 	%p579, %r2600, 0;
	selp.b64 	%rd2177, %rd2175, %rd2176, %p579;
	shl.b64 	%rd2178, %rd2177, 1;
	sub.s64 	%rd2179, %rd2178, %rd233;
	mov.b64 	%fd1198, %rd2179;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2601}, %fd1198;
	}
	setp.lt.s32 	%p580, %r2601, 0;
	selp.b64 	%rd6228, %rd2178, %rd2179, %p580;
	shl.b64 	%rd6225, %rd6228, 1;
	add.s32 	%r6036, %r6036, -4;
	add.s32 	%r6035, %r6035, -1;
	setp.ne.s32 	%p581, %r6035, 0;
	@%p581 bra 	$L__BB0_289;

$L__BB0_290:
	setp.lt.u32 	%p582, %r356, 12;
	@%p582 bra 	$L__BB0_292;

$L__BB0_291:
	sub.s64 	%rd2180, %rd6225, %rd233;
	mov.b64 	%fd1199, %rd2180;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2602}, %fd1199;
	}
	setp.lt.s32 	%p583, %r2602, 0;
	selp.b64 	%rd2181, %rd6225, %rd2180, %p583;
	shl.b64 	%rd2182, %rd2181, 1;
	sub.s64 	%rd2183, %rd2182, %rd233;
	mov.b64 	%fd1200, %rd2183;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2603}, %fd1200;
	}
	setp.lt.s32 	%p584, %r2603, 0;
	selp.b64 	%rd2184, %rd2182, %rd2183, %p584;
	shl.b64 	%rd2185, %rd2184, 1;
	sub.s64 	%rd2186, %rd2185, %rd233;
	mov.b64 	%fd1201, %rd2186;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2604}, %fd1201;
	}
	setp.lt.s32 	%p585, %r2604, 0;
	selp.b64 	%rd2187, %rd2185, %rd2186, %p585;
	shl.b64 	%rd2188, %rd2187, 1;
	sub.s64 	%rd2189, %rd2188, %rd233;
	mov.b64 	%fd1202, %rd2189;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2605}, %fd1202;
	}
	setp.lt.s32 	%p586, %r2605, 0;
	selp.b64 	%rd2190, %rd2188, %rd2189, %p586;
	shl.b64 	%rd2191, %rd2190, 1;
	sub.s64 	%rd2192, %rd2191, %rd233;
	mov.b64 	%fd1203, %rd2192;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2606}, %fd1203;
	}
	setp.lt.s32 	%p587, %r2606, 0;
	selp.b64 	%rd2193, %rd2191, %rd2192, %p587;
	shl.b64 	%rd2194, %rd2193, 1;
	sub.s64 	%rd2195, %rd2194, %rd233;
	mov.b64 	%fd1204, %rd2195;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2607}, %fd1204;
	}
	setp.lt.s32 	%p588, %r2607, 0;
	selp.b64 	%rd2196, %rd2194, %rd2195, %p588;
	shl.b64 	%rd2197, %rd2196, 1;
	sub.s64 	%rd2198, %rd2197, %rd233;
	mov.b64 	%fd1205, %rd2198;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2608}, %fd1205;
	}
	setp.lt.s32 	%p589, %r2608, 0;
	selp.b64 	%rd2199, %rd2197, %rd2198, %p589;
	shl.b64 	%rd2200, %rd2199, 1;
	sub.s64 	%rd2201, %rd2200, %rd233;
	mov.b64 	%fd1206, %rd2201;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2609}, %fd1206;
	}
	setp.lt.s32 	%p590, %r2609, 0;
	selp.b64 	%rd2202, %rd2200, %rd2201, %p590;
	shl.b64 	%rd2203, %rd2202, 1;
	sub.s64 	%rd2204, %rd2203, %rd233;
	mov.b64 	%fd1207, %rd2204;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2610}, %fd1207;
	}
	setp.lt.s32 	%p591, %r2610, 0;
	selp.b64 	%rd2205, %rd2203, %rd2204, %p591;
	shl.b64 	%rd2206, %rd2205, 1;
	sub.s64 	%rd2207, %rd2206, %rd233;
	mov.b64 	%fd1208, %rd2207;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2611}, %fd1208;
	}
	setp.lt.s32 	%p592, %r2611, 0;
	selp.b64 	%rd2208, %rd2206, %rd2207, %p592;
	shl.b64 	%rd2209, %rd2208, 1;
	sub.s64 	%rd2210, %rd2209, %rd233;
	mov.b64 	%fd1209, %rd2210;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2612}, %fd1209;
	}
	setp.lt.s32 	%p593, %r2612, 0;
	selp.b64 	%rd2211, %rd2209, %rd2210, %p593;
	shl.b64 	%rd2212, %rd2211, 1;
	sub.s64 	%rd2213, %rd2212, %rd233;
	mov.b64 	%fd1210, %rd2213;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2613}, %fd1210;
	}
	setp.lt.s32 	%p594, %r2613, 0;
	selp.b64 	%rd2214, %rd2212, %rd2213, %p594;
	shl.b64 	%rd2215, %rd2214, 1;
	sub.s64 	%rd2216, %rd2215, %rd233;
	mov.b64 	%fd1211, %rd2216;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2614}, %fd1211;
	}
	setp.lt.s32 	%p595, %r2614, 0;
	selp.b64 	%rd2217, %rd2215, %rd2216, %p595;
	shl.b64 	%rd2218, %rd2217, 1;
	sub.s64 	%rd2219, %rd2218, %rd233;
	mov.b64 	%fd1212, %rd2219;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2615}, %fd1212;
	}
	setp.lt.s32 	%p596, %r2615, 0;
	selp.b64 	%rd2220, %rd2218, %rd2219, %p596;
	shl.b64 	%rd2221, %rd2220, 1;
	sub.s64 	%rd2222, %rd2221, %rd233;
	mov.b64 	%fd1213, %rd2222;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2616}, %fd1213;
	}
	setp.lt.s32 	%p597, %r2616, 0;
	selp.b64 	%rd2223, %rd2221, %rd2222, %p597;
	shl.b64 	%rd2224, %rd2223, 1;
	sub.s64 	%rd2225, %rd2224, %rd233;
	mov.b64 	%fd1214, %rd2225;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2617}, %fd1214;
	}
	setp.lt.s32 	%p598, %r2617, 0;
	selp.b64 	%rd6228, %rd2224, %rd2225, %p598;
	shl.b64 	%rd6225, %rd6228, 1;
	add.s32 	%r364, %r6036, -16;
	setp.gt.s32 	%p599, %r6036, 15;
	mov.u32 	%r6036, %r364;
	@%p599 bra 	$L__BB0_291;

$L__BB0_292:
	and.b64  	%rd248, %rd6228, 9223372036854775807;
	setp.eq.s64 	%p600, %rd248, 0;
	mov.f64 	%fd2948, 0d0000000000000000;
	@%p600 bra 	$L__BB0_294;

	mov.b64 	%fd1216, %rd248;
	mul.f64 	%fd1217, %fd1216, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2618}, %fd1217;
	}
	shr.u32 	%r2619, %r2618, 20;
	mov.u32 	%r2620, 55;
	sub.s32 	%r2621, %r2620, %r2619;
	sub.s32 	%r2622, %r6030, %r2621;
	shl.b64 	%rd2226, %rd248, %r2621;
	setp.lt.s32 	%p601, %r2622, 1;
	mov.u32 	%r2623, 1;
	sub.s32 	%r2624, %r2623, %r2622;
	shr.u64 	%rd2227, %rd2226, %r2624;
	add.s32 	%r2625, %r2622, -1;
	cvt.u64.u32 	%rd2228, %r2625;
	shl.b64 	%rd2229, %rd2228, 52;
	add.s64 	%rd2230, %rd2229, %rd2226;
	selp.b64 	%rd2231, %rd2227, %rd2230, %p601;
	mov.b64 	%fd2948, %rd2231;

$L__BB0_294:
	and.b32  	%r2626, %r341, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2627}, %fd2948;
	}
	or.b32  	%r2628, %r2627, %r2626;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2629, %temp}, %fd2948;
	}
	mov.b64 	%fd2949, {%r2629, %r2628};
	bra.uni 	$L__BB0_298;

$L__BB0_296:
	mov.f64 	%fd1218, 0d3FF0000000000000;
	add.rn.f64 	%fd2949, %fd155, %fd1218;

$L__BB0_298:
	mov.f64 	%fd1219, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1220, %fd1219, %fd2949;
	mul.f64 	%fd1221, %fd1220, %fd87;
	mul.f64 	%fd1222, %fd1221, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 79 28
	add.s32 	%r2630, %r6047, 1;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 79 28
	cvt.rn.f64.s32 	%fd1223, %r2630;
	fma.rn.f64 	%fd166, %fd1223, 0d400921FB54442D18, %fd1222;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r365}, %fd166;
	}
	and.b32  	%r2631, %r365, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2632, %temp}, %fd166;
	}
	mov.b64 	%fd2950, {%r2632, %r2631};
	setp.gt.u32 	%p606, %r2631, 2146435071;
	or.pred  	%p608, %p606, %p18;
	@%p608 bra 	$L__BB0_315;
	bra.uni 	$L__BB0_299;

$L__BB0_315:
	.loc	1 0 9
	setp.le.f64 	%p643, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p644, %fd2950, 0d7FF0000000000000;
	and.pred  	%p645, %p644, %p643;
	@%p645 bra 	$L__BB0_317;
	bra.uni 	$L__BB0_316;

$L__BB0_317:
	setp.eq.f64 	%p646, %fd2950, 0d7FF0000000000000;
	selp.f64 	%fd2958, 0dFFF8000000000000, %fd166, %p646;
	bra.uni 	$L__BB0_318;

$L__BB0_299:
	.loc	1 0 9
	mov.f64 	%fd2958, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_318;

	setp.ltu.f64 	%p610, %fd2950, %fd3160;
	mov.f64 	%fd2958, %fd166;
	@%p610 bra 	$L__BB0_318;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2633}, %fd2950;
	}
	shr.u32 	%r6038, %r2633, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2634}, %fd3160;
	}
	shr.u32 	%r6039, %r2634, 20;
	setp.ne.s32 	%p611, %r6038, 0;
	@%p611 bra 	$L__BB0_303;

	mul.f64 	%fd2950, %fd2950, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2635}, %fd2950;
	}
	shr.u32 	%r2636, %r2635, 20;
	add.s32 	%r6038, %r2636, -54;

$L__BB0_303:
	setp.ne.s32 	%p612, %r6039, 0;
	mov.f64 	%fd2951, %fd3160;
	@%p612 bra 	$L__BB0_305;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2637}, %fd2;
	}
	shr.u32 	%r2638, %r2637, 20;
	add.s32 	%r6039, %r2638, -54;
	mov.f64 	%fd2951, %fd2;

$L__BB0_305:
	mov.b64 	%rd2233, %fd2950;
	and.b64  	%rd2234, %rd2233, 4503599627370495;
	or.b64  	%rd6233, %rd2234, 4503599627370496;
	mov.b64 	%rd2235, %fd2951;
	and.b64  	%rd2236, %rd2235, 4503599627370495;
	or.b64  	%rd250, %rd2236, 4503599627370496;
	sub.s32 	%r6045, %r6038, %r6039;
	not.b32 	%r2639, %r6038;
	add.s32 	%r2640, %r6039, %r2639;
	max.s32 	%r2641, %r2640, -1;
	add.s32 	%r373, %r2641, %r6038;
	mov.u32 	%r2642, 2;
	sub.s32 	%r2643, %r2642, %r6039;
	add.s32 	%r2644, %r2643, %r373;
	and.b32  	%r6041, %r2644, 3;
	setp.eq.s32 	%p613, %r6041, 0;
	@%p613 bra 	$L__BB0_307;

$L__BB0_306:
	.pragma "nounroll";
	sub.s64 	%rd2237, %rd6233, %rd250;
	mov.b64 	%fd1225, %rd2237;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2645}, %fd1225;
	}
	setp.lt.s32 	%p614, %r2645, 0;
	selp.b64 	%rd6236, %rd6233, %rd2237, %p614;
	shl.b64 	%rd6233, %rd6236, 1;
	add.s32 	%r6045, %r6045, -1;
	add.s32 	%r6041, %r6041, -1;
	setp.ne.s32 	%p615, %r6041, 0;
	@%p615 bra 	$L__BB0_306;

$L__BB0_307:
	mov.u32 	%r2646, 1;
	sub.s32 	%r2647, %r2646, %r6039;
	add.s32 	%r2648, %r2647, %r373;
	setp.lt.u32 	%p616, %r2648, 3;
	@%p616 bra 	$L__BB0_312;

	not.b32 	%r2649, %r6045;
	max.s32 	%r2650, %r2649, -4;
	add.s32 	%r2651, %r6045, %r2650;
	add.s32 	%r380, %r2651, 4;
	shr.u32 	%r2652, %r380, 2;
	add.s32 	%r2653, %r2652, 1;
	and.b32  	%r6044, %r2653, 3;
	setp.eq.s32 	%p617, %r6044, 0;
	@%p617 bra 	$L__BB0_310;

$L__BB0_309:
	.pragma "nounroll";
	sub.s64 	%rd2239, %rd6233, %rd250;
	mov.b64 	%fd1226, %rd2239;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2654}, %fd1226;
	}
	setp.lt.s32 	%p618, %r2654, 0;
	selp.b64 	%rd2240, %rd6233, %rd2239, %p618;
	shl.b64 	%rd2241, %rd2240, 1;
	sub.s64 	%rd2242, %rd2241, %rd250;
	mov.b64 	%fd1227, %rd2242;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2655}, %fd1227;
	}
	setp.lt.s32 	%p619, %r2655, 0;
	selp.b64 	%rd2243, %rd2241, %rd2242, %p619;
	shl.b64 	%rd2244, %rd2243, 1;
	sub.s64 	%rd2245, %rd2244, %rd250;
	mov.b64 	%fd1228, %rd2245;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2656}, %fd1228;
	}
	setp.lt.s32 	%p620, %r2656, 0;
	selp.b64 	%rd2246, %rd2244, %rd2245, %p620;
	shl.b64 	%rd2247, %rd2246, 1;
	sub.s64 	%rd2248, %rd2247, %rd250;
	mov.b64 	%fd1229, %rd2248;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2657}, %fd1229;
	}
	setp.lt.s32 	%p621, %r2657, 0;
	selp.b64 	%rd6236, %rd2247, %rd2248, %p621;
	shl.b64 	%rd6233, %rd6236, 1;
	add.s32 	%r6045, %r6045, -4;
	add.s32 	%r6044, %r6044, -1;
	setp.ne.s32 	%p622, %r6044, 0;
	@%p622 bra 	$L__BB0_309;

$L__BB0_310:
	setp.lt.u32 	%p623, %r380, 12;
	@%p623 bra 	$L__BB0_312;

$L__BB0_311:
	sub.s64 	%rd2249, %rd6233, %rd250;
	mov.b64 	%fd1230, %rd2249;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2658}, %fd1230;
	}
	setp.lt.s32 	%p624, %r2658, 0;
	selp.b64 	%rd2250, %rd6233, %rd2249, %p624;
	shl.b64 	%rd2251, %rd2250, 1;
	sub.s64 	%rd2252, %rd2251, %rd250;
	mov.b64 	%fd1231, %rd2252;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2659}, %fd1231;
	}
	setp.lt.s32 	%p625, %r2659, 0;
	selp.b64 	%rd2253, %rd2251, %rd2252, %p625;
	shl.b64 	%rd2254, %rd2253, 1;
	sub.s64 	%rd2255, %rd2254, %rd250;
	mov.b64 	%fd1232, %rd2255;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2660}, %fd1232;
	}
	setp.lt.s32 	%p626, %r2660, 0;
	selp.b64 	%rd2256, %rd2254, %rd2255, %p626;
	shl.b64 	%rd2257, %rd2256, 1;
	sub.s64 	%rd2258, %rd2257, %rd250;
	mov.b64 	%fd1233, %rd2258;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2661}, %fd1233;
	}
	setp.lt.s32 	%p627, %r2661, 0;
	selp.b64 	%rd2259, %rd2257, %rd2258, %p627;
	shl.b64 	%rd2260, %rd2259, 1;
	sub.s64 	%rd2261, %rd2260, %rd250;
	mov.b64 	%fd1234, %rd2261;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2662}, %fd1234;
	}
	setp.lt.s32 	%p628, %r2662, 0;
	selp.b64 	%rd2262, %rd2260, %rd2261, %p628;
	shl.b64 	%rd2263, %rd2262, 1;
	sub.s64 	%rd2264, %rd2263, %rd250;
	mov.b64 	%fd1235, %rd2264;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2663}, %fd1235;
	}
	setp.lt.s32 	%p629, %r2663, 0;
	selp.b64 	%rd2265, %rd2263, %rd2264, %p629;
	shl.b64 	%rd2266, %rd2265, 1;
	sub.s64 	%rd2267, %rd2266, %rd250;
	mov.b64 	%fd1236, %rd2267;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2664}, %fd1236;
	}
	setp.lt.s32 	%p630, %r2664, 0;
	selp.b64 	%rd2268, %rd2266, %rd2267, %p630;
	shl.b64 	%rd2269, %rd2268, 1;
	sub.s64 	%rd2270, %rd2269, %rd250;
	mov.b64 	%fd1237, %rd2270;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2665}, %fd1237;
	}
	setp.lt.s32 	%p631, %r2665, 0;
	selp.b64 	%rd2271, %rd2269, %rd2270, %p631;
	shl.b64 	%rd2272, %rd2271, 1;
	sub.s64 	%rd2273, %rd2272, %rd250;
	mov.b64 	%fd1238, %rd2273;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2666}, %fd1238;
	}
	setp.lt.s32 	%p632, %r2666, 0;
	selp.b64 	%rd2274, %rd2272, %rd2273, %p632;
	shl.b64 	%rd2275, %rd2274, 1;
	sub.s64 	%rd2276, %rd2275, %rd250;
	mov.b64 	%fd1239, %rd2276;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2667}, %fd1239;
	}
	setp.lt.s32 	%p633, %r2667, 0;
	selp.b64 	%rd2277, %rd2275, %rd2276, %p633;
	shl.b64 	%rd2278, %rd2277, 1;
	sub.s64 	%rd2279, %rd2278, %rd250;
	mov.b64 	%fd1240, %rd2279;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2668}, %fd1240;
	}
	setp.lt.s32 	%p634, %r2668, 0;
	selp.b64 	%rd2280, %rd2278, %rd2279, %p634;
	shl.b64 	%rd2281, %rd2280, 1;
	sub.s64 	%rd2282, %rd2281, %rd250;
	mov.b64 	%fd1241, %rd2282;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2669}, %fd1241;
	}
	setp.lt.s32 	%p635, %r2669, 0;
	selp.b64 	%rd2283, %rd2281, %rd2282, %p635;
	shl.b64 	%rd2284, %rd2283, 1;
	sub.s64 	%rd2285, %rd2284, %rd250;
	mov.b64 	%fd1242, %rd2285;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2670}, %fd1242;
	}
	setp.lt.s32 	%p636, %r2670, 0;
	selp.b64 	%rd2286, %rd2284, %rd2285, %p636;
	shl.b64 	%rd2287, %rd2286, 1;
	sub.s64 	%rd2288, %rd2287, %rd250;
	mov.b64 	%fd1243, %rd2288;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2671}, %fd1243;
	}
	setp.lt.s32 	%p637, %r2671, 0;
	selp.b64 	%rd2289, %rd2287, %rd2288, %p637;
	shl.b64 	%rd2290, %rd2289, 1;
	sub.s64 	%rd2291, %rd2290, %rd250;
	mov.b64 	%fd1244, %rd2291;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2672}, %fd1244;
	}
	setp.lt.s32 	%p638, %r2672, 0;
	selp.b64 	%rd2292, %rd2290, %rd2291, %p638;
	shl.b64 	%rd2293, %rd2292, 1;
	sub.s64 	%rd2294, %rd2293, %rd250;
	mov.b64 	%fd1245, %rd2294;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2673}, %fd1245;
	}
	setp.lt.s32 	%p639, %r2673, 0;
	selp.b64 	%rd6236, %rd2293, %rd2294, %p639;
	shl.b64 	%rd6233, %rd6236, 1;
	add.s32 	%r388, %r6045, -16;
	setp.gt.s32 	%p640, %r6045, 15;
	mov.u32 	%r6045, %r388;
	@%p640 bra 	$L__BB0_311;

$L__BB0_312:
	and.b64  	%rd265, %rd6236, 9223372036854775807;
	setp.eq.s64 	%p641, %rd265, 0;
	mov.f64 	%fd2952, 0d0000000000000000;
	@%p641 bra 	$L__BB0_314;

	mov.b64 	%fd1247, %rd265;
	mul.f64 	%fd1248, %fd1247, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2674}, %fd1248;
	}
	shr.u32 	%r2675, %r2674, 20;
	mov.u32 	%r2676, 55;
	sub.s32 	%r2677, %r2676, %r2675;
	sub.s32 	%r2678, %r6039, %r2677;
	shl.b64 	%rd2295, %rd265, %r2677;
	setp.lt.s32 	%p642, %r2678, 1;
	mov.u32 	%r2679, 1;
	sub.s32 	%r2680, %r2679, %r2678;
	shr.u64 	%rd2296, %rd2295, %r2680;
	add.s32 	%r2681, %r2678, -1;
	cvt.u64.u32 	%rd2297, %r2681;
	shl.b64 	%rd2298, %rd2297, 52;
	add.s64 	%rd2299, %rd2298, %rd2295;
	selp.b64 	%rd2300, %rd2296, %rd2299, %p642;
	mov.b64 	%fd2952, %rd2300;

$L__BB0_314:
	and.b32  	%r2682, %r365, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2683}, %fd2952;
	}
	or.b32  	%r2684, %r2683, %r2682;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2685, %temp}, %fd2952;
	}
	mov.b64 	%fd2958, {%r2685, %r2684};
	bra.uni 	$L__BB0_318;

$L__BB0_316:
	mov.f64 	%fd1249, 0d3FF0000000000000;
	add.rn.f64 	%fd2958, %fd166, %fd1249;

$L__BB0_318:
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 79 28
	setp.lt.s32 	%p647, %r6047, 1;
	@%p647 bra 	$L__BB0_341;

	.loc	1 80 9, function_name $L__info_string3, inlined_at 1 249 17
	cvt.u64.u32 	%rd266, %r195;

$L__BB0_320:
	.loc	1 0 9
	mov.u32 	%r389, %r6047;
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 79 28
	add.s32 	%r2686, %r389, -1;
	.loc	1 62 9, function_name $L__info_string6, inlined_at 1 79 28
	cvt.s64.s32 	%rd2301, %r2686;
	add.s64 	%rd2302, %rd2301, %rd266;
	add.s64 	%rd2303, %rd9, %rd2302;
	ld.global.u8 	%rs79, [%rd2303];
	cvt.rn.f64.u16 	%fd1250, %rs79;
	.loc	1 63 9, function_name $L__info_string6, inlined_at 1 79 28
	mov.f64 	%fd1251, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1252, %fd1251, %fd2958;
	mul.f64 	%fd1253, %fd1252, %fd1250;
	mul.f64 	%fd1254, %fd1253, 0d400921FB54442D18;
	cvt.rn.f64.s32 	%fd1255, %r389;
	fma.rn.f64 	%fd178, %fd1255, 0d400921FB54442D18, %fd1254;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r390}, %fd178;
	}
	and.b32  	%r2687, %r390, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2688, %temp}, %fd178;
	}
	mov.b64 	%fd2955, {%r2688, %r2687};
	setp.gt.u32 	%p648, %r2687, 2146435071;
	or.pred  	%p650, %p648, %p18;
	@%p650 bra 	$L__BB0_337;
	bra.uni 	$L__BB0_321;

$L__BB0_337:
	.loc	1 0 9
	setp.le.f64 	%p685, %fd3160, 0d7FF0000000000000;
	.loc	1 63 9
	setp.le.f64 	%p686, %fd2955, 0d7FF0000000000000;
	and.pred  	%p687, %p686, %p685;
	@%p687 bra 	$L__BB0_339;
	bra.uni 	$L__BB0_338;

$L__BB0_339:
	setp.eq.f64 	%p688, %fd2955, 0d7FF0000000000000;
	selp.f64 	%fd2958, 0dFFF8000000000000, %fd178, %p688;
	bra.uni 	$L__BB0_340;

$L__BB0_321:
	.loc	1 0 9
	mov.f64 	%fd2958, 0dFFF8000000000000;
	.loc	1 63 9
	@%p309 bra 	$L__BB0_340;

	setp.ltu.f64 	%p652, %fd2955, %fd3160;
	mov.f64 	%fd2958, %fd178;
	@%p652 bra 	$L__BB0_340;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2689}, %fd2955;
	}
	shr.u32 	%r6048, %r2689, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2690}, %fd3160;
	}
	shr.u32 	%r6049, %r2690, 20;
	setp.ne.s32 	%p653, %r6048, 0;
	@%p653 bra 	$L__BB0_325;

	mul.f64 	%fd2955, %fd2955, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2691}, %fd2955;
	}
	shr.u32 	%r2692, %r2691, 20;
	add.s32 	%r6048, %r2692, -54;

$L__BB0_325:
	setp.ne.s32 	%p654, %r6049, 0;
	mov.f64 	%fd2956, %fd3160;
	@%p654 bra 	$L__BB0_327;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2693}, %fd2;
	}
	shr.u32 	%r2694, %r2693, 20;
	add.s32 	%r6049, %r2694, -54;
	mov.f64 	%fd2956, %fd2;

$L__BB0_327:
	mov.b64 	%rd2305, %fd2955;
	and.b64  	%rd2306, %rd2305, 4503599627370495;
	or.b64  	%rd6241, %rd2306, 4503599627370496;
	mov.b64 	%rd2307, %fd2956;
	and.b64  	%rd2308, %rd2307, 4503599627370495;
	or.b64  	%rd268, %rd2308, 4503599627370496;
	sub.s32 	%r6055, %r6048, %r6049;
	not.b32 	%r2695, %r6048;
	add.s32 	%r2696, %r6049, %r2695;
	max.s32 	%r2697, %r2696, -1;
	add.s32 	%r398, %r2697, %r6048;
	mov.u32 	%r2698, 2;
	sub.s32 	%r2699, %r2698, %r6049;
	add.s32 	%r2700, %r2699, %r398;
	and.b32  	%r6051, %r2700, 3;
	setp.eq.s32 	%p655, %r6051, 0;
	@%p655 bra 	$L__BB0_329;

$L__BB0_328:
	.pragma "nounroll";
	sub.s64 	%rd2309, %rd6241, %rd268;
	mov.b64 	%fd1257, %rd2309;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2701}, %fd1257;
	}
	setp.lt.s32 	%p656, %r2701, 0;
	selp.b64 	%rd6244, %rd6241, %rd2309, %p656;
	shl.b64 	%rd6241, %rd6244, 1;
	add.s32 	%r6055, %r6055, -1;
	add.s32 	%r6051, %r6051, -1;
	setp.ne.s32 	%p657, %r6051, 0;
	@%p657 bra 	$L__BB0_328;

$L__BB0_329:
	mov.u32 	%r2702, 1;
	sub.s32 	%r2703, %r2702, %r6049;
	add.s32 	%r2704, %r2703, %r398;
	setp.lt.u32 	%p658, %r2704, 3;
	@%p658 bra 	$L__BB0_334;

	not.b32 	%r2705, %r6055;
	max.s32 	%r2706, %r2705, -4;
	add.s32 	%r2707, %r6055, %r2706;
	add.s32 	%r405, %r2707, 4;
	shr.u32 	%r2708, %r405, 2;
	add.s32 	%r2709, %r2708, 1;
	and.b32  	%r6054, %r2709, 3;
	setp.eq.s32 	%p659, %r6054, 0;
	@%p659 bra 	$L__BB0_332;

$L__BB0_331:
	.pragma "nounroll";
	sub.s64 	%rd2311, %rd6241, %rd268;
	mov.b64 	%fd1258, %rd2311;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2710}, %fd1258;
	}
	setp.lt.s32 	%p660, %r2710, 0;
	selp.b64 	%rd2312, %rd6241, %rd2311, %p660;
	shl.b64 	%rd2313, %rd2312, 1;
	sub.s64 	%rd2314, %rd2313, %rd268;
	mov.b64 	%fd1259, %rd2314;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2711}, %fd1259;
	}
	setp.lt.s32 	%p661, %r2711, 0;
	selp.b64 	%rd2315, %rd2313, %rd2314, %p661;
	shl.b64 	%rd2316, %rd2315, 1;
	sub.s64 	%rd2317, %rd2316, %rd268;
	mov.b64 	%fd1260, %rd2317;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2712}, %fd1260;
	}
	setp.lt.s32 	%p662, %r2712, 0;
	selp.b64 	%rd2318, %rd2316, %rd2317, %p662;
	shl.b64 	%rd2319, %rd2318, 1;
	sub.s64 	%rd2320, %rd2319, %rd268;
	mov.b64 	%fd1261, %rd2320;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2713}, %fd1261;
	}
	setp.lt.s32 	%p663, %r2713, 0;
	selp.b64 	%rd6244, %rd2319, %rd2320, %p663;
	shl.b64 	%rd6241, %rd6244, 1;
	add.s32 	%r6055, %r6055, -4;
	add.s32 	%r6054, %r6054, -1;
	setp.ne.s32 	%p664, %r6054, 0;
	@%p664 bra 	$L__BB0_331;

$L__BB0_332:
	setp.lt.u32 	%p665, %r405, 12;
	@%p665 bra 	$L__BB0_334;

$L__BB0_333:
	sub.s64 	%rd2321, %rd6241, %rd268;
	mov.b64 	%fd1262, %rd2321;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2714}, %fd1262;
	}
	setp.lt.s32 	%p666, %r2714, 0;
	selp.b64 	%rd2322, %rd6241, %rd2321, %p666;
	shl.b64 	%rd2323, %rd2322, 1;
	sub.s64 	%rd2324, %rd2323, %rd268;
	mov.b64 	%fd1263, %rd2324;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2715}, %fd1263;
	}
	setp.lt.s32 	%p667, %r2715, 0;
	selp.b64 	%rd2325, %rd2323, %rd2324, %p667;
	shl.b64 	%rd2326, %rd2325, 1;
	sub.s64 	%rd2327, %rd2326, %rd268;
	mov.b64 	%fd1264, %rd2327;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2716}, %fd1264;
	}
	setp.lt.s32 	%p668, %r2716, 0;
	selp.b64 	%rd2328, %rd2326, %rd2327, %p668;
	shl.b64 	%rd2329, %rd2328, 1;
	sub.s64 	%rd2330, %rd2329, %rd268;
	mov.b64 	%fd1265, %rd2330;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2717}, %fd1265;
	}
	setp.lt.s32 	%p669, %r2717, 0;
	selp.b64 	%rd2331, %rd2329, %rd2330, %p669;
	shl.b64 	%rd2332, %rd2331, 1;
	sub.s64 	%rd2333, %rd2332, %rd268;
	mov.b64 	%fd1266, %rd2333;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2718}, %fd1266;
	}
	setp.lt.s32 	%p670, %r2718, 0;
	selp.b64 	%rd2334, %rd2332, %rd2333, %p670;
	shl.b64 	%rd2335, %rd2334, 1;
	sub.s64 	%rd2336, %rd2335, %rd268;
	mov.b64 	%fd1267, %rd2336;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2719}, %fd1267;
	}
	setp.lt.s32 	%p671, %r2719, 0;
	selp.b64 	%rd2337, %rd2335, %rd2336, %p671;
	shl.b64 	%rd2338, %rd2337, 1;
	sub.s64 	%rd2339, %rd2338, %rd268;
	mov.b64 	%fd1268, %rd2339;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2720}, %fd1268;
	}
	setp.lt.s32 	%p672, %r2720, 0;
	selp.b64 	%rd2340, %rd2338, %rd2339, %p672;
	shl.b64 	%rd2341, %rd2340, 1;
	sub.s64 	%rd2342, %rd2341, %rd268;
	mov.b64 	%fd1269, %rd2342;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2721}, %fd1269;
	}
	setp.lt.s32 	%p673, %r2721, 0;
	selp.b64 	%rd2343, %rd2341, %rd2342, %p673;
	shl.b64 	%rd2344, %rd2343, 1;
	sub.s64 	%rd2345, %rd2344, %rd268;
	mov.b64 	%fd1270, %rd2345;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2722}, %fd1270;
	}
	setp.lt.s32 	%p674, %r2722, 0;
	selp.b64 	%rd2346, %rd2344, %rd2345, %p674;
	shl.b64 	%rd2347, %rd2346, 1;
	sub.s64 	%rd2348, %rd2347, %rd268;
	mov.b64 	%fd1271, %rd2348;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2723}, %fd1271;
	}
	setp.lt.s32 	%p675, %r2723, 0;
	selp.b64 	%rd2349, %rd2347, %rd2348, %p675;
	shl.b64 	%rd2350, %rd2349, 1;
	sub.s64 	%rd2351, %rd2350, %rd268;
	mov.b64 	%fd1272, %rd2351;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2724}, %fd1272;
	}
	setp.lt.s32 	%p676, %r2724, 0;
	selp.b64 	%rd2352, %rd2350, %rd2351, %p676;
	shl.b64 	%rd2353, %rd2352, 1;
	sub.s64 	%rd2354, %rd2353, %rd268;
	mov.b64 	%fd1273, %rd2354;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2725}, %fd1273;
	}
	setp.lt.s32 	%p677, %r2725, 0;
	selp.b64 	%rd2355, %rd2353, %rd2354, %p677;
	shl.b64 	%rd2356, %rd2355, 1;
	sub.s64 	%rd2357, %rd2356, %rd268;
	mov.b64 	%fd1274, %rd2357;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2726}, %fd1274;
	}
	setp.lt.s32 	%p678, %r2726, 0;
	selp.b64 	%rd2358, %rd2356, %rd2357, %p678;
	shl.b64 	%rd2359, %rd2358, 1;
	sub.s64 	%rd2360, %rd2359, %rd268;
	mov.b64 	%fd1275, %rd2360;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2727}, %fd1275;
	}
	setp.lt.s32 	%p679, %r2727, 0;
	selp.b64 	%rd2361, %rd2359, %rd2360, %p679;
	shl.b64 	%rd2362, %rd2361, 1;
	sub.s64 	%rd2363, %rd2362, %rd268;
	mov.b64 	%fd1276, %rd2363;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2728}, %fd1276;
	}
	setp.lt.s32 	%p680, %r2728, 0;
	selp.b64 	%rd2364, %rd2362, %rd2363, %p680;
	shl.b64 	%rd2365, %rd2364, 1;
	sub.s64 	%rd2366, %rd2365, %rd268;
	mov.b64 	%fd1277, %rd2366;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2729}, %fd1277;
	}
	setp.lt.s32 	%p681, %r2729, 0;
	selp.b64 	%rd6244, %rd2365, %rd2366, %p681;
	shl.b64 	%rd6241, %rd6244, 1;
	add.s32 	%r413, %r6055, -16;
	setp.gt.s32 	%p682, %r6055, 15;
	mov.u32 	%r6055, %r413;
	@%p682 bra 	$L__BB0_333;

$L__BB0_334:
	and.b64  	%rd283, %rd6244, 9223372036854775807;
	setp.eq.s64 	%p683, %rd283, 0;
	mov.f64 	%fd2957, 0d0000000000000000;
	@%p683 bra 	$L__BB0_336;

	mov.b64 	%fd1279, %rd283;
	mul.f64 	%fd1280, %fd1279, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2730}, %fd1280;
	}
	shr.u32 	%r2731, %r2730, 20;
	mov.u32 	%r2732, 55;
	sub.s32 	%r2733, %r2732, %r2731;
	sub.s32 	%r2734, %r6049, %r2733;
	shl.b64 	%rd2367, %rd283, %r2733;
	setp.lt.s32 	%p684, %r2734, 1;
	mov.u32 	%r2735, 1;
	sub.s32 	%r2736, %r2735, %r2734;
	shr.u64 	%rd2368, %rd2367, %r2736;
	add.s32 	%r2737, %r2734, -1;
	cvt.u64.u32 	%rd2369, %r2737;
	shl.b64 	%rd2370, %rd2369, 52;
	add.s64 	%rd2371, %rd2370, %rd2367;
	selp.b64 	%rd2372, %rd2368, %rd2371, %p684;
	mov.b64 	%fd2957, %rd2372;

$L__BB0_336:
	and.b32  	%r2738, %r390, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2739}, %fd2957;
	}
	or.b32  	%r2740, %r2739, %r2738;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2741, %temp}, %fd2957;
	}
	mov.b64 	%fd2958, {%r2741, %r2740};
	bra.uni 	$L__BB0_340;

$L__BB0_338:
	mov.f64 	%fd1281, 0d3FF0000000000000;
	add.rn.f64 	%fd2958, %fd178, %fd1281;

$L__BB0_340:
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 79 28
	add.s32 	%r6047, %r389, -1;
	setp.gt.s32 	%p689, %r389, 1;
	@%p689 bra 	$L__BB0_320;

$L__BB0_341:
	.loc	1 86 9, function_name $L__info_string3, inlined_at 1 249 17
	ld.global.u8 	%r2742, [%rd1206+20];
	ld.global.u8 	%r2743, [%rd1206+21];
	prmt.b32 	%r2744, %r2743, %r2742, 30212;
	ld.global.u8 	%r2745, [%rd1206+22];
	ld.global.u8 	%r2746, [%rd1206+23];
	prmt.b32 	%r2747, %r2746, %r2745, 30212;
	prmt.b32 	%r415, %r2747, %r2744, 4180;
	.loc	1 87 9, function_name $L__info_string3, inlined_at 1 249 17
	ld.global.u8 	%r2748, [%rd1206+24];
	ld.global.u8 	%r2749, [%rd1206+25];
	prmt.b32 	%r2750, %r2749, %r2748, 30212;
	ld.global.u8 	%r2751, [%rd1206+26];
	ld.global.u8 	%r2752, [%rd1206+27];
	prmt.b32 	%r2753, %r2752, %r2751, 30212;
	prmt.b32 	%r6129, %r2753, %r2750, 4180;
	.loc	1 85 26, function_name $L__info_string3, inlined_at 1 249 17
	.loc	1 53 5, function_name $L__info_string6, inlined_at 1 85 26
	add.s32 	%r2754, %r6129, 8;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 85 26
	cvt.rn.f64.s32 	%fd1282, %r2754;
	fma.rn.f64 	%fd190, %fd1282, 0d400921FB54442D18, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r417}, %fd190;
	}
	and.b32  	%r2755, %r417, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2756, %temp}, %fd190;
	}
	mov.b64 	%fd2960, {%r2756, %r2755};
	setp.gt.u32 	%p690, %r2755, 2146435071;
	or.pred  	%p692, %p690, %p18;
	@%p692 bra 	$L__BB0_358;
	bra.uni 	$L__BB0_342;

$L__BB0_358:
	.loc	1 0 9
	setp.le.f64 	%p727, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p728, %fd2960, 0d7FF0000000000000;
	and.pred  	%p729, %p728, %p727;
	@%p729 bra 	$L__BB0_360;
	bra.uni 	$L__BB0_359;

$L__BB0_360:
	setp.eq.f64 	%p730, %fd2960, 0d7FF0000000000000;
	selp.f64 	%fd2963, 0dFFF8000000000000, %fd190, %p730;
	bra.uni 	$L__BB0_361;

$L__BB0_342:
	.loc	1 0 9
	mov.f64 	%fd2963, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_361;

	setp.ltu.f64 	%p694, %fd2960, %fd3160;
	mov.f64 	%fd2963, %fd190;
	@%p694 bra 	$L__BB0_361;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2757}, %fd2960;
	}
	shr.u32 	%r6057, %r2757, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2758}, %fd3160;
	}
	shr.u32 	%r6058, %r2758, 20;
	setp.ne.s32 	%p695, %r6057, 0;
	@%p695 bra 	$L__BB0_346;

	mul.f64 	%fd2960, %fd2960, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2759}, %fd2960;
	}
	shr.u32 	%r2760, %r2759, 20;
	add.s32 	%r6057, %r2760, -54;

$L__BB0_346:
	setp.ne.s32 	%p696, %r6058, 0;
	mov.f64 	%fd2961, %fd3160;
	@%p696 bra 	$L__BB0_348;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2761}, %fd2;
	}
	shr.u32 	%r2762, %r2761, 20;
	add.s32 	%r6058, %r2762, -54;
	mov.f64 	%fd2961, %fd2;

$L__BB0_348:
	mov.b64 	%rd2374, %fd2960;
	and.b64  	%rd2375, %rd2374, 4503599627370495;
	or.b64  	%rd6249, %rd2375, 4503599627370496;
	mov.b64 	%rd2376, %fd2961;
	and.b64  	%rd2377, %rd2376, 4503599627370495;
	or.b64  	%rd285, %rd2377, 4503599627370496;
	sub.s32 	%r6064, %r6057, %r6058;
	not.b32 	%r2763, %r6057;
	add.s32 	%r2764, %r6058, %r2763;
	max.s32 	%r2765, %r2764, -1;
	add.s32 	%r425, %r2765, %r6057;
	mov.u32 	%r2766, 2;
	sub.s32 	%r2767, %r2766, %r6058;
	add.s32 	%r2768, %r2767, %r425;
	and.b32  	%r6060, %r2768, 3;
	setp.eq.s32 	%p697, %r6060, 0;
	@%p697 bra 	$L__BB0_350;

$L__BB0_349:
	.pragma "nounroll";
	sub.s64 	%rd2378, %rd6249, %rd285;
	mov.b64 	%fd1284, %rd2378;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2769}, %fd1284;
	}
	setp.lt.s32 	%p698, %r2769, 0;
	selp.b64 	%rd6252, %rd6249, %rd2378, %p698;
	shl.b64 	%rd6249, %rd6252, 1;
	add.s32 	%r6064, %r6064, -1;
	add.s32 	%r6060, %r6060, -1;
	setp.ne.s32 	%p699, %r6060, 0;
	@%p699 bra 	$L__BB0_349;

$L__BB0_350:
	mov.u32 	%r2770, 1;
	sub.s32 	%r2771, %r2770, %r6058;
	add.s32 	%r2772, %r2771, %r425;
	setp.lt.u32 	%p700, %r2772, 3;
	@%p700 bra 	$L__BB0_355;

	not.b32 	%r2773, %r6064;
	max.s32 	%r2774, %r2773, -4;
	add.s32 	%r2775, %r6064, %r2774;
	add.s32 	%r432, %r2775, 4;
	shr.u32 	%r2776, %r432, 2;
	add.s32 	%r2777, %r2776, 1;
	and.b32  	%r6063, %r2777, 3;
	setp.eq.s32 	%p701, %r6063, 0;
	@%p701 bra 	$L__BB0_353;

$L__BB0_352:
	.pragma "nounroll";
	sub.s64 	%rd2380, %rd6249, %rd285;
	mov.b64 	%fd1285, %rd2380;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2778}, %fd1285;
	}
	setp.lt.s32 	%p702, %r2778, 0;
	selp.b64 	%rd2381, %rd6249, %rd2380, %p702;
	shl.b64 	%rd2382, %rd2381, 1;
	sub.s64 	%rd2383, %rd2382, %rd285;
	mov.b64 	%fd1286, %rd2383;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2779}, %fd1286;
	}
	setp.lt.s32 	%p703, %r2779, 0;
	selp.b64 	%rd2384, %rd2382, %rd2383, %p703;
	shl.b64 	%rd2385, %rd2384, 1;
	sub.s64 	%rd2386, %rd2385, %rd285;
	mov.b64 	%fd1287, %rd2386;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2780}, %fd1287;
	}
	setp.lt.s32 	%p704, %r2780, 0;
	selp.b64 	%rd2387, %rd2385, %rd2386, %p704;
	shl.b64 	%rd2388, %rd2387, 1;
	sub.s64 	%rd2389, %rd2388, %rd285;
	mov.b64 	%fd1288, %rd2389;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2781}, %fd1288;
	}
	setp.lt.s32 	%p705, %r2781, 0;
	selp.b64 	%rd6252, %rd2388, %rd2389, %p705;
	shl.b64 	%rd6249, %rd6252, 1;
	add.s32 	%r6064, %r6064, -4;
	add.s32 	%r6063, %r6063, -1;
	setp.ne.s32 	%p706, %r6063, 0;
	@%p706 bra 	$L__BB0_352;

$L__BB0_353:
	setp.lt.u32 	%p707, %r432, 12;
	@%p707 bra 	$L__BB0_355;

$L__BB0_354:
	sub.s64 	%rd2390, %rd6249, %rd285;
	mov.b64 	%fd1289, %rd2390;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2782}, %fd1289;
	}
	setp.lt.s32 	%p708, %r2782, 0;
	selp.b64 	%rd2391, %rd6249, %rd2390, %p708;
	shl.b64 	%rd2392, %rd2391, 1;
	sub.s64 	%rd2393, %rd2392, %rd285;
	mov.b64 	%fd1290, %rd2393;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2783}, %fd1290;
	}
	setp.lt.s32 	%p709, %r2783, 0;
	selp.b64 	%rd2394, %rd2392, %rd2393, %p709;
	shl.b64 	%rd2395, %rd2394, 1;
	sub.s64 	%rd2396, %rd2395, %rd285;
	mov.b64 	%fd1291, %rd2396;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2784}, %fd1291;
	}
	setp.lt.s32 	%p710, %r2784, 0;
	selp.b64 	%rd2397, %rd2395, %rd2396, %p710;
	shl.b64 	%rd2398, %rd2397, 1;
	sub.s64 	%rd2399, %rd2398, %rd285;
	mov.b64 	%fd1292, %rd2399;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2785}, %fd1292;
	}
	setp.lt.s32 	%p711, %r2785, 0;
	selp.b64 	%rd2400, %rd2398, %rd2399, %p711;
	shl.b64 	%rd2401, %rd2400, 1;
	sub.s64 	%rd2402, %rd2401, %rd285;
	mov.b64 	%fd1293, %rd2402;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2786}, %fd1293;
	}
	setp.lt.s32 	%p712, %r2786, 0;
	selp.b64 	%rd2403, %rd2401, %rd2402, %p712;
	shl.b64 	%rd2404, %rd2403, 1;
	sub.s64 	%rd2405, %rd2404, %rd285;
	mov.b64 	%fd1294, %rd2405;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2787}, %fd1294;
	}
	setp.lt.s32 	%p713, %r2787, 0;
	selp.b64 	%rd2406, %rd2404, %rd2405, %p713;
	shl.b64 	%rd2407, %rd2406, 1;
	sub.s64 	%rd2408, %rd2407, %rd285;
	mov.b64 	%fd1295, %rd2408;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2788}, %fd1295;
	}
	setp.lt.s32 	%p714, %r2788, 0;
	selp.b64 	%rd2409, %rd2407, %rd2408, %p714;
	shl.b64 	%rd2410, %rd2409, 1;
	sub.s64 	%rd2411, %rd2410, %rd285;
	mov.b64 	%fd1296, %rd2411;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2789}, %fd1296;
	}
	setp.lt.s32 	%p715, %r2789, 0;
	selp.b64 	%rd2412, %rd2410, %rd2411, %p715;
	shl.b64 	%rd2413, %rd2412, 1;
	sub.s64 	%rd2414, %rd2413, %rd285;
	mov.b64 	%fd1297, %rd2414;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2790}, %fd1297;
	}
	setp.lt.s32 	%p716, %r2790, 0;
	selp.b64 	%rd2415, %rd2413, %rd2414, %p716;
	shl.b64 	%rd2416, %rd2415, 1;
	sub.s64 	%rd2417, %rd2416, %rd285;
	mov.b64 	%fd1298, %rd2417;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2791}, %fd1298;
	}
	setp.lt.s32 	%p717, %r2791, 0;
	selp.b64 	%rd2418, %rd2416, %rd2417, %p717;
	shl.b64 	%rd2419, %rd2418, 1;
	sub.s64 	%rd2420, %rd2419, %rd285;
	mov.b64 	%fd1299, %rd2420;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2792}, %fd1299;
	}
	setp.lt.s32 	%p718, %r2792, 0;
	selp.b64 	%rd2421, %rd2419, %rd2420, %p718;
	shl.b64 	%rd2422, %rd2421, 1;
	sub.s64 	%rd2423, %rd2422, %rd285;
	mov.b64 	%fd1300, %rd2423;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2793}, %fd1300;
	}
	setp.lt.s32 	%p719, %r2793, 0;
	selp.b64 	%rd2424, %rd2422, %rd2423, %p719;
	shl.b64 	%rd2425, %rd2424, 1;
	sub.s64 	%rd2426, %rd2425, %rd285;
	mov.b64 	%fd1301, %rd2426;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2794}, %fd1301;
	}
	setp.lt.s32 	%p720, %r2794, 0;
	selp.b64 	%rd2427, %rd2425, %rd2426, %p720;
	shl.b64 	%rd2428, %rd2427, 1;
	sub.s64 	%rd2429, %rd2428, %rd285;
	mov.b64 	%fd1302, %rd2429;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2795}, %fd1302;
	}
	setp.lt.s32 	%p721, %r2795, 0;
	selp.b64 	%rd2430, %rd2428, %rd2429, %p721;
	shl.b64 	%rd2431, %rd2430, 1;
	sub.s64 	%rd2432, %rd2431, %rd285;
	mov.b64 	%fd1303, %rd2432;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2796}, %fd1303;
	}
	setp.lt.s32 	%p722, %r2796, 0;
	selp.b64 	%rd2433, %rd2431, %rd2432, %p722;
	shl.b64 	%rd2434, %rd2433, 1;
	sub.s64 	%rd2435, %rd2434, %rd285;
	mov.b64 	%fd1304, %rd2435;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2797}, %fd1304;
	}
	setp.lt.s32 	%p723, %r2797, 0;
	selp.b64 	%rd6252, %rd2434, %rd2435, %p723;
	shl.b64 	%rd6249, %rd6252, 1;
	add.s32 	%r440, %r6064, -16;
	setp.gt.s32 	%p724, %r6064, 15;
	mov.u32 	%r6064, %r440;
	@%p724 bra 	$L__BB0_354;

$L__BB0_355:
	and.b64  	%rd300, %rd6252, 9223372036854775807;
	setp.eq.s64 	%p725, %rd300, 0;
	mov.f64 	%fd2962, 0d0000000000000000;
	@%p725 bra 	$L__BB0_357;

	mov.b64 	%fd1306, %rd300;
	mul.f64 	%fd1307, %fd1306, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2798}, %fd1307;
	}
	shr.u32 	%r2799, %r2798, 20;
	mov.u32 	%r2800, 55;
	sub.s32 	%r2801, %r2800, %r2799;
	sub.s32 	%r2802, %r6058, %r2801;
	shl.b64 	%rd2436, %rd300, %r2801;
	setp.lt.s32 	%p726, %r2802, 1;
	mov.u32 	%r2803, 1;
	sub.s32 	%r2804, %r2803, %r2802;
	shr.u64 	%rd2437, %rd2436, %r2804;
	add.s32 	%r2805, %r2802, -1;
	cvt.u64.u32 	%rd2438, %r2805;
	shl.b64 	%rd2439, %rd2438, 52;
	add.s64 	%rd2440, %rd2439, %rd2436;
	selp.b64 	%rd2441, %rd2437, %rd2440, %p726;
	mov.b64 	%fd2962, %rd2441;

$L__BB0_357:
	and.b32  	%r2806, %r417, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2807}, %fd2962;
	}
	or.b32  	%r2808, %r2807, %r2806;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2809, %temp}, %fd2962;
	}
	mov.b64 	%fd2963, {%r2809, %r2808};
	bra.uni 	$L__BB0_361;

$L__BB0_359:
	mov.f64 	%fd1308, 0d3FF0000000000000;
	add.rn.f64 	%fd2963, %fd190, %fd1308;

$L__BB0_361:
	mov.f64 	%fd1309, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1310, %fd1309, %fd2963;
	mul.f64 	%fd1311, %fd1310, %fd15;
	mul.f64 	%fd1312, %fd1311, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 85 26
	add.s32 	%r2810, %r6129, 7;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 85 26
	cvt.rn.f64.s32 	%fd1313, %r2810;
	fma.rn.f64 	%fd201, %fd1313, 0d400921FB54442D18, %fd1312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r441}, %fd201;
	}
	and.b32  	%r2811, %r441, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2812, %temp}, %fd201;
	}
	mov.b64 	%fd2964, {%r2812, %r2811};
	setp.gt.u32 	%p731, %r2811, 2146435071;
	or.pred  	%p733, %p731, %p18;
	@%p733 bra 	$L__BB0_378;
	bra.uni 	$L__BB0_362;

$L__BB0_378:
	.loc	1 0 9
	setp.le.f64 	%p768, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p769, %fd2964, 0d7FF0000000000000;
	and.pred  	%p770, %p769, %p768;
	@%p770 bra 	$L__BB0_380;
	bra.uni 	$L__BB0_379;

$L__BB0_380:
	setp.eq.f64 	%p771, %fd2964, 0d7FF0000000000000;
	selp.f64 	%fd2967, 0dFFF8000000000000, %fd201, %p771;
	bra.uni 	$L__BB0_381;

$L__BB0_362:
	.loc	1 0 9
	mov.f64 	%fd2967, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_381;

	setp.ltu.f64 	%p735, %fd2964, %fd3160;
	mov.f64 	%fd2967, %fd201;
	@%p735 bra 	$L__BB0_381;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2813}, %fd2964;
	}
	shr.u32 	%r6066, %r2813, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2814}, %fd3160;
	}
	shr.u32 	%r6067, %r2814, 20;
	setp.ne.s32 	%p736, %r6066, 0;
	@%p736 bra 	$L__BB0_366;

	mul.f64 	%fd2964, %fd2964, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2815}, %fd2964;
	}
	shr.u32 	%r2816, %r2815, 20;
	add.s32 	%r6066, %r2816, -54;

$L__BB0_366:
	setp.ne.s32 	%p737, %r6067, 0;
	mov.f64 	%fd2965, %fd3160;
	@%p737 bra 	$L__BB0_368;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2817}, %fd2;
	}
	shr.u32 	%r2818, %r2817, 20;
	add.s32 	%r6067, %r2818, -54;
	mov.f64 	%fd2965, %fd2;

$L__BB0_368:
	mov.b64 	%rd2443, %fd2964;
	and.b64  	%rd2444, %rd2443, 4503599627370495;
	or.b64  	%rd6257, %rd2444, 4503599627370496;
	mov.b64 	%rd2445, %fd2965;
	and.b64  	%rd2446, %rd2445, 4503599627370495;
	or.b64  	%rd302, %rd2446, 4503599627370496;
	sub.s32 	%r6073, %r6066, %r6067;
	not.b32 	%r2819, %r6066;
	add.s32 	%r2820, %r6067, %r2819;
	max.s32 	%r2821, %r2820, -1;
	add.s32 	%r449, %r2821, %r6066;
	mov.u32 	%r2822, 2;
	sub.s32 	%r2823, %r2822, %r6067;
	add.s32 	%r2824, %r2823, %r449;
	and.b32  	%r6069, %r2824, 3;
	setp.eq.s32 	%p738, %r6069, 0;
	@%p738 bra 	$L__BB0_370;

$L__BB0_369:
	.pragma "nounroll";
	sub.s64 	%rd2447, %rd6257, %rd302;
	mov.b64 	%fd1315, %rd2447;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2825}, %fd1315;
	}
	setp.lt.s32 	%p739, %r2825, 0;
	selp.b64 	%rd6260, %rd6257, %rd2447, %p739;
	shl.b64 	%rd6257, %rd6260, 1;
	add.s32 	%r6073, %r6073, -1;
	add.s32 	%r6069, %r6069, -1;
	setp.ne.s32 	%p740, %r6069, 0;
	@%p740 bra 	$L__BB0_369;

$L__BB0_370:
	mov.u32 	%r2826, 1;
	sub.s32 	%r2827, %r2826, %r6067;
	add.s32 	%r2828, %r2827, %r449;
	setp.lt.u32 	%p741, %r2828, 3;
	@%p741 bra 	$L__BB0_375;

	not.b32 	%r2829, %r6073;
	max.s32 	%r2830, %r2829, -4;
	add.s32 	%r2831, %r6073, %r2830;
	add.s32 	%r456, %r2831, 4;
	shr.u32 	%r2832, %r456, 2;
	add.s32 	%r2833, %r2832, 1;
	and.b32  	%r6072, %r2833, 3;
	setp.eq.s32 	%p742, %r6072, 0;
	@%p742 bra 	$L__BB0_373;

$L__BB0_372:
	.pragma "nounroll";
	sub.s64 	%rd2449, %rd6257, %rd302;
	mov.b64 	%fd1316, %rd2449;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2834}, %fd1316;
	}
	setp.lt.s32 	%p743, %r2834, 0;
	selp.b64 	%rd2450, %rd6257, %rd2449, %p743;
	shl.b64 	%rd2451, %rd2450, 1;
	sub.s64 	%rd2452, %rd2451, %rd302;
	mov.b64 	%fd1317, %rd2452;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2835}, %fd1317;
	}
	setp.lt.s32 	%p744, %r2835, 0;
	selp.b64 	%rd2453, %rd2451, %rd2452, %p744;
	shl.b64 	%rd2454, %rd2453, 1;
	sub.s64 	%rd2455, %rd2454, %rd302;
	mov.b64 	%fd1318, %rd2455;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2836}, %fd1318;
	}
	setp.lt.s32 	%p745, %r2836, 0;
	selp.b64 	%rd2456, %rd2454, %rd2455, %p745;
	shl.b64 	%rd2457, %rd2456, 1;
	sub.s64 	%rd2458, %rd2457, %rd302;
	mov.b64 	%fd1319, %rd2458;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2837}, %fd1319;
	}
	setp.lt.s32 	%p746, %r2837, 0;
	selp.b64 	%rd6260, %rd2457, %rd2458, %p746;
	shl.b64 	%rd6257, %rd6260, 1;
	add.s32 	%r6073, %r6073, -4;
	add.s32 	%r6072, %r6072, -1;
	setp.ne.s32 	%p747, %r6072, 0;
	@%p747 bra 	$L__BB0_372;

$L__BB0_373:
	setp.lt.u32 	%p748, %r456, 12;
	@%p748 bra 	$L__BB0_375;

$L__BB0_374:
	sub.s64 	%rd2459, %rd6257, %rd302;
	mov.b64 	%fd1320, %rd2459;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2838}, %fd1320;
	}
	setp.lt.s32 	%p749, %r2838, 0;
	selp.b64 	%rd2460, %rd6257, %rd2459, %p749;
	shl.b64 	%rd2461, %rd2460, 1;
	sub.s64 	%rd2462, %rd2461, %rd302;
	mov.b64 	%fd1321, %rd2462;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2839}, %fd1321;
	}
	setp.lt.s32 	%p750, %r2839, 0;
	selp.b64 	%rd2463, %rd2461, %rd2462, %p750;
	shl.b64 	%rd2464, %rd2463, 1;
	sub.s64 	%rd2465, %rd2464, %rd302;
	mov.b64 	%fd1322, %rd2465;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2840}, %fd1322;
	}
	setp.lt.s32 	%p751, %r2840, 0;
	selp.b64 	%rd2466, %rd2464, %rd2465, %p751;
	shl.b64 	%rd2467, %rd2466, 1;
	sub.s64 	%rd2468, %rd2467, %rd302;
	mov.b64 	%fd1323, %rd2468;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2841}, %fd1323;
	}
	setp.lt.s32 	%p752, %r2841, 0;
	selp.b64 	%rd2469, %rd2467, %rd2468, %p752;
	shl.b64 	%rd2470, %rd2469, 1;
	sub.s64 	%rd2471, %rd2470, %rd302;
	mov.b64 	%fd1324, %rd2471;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2842}, %fd1324;
	}
	setp.lt.s32 	%p753, %r2842, 0;
	selp.b64 	%rd2472, %rd2470, %rd2471, %p753;
	shl.b64 	%rd2473, %rd2472, 1;
	sub.s64 	%rd2474, %rd2473, %rd302;
	mov.b64 	%fd1325, %rd2474;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2843}, %fd1325;
	}
	setp.lt.s32 	%p754, %r2843, 0;
	selp.b64 	%rd2475, %rd2473, %rd2474, %p754;
	shl.b64 	%rd2476, %rd2475, 1;
	sub.s64 	%rd2477, %rd2476, %rd302;
	mov.b64 	%fd1326, %rd2477;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2844}, %fd1326;
	}
	setp.lt.s32 	%p755, %r2844, 0;
	selp.b64 	%rd2478, %rd2476, %rd2477, %p755;
	shl.b64 	%rd2479, %rd2478, 1;
	sub.s64 	%rd2480, %rd2479, %rd302;
	mov.b64 	%fd1327, %rd2480;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2845}, %fd1327;
	}
	setp.lt.s32 	%p756, %r2845, 0;
	selp.b64 	%rd2481, %rd2479, %rd2480, %p756;
	shl.b64 	%rd2482, %rd2481, 1;
	sub.s64 	%rd2483, %rd2482, %rd302;
	mov.b64 	%fd1328, %rd2483;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2846}, %fd1328;
	}
	setp.lt.s32 	%p757, %r2846, 0;
	selp.b64 	%rd2484, %rd2482, %rd2483, %p757;
	shl.b64 	%rd2485, %rd2484, 1;
	sub.s64 	%rd2486, %rd2485, %rd302;
	mov.b64 	%fd1329, %rd2486;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2847}, %fd1329;
	}
	setp.lt.s32 	%p758, %r2847, 0;
	selp.b64 	%rd2487, %rd2485, %rd2486, %p758;
	shl.b64 	%rd2488, %rd2487, 1;
	sub.s64 	%rd2489, %rd2488, %rd302;
	mov.b64 	%fd1330, %rd2489;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2848}, %fd1330;
	}
	setp.lt.s32 	%p759, %r2848, 0;
	selp.b64 	%rd2490, %rd2488, %rd2489, %p759;
	shl.b64 	%rd2491, %rd2490, 1;
	sub.s64 	%rd2492, %rd2491, %rd302;
	mov.b64 	%fd1331, %rd2492;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2849}, %fd1331;
	}
	setp.lt.s32 	%p760, %r2849, 0;
	selp.b64 	%rd2493, %rd2491, %rd2492, %p760;
	shl.b64 	%rd2494, %rd2493, 1;
	sub.s64 	%rd2495, %rd2494, %rd302;
	mov.b64 	%fd1332, %rd2495;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2850}, %fd1332;
	}
	setp.lt.s32 	%p761, %r2850, 0;
	selp.b64 	%rd2496, %rd2494, %rd2495, %p761;
	shl.b64 	%rd2497, %rd2496, 1;
	sub.s64 	%rd2498, %rd2497, %rd302;
	mov.b64 	%fd1333, %rd2498;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2851}, %fd1333;
	}
	setp.lt.s32 	%p762, %r2851, 0;
	selp.b64 	%rd2499, %rd2497, %rd2498, %p762;
	shl.b64 	%rd2500, %rd2499, 1;
	sub.s64 	%rd2501, %rd2500, %rd302;
	mov.b64 	%fd1334, %rd2501;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2852}, %fd1334;
	}
	setp.lt.s32 	%p763, %r2852, 0;
	selp.b64 	%rd2502, %rd2500, %rd2501, %p763;
	shl.b64 	%rd2503, %rd2502, 1;
	sub.s64 	%rd2504, %rd2503, %rd302;
	mov.b64 	%fd1335, %rd2504;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2853}, %fd1335;
	}
	setp.lt.s32 	%p764, %r2853, 0;
	selp.b64 	%rd6260, %rd2503, %rd2504, %p764;
	shl.b64 	%rd6257, %rd6260, 1;
	add.s32 	%r464, %r6073, -16;
	setp.gt.s32 	%p765, %r6073, 15;
	mov.u32 	%r6073, %r464;
	@%p765 bra 	$L__BB0_374;

$L__BB0_375:
	and.b64  	%rd317, %rd6260, 9223372036854775807;
	setp.eq.s64 	%p766, %rd317, 0;
	mov.f64 	%fd2966, 0d0000000000000000;
	@%p766 bra 	$L__BB0_377;

	mov.b64 	%fd1337, %rd317;
	mul.f64 	%fd1338, %fd1337, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2854}, %fd1338;
	}
	shr.u32 	%r2855, %r2854, 20;
	mov.u32 	%r2856, 55;
	sub.s32 	%r2857, %r2856, %r2855;
	sub.s32 	%r2858, %r6067, %r2857;
	shl.b64 	%rd2505, %rd317, %r2857;
	setp.lt.s32 	%p767, %r2858, 1;
	mov.u32 	%r2859, 1;
	sub.s32 	%r2860, %r2859, %r2858;
	shr.u64 	%rd2506, %rd2505, %r2860;
	add.s32 	%r2861, %r2858, -1;
	cvt.u64.u32 	%rd2507, %r2861;
	shl.b64 	%rd2508, %rd2507, 52;
	add.s64 	%rd2509, %rd2508, %rd2505;
	selp.b64 	%rd2510, %rd2506, %rd2509, %p767;
	mov.b64 	%fd2966, %rd2510;

$L__BB0_377:
	and.b32  	%r2862, %r441, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2863}, %fd2966;
	}
	or.b32  	%r2864, %r2863, %r2862;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2865, %temp}, %fd2966;
	}
	mov.b64 	%fd2967, {%r2865, %r2864};
	bra.uni 	$L__BB0_381;

$L__BB0_379:
	mov.f64 	%fd1339, 0d3FF0000000000000;
	add.rn.f64 	%fd2967, %fd201, %fd1339;

$L__BB0_381:
	mov.f64 	%fd1340, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1341, %fd1340, %fd2967;
	mul.f64 	%fd1342, %fd1341, %fd27;
	mul.f64 	%fd1343, %fd1342, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 85 26
	add.s32 	%r2866, %r6129, 6;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 85 26
	cvt.rn.f64.s32 	%fd1344, %r2866;
	fma.rn.f64 	%fd212, %fd1344, 0d400921FB54442D18, %fd1343;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r465}, %fd212;
	}
	and.b32  	%r2867, %r465, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2868, %temp}, %fd212;
	}
	mov.b64 	%fd2968, {%r2868, %r2867};
	setp.gt.u32 	%p772, %r2867, 2146435071;
	or.pred  	%p774, %p772, %p18;
	@%p774 bra 	$L__BB0_398;
	bra.uni 	$L__BB0_382;

$L__BB0_398:
	.loc	1 0 9
	setp.le.f64 	%p809, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p810, %fd2968, 0d7FF0000000000000;
	and.pred  	%p811, %p810, %p809;
	@%p811 bra 	$L__BB0_400;
	bra.uni 	$L__BB0_399;

$L__BB0_400:
	setp.eq.f64 	%p812, %fd2968, 0d7FF0000000000000;
	selp.f64 	%fd2971, 0dFFF8000000000000, %fd212, %p812;
	bra.uni 	$L__BB0_401;

$L__BB0_382:
	.loc	1 0 9
	mov.f64 	%fd2971, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_401;

	setp.ltu.f64 	%p776, %fd2968, %fd3160;
	mov.f64 	%fd2971, %fd212;
	@%p776 bra 	$L__BB0_401;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2869}, %fd2968;
	}
	shr.u32 	%r6075, %r2869, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2870}, %fd3160;
	}
	shr.u32 	%r6076, %r2870, 20;
	setp.ne.s32 	%p777, %r6075, 0;
	@%p777 bra 	$L__BB0_386;

	mul.f64 	%fd2968, %fd2968, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2871}, %fd2968;
	}
	shr.u32 	%r2872, %r2871, 20;
	add.s32 	%r6075, %r2872, -54;

$L__BB0_386:
	setp.ne.s32 	%p778, %r6076, 0;
	mov.f64 	%fd2969, %fd3160;
	@%p778 bra 	$L__BB0_388;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2873}, %fd2;
	}
	shr.u32 	%r2874, %r2873, 20;
	add.s32 	%r6076, %r2874, -54;
	mov.f64 	%fd2969, %fd2;

$L__BB0_388:
	mov.b64 	%rd2512, %fd2968;
	and.b64  	%rd2513, %rd2512, 4503599627370495;
	or.b64  	%rd6265, %rd2513, 4503599627370496;
	mov.b64 	%rd2514, %fd2969;
	and.b64  	%rd2515, %rd2514, 4503599627370495;
	or.b64  	%rd319, %rd2515, 4503599627370496;
	sub.s32 	%r6082, %r6075, %r6076;
	not.b32 	%r2875, %r6075;
	add.s32 	%r2876, %r6076, %r2875;
	max.s32 	%r2877, %r2876, -1;
	add.s32 	%r473, %r2877, %r6075;
	mov.u32 	%r2878, 2;
	sub.s32 	%r2879, %r2878, %r6076;
	add.s32 	%r2880, %r2879, %r473;
	and.b32  	%r6078, %r2880, 3;
	setp.eq.s32 	%p779, %r6078, 0;
	@%p779 bra 	$L__BB0_390;

$L__BB0_389:
	.pragma "nounroll";
	sub.s64 	%rd2516, %rd6265, %rd319;
	mov.b64 	%fd1346, %rd2516;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2881}, %fd1346;
	}
	setp.lt.s32 	%p780, %r2881, 0;
	selp.b64 	%rd6268, %rd6265, %rd2516, %p780;
	shl.b64 	%rd6265, %rd6268, 1;
	add.s32 	%r6082, %r6082, -1;
	add.s32 	%r6078, %r6078, -1;
	setp.ne.s32 	%p781, %r6078, 0;
	@%p781 bra 	$L__BB0_389;

$L__BB0_390:
	mov.u32 	%r2882, 1;
	sub.s32 	%r2883, %r2882, %r6076;
	add.s32 	%r2884, %r2883, %r473;
	setp.lt.u32 	%p782, %r2884, 3;
	@%p782 bra 	$L__BB0_395;

	not.b32 	%r2885, %r6082;
	max.s32 	%r2886, %r2885, -4;
	add.s32 	%r2887, %r6082, %r2886;
	add.s32 	%r480, %r2887, 4;
	shr.u32 	%r2888, %r480, 2;
	add.s32 	%r2889, %r2888, 1;
	and.b32  	%r6081, %r2889, 3;
	setp.eq.s32 	%p783, %r6081, 0;
	@%p783 bra 	$L__BB0_393;

$L__BB0_392:
	.pragma "nounroll";
	sub.s64 	%rd2518, %rd6265, %rd319;
	mov.b64 	%fd1347, %rd2518;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2890}, %fd1347;
	}
	setp.lt.s32 	%p784, %r2890, 0;
	selp.b64 	%rd2519, %rd6265, %rd2518, %p784;
	shl.b64 	%rd2520, %rd2519, 1;
	sub.s64 	%rd2521, %rd2520, %rd319;
	mov.b64 	%fd1348, %rd2521;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2891}, %fd1348;
	}
	setp.lt.s32 	%p785, %r2891, 0;
	selp.b64 	%rd2522, %rd2520, %rd2521, %p785;
	shl.b64 	%rd2523, %rd2522, 1;
	sub.s64 	%rd2524, %rd2523, %rd319;
	mov.b64 	%fd1349, %rd2524;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2892}, %fd1349;
	}
	setp.lt.s32 	%p786, %r2892, 0;
	selp.b64 	%rd2525, %rd2523, %rd2524, %p786;
	shl.b64 	%rd2526, %rd2525, 1;
	sub.s64 	%rd2527, %rd2526, %rd319;
	mov.b64 	%fd1350, %rd2527;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2893}, %fd1350;
	}
	setp.lt.s32 	%p787, %r2893, 0;
	selp.b64 	%rd6268, %rd2526, %rd2527, %p787;
	shl.b64 	%rd6265, %rd6268, 1;
	add.s32 	%r6082, %r6082, -4;
	add.s32 	%r6081, %r6081, -1;
	setp.ne.s32 	%p788, %r6081, 0;
	@%p788 bra 	$L__BB0_392;

$L__BB0_393:
	setp.lt.u32 	%p789, %r480, 12;
	@%p789 bra 	$L__BB0_395;

$L__BB0_394:
	sub.s64 	%rd2528, %rd6265, %rd319;
	mov.b64 	%fd1351, %rd2528;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2894}, %fd1351;
	}
	setp.lt.s32 	%p790, %r2894, 0;
	selp.b64 	%rd2529, %rd6265, %rd2528, %p790;
	shl.b64 	%rd2530, %rd2529, 1;
	sub.s64 	%rd2531, %rd2530, %rd319;
	mov.b64 	%fd1352, %rd2531;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2895}, %fd1352;
	}
	setp.lt.s32 	%p791, %r2895, 0;
	selp.b64 	%rd2532, %rd2530, %rd2531, %p791;
	shl.b64 	%rd2533, %rd2532, 1;
	sub.s64 	%rd2534, %rd2533, %rd319;
	mov.b64 	%fd1353, %rd2534;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2896}, %fd1353;
	}
	setp.lt.s32 	%p792, %r2896, 0;
	selp.b64 	%rd2535, %rd2533, %rd2534, %p792;
	shl.b64 	%rd2536, %rd2535, 1;
	sub.s64 	%rd2537, %rd2536, %rd319;
	mov.b64 	%fd1354, %rd2537;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2897}, %fd1354;
	}
	setp.lt.s32 	%p793, %r2897, 0;
	selp.b64 	%rd2538, %rd2536, %rd2537, %p793;
	shl.b64 	%rd2539, %rd2538, 1;
	sub.s64 	%rd2540, %rd2539, %rd319;
	mov.b64 	%fd1355, %rd2540;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2898}, %fd1355;
	}
	setp.lt.s32 	%p794, %r2898, 0;
	selp.b64 	%rd2541, %rd2539, %rd2540, %p794;
	shl.b64 	%rd2542, %rd2541, 1;
	sub.s64 	%rd2543, %rd2542, %rd319;
	mov.b64 	%fd1356, %rd2543;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2899}, %fd1356;
	}
	setp.lt.s32 	%p795, %r2899, 0;
	selp.b64 	%rd2544, %rd2542, %rd2543, %p795;
	shl.b64 	%rd2545, %rd2544, 1;
	sub.s64 	%rd2546, %rd2545, %rd319;
	mov.b64 	%fd1357, %rd2546;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2900}, %fd1357;
	}
	setp.lt.s32 	%p796, %r2900, 0;
	selp.b64 	%rd2547, %rd2545, %rd2546, %p796;
	shl.b64 	%rd2548, %rd2547, 1;
	sub.s64 	%rd2549, %rd2548, %rd319;
	mov.b64 	%fd1358, %rd2549;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2901}, %fd1358;
	}
	setp.lt.s32 	%p797, %r2901, 0;
	selp.b64 	%rd2550, %rd2548, %rd2549, %p797;
	shl.b64 	%rd2551, %rd2550, 1;
	sub.s64 	%rd2552, %rd2551, %rd319;
	mov.b64 	%fd1359, %rd2552;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2902}, %fd1359;
	}
	setp.lt.s32 	%p798, %r2902, 0;
	selp.b64 	%rd2553, %rd2551, %rd2552, %p798;
	shl.b64 	%rd2554, %rd2553, 1;
	sub.s64 	%rd2555, %rd2554, %rd319;
	mov.b64 	%fd1360, %rd2555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2903}, %fd1360;
	}
	setp.lt.s32 	%p799, %r2903, 0;
	selp.b64 	%rd2556, %rd2554, %rd2555, %p799;
	shl.b64 	%rd2557, %rd2556, 1;
	sub.s64 	%rd2558, %rd2557, %rd319;
	mov.b64 	%fd1361, %rd2558;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2904}, %fd1361;
	}
	setp.lt.s32 	%p800, %r2904, 0;
	selp.b64 	%rd2559, %rd2557, %rd2558, %p800;
	shl.b64 	%rd2560, %rd2559, 1;
	sub.s64 	%rd2561, %rd2560, %rd319;
	mov.b64 	%fd1362, %rd2561;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2905}, %fd1362;
	}
	setp.lt.s32 	%p801, %r2905, 0;
	selp.b64 	%rd2562, %rd2560, %rd2561, %p801;
	shl.b64 	%rd2563, %rd2562, 1;
	sub.s64 	%rd2564, %rd2563, %rd319;
	mov.b64 	%fd1363, %rd2564;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2906}, %fd1363;
	}
	setp.lt.s32 	%p802, %r2906, 0;
	selp.b64 	%rd2565, %rd2563, %rd2564, %p802;
	shl.b64 	%rd2566, %rd2565, 1;
	sub.s64 	%rd2567, %rd2566, %rd319;
	mov.b64 	%fd1364, %rd2567;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2907}, %fd1364;
	}
	setp.lt.s32 	%p803, %r2907, 0;
	selp.b64 	%rd2568, %rd2566, %rd2567, %p803;
	shl.b64 	%rd2569, %rd2568, 1;
	sub.s64 	%rd2570, %rd2569, %rd319;
	mov.b64 	%fd1365, %rd2570;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2908}, %fd1365;
	}
	setp.lt.s32 	%p804, %r2908, 0;
	selp.b64 	%rd2571, %rd2569, %rd2570, %p804;
	shl.b64 	%rd2572, %rd2571, 1;
	sub.s64 	%rd2573, %rd2572, %rd319;
	mov.b64 	%fd1366, %rd2573;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2909}, %fd1366;
	}
	setp.lt.s32 	%p805, %r2909, 0;
	selp.b64 	%rd6268, %rd2572, %rd2573, %p805;
	shl.b64 	%rd6265, %rd6268, 1;
	add.s32 	%r488, %r6082, -16;
	setp.gt.s32 	%p806, %r6082, 15;
	mov.u32 	%r6082, %r488;
	@%p806 bra 	$L__BB0_394;

$L__BB0_395:
	and.b64  	%rd334, %rd6268, 9223372036854775807;
	setp.eq.s64 	%p807, %rd334, 0;
	mov.f64 	%fd2970, 0d0000000000000000;
	@%p807 bra 	$L__BB0_397;

	mov.b64 	%fd1368, %rd334;
	mul.f64 	%fd1369, %fd1368, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2910}, %fd1369;
	}
	shr.u32 	%r2911, %r2910, 20;
	mov.u32 	%r2912, 55;
	sub.s32 	%r2913, %r2912, %r2911;
	sub.s32 	%r2914, %r6076, %r2913;
	shl.b64 	%rd2574, %rd334, %r2913;
	setp.lt.s32 	%p808, %r2914, 1;
	mov.u32 	%r2915, 1;
	sub.s32 	%r2916, %r2915, %r2914;
	shr.u64 	%rd2575, %rd2574, %r2916;
	add.s32 	%r2917, %r2914, -1;
	cvt.u64.u32 	%rd2576, %r2917;
	shl.b64 	%rd2577, %rd2576, 52;
	add.s64 	%rd2578, %rd2577, %rd2574;
	selp.b64 	%rd2579, %rd2575, %rd2578, %p808;
	mov.b64 	%fd2970, %rd2579;

$L__BB0_397:
	and.b32  	%r2918, %r465, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2919}, %fd2970;
	}
	or.b32  	%r2920, %r2919, %r2918;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2921, %temp}, %fd2970;
	}
	mov.b64 	%fd2971, {%r2921, %r2920};
	bra.uni 	$L__BB0_401;

$L__BB0_399:
	mov.f64 	%fd1370, 0d3FF0000000000000;
	add.rn.f64 	%fd2971, %fd212, %fd1370;

$L__BB0_401:
	mov.f64 	%fd1371, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1372, %fd1371, %fd2971;
	mul.f64 	%fd1373, %fd1372, %fd39;
	mul.f64 	%fd1374, %fd1373, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 85 26
	add.s32 	%r2922, %r6129, 5;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 85 26
	cvt.rn.f64.s32 	%fd1375, %r2922;
	fma.rn.f64 	%fd223, %fd1375, 0d400921FB54442D18, %fd1374;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r489}, %fd223;
	}
	and.b32  	%r2923, %r489, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2924, %temp}, %fd223;
	}
	mov.b64 	%fd2972, {%r2924, %r2923};
	setp.gt.u32 	%p813, %r2923, 2146435071;
	or.pred  	%p815, %p813, %p18;
	@%p815 bra 	$L__BB0_418;
	bra.uni 	$L__BB0_402;

$L__BB0_418:
	.loc	1 0 9
	setp.le.f64 	%p850, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p851, %fd2972, 0d7FF0000000000000;
	and.pred  	%p852, %p851, %p850;
	@%p852 bra 	$L__BB0_420;
	bra.uni 	$L__BB0_419;

$L__BB0_420:
	setp.eq.f64 	%p853, %fd2972, 0d7FF0000000000000;
	selp.f64 	%fd2975, 0dFFF8000000000000, %fd223, %p853;
	bra.uni 	$L__BB0_421;

$L__BB0_402:
	.loc	1 0 9
	mov.f64 	%fd2975, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_421;

	setp.ltu.f64 	%p817, %fd2972, %fd3160;
	mov.f64 	%fd2975, %fd223;
	@%p817 bra 	$L__BB0_421;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2925}, %fd2972;
	}
	shr.u32 	%r6084, %r2925, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2926}, %fd3160;
	}
	shr.u32 	%r6085, %r2926, 20;
	setp.ne.s32 	%p818, %r6084, 0;
	@%p818 bra 	$L__BB0_406;

	mul.f64 	%fd2972, %fd2972, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2927}, %fd2972;
	}
	shr.u32 	%r2928, %r2927, 20;
	add.s32 	%r6084, %r2928, -54;

$L__BB0_406:
	setp.ne.s32 	%p819, %r6085, 0;
	mov.f64 	%fd2973, %fd3160;
	@%p819 bra 	$L__BB0_408;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2929}, %fd2;
	}
	shr.u32 	%r2930, %r2929, 20;
	add.s32 	%r6085, %r2930, -54;
	mov.f64 	%fd2973, %fd2;

$L__BB0_408:
	mov.b64 	%rd2581, %fd2972;
	and.b64  	%rd2582, %rd2581, 4503599627370495;
	or.b64  	%rd6273, %rd2582, 4503599627370496;
	mov.b64 	%rd2583, %fd2973;
	and.b64  	%rd2584, %rd2583, 4503599627370495;
	or.b64  	%rd336, %rd2584, 4503599627370496;
	sub.s32 	%r6091, %r6084, %r6085;
	not.b32 	%r2931, %r6084;
	add.s32 	%r2932, %r6085, %r2931;
	max.s32 	%r2933, %r2932, -1;
	add.s32 	%r497, %r2933, %r6084;
	mov.u32 	%r2934, 2;
	sub.s32 	%r2935, %r2934, %r6085;
	add.s32 	%r2936, %r2935, %r497;
	and.b32  	%r6087, %r2936, 3;
	setp.eq.s32 	%p820, %r6087, 0;
	@%p820 bra 	$L__BB0_410;

$L__BB0_409:
	.pragma "nounroll";
	sub.s64 	%rd2585, %rd6273, %rd336;
	mov.b64 	%fd1377, %rd2585;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2937}, %fd1377;
	}
	setp.lt.s32 	%p821, %r2937, 0;
	selp.b64 	%rd6276, %rd6273, %rd2585, %p821;
	shl.b64 	%rd6273, %rd6276, 1;
	add.s32 	%r6091, %r6091, -1;
	add.s32 	%r6087, %r6087, -1;
	setp.ne.s32 	%p822, %r6087, 0;
	@%p822 bra 	$L__BB0_409;

$L__BB0_410:
	mov.u32 	%r2938, 1;
	sub.s32 	%r2939, %r2938, %r6085;
	add.s32 	%r2940, %r2939, %r497;
	setp.lt.u32 	%p823, %r2940, 3;
	@%p823 bra 	$L__BB0_415;

	not.b32 	%r2941, %r6091;
	max.s32 	%r2942, %r2941, -4;
	add.s32 	%r2943, %r6091, %r2942;
	add.s32 	%r504, %r2943, 4;
	shr.u32 	%r2944, %r504, 2;
	add.s32 	%r2945, %r2944, 1;
	and.b32  	%r6090, %r2945, 3;
	setp.eq.s32 	%p824, %r6090, 0;
	@%p824 bra 	$L__BB0_413;

$L__BB0_412:
	.pragma "nounroll";
	sub.s64 	%rd2587, %rd6273, %rd336;
	mov.b64 	%fd1378, %rd2587;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2946}, %fd1378;
	}
	setp.lt.s32 	%p825, %r2946, 0;
	selp.b64 	%rd2588, %rd6273, %rd2587, %p825;
	shl.b64 	%rd2589, %rd2588, 1;
	sub.s64 	%rd2590, %rd2589, %rd336;
	mov.b64 	%fd1379, %rd2590;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2947}, %fd1379;
	}
	setp.lt.s32 	%p826, %r2947, 0;
	selp.b64 	%rd2591, %rd2589, %rd2590, %p826;
	shl.b64 	%rd2592, %rd2591, 1;
	sub.s64 	%rd2593, %rd2592, %rd336;
	mov.b64 	%fd1380, %rd2593;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2948}, %fd1380;
	}
	setp.lt.s32 	%p827, %r2948, 0;
	selp.b64 	%rd2594, %rd2592, %rd2593, %p827;
	shl.b64 	%rd2595, %rd2594, 1;
	sub.s64 	%rd2596, %rd2595, %rd336;
	mov.b64 	%fd1381, %rd2596;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2949}, %fd1381;
	}
	setp.lt.s32 	%p828, %r2949, 0;
	selp.b64 	%rd6276, %rd2595, %rd2596, %p828;
	shl.b64 	%rd6273, %rd6276, 1;
	add.s32 	%r6091, %r6091, -4;
	add.s32 	%r6090, %r6090, -1;
	setp.ne.s32 	%p829, %r6090, 0;
	@%p829 bra 	$L__BB0_412;

$L__BB0_413:
	setp.lt.u32 	%p830, %r504, 12;
	@%p830 bra 	$L__BB0_415;

$L__BB0_414:
	sub.s64 	%rd2597, %rd6273, %rd336;
	mov.b64 	%fd1382, %rd2597;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2950}, %fd1382;
	}
	setp.lt.s32 	%p831, %r2950, 0;
	selp.b64 	%rd2598, %rd6273, %rd2597, %p831;
	shl.b64 	%rd2599, %rd2598, 1;
	sub.s64 	%rd2600, %rd2599, %rd336;
	mov.b64 	%fd1383, %rd2600;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2951}, %fd1383;
	}
	setp.lt.s32 	%p832, %r2951, 0;
	selp.b64 	%rd2601, %rd2599, %rd2600, %p832;
	shl.b64 	%rd2602, %rd2601, 1;
	sub.s64 	%rd2603, %rd2602, %rd336;
	mov.b64 	%fd1384, %rd2603;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2952}, %fd1384;
	}
	setp.lt.s32 	%p833, %r2952, 0;
	selp.b64 	%rd2604, %rd2602, %rd2603, %p833;
	shl.b64 	%rd2605, %rd2604, 1;
	sub.s64 	%rd2606, %rd2605, %rd336;
	mov.b64 	%fd1385, %rd2606;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2953}, %fd1385;
	}
	setp.lt.s32 	%p834, %r2953, 0;
	selp.b64 	%rd2607, %rd2605, %rd2606, %p834;
	shl.b64 	%rd2608, %rd2607, 1;
	sub.s64 	%rd2609, %rd2608, %rd336;
	mov.b64 	%fd1386, %rd2609;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2954}, %fd1386;
	}
	setp.lt.s32 	%p835, %r2954, 0;
	selp.b64 	%rd2610, %rd2608, %rd2609, %p835;
	shl.b64 	%rd2611, %rd2610, 1;
	sub.s64 	%rd2612, %rd2611, %rd336;
	mov.b64 	%fd1387, %rd2612;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2955}, %fd1387;
	}
	setp.lt.s32 	%p836, %r2955, 0;
	selp.b64 	%rd2613, %rd2611, %rd2612, %p836;
	shl.b64 	%rd2614, %rd2613, 1;
	sub.s64 	%rd2615, %rd2614, %rd336;
	mov.b64 	%fd1388, %rd2615;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2956}, %fd1388;
	}
	setp.lt.s32 	%p837, %r2956, 0;
	selp.b64 	%rd2616, %rd2614, %rd2615, %p837;
	shl.b64 	%rd2617, %rd2616, 1;
	sub.s64 	%rd2618, %rd2617, %rd336;
	mov.b64 	%fd1389, %rd2618;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2957}, %fd1389;
	}
	setp.lt.s32 	%p838, %r2957, 0;
	selp.b64 	%rd2619, %rd2617, %rd2618, %p838;
	shl.b64 	%rd2620, %rd2619, 1;
	sub.s64 	%rd2621, %rd2620, %rd336;
	mov.b64 	%fd1390, %rd2621;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2958}, %fd1390;
	}
	setp.lt.s32 	%p839, %r2958, 0;
	selp.b64 	%rd2622, %rd2620, %rd2621, %p839;
	shl.b64 	%rd2623, %rd2622, 1;
	sub.s64 	%rd2624, %rd2623, %rd336;
	mov.b64 	%fd1391, %rd2624;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2959}, %fd1391;
	}
	setp.lt.s32 	%p840, %r2959, 0;
	selp.b64 	%rd2625, %rd2623, %rd2624, %p840;
	shl.b64 	%rd2626, %rd2625, 1;
	sub.s64 	%rd2627, %rd2626, %rd336;
	mov.b64 	%fd1392, %rd2627;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2960}, %fd1392;
	}
	setp.lt.s32 	%p841, %r2960, 0;
	selp.b64 	%rd2628, %rd2626, %rd2627, %p841;
	shl.b64 	%rd2629, %rd2628, 1;
	sub.s64 	%rd2630, %rd2629, %rd336;
	mov.b64 	%fd1393, %rd2630;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2961}, %fd1393;
	}
	setp.lt.s32 	%p842, %r2961, 0;
	selp.b64 	%rd2631, %rd2629, %rd2630, %p842;
	shl.b64 	%rd2632, %rd2631, 1;
	sub.s64 	%rd2633, %rd2632, %rd336;
	mov.b64 	%fd1394, %rd2633;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2962}, %fd1394;
	}
	setp.lt.s32 	%p843, %r2962, 0;
	selp.b64 	%rd2634, %rd2632, %rd2633, %p843;
	shl.b64 	%rd2635, %rd2634, 1;
	sub.s64 	%rd2636, %rd2635, %rd336;
	mov.b64 	%fd1395, %rd2636;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2963}, %fd1395;
	}
	setp.lt.s32 	%p844, %r2963, 0;
	selp.b64 	%rd2637, %rd2635, %rd2636, %p844;
	shl.b64 	%rd2638, %rd2637, 1;
	sub.s64 	%rd2639, %rd2638, %rd336;
	mov.b64 	%fd1396, %rd2639;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2964}, %fd1396;
	}
	setp.lt.s32 	%p845, %r2964, 0;
	selp.b64 	%rd2640, %rd2638, %rd2639, %p845;
	shl.b64 	%rd2641, %rd2640, 1;
	sub.s64 	%rd2642, %rd2641, %rd336;
	mov.b64 	%fd1397, %rd2642;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2965}, %fd1397;
	}
	setp.lt.s32 	%p846, %r2965, 0;
	selp.b64 	%rd6276, %rd2641, %rd2642, %p846;
	shl.b64 	%rd6273, %rd6276, 1;
	add.s32 	%r512, %r6091, -16;
	setp.gt.s32 	%p847, %r6091, 15;
	mov.u32 	%r6091, %r512;
	@%p847 bra 	$L__BB0_414;

$L__BB0_415:
	and.b64  	%rd351, %rd6276, 9223372036854775807;
	setp.eq.s64 	%p848, %rd351, 0;
	mov.f64 	%fd2974, 0d0000000000000000;
	@%p848 bra 	$L__BB0_417;

	mov.b64 	%fd1399, %rd351;
	mul.f64 	%fd1400, %fd1399, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2966}, %fd1400;
	}
	shr.u32 	%r2967, %r2966, 20;
	mov.u32 	%r2968, 55;
	sub.s32 	%r2969, %r2968, %r2967;
	sub.s32 	%r2970, %r6085, %r2969;
	shl.b64 	%rd2643, %rd351, %r2969;
	setp.lt.s32 	%p849, %r2970, 1;
	mov.u32 	%r2971, 1;
	sub.s32 	%r2972, %r2971, %r2970;
	shr.u64 	%rd2644, %rd2643, %r2972;
	add.s32 	%r2973, %r2970, -1;
	cvt.u64.u32 	%rd2645, %r2973;
	shl.b64 	%rd2646, %rd2645, 52;
	add.s64 	%rd2647, %rd2646, %rd2643;
	selp.b64 	%rd2648, %rd2644, %rd2647, %p849;
	mov.b64 	%fd2974, %rd2648;

$L__BB0_417:
	and.b32  	%r2974, %r489, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2975}, %fd2974;
	}
	or.b32  	%r2976, %r2975, %r2974;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2977, %temp}, %fd2974;
	}
	mov.b64 	%fd2975, {%r2977, %r2976};
	bra.uni 	$L__BB0_421;

$L__BB0_419:
	mov.f64 	%fd1401, 0d3FF0000000000000;
	add.rn.f64 	%fd2975, %fd223, %fd1401;

$L__BB0_421:
	mov.f64 	%fd1402, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1403, %fd1402, %fd2975;
	mul.f64 	%fd1404, %fd1403, %fd51;
	mul.f64 	%fd1405, %fd1404, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 85 26
	add.s32 	%r2978, %r6129, 4;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 85 26
	cvt.rn.f64.s32 	%fd1406, %r2978;
	fma.rn.f64 	%fd234, %fd1406, 0d400921FB54442D18, %fd1405;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r513}, %fd234;
	}
	and.b32  	%r2979, %r513, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2980, %temp}, %fd234;
	}
	mov.b64 	%fd2976, {%r2980, %r2979};
	setp.gt.u32 	%p854, %r2979, 2146435071;
	or.pred  	%p856, %p854, %p18;
	@%p856 bra 	$L__BB0_438;
	bra.uni 	$L__BB0_422;

$L__BB0_438:
	.loc	1 0 9
	setp.le.f64 	%p891, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p892, %fd2976, 0d7FF0000000000000;
	and.pred  	%p893, %p892, %p891;
	@%p893 bra 	$L__BB0_440;
	bra.uni 	$L__BB0_439;

$L__BB0_440:
	setp.eq.f64 	%p894, %fd2976, 0d7FF0000000000000;
	selp.f64 	%fd2979, 0dFFF8000000000000, %fd234, %p894;
	bra.uni 	$L__BB0_441;

$L__BB0_422:
	.loc	1 0 9
	mov.f64 	%fd2979, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_441;

	setp.ltu.f64 	%p858, %fd2976, %fd3160;
	mov.f64 	%fd2979, %fd234;
	@%p858 bra 	$L__BB0_441;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2981}, %fd2976;
	}
	shr.u32 	%r6093, %r2981, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2982}, %fd3160;
	}
	shr.u32 	%r6094, %r2982, 20;
	setp.ne.s32 	%p859, %r6093, 0;
	@%p859 bra 	$L__BB0_426;

	mul.f64 	%fd2976, %fd2976, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2983}, %fd2976;
	}
	shr.u32 	%r2984, %r2983, 20;
	add.s32 	%r6093, %r2984, -54;

$L__BB0_426:
	setp.ne.s32 	%p860, %r6094, 0;
	mov.f64 	%fd2977, %fd3160;
	@%p860 bra 	$L__BB0_428;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2985}, %fd2;
	}
	shr.u32 	%r2986, %r2985, 20;
	add.s32 	%r6094, %r2986, -54;
	mov.f64 	%fd2977, %fd2;

$L__BB0_428:
	mov.b64 	%rd2650, %fd2976;
	and.b64  	%rd2651, %rd2650, 4503599627370495;
	or.b64  	%rd6281, %rd2651, 4503599627370496;
	mov.b64 	%rd2652, %fd2977;
	and.b64  	%rd2653, %rd2652, 4503599627370495;
	or.b64  	%rd353, %rd2653, 4503599627370496;
	sub.s32 	%r6100, %r6093, %r6094;
	not.b32 	%r2987, %r6093;
	add.s32 	%r2988, %r6094, %r2987;
	max.s32 	%r2989, %r2988, -1;
	add.s32 	%r521, %r2989, %r6093;
	mov.u32 	%r2990, 2;
	sub.s32 	%r2991, %r2990, %r6094;
	add.s32 	%r2992, %r2991, %r521;
	and.b32  	%r6096, %r2992, 3;
	setp.eq.s32 	%p861, %r6096, 0;
	@%p861 bra 	$L__BB0_430;

$L__BB0_429:
	.pragma "nounroll";
	sub.s64 	%rd2654, %rd6281, %rd353;
	mov.b64 	%fd1408, %rd2654;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2993}, %fd1408;
	}
	setp.lt.s32 	%p862, %r2993, 0;
	selp.b64 	%rd6284, %rd6281, %rd2654, %p862;
	shl.b64 	%rd6281, %rd6284, 1;
	add.s32 	%r6100, %r6100, -1;
	add.s32 	%r6096, %r6096, -1;
	setp.ne.s32 	%p863, %r6096, 0;
	@%p863 bra 	$L__BB0_429;

$L__BB0_430:
	mov.u32 	%r2994, 1;
	sub.s32 	%r2995, %r2994, %r6094;
	add.s32 	%r2996, %r2995, %r521;
	setp.lt.u32 	%p864, %r2996, 3;
	@%p864 bra 	$L__BB0_435;

	not.b32 	%r2997, %r6100;
	max.s32 	%r2998, %r2997, -4;
	add.s32 	%r2999, %r6100, %r2998;
	add.s32 	%r528, %r2999, 4;
	shr.u32 	%r3000, %r528, 2;
	add.s32 	%r3001, %r3000, 1;
	and.b32  	%r6099, %r3001, 3;
	setp.eq.s32 	%p865, %r6099, 0;
	@%p865 bra 	$L__BB0_433;

$L__BB0_432:
	.pragma "nounroll";
	sub.s64 	%rd2656, %rd6281, %rd353;
	mov.b64 	%fd1409, %rd2656;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3002}, %fd1409;
	}
	setp.lt.s32 	%p866, %r3002, 0;
	selp.b64 	%rd2657, %rd6281, %rd2656, %p866;
	shl.b64 	%rd2658, %rd2657, 1;
	sub.s64 	%rd2659, %rd2658, %rd353;
	mov.b64 	%fd1410, %rd2659;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3003}, %fd1410;
	}
	setp.lt.s32 	%p867, %r3003, 0;
	selp.b64 	%rd2660, %rd2658, %rd2659, %p867;
	shl.b64 	%rd2661, %rd2660, 1;
	sub.s64 	%rd2662, %rd2661, %rd353;
	mov.b64 	%fd1411, %rd2662;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3004}, %fd1411;
	}
	setp.lt.s32 	%p868, %r3004, 0;
	selp.b64 	%rd2663, %rd2661, %rd2662, %p868;
	shl.b64 	%rd2664, %rd2663, 1;
	sub.s64 	%rd2665, %rd2664, %rd353;
	mov.b64 	%fd1412, %rd2665;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3005}, %fd1412;
	}
	setp.lt.s32 	%p869, %r3005, 0;
	selp.b64 	%rd6284, %rd2664, %rd2665, %p869;
	shl.b64 	%rd6281, %rd6284, 1;
	add.s32 	%r6100, %r6100, -4;
	add.s32 	%r6099, %r6099, -1;
	setp.ne.s32 	%p870, %r6099, 0;
	@%p870 bra 	$L__BB0_432;

$L__BB0_433:
	setp.lt.u32 	%p871, %r528, 12;
	@%p871 bra 	$L__BB0_435;

$L__BB0_434:
	sub.s64 	%rd2666, %rd6281, %rd353;
	mov.b64 	%fd1413, %rd2666;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3006}, %fd1413;
	}
	setp.lt.s32 	%p872, %r3006, 0;
	selp.b64 	%rd2667, %rd6281, %rd2666, %p872;
	shl.b64 	%rd2668, %rd2667, 1;
	sub.s64 	%rd2669, %rd2668, %rd353;
	mov.b64 	%fd1414, %rd2669;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3007}, %fd1414;
	}
	setp.lt.s32 	%p873, %r3007, 0;
	selp.b64 	%rd2670, %rd2668, %rd2669, %p873;
	shl.b64 	%rd2671, %rd2670, 1;
	sub.s64 	%rd2672, %rd2671, %rd353;
	mov.b64 	%fd1415, %rd2672;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3008}, %fd1415;
	}
	setp.lt.s32 	%p874, %r3008, 0;
	selp.b64 	%rd2673, %rd2671, %rd2672, %p874;
	shl.b64 	%rd2674, %rd2673, 1;
	sub.s64 	%rd2675, %rd2674, %rd353;
	mov.b64 	%fd1416, %rd2675;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3009}, %fd1416;
	}
	setp.lt.s32 	%p875, %r3009, 0;
	selp.b64 	%rd2676, %rd2674, %rd2675, %p875;
	shl.b64 	%rd2677, %rd2676, 1;
	sub.s64 	%rd2678, %rd2677, %rd353;
	mov.b64 	%fd1417, %rd2678;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3010}, %fd1417;
	}
	setp.lt.s32 	%p876, %r3010, 0;
	selp.b64 	%rd2679, %rd2677, %rd2678, %p876;
	shl.b64 	%rd2680, %rd2679, 1;
	sub.s64 	%rd2681, %rd2680, %rd353;
	mov.b64 	%fd1418, %rd2681;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3011}, %fd1418;
	}
	setp.lt.s32 	%p877, %r3011, 0;
	selp.b64 	%rd2682, %rd2680, %rd2681, %p877;
	shl.b64 	%rd2683, %rd2682, 1;
	sub.s64 	%rd2684, %rd2683, %rd353;
	mov.b64 	%fd1419, %rd2684;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3012}, %fd1419;
	}
	setp.lt.s32 	%p878, %r3012, 0;
	selp.b64 	%rd2685, %rd2683, %rd2684, %p878;
	shl.b64 	%rd2686, %rd2685, 1;
	sub.s64 	%rd2687, %rd2686, %rd353;
	mov.b64 	%fd1420, %rd2687;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3013}, %fd1420;
	}
	setp.lt.s32 	%p879, %r3013, 0;
	selp.b64 	%rd2688, %rd2686, %rd2687, %p879;
	shl.b64 	%rd2689, %rd2688, 1;
	sub.s64 	%rd2690, %rd2689, %rd353;
	mov.b64 	%fd1421, %rd2690;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3014}, %fd1421;
	}
	setp.lt.s32 	%p880, %r3014, 0;
	selp.b64 	%rd2691, %rd2689, %rd2690, %p880;
	shl.b64 	%rd2692, %rd2691, 1;
	sub.s64 	%rd2693, %rd2692, %rd353;
	mov.b64 	%fd1422, %rd2693;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3015}, %fd1422;
	}
	setp.lt.s32 	%p881, %r3015, 0;
	selp.b64 	%rd2694, %rd2692, %rd2693, %p881;
	shl.b64 	%rd2695, %rd2694, 1;
	sub.s64 	%rd2696, %rd2695, %rd353;
	mov.b64 	%fd1423, %rd2696;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3016}, %fd1423;
	}
	setp.lt.s32 	%p882, %r3016, 0;
	selp.b64 	%rd2697, %rd2695, %rd2696, %p882;
	shl.b64 	%rd2698, %rd2697, 1;
	sub.s64 	%rd2699, %rd2698, %rd353;
	mov.b64 	%fd1424, %rd2699;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3017}, %fd1424;
	}
	setp.lt.s32 	%p883, %r3017, 0;
	selp.b64 	%rd2700, %rd2698, %rd2699, %p883;
	shl.b64 	%rd2701, %rd2700, 1;
	sub.s64 	%rd2702, %rd2701, %rd353;
	mov.b64 	%fd1425, %rd2702;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3018}, %fd1425;
	}
	setp.lt.s32 	%p884, %r3018, 0;
	selp.b64 	%rd2703, %rd2701, %rd2702, %p884;
	shl.b64 	%rd2704, %rd2703, 1;
	sub.s64 	%rd2705, %rd2704, %rd353;
	mov.b64 	%fd1426, %rd2705;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3019}, %fd1426;
	}
	setp.lt.s32 	%p885, %r3019, 0;
	selp.b64 	%rd2706, %rd2704, %rd2705, %p885;
	shl.b64 	%rd2707, %rd2706, 1;
	sub.s64 	%rd2708, %rd2707, %rd353;
	mov.b64 	%fd1427, %rd2708;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3020}, %fd1427;
	}
	setp.lt.s32 	%p886, %r3020, 0;
	selp.b64 	%rd2709, %rd2707, %rd2708, %p886;
	shl.b64 	%rd2710, %rd2709, 1;
	sub.s64 	%rd2711, %rd2710, %rd353;
	mov.b64 	%fd1428, %rd2711;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3021}, %fd1428;
	}
	setp.lt.s32 	%p887, %r3021, 0;
	selp.b64 	%rd6284, %rd2710, %rd2711, %p887;
	shl.b64 	%rd6281, %rd6284, 1;
	add.s32 	%r536, %r6100, -16;
	setp.gt.s32 	%p888, %r6100, 15;
	mov.u32 	%r6100, %r536;
	@%p888 bra 	$L__BB0_434;

$L__BB0_435:
	and.b64  	%rd368, %rd6284, 9223372036854775807;
	setp.eq.s64 	%p889, %rd368, 0;
	mov.f64 	%fd2978, 0d0000000000000000;
	@%p889 bra 	$L__BB0_437;

	mov.b64 	%fd1430, %rd368;
	mul.f64 	%fd1431, %fd1430, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3022}, %fd1431;
	}
	shr.u32 	%r3023, %r3022, 20;
	mov.u32 	%r3024, 55;
	sub.s32 	%r3025, %r3024, %r3023;
	sub.s32 	%r3026, %r6094, %r3025;
	shl.b64 	%rd2712, %rd368, %r3025;
	setp.lt.s32 	%p890, %r3026, 1;
	mov.u32 	%r3027, 1;
	sub.s32 	%r3028, %r3027, %r3026;
	shr.u64 	%rd2713, %rd2712, %r3028;
	add.s32 	%r3029, %r3026, -1;
	cvt.u64.u32 	%rd2714, %r3029;
	shl.b64 	%rd2715, %rd2714, 52;
	add.s64 	%rd2716, %rd2715, %rd2712;
	selp.b64 	%rd2717, %rd2713, %rd2716, %p890;
	mov.b64 	%fd2978, %rd2717;

$L__BB0_437:
	and.b32  	%r3030, %r513, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3031}, %fd2978;
	}
	or.b32  	%r3032, %r3031, %r3030;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3033, %temp}, %fd2978;
	}
	mov.b64 	%fd2979, {%r3033, %r3032};
	bra.uni 	$L__BB0_441;

$L__BB0_439:
	mov.f64 	%fd1432, 0d3FF0000000000000;
	add.rn.f64 	%fd2979, %fd234, %fd1432;

$L__BB0_441:
	mov.f64 	%fd1433, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1434, %fd1433, %fd2979;
	mul.f64 	%fd1435, %fd1434, %fd63;
	mul.f64 	%fd1436, %fd1435, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 85 26
	add.s32 	%r3034, %r6129, 3;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 85 26
	cvt.rn.f64.s32 	%fd1437, %r3034;
	fma.rn.f64 	%fd245, %fd1437, 0d400921FB54442D18, %fd1436;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r537}, %fd245;
	}
	and.b32  	%r3035, %r537, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3036, %temp}, %fd245;
	}
	mov.b64 	%fd2980, {%r3036, %r3035};
	setp.gt.u32 	%p895, %r3035, 2146435071;
	or.pred  	%p897, %p895, %p18;
	@%p897 bra 	$L__BB0_458;
	bra.uni 	$L__BB0_442;

$L__BB0_458:
	.loc	1 0 9
	setp.le.f64 	%p932, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p933, %fd2980, 0d7FF0000000000000;
	and.pred  	%p934, %p933, %p932;
	@%p934 bra 	$L__BB0_460;
	bra.uni 	$L__BB0_459;

$L__BB0_460:
	setp.eq.f64 	%p935, %fd2980, 0d7FF0000000000000;
	selp.f64 	%fd2983, 0dFFF8000000000000, %fd245, %p935;
	bra.uni 	$L__BB0_461;

$L__BB0_442:
	.loc	1 0 9
	mov.f64 	%fd2983, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_461;

	setp.ltu.f64 	%p899, %fd2980, %fd3160;
	mov.f64 	%fd2983, %fd245;
	@%p899 bra 	$L__BB0_461;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3037}, %fd2980;
	}
	shr.u32 	%r6102, %r3037, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3038}, %fd3160;
	}
	shr.u32 	%r6103, %r3038, 20;
	setp.ne.s32 	%p900, %r6102, 0;
	@%p900 bra 	$L__BB0_446;

	mul.f64 	%fd2980, %fd2980, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3039}, %fd2980;
	}
	shr.u32 	%r3040, %r3039, 20;
	add.s32 	%r6102, %r3040, -54;

$L__BB0_446:
	setp.ne.s32 	%p901, %r6103, 0;
	mov.f64 	%fd2981, %fd3160;
	@%p901 bra 	$L__BB0_448;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3041}, %fd2;
	}
	shr.u32 	%r3042, %r3041, 20;
	add.s32 	%r6103, %r3042, -54;
	mov.f64 	%fd2981, %fd2;

$L__BB0_448:
	mov.b64 	%rd2719, %fd2980;
	and.b64  	%rd2720, %rd2719, 4503599627370495;
	or.b64  	%rd6289, %rd2720, 4503599627370496;
	mov.b64 	%rd2721, %fd2981;
	and.b64  	%rd2722, %rd2721, 4503599627370495;
	or.b64  	%rd370, %rd2722, 4503599627370496;
	sub.s32 	%r6109, %r6102, %r6103;
	not.b32 	%r3043, %r6102;
	add.s32 	%r3044, %r6103, %r3043;
	max.s32 	%r3045, %r3044, -1;
	add.s32 	%r545, %r3045, %r6102;
	mov.u32 	%r3046, 2;
	sub.s32 	%r3047, %r3046, %r6103;
	add.s32 	%r3048, %r3047, %r545;
	and.b32  	%r6105, %r3048, 3;
	setp.eq.s32 	%p902, %r6105, 0;
	@%p902 bra 	$L__BB0_450;

$L__BB0_449:
	.pragma "nounroll";
	sub.s64 	%rd2723, %rd6289, %rd370;
	mov.b64 	%fd1439, %rd2723;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3049}, %fd1439;
	}
	setp.lt.s32 	%p903, %r3049, 0;
	selp.b64 	%rd6292, %rd6289, %rd2723, %p903;
	shl.b64 	%rd6289, %rd6292, 1;
	add.s32 	%r6109, %r6109, -1;
	add.s32 	%r6105, %r6105, -1;
	setp.ne.s32 	%p904, %r6105, 0;
	@%p904 bra 	$L__BB0_449;

$L__BB0_450:
	mov.u32 	%r3050, 1;
	sub.s32 	%r3051, %r3050, %r6103;
	add.s32 	%r3052, %r3051, %r545;
	setp.lt.u32 	%p905, %r3052, 3;
	@%p905 bra 	$L__BB0_455;

	not.b32 	%r3053, %r6109;
	max.s32 	%r3054, %r3053, -4;
	add.s32 	%r3055, %r6109, %r3054;
	add.s32 	%r552, %r3055, 4;
	shr.u32 	%r3056, %r552, 2;
	add.s32 	%r3057, %r3056, 1;
	and.b32  	%r6108, %r3057, 3;
	setp.eq.s32 	%p906, %r6108, 0;
	@%p906 bra 	$L__BB0_453;

$L__BB0_452:
	.pragma "nounroll";
	sub.s64 	%rd2725, %rd6289, %rd370;
	mov.b64 	%fd1440, %rd2725;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3058}, %fd1440;
	}
	setp.lt.s32 	%p907, %r3058, 0;
	selp.b64 	%rd2726, %rd6289, %rd2725, %p907;
	shl.b64 	%rd2727, %rd2726, 1;
	sub.s64 	%rd2728, %rd2727, %rd370;
	mov.b64 	%fd1441, %rd2728;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3059}, %fd1441;
	}
	setp.lt.s32 	%p908, %r3059, 0;
	selp.b64 	%rd2729, %rd2727, %rd2728, %p908;
	shl.b64 	%rd2730, %rd2729, 1;
	sub.s64 	%rd2731, %rd2730, %rd370;
	mov.b64 	%fd1442, %rd2731;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3060}, %fd1442;
	}
	setp.lt.s32 	%p909, %r3060, 0;
	selp.b64 	%rd2732, %rd2730, %rd2731, %p909;
	shl.b64 	%rd2733, %rd2732, 1;
	sub.s64 	%rd2734, %rd2733, %rd370;
	mov.b64 	%fd1443, %rd2734;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3061}, %fd1443;
	}
	setp.lt.s32 	%p910, %r3061, 0;
	selp.b64 	%rd6292, %rd2733, %rd2734, %p910;
	shl.b64 	%rd6289, %rd6292, 1;
	add.s32 	%r6109, %r6109, -4;
	add.s32 	%r6108, %r6108, -1;
	setp.ne.s32 	%p911, %r6108, 0;
	@%p911 bra 	$L__BB0_452;

$L__BB0_453:
	setp.lt.u32 	%p912, %r552, 12;
	@%p912 bra 	$L__BB0_455;

$L__BB0_454:
	sub.s64 	%rd2735, %rd6289, %rd370;
	mov.b64 	%fd1444, %rd2735;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3062}, %fd1444;
	}
	setp.lt.s32 	%p913, %r3062, 0;
	selp.b64 	%rd2736, %rd6289, %rd2735, %p913;
	shl.b64 	%rd2737, %rd2736, 1;
	sub.s64 	%rd2738, %rd2737, %rd370;
	mov.b64 	%fd1445, %rd2738;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3063}, %fd1445;
	}
	setp.lt.s32 	%p914, %r3063, 0;
	selp.b64 	%rd2739, %rd2737, %rd2738, %p914;
	shl.b64 	%rd2740, %rd2739, 1;
	sub.s64 	%rd2741, %rd2740, %rd370;
	mov.b64 	%fd1446, %rd2741;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3064}, %fd1446;
	}
	setp.lt.s32 	%p915, %r3064, 0;
	selp.b64 	%rd2742, %rd2740, %rd2741, %p915;
	shl.b64 	%rd2743, %rd2742, 1;
	sub.s64 	%rd2744, %rd2743, %rd370;
	mov.b64 	%fd1447, %rd2744;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3065}, %fd1447;
	}
	setp.lt.s32 	%p916, %r3065, 0;
	selp.b64 	%rd2745, %rd2743, %rd2744, %p916;
	shl.b64 	%rd2746, %rd2745, 1;
	sub.s64 	%rd2747, %rd2746, %rd370;
	mov.b64 	%fd1448, %rd2747;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3066}, %fd1448;
	}
	setp.lt.s32 	%p917, %r3066, 0;
	selp.b64 	%rd2748, %rd2746, %rd2747, %p917;
	shl.b64 	%rd2749, %rd2748, 1;
	sub.s64 	%rd2750, %rd2749, %rd370;
	mov.b64 	%fd1449, %rd2750;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3067}, %fd1449;
	}
	setp.lt.s32 	%p918, %r3067, 0;
	selp.b64 	%rd2751, %rd2749, %rd2750, %p918;
	shl.b64 	%rd2752, %rd2751, 1;
	sub.s64 	%rd2753, %rd2752, %rd370;
	mov.b64 	%fd1450, %rd2753;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3068}, %fd1450;
	}
	setp.lt.s32 	%p919, %r3068, 0;
	selp.b64 	%rd2754, %rd2752, %rd2753, %p919;
	shl.b64 	%rd2755, %rd2754, 1;
	sub.s64 	%rd2756, %rd2755, %rd370;
	mov.b64 	%fd1451, %rd2756;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3069}, %fd1451;
	}
	setp.lt.s32 	%p920, %r3069, 0;
	selp.b64 	%rd2757, %rd2755, %rd2756, %p920;
	shl.b64 	%rd2758, %rd2757, 1;
	sub.s64 	%rd2759, %rd2758, %rd370;
	mov.b64 	%fd1452, %rd2759;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3070}, %fd1452;
	}
	setp.lt.s32 	%p921, %r3070, 0;
	selp.b64 	%rd2760, %rd2758, %rd2759, %p921;
	shl.b64 	%rd2761, %rd2760, 1;
	sub.s64 	%rd2762, %rd2761, %rd370;
	mov.b64 	%fd1453, %rd2762;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3071}, %fd1453;
	}
	setp.lt.s32 	%p922, %r3071, 0;
	selp.b64 	%rd2763, %rd2761, %rd2762, %p922;
	shl.b64 	%rd2764, %rd2763, 1;
	sub.s64 	%rd2765, %rd2764, %rd370;
	mov.b64 	%fd1454, %rd2765;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3072}, %fd1454;
	}
	setp.lt.s32 	%p923, %r3072, 0;
	selp.b64 	%rd2766, %rd2764, %rd2765, %p923;
	shl.b64 	%rd2767, %rd2766, 1;
	sub.s64 	%rd2768, %rd2767, %rd370;
	mov.b64 	%fd1455, %rd2768;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3073}, %fd1455;
	}
	setp.lt.s32 	%p924, %r3073, 0;
	selp.b64 	%rd2769, %rd2767, %rd2768, %p924;
	shl.b64 	%rd2770, %rd2769, 1;
	sub.s64 	%rd2771, %rd2770, %rd370;
	mov.b64 	%fd1456, %rd2771;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3074}, %fd1456;
	}
	setp.lt.s32 	%p925, %r3074, 0;
	selp.b64 	%rd2772, %rd2770, %rd2771, %p925;
	shl.b64 	%rd2773, %rd2772, 1;
	sub.s64 	%rd2774, %rd2773, %rd370;
	mov.b64 	%fd1457, %rd2774;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3075}, %fd1457;
	}
	setp.lt.s32 	%p926, %r3075, 0;
	selp.b64 	%rd2775, %rd2773, %rd2774, %p926;
	shl.b64 	%rd2776, %rd2775, 1;
	sub.s64 	%rd2777, %rd2776, %rd370;
	mov.b64 	%fd1458, %rd2777;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3076}, %fd1458;
	}
	setp.lt.s32 	%p927, %r3076, 0;
	selp.b64 	%rd2778, %rd2776, %rd2777, %p927;
	shl.b64 	%rd2779, %rd2778, 1;
	sub.s64 	%rd2780, %rd2779, %rd370;
	mov.b64 	%fd1459, %rd2780;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3077}, %fd1459;
	}
	setp.lt.s32 	%p928, %r3077, 0;
	selp.b64 	%rd6292, %rd2779, %rd2780, %p928;
	shl.b64 	%rd6289, %rd6292, 1;
	add.s32 	%r560, %r6109, -16;
	setp.gt.s32 	%p929, %r6109, 15;
	mov.u32 	%r6109, %r560;
	@%p929 bra 	$L__BB0_454;

$L__BB0_455:
	and.b64  	%rd385, %rd6292, 9223372036854775807;
	setp.eq.s64 	%p930, %rd385, 0;
	mov.f64 	%fd2982, 0d0000000000000000;
	@%p930 bra 	$L__BB0_457;

	mov.b64 	%fd1461, %rd385;
	mul.f64 	%fd1462, %fd1461, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3078}, %fd1462;
	}
	shr.u32 	%r3079, %r3078, 20;
	mov.u32 	%r3080, 55;
	sub.s32 	%r3081, %r3080, %r3079;
	sub.s32 	%r3082, %r6103, %r3081;
	shl.b64 	%rd2781, %rd385, %r3081;
	setp.lt.s32 	%p931, %r3082, 1;
	mov.u32 	%r3083, 1;
	sub.s32 	%r3084, %r3083, %r3082;
	shr.u64 	%rd2782, %rd2781, %r3084;
	add.s32 	%r3085, %r3082, -1;
	cvt.u64.u32 	%rd2783, %r3085;
	shl.b64 	%rd2784, %rd2783, 52;
	add.s64 	%rd2785, %rd2784, %rd2781;
	selp.b64 	%rd2786, %rd2782, %rd2785, %p931;
	mov.b64 	%fd2982, %rd2786;

$L__BB0_457:
	and.b32  	%r3086, %r537, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3087}, %fd2982;
	}
	or.b32  	%r3088, %r3087, %r3086;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3089, %temp}, %fd2982;
	}
	mov.b64 	%fd2983, {%r3089, %r3088};
	bra.uni 	$L__BB0_461;

$L__BB0_459:
	mov.f64 	%fd1463, 0d3FF0000000000000;
	add.rn.f64 	%fd2983, %fd245, %fd1463;

$L__BB0_461:
	mov.f64 	%fd1464, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1465, %fd1464, %fd2983;
	mul.f64 	%fd1466, %fd1465, %fd75;
	mul.f64 	%fd1467, %fd1466, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 85 26
	add.s32 	%r3090, %r6129, 2;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 85 26
	cvt.rn.f64.s32 	%fd1468, %r3090;
	fma.rn.f64 	%fd256, %fd1468, 0d400921FB54442D18, %fd1467;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r561}, %fd256;
	}
	and.b32  	%r3091, %r561, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3092, %temp}, %fd256;
	}
	mov.b64 	%fd2984, {%r3092, %r3091};
	setp.gt.u32 	%p936, %r3091, 2146435071;
	or.pred  	%p938, %p936, %p18;
	@%p938 bra 	$L__BB0_478;
	bra.uni 	$L__BB0_462;

$L__BB0_478:
	.loc	1 0 9
	setp.le.f64 	%p973, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p974, %fd2984, 0d7FF0000000000000;
	and.pred  	%p975, %p974, %p973;
	@%p975 bra 	$L__BB0_480;
	bra.uni 	$L__BB0_479;

$L__BB0_480:
	setp.eq.f64 	%p976, %fd2984, 0d7FF0000000000000;
	selp.f64 	%fd2987, 0dFFF8000000000000, %fd256, %p976;
	bra.uni 	$L__BB0_481;

$L__BB0_462:
	.loc	1 0 9
	mov.f64 	%fd2987, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_481;

	setp.ltu.f64 	%p940, %fd2984, %fd3160;
	mov.f64 	%fd2987, %fd256;
	@%p940 bra 	$L__BB0_481;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3093}, %fd2984;
	}
	shr.u32 	%r6111, %r3093, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3094}, %fd3160;
	}
	shr.u32 	%r6112, %r3094, 20;
	setp.ne.s32 	%p941, %r6111, 0;
	@%p941 bra 	$L__BB0_466;

	mul.f64 	%fd2984, %fd2984, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3095}, %fd2984;
	}
	shr.u32 	%r3096, %r3095, 20;
	add.s32 	%r6111, %r3096, -54;

$L__BB0_466:
	setp.ne.s32 	%p942, %r6112, 0;
	mov.f64 	%fd2985, %fd3160;
	@%p942 bra 	$L__BB0_468;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3097}, %fd2;
	}
	shr.u32 	%r3098, %r3097, 20;
	add.s32 	%r6112, %r3098, -54;
	mov.f64 	%fd2985, %fd2;

$L__BB0_468:
	mov.b64 	%rd2788, %fd2984;
	and.b64  	%rd2789, %rd2788, 4503599627370495;
	or.b64  	%rd6297, %rd2789, 4503599627370496;
	mov.b64 	%rd2790, %fd2985;
	and.b64  	%rd2791, %rd2790, 4503599627370495;
	or.b64  	%rd387, %rd2791, 4503599627370496;
	sub.s32 	%r6118, %r6111, %r6112;
	not.b32 	%r3099, %r6111;
	add.s32 	%r3100, %r6112, %r3099;
	max.s32 	%r3101, %r3100, -1;
	add.s32 	%r569, %r3101, %r6111;
	mov.u32 	%r3102, 2;
	sub.s32 	%r3103, %r3102, %r6112;
	add.s32 	%r3104, %r3103, %r569;
	and.b32  	%r6114, %r3104, 3;
	setp.eq.s32 	%p943, %r6114, 0;
	@%p943 bra 	$L__BB0_470;

$L__BB0_469:
	.pragma "nounroll";
	sub.s64 	%rd2792, %rd6297, %rd387;
	mov.b64 	%fd1470, %rd2792;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3105}, %fd1470;
	}
	setp.lt.s32 	%p944, %r3105, 0;
	selp.b64 	%rd6300, %rd6297, %rd2792, %p944;
	shl.b64 	%rd6297, %rd6300, 1;
	add.s32 	%r6118, %r6118, -1;
	add.s32 	%r6114, %r6114, -1;
	setp.ne.s32 	%p945, %r6114, 0;
	@%p945 bra 	$L__BB0_469;

$L__BB0_470:
	mov.u32 	%r3106, 1;
	sub.s32 	%r3107, %r3106, %r6112;
	add.s32 	%r3108, %r3107, %r569;
	setp.lt.u32 	%p946, %r3108, 3;
	@%p946 bra 	$L__BB0_475;

	not.b32 	%r3109, %r6118;
	max.s32 	%r3110, %r3109, -4;
	add.s32 	%r3111, %r6118, %r3110;
	add.s32 	%r576, %r3111, 4;
	shr.u32 	%r3112, %r576, 2;
	add.s32 	%r3113, %r3112, 1;
	and.b32  	%r6117, %r3113, 3;
	setp.eq.s32 	%p947, %r6117, 0;
	@%p947 bra 	$L__BB0_473;

$L__BB0_472:
	.pragma "nounroll";
	sub.s64 	%rd2794, %rd6297, %rd387;
	mov.b64 	%fd1471, %rd2794;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3114}, %fd1471;
	}
	setp.lt.s32 	%p948, %r3114, 0;
	selp.b64 	%rd2795, %rd6297, %rd2794, %p948;
	shl.b64 	%rd2796, %rd2795, 1;
	sub.s64 	%rd2797, %rd2796, %rd387;
	mov.b64 	%fd1472, %rd2797;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3115}, %fd1472;
	}
	setp.lt.s32 	%p949, %r3115, 0;
	selp.b64 	%rd2798, %rd2796, %rd2797, %p949;
	shl.b64 	%rd2799, %rd2798, 1;
	sub.s64 	%rd2800, %rd2799, %rd387;
	mov.b64 	%fd1473, %rd2800;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3116}, %fd1473;
	}
	setp.lt.s32 	%p950, %r3116, 0;
	selp.b64 	%rd2801, %rd2799, %rd2800, %p950;
	shl.b64 	%rd2802, %rd2801, 1;
	sub.s64 	%rd2803, %rd2802, %rd387;
	mov.b64 	%fd1474, %rd2803;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3117}, %fd1474;
	}
	setp.lt.s32 	%p951, %r3117, 0;
	selp.b64 	%rd6300, %rd2802, %rd2803, %p951;
	shl.b64 	%rd6297, %rd6300, 1;
	add.s32 	%r6118, %r6118, -4;
	add.s32 	%r6117, %r6117, -1;
	setp.ne.s32 	%p952, %r6117, 0;
	@%p952 bra 	$L__BB0_472;

$L__BB0_473:
	setp.lt.u32 	%p953, %r576, 12;
	@%p953 bra 	$L__BB0_475;

$L__BB0_474:
	sub.s64 	%rd2804, %rd6297, %rd387;
	mov.b64 	%fd1475, %rd2804;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3118}, %fd1475;
	}
	setp.lt.s32 	%p954, %r3118, 0;
	selp.b64 	%rd2805, %rd6297, %rd2804, %p954;
	shl.b64 	%rd2806, %rd2805, 1;
	sub.s64 	%rd2807, %rd2806, %rd387;
	mov.b64 	%fd1476, %rd2807;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3119}, %fd1476;
	}
	setp.lt.s32 	%p955, %r3119, 0;
	selp.b64 	%rd2808, %rd2806, %rd2807, %p955;
	shl.b64 	%rd2809, %rd2808, 1;
	sub.s64 	%rd2810, %rd2809, %rd387;
	mov.b64 	%fd1477, %rd2810;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3120}, %fd1477;
	}
	setp.lt.s32 	%p956, %r3120, 0;
	selp.b64 	%rd2811, %rd2809, %rd2810, %p956;
	shl.b64 	%rd2812, %rd2811, 1;
	sub.s64 	%rd2813, %rd2812, %rd387;
	mov.b64 	%fd1478, %rd2813;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3121}, %fd1478;
	}
	setp.lt.s32 	%p957, %r3121, 0;
	selp.b64 	%rd2814, %rd2812, %rd2813, %p957;
	shl.b64 	%rd2815, %rd2814, 1;
	sub.s64 	%rd2816, %rd2815, %rd387;
	mov.b64 	%fd1479, %rd2816;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3122}, %fd1479;
	}
	setp.lt.s32 	%p958, %r3122, 0;
	selp.b64 	%rd2817, %rd2815, %rd2816, %p958;
	shl.b64 	%rd2818, %rd2817, 1;
	sub.s64 	%rd2819, %rd2818, %rd387;
	mov.b64 	%fd1480, %rd2819;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3123}, %fd1480;
	}
	setp.lt.s32 	%p959, %r3123, 0;
	selp.b64 	%rd2820, %rd2818, %rd2819, %p959;
	shl.b64 	%rd2821, %rd2820, 1;
	sub.s64 	%rd2822, %rd2821, %rd387;
	mov.b64 	%fd1481, %rd2822;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3124}, %fd1481;
	}
	setp.lt.s32 	%p960, %r3124, 0;
	selp.b64 	%rd2823, %rd2821, %rd2822, %p960;
	shl.b64 	%rd2824, %rd2823, 1;
	sub.s64 	%rd2825, %rd2824, %rd387;
	mov.b64 	%fd1482, %rd2825;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3125}, %fd1482;
	}
	setp.lt.s32 	%p961, %r3125, 0;
	selp.b64 	%rd2826, %rd2824, %rd2825, %p961;
	shl.b64 	%rd2827, %rd2826, 1;
	sub.s64 	%rd2828, %rd2827, %rd387;
	mov.b64 	%fd1483, %rd2828;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3126}, %fd1483;
	}
	setp.lt.s32 	%p962, %r3126, 0;
	selp.b64 	%rd2829, %rd2827, %rd2828, %p962;
	shl.b64 	%rd2830, %rd2829, 1;
	sub.s64 	%rd2831, %rd2830, %rd387;
	mov.b64 	%fd1484, %rd2831;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3127}, %fd1484;
	}
	setp.lt.s32 	%p963, %r3127, 0;
	selp.b64 	%rd2832, %rd2830, %rd2831, %p963;
	shl.b64 	%rd2833, %rd2832, 1;
	sub.s64 	%rd2834, %rd2833, %rd387;
	mov.b64 	%fd1485, %rd2834;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3128}, %fd1485;
	}
	setp.lt.s32 	%p964, %r3128, 0;
	selp.b64 	%rd2835, %rd2833, %rd2834, %p964;
	shl.b64 	%rd2836, %rd2835, 1;
	sub.s64 	%rd2837, %rd2836, %rd387;
	mov.b64 	%fd1486, %rd2837;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3129}, %fd1486;
	}
	setp.lt.s32 	%p965, %r3129, 0;
	selp.b64 	%rd2838, %rd2836, %rd2837, %p965;
	shl.b64 	%rd2839, %rd2838, 1;
	sub.s64 	%rd2840, %rd2839, %rd387;
	mov.b64 	%fd1487, %rd2840;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3130}, %fd1487;
	}
	setp.lt.s32 	%p966, %r3130, 0;
	selp.b64 	%rd2841, %rd2839, %rd2840, %p966;
	shl.b64 	%rd2842, %rd2841, 1;
	sub.s64 	%rd2843, %rd2842, %rd387;
	mov.b64 	%fd1488, %rd2843;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3131}, %fd1488;
	}
	setp.lt.s32 	%p967, %r3131, 0;
	selp.b64 	%rd2844, %rd2842, %rd2843, %p967;
	shl.b64 	%rd2845, %rd2844, 1;
	sub.s64 	%rd2846, %rd2845, %rd387;
	mov.b64 	%fd1489, %rd2846;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3132}, %fd1489;
	}
	setp.lt.s32 	%p968, %r3132, 0;
	selp.b64 	%rd2847, %rd2845, %rd2846, %p968;
	shl.b64 	%rd2848, %rd2847, 1;
	sub.s64 	%rd2849, %rd2848, %rd387;
	mov.b64 	%fd1490, %rd2849;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3133}, %fd1490;
	}
	setp.lt.s32 	%p969, %r3133, 0;
	selp.b64 	%rd6300, %rd2848, %rd2849, %p969;
	shl.b64 	%rd6297, %rd6300, 1;
	add.s32 	%r584, %r6118, -16;
	setp.gt.s32 	%p970, %r6118, 15;
	mov.u32 	%r6118, %r584;
	@%p970 bra 	$L__BB0_474;

$L__BB0_475:
	and.b64  	%rd402, %rd6300, 9223372036854775807;
	setp.eq.s64 	%p971, %rd402, 0;
	mov.f64 	%fd2986, 0d0000000000000000;
	@%p971 bra 	$L__BB0_477;

	mov.b64 	%fd1492, %rd402;
	mul.f64 	%fd1493, %fd1492, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3134}, %fd1493;
	}
	shr.u32 	%r3135, %r3134, 20;
	mov.u32 	%r3136, 55;
	sub.s32 	%r3137, %r3136, %r3135;
	sub.s32 	%r3138, %r6112, %r3137;
	shl.b64 	%rd2850, %rd402, %r3137;
	setp.lt.s32 	%p972, %r3138, 1;
	mov.u32 	%r3139, 1;
	sub.s32 	%r3140, %r3139, %r3138;
	shr.u64 	%rd2851, %rd2850, %r3140;
	add.s32 	%r3141, %r3138, -1;
	cvt.u64.u32 	%rd2852, %r3141;
	shl.b64 	%rd2853, %rd2852, 52;
	add.s64 	%rd2854, %rd2853, %rd2850;
	selp.b64 	%rd2855, %rd2851, %rd2854, %p972;
	mov.b64 	%fd2986, %rd2855;

$L__BB0_477:
	and.b32  	%r3142, %r561, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3143}, %fd2986;
	}
	or.b32  	%r3144, %r3143, %r3142;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3145, %temp}, %fd2986;
	}
	mov.b64 	%fd2987, {%r3145, %r3144};
	bra.uni 	$L__BB0_481;

$L__BB0_479:
	mov.f64 	%fd1494, 0d3FF0000000000000;
	add.rn.f64 	%fd2987, %fd256, %fd1494;

$L__BB0_481:
	mov.f64 	%fd1495, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1496, %fd1495, %fd2987;
	mul.f64 	%fd1497, %fd1496, %fd87;
	mul.f64 	%fd1498, %fd1497, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 85 26
	add.s32 	%r3146, %r6129, 1;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 85 26
	cvt.rn.f64.s32 	%fd1499, %r3146;
	fma.rn.f64 	%fd267, %fd1499, 0d400921FB54442D18, %fd1498;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r585}, %fd267;
	}
	and.b32  	%r3147, %r585, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3148, %temp}, %fd267;
	}
	mov.b64 	%fd2988, {%r3148, %r3147};
	setp.gt.u32 	%p977, %r3147, 2146435071;
	or.pred  	%p979, %p977, %p18;
	@%p979 bra 	$L__BB0_498;
	bra.uni 	$L__BB0_482;

$L__BB0_498:
	.loc	1 0 9
	setp.le.f64 	%p1014, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1015, %fd2988, 0d7FF0000000000000;
	and.pred  	%p1016, %p1015, %p1014;
	@%p1016 bra 	$L__BB0_500;
	bra.uni 	$L__BB0_499;

$L__BB0_500:
	setp.eq.f64 	%p1017, %fd2988, 0d7FF0000000000000;
	selp.f64 	%fd2996, 0dFFF8000000000000, %fd267, %p1017;
	bra.uni 	$L__BB0_501;

$L__BB0_482:
	.loc	1 0 9
	mov.f64 	%fd2996, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_501;

	setp.ltu.f64 	%p981, %fd2988, %fd3160;
	mov.f64 	%fd2996, %fd267;
	@%p981 bra 	$L__BB0_501;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3149}, %fd2988;
	}
	shr.u32 	%r6120, %r3149, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3150}, %fd3160;
	}
	shr.u32 	%r6121, %r3150, 20;
	setp.ne.s32 	%p982, %r6120, 0;
	@%p982 bra 	$L__BB0_486;

	mul.f64 	%fd2988, %fd2988, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3151}, %fd2988;
	}
	shr.u32 	%r3152, %r3151, 20;
	add.s32 	%r6120, %r3152, -54;

$L__BB0_486:
	setp.ne.s32 	%p983, %r6121, 0;
	mov.f64 	%fd2989, %fd3160;
	@%p983 bra 	$L__BB0_488;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3153}, %fd2;
	}
	shr.u32 	%r3154, %r3153, 20;
	add.s32 	%r6121, %r3154, -54;
	mov.f64 	%fd2989, %fd2;

$L__BB0_488:
	mov.b64 	%rd2857, %fd2988;
	and.b64  	%rd2858, %rd2857, 4503599627370495;
	or.b64  	%rd6305, %rd2858, 4503599627370496;
	mov.b64 	%rd2859, %fd2989;
	and.b64  	%rd2860, %rd2859, 4503599627370495;
	or.b64  	%rd404, %rd2860, 4503599627370496;
	sub.s32 	%r6127, %r6120, %r6121;
	not.b32 	%r3155, %r6120;
	add.s32 	%r3156, %r6121, %r3155;
	max.s32 	%r3157, %r3156, -1;
	add.s32 	%r593, %r3157, %r6120;
	mov.u32 	%r3158, 2;
	sub.s32 	%r3159, %r3158, %r6121;
	add.s32 	%r3160, %r3159, %r593;
	and.b32  	%r6123, %r3160, 3;
	setp.eq.s32 	%p984, %r6123, 0;
	@%p984 bra 	$L__BB0_490;

$L__BB0_489:
	.pragma "nounroll";
	sub.s64 	%rd2861, %rd6305, %rd404;
	mov.b64 	%fd1501, %rd2861;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3161}, %fd1501;
	}
	setp.lt.s32 	%p985, %r3161, 0;
	selp.b64 	%rd6308, %rd6305, %rd2861, %p985;
	shl.b64 	%rd6305, %rd6308, 1;
	add.s32 	%r6127, %r6127, -1;
	add.s32 	%r6123, %r6123, -1;
	setp.ne.s32 	%p986, %r6123, 0;
	@%p986 bra 	$L__BB0_489;

$L__BB0_490:
	mov.u32 	%r3162, 1;
	sub.s32 	%r3163, %r3162, %r6121;
	add.s32 	%r3164, %r3163, %r593;
	setp.lt.u32 	%p987, %r3164, 3;
	@%p987 bra 	$L__BB0_495;

	not.b32 	%r3165, %r6127;
	max.s32 	%r3166, %r3165, -4;
	add.s32 	%r3167, %r6127, %r3166;
	add.s32 	%r600, %r3167, 4;
	shr.u32 	%r3168, %r600, 2;
	add.s32 	%r3169, %r3168, 1;
	and.b32  	%r6126, %r3169, 3;
	setp.eq.s32 	%p988, %r6126, 0;
	@%p988 bra 	$L__BB0_493;

$L__BB0_492:
	.pragma "nounroll";
	sub.s64 	%rd2863, %rd6305, %rd404;
	mov.b64 	%fd1502, %rd2863;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3170}, %fd1502;
	}
	setp.lt.s32 	%p989, %r3170, 0;
	selp.b64 	%rd2864, %rd6305, %rd2863, %p989;
	shl.b64 	%rd2865, %rd2864, 1;
	sub.s64 	%rd2866, %rd2865, %rd404;
	mov.b64 	%fd1503, %rd2866;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3171}, %fd1503;
	}
	setp.lt.s32 	%p990, %r3171, 0;
	selp.b64 	%rd2867, %rd2865, %rd2866, %p990;
	shl.b64 	%rd2868, %rd2867, 1;
	sub.s64 	%rd2869, %rd2868, %rd404;
	mov.b64 	%fd1504, %rd2869;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3172}, %fd1504;
	}
	setp.lt.s32 	%p991, %r3172, 0;
	selp.b64 	%rd2870, %rd2868, %rd2869, %p991;
	shl.b64 	%rd2871, %rd2870, 1;
	sub.s64 	%rd2872, %rd2871, %rd404;
	mov.b64 	%fd1505, %rd2872;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3173}, %fd1505;
	}
	setp.lt.s32 	%p992, %r3173, 0;
	selp.b64 	%rd6308, %rd2871, %rd2872, %p992;
	shl.b64 	%rd6305, %rd6308, 1;
	add.s32 	%r6127, %r6127, -4;
	add.s32 	%r6126, %r6126, -1;
	setp.ne.s32 	%p993, %r6126, 0;
	@%p993 bra 	$L__BB0_492;

$L__BB0_493:
	setp.lt.u32 	%p994, %r600, 12;
	@%p994 bra 	$L__BB0_495;

$L__BB0_494:
	sub.s64 	%rd2873, %rd6305, %rd404;
	mov.b64 	%fd1506, %rd2873;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3174}, %fd1506;
	}
	setp.lt.s32 	%p995, %r3174, 0;
	selp.b64 	%rd2874, %rd6305, %rd2873, %p995;
	shl.b64 	%rd2875, %rd2874, 1;
	sub.s64 	%rd2876, %rd2875, %rd404;
	mov.b64 	%fd1507, %rd2876;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3175}, %fd1507;
	}
	setp.lt.s32 	%p996, %r3175, 0;
	selp.b64 	%rd2877, %rd2875, %rd2876, %p996;
	shl.b64 	%rd2878, %rd2877, 1;
	sub.s64 	%rd2879, %rd2878, %rd404;
	mov.b64 	%fd1508, %rd2879;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3176}, %fd1508;
	}
	setp.lt.s32 	%p997, %r3176, 0;
	selp.b64 	%rd2880, %rd2878, %rd2879, %p997;
	shl.b64 	%rd2881, %rd2880, 1;
	sub.s64 	%rd2882, %rd2881, %rd404;
	mov.b64 	%fd1509, %rd2882;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3177}, %fd1509;
	}
	setp.lt.s32 	%p998, %r3177, 0;
	selp.b64 	%rd2883, %rd2881, %rd2882, %p998;
	shl.b64 	%rd2884, %rd2883, 1;
	sub.s64 	%rd2885, %rd2884, %rd404;
	mov.b64 	%fd1510, %rd2885;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3178}, %fd1510;
	}
	setp.lt.s32 	%p999, %r3178, 0;
	selp.b64 	%rd2886, %rd2884, %rd2885, %p999;
	shl.b64 	%rd2887, %rd2886, 1;
	sub.s64 	%rd2888, %rd2887, %rd404;
	mov.b64 	%fd1511, %rd2888;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3179}, %fd1511;
	}
	setp.lt.s32 	%p1000, %r3179, 0;
	selp.b64 	%rd2889, %rd2887, %rd2888, %p1000;
	shl.b64 	%rd2890, %rd2889, 1;
	sub.s64 	%rd2891, %rd2890, %rd404;
	mov.b64 	%fd1512, %rd2891;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3180}, %fd1512;
	}
	setp.lt.s32 	%p1001, %r3180, 0;
	selp.b64 	%rd2892, %rd2890, %rd2891, %p1001;
	shl.b64 	%rd2893, %rd2892, 1;
	sub.s64 	%rd2894, %rd2893, %rd404;
	mov.b64 	%fd1513, %rd2894;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3181}, %fd1513;
	}
	setp.lt.s32 	%p1002, %r3181, 0;
	selp.b64 	%rd2895, %rd2893, %rd2894, %p1002;
	shl.b64 	%rd2896, %rd2895, 1;
	sub.s64 	%rd2897, %rd2896, %rd404;
	mov.b64 	%fd1514, %rd2897;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3182}, %fd1514;
	}
	setp.lt.s32 	%p1003, %r3182, 0;
	selp.b64 	%rd2898, %rd2896, %rd2897, %p1003;
	shl.b64 	%rd2899, %rd2898, 1;
	sub.s64 	%rd2900, %rd2899, %rd404;
	mov.b64 	%fd1515, %rd2900;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3183}, %fd1515;
	}
	setp.lt.s32 	%p1004, %r3183, 0;
	selp.b64 	%rd2901, %rd2899, %rd2900, %p1004;
	shl.b64 	%rd2902, %rd2901, 1;
	sub.s64 	%rd2903, %rd2902, %rd404;
	mov.b64 	%fd1516, %rd2903;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3184}, %fd1516;
	}
	setp.lt.s32 	%p1005, %r3184, 0;
	selp.b64 	%rd2904, %rd2902, %rd2903, %p1005;
	shl.b64 	%rd2905, %rd2904, 1;
	sub.s64 	%rd2906, %rd2905, %rd404;
	mov.b64 	%fd1517, %rd2906;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3185}, %fd1517;
	}
	setp.lt.s32 	%p1006, %r3185, 0;
	selp.b64 	%rd2907, %rd2905, %rd2906, %p1006;
	shl.b64 	%rd2908, %rd2907, 1;
	sub.s64 	%rd2909, %rd2908, %rd404;
	mov.b64 	%fd1518, %rd2909;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3186}, %fd1518;
	}
	setp.lt.s32 	%p1007, %r3186, 0;
	selp.b64 	%rd2910, %rd2908, %rd2909, %p1007;
	shl.b64 	%rd2911, %rd2910, 1;
	sub.s64 	%rd2912, %rd2911, %rd404;
	mov.b64 	%fd1519, %rd2912;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3187}, %fd1519;
	}
	setp.lt.s32 	%p1008, %r3187, 0;
	selp.b64 	%rd2913, %rd2911, %rd2912, %p1008;
	shl.b64 	%rd2914, %rd2913, 1;
	sub.s64 	%rd2915, %rd2914, %rd404;
	mov.b64 	%fd1520, %rd2915;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3188}, %fd1520;
	}
	setp.lt.s32 	%p1009, %r3188, 0;
	selp.b64 	%rd2916, %rd2914, %rd2915, %p1009;
	shl.b64 	%rd2917, %rd2916, 1;
	sub.s64 	%rd2918, %rd2917, %rd404;
	mov.b64 	%fd1521, %rd2918;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3189}, %fd1521;
	}
	setp.lt.s32 	%p1010, %r3189, 0;
	selp.b64 	%rd6308, %rd2917, %rd2918, %p1010;
	shl.b64 	%rd6305, %rd6308, 1;
	add.s32 	%r608, %r6127, -16;
	setp.gt.s32 	%p1011, %r6127, 15;
	mov.u32 	%r6127, %r608;
	@%p1011 bra 	$L__BB0_494;

$L__BB0_495:
	and.b64  	%rd419, %rd6308, 9223372036854775807;
	setp.eq.s64 	%p1012, %rd419, 0;
	mov.f64 	%fd2990, 0d0000000000000000;
	@%p1012 bra 	$L__BB0_497;

	mov.b64 	%fd1523, %rd419;
	mul.f64 	%fd1524, %fd1523, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3190}, %fd1524;
	}
	shr.u32 	%r3191, %r3190, 20;
	mov.u32 	%r3192, 55;
	sub.s32 	%r3193, %r3192, %r3191;
	sub.s32 	%r3194, %r6121, %r3193;
	shl.b64 	%rd2919, %rd419, %r3193;
	setp.lt.s32 	%p1013, %r3194, 1;
	mov.u32 	%r3195, 1;
	sub.s32 	%r3196, %r3195, %r3194;
	shr.u64 	%rd2920, %rd2919, %r3196;
	add.s32 	%r3197, %r3194, -1;
	cvt.u64.u32 	%rd2921, %r3197;
	shl.b64 	%rd2922, %rd2921, 52;
	add.s64 	%rd2923, %rd2922, %rd2919;
	selp.b64 	%rd2924, %rd2920, %rd2923, %p1013;
	mov.b64 	%fd2990, %rd2924;

$L__BB0_497:
	and.b32  	%r3198, %r585, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3199}, %fd2990;
	}
	or.b32  	%r3200, %r3199, %r3198;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3201, %temp}, %fd2990;
	}
	mov.b64 	%fd2996, {%r3201, %r3200};
	bra.uni 	$L__BB0_501;

$L__BB0_499:
	mov.f64 	%fd1525, 0d3FF0000000000000;
	add.rn.f64 	%fd2996, %fd267, %fd1525;

$L__BB0_501:
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 85 26
	setp.lt.s32 	%p1018, %r6129, 1;
	@%p1018 bra 	$L__BB0_524;

	.loc	1 86 9, function_name $L__info_string3, inlined_at 1 249 17
	cvt.u64.u32 	%rd420, %r415;

$L__BB0_503:
	.loc	1 0 9
	mov.u32 	%r609, %r6129;
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 85 26
	add.s32 	%r3202, %r609, -1;
	.loc	1 62 9, function_name $L__info_string6, inlined_at 1 85 26
	cvt.s64.s32 	%rd2925, %r3202;
	add.s64 	%rd2926, %rd2925, %rd420;
	add.s64 	%rd2927, %rd9, %rd2926;
	ld.global.u8 	%rs80, [%rd2927];
	cvt.rn.f64.u16 	%fd1526, %rs80;
	.loc	1 63 9, function_name $L__info_string6, inlined_at 1 85 26
	mov.f64 	%fd1527, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1528, %fd1527, %fd2996;
	mul.f64 	%fd1529, %fd1528, %fd1526;
	mul.f64 	%fd1530, %fd1529, 0d400921FB54442D18;
	cvt.rn.f64.s32 	%fd1531, %r609;
	fma.rn.f64 	%fd279, %fd1531, 0d400921FB54442D18, %fd1530;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r610}, %fd279;
	}
	and.b32  	%r3203, %r610, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3204, %temp}, %fd279;
	}
	mov.b64 	%fd2993, {%r3204, %r3203};
	setp.gt.u32 	%p1019, %r3203, 2146435071;
	or.pred  	%p1021, %p1019, %p18;
	@%p1021 bra 	$L__BB0_520;
	bra.uni 	$L__BB0_504;

$L__BB0_520:
	.loc	1 0 9
	setp.le.f64 	%p1056, %fd3160, 0d7FF0000000000000;
	.loc	1 63 9
	setp.le.f64 	%p1057, %fd2993, 0d7FF0000000000000;
	and.pred  	%p1058, %p1057, %p1056;
	@%p1058 bra 	$L__BB0_522;
	bra.uni 	$L__BB0_521;

$L__BB0_522:
	setp.eq.f64 	%p1059, %fd2993, 0d7FF0000000000000;
	selp.f64 	%fd2996, 0dFFF8000000000000, %fd279, %p1059;
	bra.uni 	$L__BB0_523;

$L__BB0_504:
	.loc	1 0 9
	mov.f64 	%fd2996, 0dFFF8000000000000;
	.loc	1 63 9
	@%p309 bra 	$L__BB0_523;

	setp.ltu.f64 	%p1023, %fd2993, %fd3160;
	mov.f64 	%fd2996, %fd279;
	@%p1023 bra 	$L__BB0_523;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3205}, %fd2993;
	}
	shr.u32 	%r6130, %r3205, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3206}, %fd3160;
	}
	shr.u32 	%r6131, %r3206, 20;
	setp.ne.s32 	%p1024, %r6130, 0;
	@%p1024 bra 	$L__BB0_508;

	mul.f64 	%fd2993, %fd2993, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3207}, %fd2993;
	}
	shr.u32 	%r3208, %r3207, 20;
	add.s32 	%r6130, %r3208, -54;

$L__BB0_508:
	setp.ne.s32 	%p1025, %r6131, 0;
	mov.f64 	%fd2994, %fd3160;
	@%p1025 bra 	$L__BB0_510;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3209}, %fd2;
	}
	shr.u32 	%r3210, %r3209, 20;
	add.s32 	%r6131, %r3210, -54;
	mov.f64 	%fd2994, %fd2;

$L__BB0_510:
	mov.b64 	%rd2929, %fd2993;
	and.b64  	%rd2930, %rd2929, 4503599627370495;
	or.b64  	%rd6313, %rd2930, 4503599627370496;
	mov.b64 	%rd2931, %fd2994;
	and.b64  	%rd2932, %rd2931, 4503599627370495;
	or.b64  	%rd422, %rd2932, 4503599627370496;
	sub.s32 	%r6137, %r6130, %r6131;
	not.b32 	%r3211, %r6130;
	add.s32 	%r3212, %r6131, %r3211;
	max.s32 	%r3213, %r3212, -1;
	add.s32 	%r618, %r3213, %r6130;
	mov.u32 	%r3214, 2;
	sub.s32 	%r3215, %r3214, %r6131;
	add.s32 	%r3216, %r3215, %r618;
	and.b32  	%r6133, %r3216, 3;
	setp.eq.s32 	%p1026, %r6133, 0;
	@%p1026 bra 	$L__BB0_512;

$L__BB0_511:
	.pragma "nounroll";
	sub.s64 	%rd2933, %rd6313, %rd422;
	mov.b64 	%fd1533, %rd2933;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3217}, %fd1533;
	}
	setp.lt.s32 	%p1027, %r3217, 0;
	selp.b64 	%rd6316, %rd6313, %rd2933, %p1027;
	shl.b64 	%rd6313, %rd6316, 1;
	add.s32 	%r6137, %r6137, -1;
	add.s32 	%r6133, %r6133, -1;
	setp.ne.s32 	%p1028, %r6133, 0;
	@%p1028 bra 	$L__BB0_511;

$L__BB0_512:
	mov.u32 	%r3218, 1;
	sub.s32 	%r3219, %r3218, %r6131;
	add.s32 	%r3220, %r3219, %r618;
	setp.lt.u32 	%p1029, %r3220, 3;
	@%p1029 bra 	$L__BB0_517;

	not.b32 	%r3221, %r6137;
	max.s32 	%r3222, %r3221, -4;
	add.s32 	%r3223, %r6137, %r3222;
	add.s32 	%r625, %r3223, 4;
	shr.u32 	%r3224, %r625, 2;
	add.s32 	%r3225, %r3224, 1;
	and.b32  	%r6136, %r3225, 3;
	setp.eq.s32 	%p1030, %r6136, 0;
	@%p1030 bra 	$L__BB0_515;

$L__BB0_514:
	.pragma "nounroll";
	sub.s64 	%rd2935, %rd6313, %rd422;
	mov.b64 	%fd1534, %rd2935;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3226}, %fd1534;
	}
	setp.lt.s32 	%p1031, %r3226, 0;
	selp.b64 	%rd2936, %rd6313, %rd2935, %p1031;
	shl.b64 	%rd2937, %rd2936, 1;
	sub.s64 	%rd2938, %rd2937, %rd422;
	mov.b64 	%fd1535, %rd2938;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3227}, %fd1535;
	}
	setp.lt.s32 	%p1032, %r3227, 0;
	selp.b64 	%rd2939, %rd2937, %rd2938, %p1032;
	shl.b64 	%rd2940, %rd2939, 1;
	sub.s64 	%rd2941, %rd2940, %rd422;
	mov.b64 	%fd1536, %rd2941;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3228}, %fd1536;
	}
	setp.lt.s32 	%p1033, %r3228, 0;
	selp.b64 	%rd2942, %rd2940, %rd2941, %p1033;
	shl.b64 	%rd2943, %rd2942, 1;
	sub.s64 	%rd2944, %rd2943, %rd422;
	mov.b64 	%fd1537, %rd2944;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3229}, %fd1537;
	}
	setp.lt.s32 	%p1034, %r3229, 0;
	selp.b64 	%rd6316, %rd2943, %rd2944, %p1034;
	shl.b64 	%rd6313, %rd6316, 1;
	add.s32 	%r6137, %r6137, -4;
	add.s32 	%r6136, %r6136, -1;
	setp.ne.s32 	%p1035, %r6136, 0;
	@%p1035 bra 	$L__BB0_514;

$L__BB0_515:
	setp.lt.u32 	%p1036, %r625, 12;
	@%p1036 bra 	$L__BB0_517;

$L__BB0_516:
	sub.s64 	%rd2945, %rd6313, %rd422;
	mov.b64 	%fd1538, %rd2945;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3230}, %fd1538;
	}
	setp.lt.s32 	%p1037, %r3230, 0;
	selp.b64 	%rd2946, %rd6313, %rd2945, %p1037;
	shl.b64 	%rd2947, %rd2946, 1;
	sub.s64 	%rd2948, %rd2947, %rd422;
	mov.b64 	%fd1539, %rd2948;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3231}, %fd1539;
	}
	setp.lt.s32 	%p1038, %r3231, 0;
	selp.b64 	%rd2949, %rd2947, %rd2948, %p1038;
	shl.b64 	%rd2950, %rd2949, 1;
	sub.s64 	%rd2951, %rd2950, %rd422;
	mov.b64 	%fd1540, %rd2951;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3232}, %fd1540;
	}
	setp.lt.s32 	%p1039, %r3232, 0;
	selp.b64 	%rd2952, %rd2950, %rd2951, %p1039;
	shl.b64 	%rd2953, %rd2952, 1;
	sub.s64 	%rd2954, %rd2953, %rd422;
	mov.b64 	%fd1541, %rd2954;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3233}, %fd1541;
	}
	setp.lt.s32 	%p1040, %r3233, 0;
	selp.b64 	%rd2955, %rd2953, %rd2954, %p1040;
	shl.b64 	%rd2956, %rd2955, 1;
	sub.s64 	%rd2957, %rd2956, %rd422;
	mov.b64 	%fd1542, %rd2957;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3234}, %fd1542;
	}
	setp.lt.s32 	%p1041, %r3234, 0;
	selp.b64 	%rd2958, %rd2956, %rd2957, %p1041;
	shl.b64 	%rd2959, %rd2958, 1;
	sub.s64 	%rd2960, %rd2959, %rd422;
	mov.b64 	%fd1543, %rd2960;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3235}, %fd1543;
	}
	setp.lt.s32 	%p1042, %r3235, 0;
	selp.b64 	%rd2961, %rd2959, %rd2960, %p1042;
	shl.b64 	%rd2962, %rd2961, 1;
	sub.s64 	%rd2963, %rd2962, %rd422;
	mov.b64 	%fd1544, %rd2963;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3236}, %fd1544;
	}
	setp.lt.s32 	%p1043, %r3236, 0;
	selp.b64 	%rd2964, %rd2962, %rd2963, %p1043;
	shl.b64 	%rd2965, %rd2964, 1;
	sub.s64 	%rd2966, %rd2965, %rd422;
	mov.b64 	%fd1545, %rd2966;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3237}, %fd1545;
	}
	setp.lt.s32 	%p1044, %r3237, 0;
	selp.b64 	%rd2967, %rd2965, %rd2966, %p1044;
	shl.b64 	%rd2968, %rd2967, 1;
	sub.s64 	%rd2969, %rd2968, %rd422;
	mov.b64 	%fd1546, %rd2969;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3238}, %fd1546;
	}
	setp.lt.s32 	%p1045, %r3238, 0;
	selp.b64 	%rd2970, %rd2968, %rd2969, %p1045;
	shl.b64 	%rd2971, %rd2970, 1;
	sub.s64 	%rd2972, %rd2971, %rd422;
	mov.b64 	%fd1547, %rd2972;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3239}, %fd1547;
	}
	setp.lt.s32 	%p1046, %r3239, 0;
	selp.b64 	%rd2973, %rd2971, %rd2972, %p1046;
	shl.b64 	%rd2974, %rd2973, 1;
	sub.s64 	%rd2975, %rd2974, %rd422;
	mov.b64 	%fd1548, %rd2975;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3240}, %fd1548;
	}
	setp.lt.s32 	%p1047, %r3240, 0;
	selp.b64 	%rd2976, %rd2974, %rd2975, %p1047;
	shl.b64 	%rd2977, %rd2976, 1;
	sub.s64 	%rd2978, %rd2977, %rd422;
	mov.b64 	%fd1549, %rd2978;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3241}, %fd1549;
	}
	setp.lt.s32 	%p1048, %r3241, 0;
	selp.b64 	%rd2979, %rd2977, %rd2978, %p1048;
	shl.b64 	%rd2980, %rd2979, 1;
	sub.s64 	%rd2981, %rd2980, %rd422;
	mov.b64 	%fd1550, %rd2981;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3242}, %fd1550;
	}
	setp.lt.s32 	%p1049, %r3242, 0;
	selp.b64 	%rd2982, %rd2980, %rd2981, %p1049;
	shl.b64 	%rd2983, %rd2982, 1;
	sub.s64 	%rd2984, %rd2983, %rd422;
	mov.b64 	%fd1551, %rd2984;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3243}, %fd1551;
	}
	setp.lt.s32 	%p1050, %r3243, 0;
	selp.b64 	%rd2985, %rd2983, %rd2984, %p1050;
	shl.b64 	%rd2986, %rd2985, 1;
	sub.s64 	%rd2987, %rd2986, %rd422;
	mov.b64 	%fd1552, %rd2987;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3244}, %fd1552;
	}
	setp.lt.s32 	%p1051, %r3244, 0;
	selp.b64 	%rd2988, %rd2986, %rd2987, %p1051;
	shl.b64 	%rd2989, %rd2988, 1;
	sub.s64 	%rd2990, %rd2989, %rd422;
	mov.b64 	%fd1553, %rd2990;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3245}, %fd1553;
	}
	setp.lt.s32 	%p1052, %r3245, 0;
	selp.b64 	%rd6316, %rd2989, %rd2990, %p1052;
	shl.b64 	%rd6313, %rd6316, 1;
	add.s32 	%r633, %r6137, -16;
	setp.gt.s32 	%p1053, %r6137, 15;
	mov.u32 	%r6137, %r633;
	@%p1053 bra 	$L__BB0_516;

$L__BB0_517:
	and.b64  	%rd437, %rd6316, 9223372036854775807;
	setp.eq.s64 	%p1054, %rd437, 0;
	mov.f64 	%fd2995, 0d0000000000000000;
	@%p1054 bra 	$L__BB0_519;

	mov.b64 	%fd1555, %rd437;
	mul.f64 	%fd1556, %fd1555, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3246}, %fd1556;
	}
	shr.u32 	%r3247, %r3246, 20;
	mov.u32 	%r3248, 55;
	sub.s32 	%r3249, %r3248, %r3247;
	sub.s32 	%r3250, %r6131, %r3249;
	shl.b64 	%rd2991, %rd437, %r3249;
	setp.lt.s32 	%p1055, %r3250, 1;
	mov.u32 	%r3251, 1;
	sub.s32 	%r3252, %r3251, %r3250;
	shr.u64 	%rd2992, %rd2991, %r3252;
	add.s32 	%r3253, %r3250, -1;
	cvt.u64.u32 	%rd2993, %r3253;
	shl.b64 	%rd2994, %rd2993, 52;
	add.s64 	%rd2995, %rd2994, %rd2991;
	selp.b64 	%rd2996, %rd2992, %rd2995, %p1055;
	mov.b64 	%fd2995, %rd2996;

$L__BB0_519:
	and.b32  	%r3254, %r610, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3255}, %fd2995;
	}
	or.b32  	%r3256, %r3255, %r3254;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3257, %temp}, %fd2995;
	}
	mov.b64 	%fd2996, {%r3257, %r3256};
	bra.uni 	$L__BB0_523;

$L__BB0_521:
	mov.f64 	%fd1557, 0d3FF0000000000000;
	add.rn.f64 	%fd2996, %fd279, %fd1557;

$L__BB0_523:
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 85 26
	add.s32 	%r6129, %r609, -1;
	setp.gt.s32 	%p1060, %r609, 1;
	@%p1060 bra 	$L__BB0_503;

$L__BB0_524:
	.loc	1 92 9, function_name $L__info_string3, inlined_at 1 249 17
	ld.global.u8 	%r3258, [%rd1206+40];
	ld.global.u8 	%r3259, [%rd1206+41];
	prmt.b32 	%r3260, %r3259, %r3258, 30212;
	ld.global.u8 	%r3261, [%rd1206+42];
	ld.global.u8 	%r3262, [%rd1206+43];
	prmt.b32 	%r3263, %r3262, %r3261, 30212;
	prmt.b32 	%r635, %r3263, %r3260, 4180;
	.loc	1 93 9, function_name $L__info_string3, inlined_at 1 249 17
	ld.global.u8 	%r3264, [%rd1206+44];
	ld.global.u8 	%r3265, [%rd1206+45];
	prmt.b32 	%r3266, %r3265, %r3264, 30212;
	ld.global.u8 	%r3267, [%rd1206+46];
	ld.global.u8 	%r3268, [%rd1206+47];
	prmt.b32 	%r3269, %r3268, %r3267, 30212;
	prmt.b32 	%r6211, %r3269, %r3266, 4180;
	.loc	1 91 26, function_name $L__info_string3, inlined_at 1 249 17
	.loc	1 53 5, function_name $L__info_string6, inlined_at 1 91 26
	add.s32 	%r3270, %r6211, 8;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 91 26
	cvt.rn.f64.s32 	%fd1558, %r3270;
	fma.rn.f64 	%fd291, %fd1558, 0d400921FB54442D18, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r637}, %fd291;
	}
	and.b32  	%r3271, %r637, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3272, %temp}, %fd291;
	}
	mov.b64 	%fd2998, {%r3272, %r3271};
	setp.gt.u32 	%p1061, %r3271, 2146435071;
	or.pred  	%p1063, %p1061, %p18;
	@%p1063 bra 	$L__BB0_541;
	bra.uni 	$L__BB0_525;

$L__BB0_541:
	.loc	1 0 9
	setp.le.f64 	%p1098, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1099, %fd2998, 0d7FF0000000000000;
	and.pred  	%p1100, %p1099, %p1098;
	@%p1100 bra 	$L__BB0_543;
	bra.uni 	$L__BB0_542;

$L__BB0_543:
	setp.eq.f64 	%p1101, %fd2998, 0d7FF0000000000000;
	selp.f64 	%fd3001, 0dFFF8000000000000, %fd291, %p1101;
	bra.uni 	$L__BB0_544;

$L__BB0_525:
	.loc	1 0 9
	mov.f64 	%fd3001, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_544;

	setp.ltu.f64 	%p1065, %fd2998, %fd3160;
	mov.f64 	%fd3001, %fd291;
	@%p1065 bra 	$L__BB0_544;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3273}, %fd2998;
	}
	shr.u32 	%r6139, %r3273, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3274}, %fd3160;
	}
	shr.u32 	%r6140, %r3274, 20;
	setp.ne.s32 	%p1066, %r6139, 0;
	@%p1066 bra 	$L__BB0_529;

	mul.f64 	%fd2998, %fd2998, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3275}, %fd2998;
	}
	shr.u32 	%r3276, %r3275, 20;
	add.s32 	%r6139, %r3276, -54;

$L__BB0_529:
	setp.ne.s32 	%p1067, %r6140, 0;
	mov.f64 	%fd2999, %fd3160;
	@%p1067 bra 	$L__BB0_531;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3277}, %fd2;
	}
	shr.u32 	%r3278, %r3277, 20;
	add.s32 	%r6140, %r3278, -54;
	mov.f64 	%fd2999, %fd2;

$L__BB0_531:
	mov.b64 	%rd2998, %fd2998;
	and.b64  	%rd2999, %rd2998, 4503599627370495;
	or.b64  	%rd6321, %rd2999, 4503599627370496;
	mov.b64 	%rd3000, %fd2999;
	and.b64  	%rd3001, %rd3000, 4503599627370495;
	or.b64  	%rd439, %rd3001, 4503599627370496;
	sub.s32 	%r6146, %r6139, %r6140;
	not.b32 	%r3279, %r6139;
	add.s32 	%r3280, %r6140, %r3279;
	max.s32 	%r3281, %r3280, -1;
	add.s32 	%r645, %r3281, %r6139;
	mov.u32 	%r3282, 2;
	sub.s32 	%r3283, %r3282, %r6140;
	add.s32 	%r3284, %r3283, %r645;
	and.b32  	%r6142, %r3284, 3;
	setp.eq.s32 	%p1068, %r6142, 0;
	@%p1068 bra 	$L__BB0_533;

$L__BB0_532:
	.pragma "nounroll";
	sub.s64 	%rd3002, %rd6321, %rd439;
	mov.b64 	%fd1560, %rd3002;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3285}, %fd1560;
	}
	setp.lt.s32 	%p1069, %r3285, 0;
	selp.b64 	%rd6324, %rd6321, %rd3002, %p1069;
	shl.b64 	%rd6321, %rd6324, 1;
	add.s32 	%r6146, %r6146, -1;
	add.s32 	%r6142, %r6142, -1;
	setp.ne.s32 	%p1070, %r6142, 0;
	@%p1070 bra 	$L__BB0_532;

$L__BB0_533:
	mov.u32 	%r3286, 1;
	sub.s32 	%r3287, %r3286, %r6140;
	add.s32 	%r3288, %r3287, %r645;
	setp.lt.u32 	%p1071, %r3288, 3;
	@%p1071 bra 	$L__BB0_538;

	not.b32 	%r3289, %r6146;
	max.s32 	%r3290, %r3289, -4;
	add.s32 	%r3291, %r6146, %r3290;
	add.s32 	%r652, %r3291, 4;
	shr.u32 	%r3292, %r652, 2;
	add.s32 	%r3293, %r3292, 1;
	and.b32  	%r6145, %r3293, 3;
	setp.eq.s32 	%p1072, %r6145, 0;
	@%p1072 bra 	$L__BB0_536;

$L__BB0_535:
	.pragma "nounroll";
	sub.s64 	%rd3004, %rd6321, %rd439;
	mov.b64 	%fd1561, %rd3004;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3294}, %fd1561;
	}
	setp.lt.s32 	%p1073, %r3294, 0;
	selp.b64 	%rd3005, %rd6321, %rd3004, %p1073;
	shl.b64 	%rd3006, %rd3005, 1;
	sub.s64 	%rd3007, %rd3006, %rd439;
	mov.b64 	%fd1562, %rd3007;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3295}, %fd1562;
	}
	setp.lt.s32 	%p1074, %r3295, 0;
	selp.b64 	%rd3008, %rd3006, %rd3007, %p1074;
	shl.b64 	%rd3009, %rd3008, 1;
	sub.s64 	%rd3010, %rd3009, %rd439;
	mov.b64 	%fd1563, %rd3010;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3296}, %fd1563;
	}
	setp.lt.s32 	%p1075, %r3296, 0;
	selp.b64 	%rd3011, %rd3009, %rd3010, %p1075;
	shl.b64 	%rd3012, %rd3011, 1;
	sub.s64 	%rd3013, %rd3012, %rd439;
	mov.b64 	%fd1564, %rd3013;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3297}, %fd1564;
	}
	setp.lt.s32 	%p1076, %r3297, 0;
	selp.b64 	%rd6324, %rd3012, %rd3013, %p1076;
	shl.b64 	%rd6321, %rd6324, 1;
	add.s32 	%r6146, %r6146, -4;
	add.s32 	%r6145, %r6145, -1;
	setp.ne.s32 	%p1077, %r6145, 0;
	@%p1077 bra 	$L__BB0_535;

$L__BB0_536:
	setp.lt.u32 	%p1078, %r652, 12;
	@%p1078 bra 	$L__BB0_538;

$L__BB0_537:
	sub.s64 	%rd3014, %rd6321, %rd439;
	mov.b64 	%fd1565, %rd3014;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3298}, %fd1565;
	}
	setp.lt.s32 	%p1079, %r3298, 0;
	selp.b64 	%rd3015, %rd6321, %rd3014, %p1079;
	shl.b64 	%rd3016, %rd3015, 1;
	sub.s64 	%rd3017, %rd3016, %rd439;
	mov.b64 	%fd1566, %rd3017;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3299}, %fd1566;
	}
	setp.lt.s32 	%p1080, %r3299, 0;
	selp.b64 	%rd3018, %rd3016, %rd3017, %p1080;
	shl.b64 	%rd3019, %rd3018, 1;
	sub.s64 	%rd3020, %rd3019, %rd439;
	mov.b64 	%fd1567, %rd3020;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3300}, %fd1567;
	}
	setp.lt.s32 	%p1081, %r3300, 0;
	selp.b64 	%rd3021, %rd3019, %rd3020, %p1081;
	shl.b64 	%rd3022, %rd3021, 1;
	sub.s64 	%rd3023, %rd3022, %rd439;
	mov.b64 	%fd1568, %rd3023;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3301}, %fd1568;
	}
	setp.lt.s32 	%p1082, %r3301, 0;
	selp.b64 	%rd3024, %rd3022, %rd3023, %p1082;
	shl.b64 	%rd3025, %rd3024, 1;
	sub.s64 	%rd3026, %rd3025, %rd439;
	mov.b64 	%fd1569, %rd3026;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3302}, %fd1569;
	}
	setp.lt.s32 	%p1083, %r3302, 0;
	selp.b64 	%rd3027, %rd3025, %rd3026, %p1083;
	shl.b64 	%rd3028, %rd3027, 1;
	sub.s64 	%rd3029, %rd3028, %rd439;
	mov.b64 	%fd1570, %rd3029;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3303}, %fd1570;
	}
	setp.lt.s32 	%p1084, %r3303, 0;
	selp.b64 	%rd3030, %rd3028, %rd3029, %p1084;
	shl.b64 	%rd3031, %rd3030, 1;
	sub.s64 	%rd3032, %rd3031, %rd439;
	mov.b64 	%fd1571, %rd3032;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3304}, %fd1571;
	}
	setp.lt.s32 	%p1085, %r3304, 0;
	selp.b64 	%rd3033, %rd3031, %rd3032, %p1085;
	shl.b64 	%rd3034, %rd3033, 1;
	sub.s64 	%rd3035, %rd3034, %rd439;
	mov.b64 	%fd1572, %rd3035;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3305}, %fd1572;
	}
	setp.lt.s32 	%p1086, %r3305, 0;
	selp.b64 	%rd3036, %rd3034, %rd3035, %p1086;
	shl.b64 	%rd3037, %rd3036, 1;
	sub.s64 	%rd3038, %rd3037, %rd439;
	mov.b64 	%fd1573, %rd3038;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3306}, %fd1573;
	}
	setp.lt.s32 	%p1087, %r3306, 0;
	selp.b64 	%rd3039, %rd3037, %rd3038, %p1087;
	shl.b64 	%rd3040, %rd3039, 1;
	sub.s64 	%rd3041, %rd3040, %rd439;
	mov.b64 	%fd1574, %rd3041;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3307}, %fd1574;
	}
	setp.lt.s32 	%p1088, %r3307, 0;
	selp.b64 	%rd3042, %rd3040, %rd3041, %p1088;
	shl.b64 	%rd3043, %rd3042, 1;
	sub.s64 	%rd3044, %rd3043, %rd439;
	mov.b64 	%fd1575, %rd3044;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3308}, %fd1575;
	}
	setp.lt.s32 	%p1089, %r3308, 0;
	selp.b64 	%rd3045, %rd3043, %rd3044, %p1089;
	shl.b64 	%rd3046, %rd3045, 1;
	sub.s64 	%rd3047, %rd3046, %rd439;
	mov.b64 	%fd1576, %rd3047;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3309}, %fd1576;
	}
	setp.lt.s32 	%p1090, %r3309, 0;
	selp.b64 	%rd3048, %rd3046, %rd3047, %p1090;
	shl.b64 	%rd3049, %rd3048, 1;
	sub.s64 	%rd3050, %rd3049, %rd439;
	mov.b64 	%fd1577, %rd3050;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3310}, %fd1577;
	}
	setp.lt.s32 	%p1091, %r3310, 0;
	selp.b64 	%rd3051, %rd3049, %rd3050, %p1091;
	shl.b64 	%rd3052, %rd3051, 1;
	sub.s64 	%rd3053, %rd3052, %rd439;
	mov.b64 	%fd1578, %rd3053;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3311}, %fd1578;
	}
	setp.lt.s32 	%p1092, %r3311, 0;
	selp.b64 	%rd3054, %rd3052, %rd3053, %p1092;
	shl.b64 	%rd3055, %rd3054, 1;
	sub.s64 	%rd3056, %rd3055, %rd439;
	mov.b64 	%fd1579, %rd3056;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3312}, %fd1579;
	}
	setp.lt.s32 	%p1093, %r3312, 0;
	selp.b64 	%rd3057, %rd3055, %rd3056, %p1093;
	shl.b64 	%rd3058, %rd3057, 1;
	sub.s64 	%rd3059, %rd3058, %rd439;
	mov.b64 	%fd1580, %rd3059;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3313}, %fd1580;
	}
	setp.lt.s32 	%p1094, %r3313, 0;
	selp.b64 	%rd6324, %rd3058, %rd3059, %p1094;
	shl.b64 	%rd6321, %rd6324, 1;
	add.s32 	%r660, %r6146, -16;
	setp.gt.s32 	%p1095, %r6146, 15;
	mov.u32 	%r6146, %r660;
	@%p1095 bra 	$L__BB0_537;

$L__BB0_538:
	and.b64  	%rd454, %rd6324, 9223372036854775807;
	setp.eq.s64 	%p1096, %rd454, 0;
	mov.f64 	%fd3000, 0d0000000000000000;
	@%p1096 bra 	$L__BB0_540;

	mov.b64 	%fd1582, %rd454;
	mul.f64 	%fd1583, %fd1582, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3314}, %fd1583;
	}
	shr.u32 	%r3315, %r3314, 20;
	mov.u32 	%r3316, 55;
	sub.s32 	%r3317, %r3316, %r3315;
	sub.s32 	%r3318, %r6140, %r3317;
	shl.b64 	%rd3060, %rd454, %r3317;
	setp.lt.s32 	%p1097, %r3318, 1;
	mov.u32 	%r3319, 1;
	sub.s32 	%r3320, %r3319, %r3318;
	shr.u64 	%rd3061, %rd3060, %r3320;
	add.s32 	%r3321, %r3318, -1;
	cvt.u64.u32 	%rd3062, %r3321;
	shl.b64 	%rd3063, %rd3062, 52;
	add.s64 	%rd3064, %rd3063, %rd3060;
	selp.b64 	%rd3065, %rd3061, %rd3064, %p1097;
	mov.b64 	%fd3000, %rd3065;

$L__BB0_540:
	and.b32  	%r3322, %r637, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3323}, %fd3000;
	}
	or.b32  	%r3324, %r3323, %r3322;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3325, %temp}, %fd3000;
	}
	mov.b64 	%fd3001, {%r3325, %r3324};
	bra.uni 	$L__BB0_544;

$L__BB0_542:
	mov.f64 	%fd1584, 0d3FF0000000000000;
	add.rn.f64 	%fd3001, %fd291, %fd1584;

$L__BB0_544:
	mov.f64 	%fd1585, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1586, %fd1585, %fd3001;
	mul.f64 	%fd1587, %fd1586, %fd15;
	mul.f64 	%fd1588, %fd1587, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 91 26
	add.s32 	%r3326, %r6211, 7;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 91 26
	cvt.rn.f64.s32 	%fd1589, %r3326;
	fma.rn.f64 	%fd302, %fd1589, 0d400921FB54442D18, %fd1588;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r661}, %fd302;
	}
	and.b32  	%r3327, %r661, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3328, %temp}, %fd302;
	}
	mov.b64 	%fd3002, {%r3328, %r3327};
	setp.gt.u32 	%p1102, %r3327, 2146435071;
	or.pred  	%p1104, %p1102, %p18;
	@%p1104 bra 	$L__BB0_561;
	bra.uni 	$L__BB0_545;

$L__BB0_561:
	.loc	1 0 9
	setp.le.f64 	%p1139, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1140, %fd3002, 0d7FF0000000000000;
	and.pred  	%p1141, %p1140, %p1139;
	@%p1141 bra 	$L__BB0_563;
	bra.uni 	$L__BB0_562;

$L__BB0_563:
	setp.eq.f64 	%p1142, %fd3002, 0d7FF0000000000000;
	selp.f64 	%fd3005, 0dFFF8000000000000, %fd302, %p1142;
	bra.uni 	$L__BB0_564;

$L__BB0_545:
	.loc	1 0 9
	mov.f64 	%fd3005, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_564;

	setp.ltu.f64 	%p1106, %fd3002, %fd3160;
	mov.f64 	%fd3005, %fd302;
	@%p1106 bra 	$L__BB0_564;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3329}, %fd3002;
	}
	shr.u32 	%r6148, %r3329, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3330}, %fd3160;
	}
	shr.u32 	%r6149, %r3330, 20;
	setp.ne.s32 	%p1107, %r6148, 0;
	@%p1107 bra 	$L__BB0_549;

	mul.f64 	%fd3002, %fd3002, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3331}, %fd3002;
	}
	shr.u32 	%r3332, %r3331, 20;
	add.s32 	%r6148, %r3332, -54;

$L__BB0_549:
	setp.ne.s32 	%p1108, %r6149, 0;
	mov.f64 	%fd3003, %fd3160;
	@%p1108 bra 	$L__BB0_551;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3333}, %fd2;
	}
	shr.u32 	%r3334, %r3333, 20;
	add.s32 	%r6149, %r3334, -54;
	mov.f64 	%fd3003, %fd2;

$L__BB0_551:
	mov.b64 	%rd3067, %fd3002;
	and.b64  	%rd3068, %rd3067, 4503599627370495;
	or.b64  	%rd6329, %rd3068, 4503599627370496;
	mov.b64 	%rd3069, %fd3003;
	and.b64  	%rd3070, %rd3069, 4503599627370495;
	or.b64  	%rd456, %rd3070, 4503599627370496;
	sub.s32 	%r6155, %r6148, %r6149;
	not.b32 	%r3335, %r6148;
	add.s32 	%r3336, %r6149, %r3335;
	max.s32 	%r3337, %r3336, -1;
	add.s32 	%r669, %r3337, %r6148;
	mov.u32 	%r3338, 2;
	sub.s32 	%r3339, %r3338, %r6149;
	add.s32 	%r3340, %r3339, %r669;
	and.b32  	%r6151, %r3340, 3;
	setp.eq.s32 	%p1109, %r6151, 0;
	@%p1109 bra 	$L__BB0_553;

$L__BB0_552:
	.pragma "nounroll";
	sub.s64 	%rd3071, %rd6329, %rd456;
	mov.b64 	%fd1591, %rd3071;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3341}, %fd1591;
	}
	setp.lt.s32 	%p1110, %r3341, 0;
	selp.b64 	%rd6332, %rd6329, %rd3071, %p1110;
	shl.b64 	%rd6329, %rd6332, 1;
	add.s32 	%r6155, %r6155, -1;
	add.s32 	%r6151, %r6151, -1;
	setp.ne.s32 	%p1111, %r6151, 0;
	@%p1111 bra 	$L__BB0_552;

$L__BB0_553:
	mov.u32 	%r3342, 1;
	sub.s32 	%r3343, %r3342, %r6149;
	add.s32 	%r3344, %r3343, %r669;
	setp.lt.u32 	%p1112, %r3344, 3;
	@%p1112 bra 	$L__BB0_558;

	not.b32 	%r3345, %r6155;
	max.s32 	%r3346, %r3345, -4;
	add.s32 	%r3347, %r6155, %r3346;
	add.s32 	%r676, %r3347, 4;
	shr.u32 	%r3348, %r676, 2;
	add.s32 	%r3349, %r3348, 1;
	and.b32  	%r6154, %r3349, 3;
	setp.eq.s32 	%p1113, %r6154, 0;
	@%p1113 bra 	$L__BB0_556;

$L__BB0_555:
	.pragma "nounroll";
	sub.s64 	%rd3073, %rd6329, %rd456;
	mov.b64 	%fd1592, %rd3073;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3350}, %fd1592;
	}
	setp.lt.s32 	%p1114, %r3350, 0;
	selp.b64 	%rd3074, %rd6329, %rd3073, %p1114;
	shl.b64 	%rd3075, %rd3074, 1;
	sub.s64 	%rd3076, %rd3075, %rd456;
	mov.b64 	%fd1593, %rd3076;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3351}, %fd1593;
	}
	setp.lt.s32 	%p1115, %r3351, 0;
	selp.b64 	%rd3077, %rd3075, %rd3076, %p1115;
	shl.b64 	%rd3078, %rd3077, 1;
	sub.s64 	%rd3079, %rd3078, %rd456;
	mov.b64 	%fd1594, %rd3079;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3352}, %fd1594;
	}
	setp.lt.s32 	%p1116, %r3352, 0;
	selp.b64 	%rd3080, %rd3078, %rd3079, %p1116;
	shl.b64 	%rd3081, %rd3080, 1;
	sub.s64 	%rd3082, %rd3081, %rd456;
	mov.b64 	%fd1595, %rd3082;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3353}, %fd1595;
	}
	setp.lt.s32 	%p1117, %r3353, 0;
	selp.b64 	%rd6332, %rd3081, %rd3082, %p1117;
	shl.b64 	%rd6329, %rd6332, 1;
	add.s32 	%r6155, %r6155, -4;
	add.s32 	%r6154, %r6154, -1;
	setp.ne.s32 	%p1118, %r6154, 0;
	@%p1118 bra 	$L__BB0_555;

$L__BB0_556:
	setp.lt.u32 	%p1119, %r676, 12;
	@%p1119 bra 	$L__BB0_558;

$L__BB0_557:
	sub.s64 	%rd3083, %rd6329, %rd456;
	mov.b64 	%fd1596, %rd3083;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3354}, %fd1596;
	}
	setp.lt.s32 	%p1120, %r3354, 0;
	selp.b64 	%rd3084, %rd6329, %rd3083, %p1120;
	shl.b64 	%rd3085, %rd3084, 1;
	sub.s64 	%rd3086, %rd3085, %rd456;
	mov.b64 	%fd1597, %rd3086;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3355}, %fd1597;
	}
	setp.lt.s32 	%p1121, %r3355, 0;
	selp.b64 	%rd3087, %rd3085, %rd3086, %p1121;
	shl.b64 	%rd3088, %rd3087, 1;
	sub.s64 	%rd3089, %rd3088, %rd456;
	mov.b64 	%fd1598, %rd3089;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3356}, %fd1598;
	}
	setp.lt.s32 	%p1122, %r3356, 0;
	selp.b64 	%rd3090, %rd3088, %rd3089, %p1122;
	shl.b64 	%rd3091, %rd3090, 1;
	sub.s64 	%rd3092, %rd3091, %rd456;
	mov.b64 	%fd1599, %rd3092;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3357}, %fd1599;
	}
	setp.lt.s32 	%p1123, %r3357, 0;
	selp.b64 	%rd3093, %rd3091, %rd3092, %p1123;
	shl.b64 	%rd3094, %rd3093, 1;
	sub.s64 	%rd3095, %rd3094, %rd456;
	mov.b64 	%fd1600, %rd3095;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3358}, %fd1600;
	}
	setp.lt.s32 	%p1124, %r3358, 0;
	selp.b64 	%rd3096, %rd3094, %rd3095, %p1124;
	shl.b64 	%rd3097, %rd3096, 1;
	sub.s64 	%rd3098, %rd3097, %rd456;
	mov.b64 	%fd1601, %rd3098;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3359}, %fd1601;
	}
	setp.lt.s32 	%p1125, %r3359, 0;
	selp.b64 	%rd3099, %rd3097, %rd3098, %p1125;
	shl.b64 	%rd3100, %rd3099, 1;
	sub.s64 	%rd3101, %rd3100, %rd456;
	mov.b64 	%fd1602, %rd3101;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3360}, %fd1602;
	}
	setp.lt.s32 	%p1126, %r3360, 0;
	selp.b64 	%rd3102, %rd3100, %rd3101, %p1126;
	shl.b64 	%rd3103, %rd3102, 1;
	sub.s64 	%rd3104, %rd3103, %rd456;
	mov.b64 	%fd1603, %rd3104;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3361}, %fd1603;
	}
	setp.lt.s32 	%p1127, %r3361, 0;
	selp.b64 	%rd3105, %rd3103, %rd3104, %p1127;
	shl.b64 	%rd3106, %rd3105, 1;
	sub.s64 	%rd3107, %rd3106, %rd456;
	mov.b64 	%fd1604, %rd3107;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3362}, %fd1604;
	}
	setp.lt.s32 	%p1128, %r3362, 0;
	selp.b64 	%rd3108, %rd3106, %rd3107, %p1128;
	shl.b64 	%rd3109, %rd3108, 1;
	sub.s64 	%rd3110, %rd3109, %rd456;
	mov.b64 	%fd1605, %rd3110;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3363}, %fd1605;
	}
	setp.lt.s32 	%p1129, %r3363, 0;
	selp.b64 	%rd3111, %rd3109, %rd3110, %p1129;
	shl.b64 	%rd3112, %rd3111, 1;
	sub.s64 	%rd3113, %rd3112, %rd456;
	mov.b64 	%fd1606, %rd3113;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3364}, %fd1606;
	}
	setp.lt.s32 	%p1130, %r3364, 0;
	selp.b64 	%rd3114, %rd3112, %rd3113, %p1130;
	shl.b64 	%rd3115, %rd3114, 1;
	sub.s64 	%rd3116, %rd3115, %rd456;
	mov.b64 	%fd1607, %rd3116;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3365}, %fd1607;
	}
	setp.lt.s32 	%p1131, %r3365, 0;
	selp.b64 	%rd3117, %rd3115, %rd3116, %p1131;
	shl.b64 	%rd3118, %rd3117, 1;
	sub.s64 	%rd3119, %rd3118, %rd456;
	mov.b64 	%fd1608, %rd3119;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3366}, %fd1608;
	}
	setp.lt.s32 	%p1132, %r3366, 0;
	selp.b64 	%rd3120, %rd3118, %rd3119, %p1132;
	shl.b64 	%rd3121, %rd3120, 1;
	sub.s64 	%rd3122, %rd3121, %rd456;
	mov.b64 	%fd1609, %rd3122;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3367}, %fd1609;
	}
	setp.lt.s32 	%p1133, %r3367, 0;
	selp.b64 	%rd3123, %rd3121, %rd3122, %p1133;
	shl.b64 	%rd3124, %rd3123, 1;
	sub.s64 	%rd3125, %rd3124, %rd456;
	mov.b64 	%fd1610, %rd3125;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3368}, %fd1610;
	}
	setp.lt.s32 	%p1134, %r3368, 0;
	selp.b64 	%rd3126, %rd3124, %rd3125, %p1134;
	shl.b64 	%rd3127, %rd3126, 1;
	sub.s64 	%rd3128, %rd3127, %rd456;
	mov.b64 	%fd1611, %rd3128;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3369}, %fd1611;
	}
	setp.lt.s32 	%p1135, %r3369, 0;
	selp.b64 	%rd6332, %rd3127, %rd3128, %p1135;
	shl.b64 	%rd6329, %rd6332, 1;
	add.s32 	%r684, %r6155, -16;
	setp.gt.s32 	%p1136, %r6155, 15;
	mov.u32 	%r6155, %r684;
	@%p1136 bra 	$L__BB0_557;

$L__BB0_558:
	and.b64  	%rd471, %rd6332, 9223372036854775807;
	setp.eq.s64 	%p1137, %rd471, 0;
	mov.f64 	%fd3004, 0d0000000000000000;
	@%p1137 bra 	$L__BB0_560;

	mov.b64 	%fd1613, %rd471;
	mul.f64 	%fd1614, %fd1613, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3370}, %fd1614;
	}
	shr.u32 	%r3371, %r3370, 20;
	mov.u32 	%r3372, 55;
	sub.s32 	%r3373, %r3372, %r3371;
	sub.s32 	%r3374, %r6149, %r3373;
	shl.b64 	%rd3129, %rd471, %r3373;
	setp.lt.s32 	%p1138, %r3374, 1;
	mov.u32 	%r3375, 1;
	sub.s32 	%r3376, %r3375, %r3374;
	shr.u64 	%rd3130, %rd3129, %r3376;
	add.s32 	%r3377, %r3374, -1;
	cvt.u64.u32 	%rd3131, %r3377;
	shl.b64 	%rd3132, %rd3131, 52;
	add.s64 	%rd3133, %rd3132, %rd3129;
	selp.b64 	%rd3134, %rd3130, %rd3133, %p1138;
	mov.b64 	%fd3004, %rd3134;

$L__BB0_560:
	and.b32  	%r3378, %r661, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3379}, %fd3004;
	}
	or.b32  	%r3380, %r3379, %r3378;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3381, %temp}, %fd3004;
	}
	mov.b64 	%fd3005, {%r3381, %r3380};
	bra.uni 	$L__BB0_564;

$L__BB0_562:
	mov.f64 	%fd1615, 0d3FF0000000000000;
	add.rn.f64 	%fd3005, %fd302, %fd1615;

$L__BB0_564:
	mov.f64 	%fd1616, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1617, %fd1616, %fd3005;
	mul.f64 	%fd1618, %fd1617, %fd27;
	mul.f64 	%fd1619, %fd1618, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 91 26
	add.s32 	%r3382, %r6211, 6;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 91 26
	cvt.rn.f64.s32 	%fd1620, %r3382;
	fma.rn.f64 	%fd313, %fd1620, 0d400921FB54442D18, %fd1619;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r685}, %fd313;
	}
	and.b32  	%r3383, %r685, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3384, %temp}, %fd313;
	}
	mov.b64 	%fd3006, {%r3384, %r3383};
	setp.gt.u32 	%p1143, %r3383, 2146435071;
	or.pred  	%p1145, %p1143, %p18;
	@%p1145 bra 	$L__BB0_581;
	bra.uni 	$L__BB0_565;

$L__BB0_581:
	.loc	1 0 9
	setp.le.f64 	%p1180, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1181, %fd3006, 0d7FF0000000000000;
	and.pred  	%p1182, %p1181, %p1180;
	@%p1182 bra 	$L__BB0_583;
	bra.uni 	$L__BB0_582;

$L__BB0_583:
	setp.eq.f64 	%p1183, %fd3006, 0d7FF0000000000000;
	selp.f64 	%fd3009, 0dFFF8000000000000, %fd313, %p1183;
	bra.uni 	$L__BB0_584;

$L__BB0_565:
	.loc	1 0 9
	mov.f64 	%fd3009, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_584;

	setp.ltu.f64 	%p1147, %fd3006, %fd3160;
	mov.f64 	%fd3009, %fd313;
	@%p1147 bra 	$L__BB0_584;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3385}, %fd3006;
	}
	shr.u32 	%r6157, %r3385, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3386}, %fd3160;
	}
	shr.u32 	%r6158, %r3386, 20;
	setp.ne.s32 	%p1148, %r6157, 0;
	@%p1148 bra 	$L__BB0_569;

	mul.f64 	%fd3006, %fd3006, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3387}, %fd3006;
	}
	shr.u32 	%r3388, %r3387, 20;
	add.s32 	%r6157, %r3388, -54;

$L__BB0_569:
	setp.ne.s32 	%p1149, %r6158, 0;
	mov.f64 	%fd3007, %fd3160;
	@%p1149 bra 	$L__BB0_571;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3389}, %fd2;
	}
	shr.u32 	%r3390, %r3389, 20;
	add.s32 	%r6158, %r3390, -54;
	mov.f64 	%fd3007, %fd2;

$L__BB0_571:
	mov.b64 	%rd3136, %fd3006;
	and.b64  	%rd3137, %rd3136, 4503599627370495;
	or.b64  	%rd6337, %rd3137, 4503599627370496;
	mov.b64 	%rd3138, %fd3007;
	and.b64  	%rd3139, %rd3138, 4503599627370495;
	or.b64  	%rd473, %rd3139, 4503599627370496;
	sub.s32 	%r6164, %r6157, %r6158;
	not.b32 	%r3391, %r6157;
	add.s32 	%r3392, %r6158, %r3391;
	max.s32 	%r3393, %r3392, -1;
	add.s32 	%r693, %r3393, %r6157;
	mov.u32 	%r3394, 2;
	sub.s32 	%r3395, %r3394, %r6158;
	add.s32 	%r3396, %r3395, %r693;
	and.b32  	%r6160, %r3396, 3;
	setp.eq.s32 	%p1150, %r6160, 0;
	@%p1150 bra 	$L__BB0_573;

$L__BB0_572:
	.pragma "nounroll";
	sub.s64 	%rd3140, %rd6337, %rd473;
	mov.b64 	%fd1622, %rd3140;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3397}, %fd1622;
	}
	setp.lt.s32 	%p1151, %r3397, 0;
	selp.b64 	%rd6340, %rd6337, %rd3140, %p1151;
	shl.b64 	%rd6337, %rd6340, 1;
	add.s32 	%r6164, %r6164, -1;
	add.s32 	%r6160, %r6160, -1;
	setp.ne.s32 	%p1152, %r6160, 0;
	@%p1152 bra 	$L__BB0_572;

$L__BB0_573:
	mov.u32 	%r3398, 1;
	sub.s32 	%r3399, %r3398, %r6158;
	add.s32 	%r3400, %r3399, %r693;
	setp.lt.u32 	%p1153, %r3400, 3;
	@%p1153 bra 	$L__BB0_578;

	not.b32 	%r3401, %r6164;
	max.s32 	%r3402, %r3401, -4;
	add.s32 	%r3403, %r6164, %r3402;
	add.s32 	%r700, %r3403, 4;
	shr.u32 	%r3404, %r700, 2;
	add.s32 	%r3405, %r3404, 1;
	and.b32  	%r6163, %r3405, 3;
	setp.eq.s32 	%p1154, %r6163, 0;
	@%p1154 bra 	$L__BB0_576;

$L__BB0_575:
	.pragma "nounroll";
	sub.s64 	%rd3142, %rd6337, %rd473;
	mov.b64 	%fd1623, %rd3142;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3406}, %fd1623;
	}
	setp.lt.s32 	%p1155, %r3406, 0;
	selp.b64 	%rd3143, %rd6337, %rd3142, %p1155;
	shl.b64 	%rd3144, %rd3143, 1;
	sub.s64 	%rd3145, %rd3144, %rd473;
	mov.b64 	%fd1624, %rd3145;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3407}, %fd1624;
	}
	setp.lt.s32 	%p1156, %r3407, 0;
	selp.b64 	%rd3146, %rd3144, %rd3145, %p1156;
	shl.b64 	%rd3147, %rd3146, 1;
	sub.s64 	%rd3148, %rd3147, %rd473;
	mov.b64 	%fd1625, %rd3148;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3408}, %fd1625;
	}
	setp.lt.s32 	%p1157, %r3408, 0;
	selp.b64 	%rd3149, %rd3147, %rd3148, %p1157;
	shl.b64 	%rd3150, %rd3149, 1;
	sub.s64 	%rd3151, %rd3150, %rd473;
	mov.b64 	%fd1626, %rd3151;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3409}, %fd1626;
	}
	setp.lt.s32 	%p1158, %r3409, 0;
	selp.b64 	%rd6340, %rd3150, %rd3151, %p1158;
	shl.b64 	%rd6337, %rd6340, 1;
	add.s32 	%r6164, %r6164, -4;
	add.s32 	%r6163, %r6163, -1;
	setp.ne.s32 	%p1159, %r6163, 0;
	@%p1159 bra 	$L__BB0_575;

$L__BB0_576:
	setp.lt.u32 	%p1160, %r700, 12;
	@%p1160 bra 	$L__BB0_578;

$L__BB0_577:
	sub.s64 	%rd3152, %rd6337, %rd473;
	mov.b64 	%fd1627, %rd3152;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3410}, %fd1627;
	}
	setp.lt.s32 	%p1161, %r3410, 0;
	selp.b64 	%rd3153, %rd6337, %rd3152, %p1161;
	shl.b64 	%rd3154, %rd3153, 1;
	sub.s64 	%rd3155, %rd3154, %rd473;
	mov.b64 	%fd1628, %rd3155;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3411}, %fd1628;
	}
	setp.lt.s32 	%p1162, %r3411, 0;
	selp.b64 	%rd3156, %rd3154, %rd3155, %p1162;
	shl.b64 	%rd3157, %rd3156, 1;
	sub.s64 	%rd3158, %rd3157, %rd473;
	mov.b64 	%fd1629, %rd3158;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3412}, %fd1629;
	}
	setp.lt.s32 	%p1163, %r3412, 0;
	selp.b64 	%rd3159, %rd3157, %rd3158, %p1163;
	shl.b64 	%rd3160, %rd3159, 1;
	sub.s64 	%rd3161, %rd3160, %rd473;
	mov.b64 	%fd1630, %rd3161;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3413}, %fd1630;
	}
	setp.lt.s32 	%p1164, %r3413, 0;
	selp.b64 	%rd3162, %rd3160, %rd3161, %p1164;
	shl.b64 	%rd3163, %rd3162, 1;
	sub.s64 	%rd3164, %rd3163, %rd473;
	mov.b64 	%fd1631, %rd3164;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3414}, %fd1631;
	}
	setp.lt.s32 	%p1165, %r3414, 0;
	selp.b64 	%rd3165, %rd3163, %rd3164, %p1165;
	shl.b64 	%rd3166, %rd3165, 1;
	sub.s64 	%rd3167, %rd3166, %rd473;
	mov.b64 	%fd1632, %rd3167;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3415}, %fd1632;
	}
	setp.lt.s32 	%p1166, %r3415, 0;
	selp.b64 	%rd3168, %rd3166, %rd3167, %p1166;
	shl.b64 	%rd3169, %rd3168, 1;
	sub.s64 	%rd3170, %rd3169, %rd473;
	mov.b64 	%fd1633, %rd3170;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3416}, %fd1633;
	}
	setp.lt.s32 	%p1167, %r3416, 0;
	selp.b64 	%rd3171, %rd3169, %rd3170, %p1167;
	shl.b64 	%rd3172, %rd3171, 1;
	sub.s64 	%rd3173, %rd3172, %rd473;
	mov.b64 	%fd1634, %rd3173;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3417}, %fd1634;
	}
	setp.lt.s32 	%p1168, %r3417, 0;
	selp.b64 	%rd3174, %rd3172, %rd3173, %p1168;
	shl.b64 	%rd3175, %rd3174, 1;
	sub.s64 	%rd3176, %rd3175, %rd473;
	mov.b64 	%fd1635, %rd3176;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3418}, %fd1635;
	}
	setp.lt.s32 	%p1169, %r3418, 0;
	selp.b64 	%rd3177, %rd3175, %rd3176, %p1169;
	shl.b64 	%rd3178, %rd3177, 1;
	sub.s64 	%rd3179, %rd3178, %rd473;
	mov.b64 	%fd1636, %rd3179;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3419}, %fd1636;
	}
	setp.lt.s32 	%p1170, %r3419, 0;
	selp.b64 	%rd3180, %rd3178, %rd3179, %p1170;
	shl.b64 	%rd3181, %rd3180, 1;
	sub.s64 	%rd3182, %rd3181, %rd473;
	mov.b64 	%fd1637, %rd3182;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3420}, %fd1637;
	}
	setp.lt.s32 	%p1171, %r3420, 0;
	selp.b64 	%rd3183, %rd3181, %rd3182, %p1171;
	shl.b64 	%rd3184, %rd3183, 1;
	sub.s64 	%rd3185, %rd3184, %rd473;
	mov.b64 	%fd1638, %rd3185;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3421}, %fd1638;
	}
	setp.lt.s32 	%p1172, %r3421, 0;
	selp.b64 	%rd3186, %rd3184, %rd3185, %p1172;
	shl.b64 	%rd3187, %rd3186, 1;
	sub.s64 	%rd3188, %rd3187, %rd473;
	mov.b64 	%fd1639, %rd3188;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3422}, %fd1639;
	}
	setp.lt.s32 	%p1173, %r3422, 0;
	selp.b64 	%rd3189, %rd3187, %rd3188, %p1173;
	shl.b64 	%rd3190, %rd3189, 1;
	sub.s64 	%rd3191, %rd3190, %rd473;
	mov.b64 	%fd1640, %rd3191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3423}, %fd1640;
	}
	setp.lt.s32 	%p1174, %r3423, 0;
	selp.b64 	%rd3192, %rd3190, %rd3191, %p1174;
	shl.b64 	%rd3193, %rd3192, 1;
	sub.s64 	%rd3194, %rd3193, %rd473;
	mov.b64 	%fd1641, %rd3194;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3424}, %fd1641;
	}
	setp.lt.s32 	%p1175, %r3424, 0;
	selp.b64 	%rd3195, %rd3193, %rd3194, %p1175;
	shl.b64 	%rd3196, %rd3195, 1;
	sub.s64 	%rd3197, %rd3196, %rd473;
	mov.b64 	%fd1642, %rd3197;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3425}, %fd1642;
	}
	setp.lt.s32 	%p1176, %r3425, 0;
	selp.b64 	%rd6340, %rd3196, %rd3197, %p1176;
	shl.b64 	%rd6337, %rd6340, 1;
	add.s32 	%r708, %r6164, -16;
	setp.gt.s32 	%p1177, %r6164, 15;
	mov.u32 	%r6164, %r708;
	@%p1177 bra 	$L__BB0_577;

$L__BB0_578:
	and.b64  	%rd488, %rd6340, 9223372036854775807;
	setp.eq.s64 	%p1178, %rd488, 0;
	mov.f64 	%fd3008, 0d0000000000000000;
	@%p1178 bra 	$L__BB0_580;

	mov.b64 	%fd1644, %rd488;
	mul.f64 	%fd1645, %fd1644, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3426}, %fd1645;
	}
	shr.u32 	%r3427, %r3426, 20;
	mov.u32 	%r3428, 55;
	sub.s32 	%r3429, %r3428, %r3427;
	sub.s32 	%r3430, %r6158, %r3429;
	shl.b64 	%rd3198, %rd488, %r3429;
	setp.lt.s32 	%p1179, %r3430, 1;
	mov.u32 	%r3431, 1;
	sub.s32 	%r3432, %r3431, %r3430;
	shr.u64 	%rd3199, %rd3198, %r3432;
	add.s32 	%r3433, %r3430, -1;
	cvt.u64.u32 	%rd3200, %r3433;
	shl.b64 	%rd3201, %rd3200, 52;
	add.s64 	%rd3202, %rd3201, %rd3198;
	selp.b64 	%rd3203, %rd3199, %rd3202, %p1179;
	mov.b64 	%fd3008, %rd3203;

$L__BB0_580:
	and.b32  	%r3434, %r685, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3435}, %fd3008;
	}
	or.b32  	%r3436, %r3435, %r3434;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3437, %temp}, %fd3008;
	}
	mov.b64 	%fd3009, {%r3437, %r3436};
	bra.uni 	$L__BB0_584;

$L__BB0_582:
	mov.f64 	%fd1646, 0d3FF0000000000000;
	add.rn.f64 	%fd3009, %fd313, %fd1646;

$L__BB0_584:
	mov.f64 	%fd1647, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1648, %fd1647, %fd3009;
	mul.f64 	%fd1649, %fd1648, %fd39;
	mul.f64 	%fd1650, %fd1649, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 91 26
	add.s32 	%r3438, %r6211, 5;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 91 26
	cvt.rn.f64.s32 	%fd1651, %r3438;
	fma.rn.f64 	%fd324, %fd1651, 0d400921FB54442D18, %fd1650;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r709}, %fd324;
	}
	and.b32  	%r3439, %r709, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3440, %temp}, %fd324;
	}
	mov.b64 	%fd3010, {%r3440, %r3439};
	setp.gt.u32 	%p1184, %r3439, 2146435071;
	or.pred  	%p1186, %p1184, %p18;
	@%p1186 bra 	$L__BB0_601;
	bra.uni 	$L__BB0_585;

$L__BB0_601:
	.loc	1 0 9
	setp.le.f64 	%p1221, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1222, %fd3010, 0d7FF0000000000000;
	and.pred  	%p1223, %p1222, %p1221;
	@%p1223 bra 	$L__BB0_603;
	bra.uni 	$L__BB0_602;

$L__BB0_603:
	setp.eq.f64 	%p1224, %fd3010, 0d7FF0000000000000;
	selp.f64 	%fd3013, 0dFFF8000000000000, %fd324, %p1224;
	bra.uni 	$L__BB0_604;

$L__BB0_585:
	.loc	1 0 9
	mov.f64 	%fd3013, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_604;

	setp.ltu.f64 	%p1188, %fd3010, %fd3160;
	mov.f64 	%fd3013, %fd324;
	@%p1188 bra 	$L__BB0_604;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3441}, %fd3010;
	}
	shr.u32 	%r6166, %r3441, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3442}, %fd3160;
	}
	shr.u32 	%r6167, %r3442, 20;
	setp.ne.s32 	%p1189, %r6166, 0;
	@%p1189 bra 	$L__BB0_589;

	mul.f64 	%fd3010, %fd3010, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3443}, %fd3010;
	}
	shr.u32 	%r3444, %r3443, 20;
	add.s32 	%r6166, %r3444, -54;

$L__BB0_589:
	setp.ne.s32 	%p1190, %r6167, 0;
	mov.f64 	%fd3011, %fd3160;
	@%p1190 bra 	$L__BB0_591;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3445}, %fd2;
	}
	shr.u32 	%r3446, %r3445, 20;
	add.s32 	%r6167, %r3446, -54;
	mov.f64 	%fd3011, %fd2;

$L__BB0_591:
	mov.b64 	%rd3205, %fd3010;
	and.b64  	%rd3206, %rd3205, 4503599627370495;
	or.b64  	%rd6345, %rd3206, 4503599627370496;
	mov.b64 	%rd3207, %fd3011;
	and.b64  	%rd3208, %rd3207, 4503599627370495;
	or.b64  	%rd490, %rd3208, 4503599627370496;
	sub.s32 	%r6173, %r6166, %r6167;
	not.b32 	%r3447, %r6166;
	add.s32 	%r3448, %r6167, %r3447;
	max.s32 	%r3449, %r3448, -1;
	add.s32 	%r717, %r3449, %r6166;
	mov.u32 	%r3450, 2;
	sub.s32 	%r3451, %r3450, %r6167;
	add.s32 	%r3452, %r3451, %r717;
	and.b32  	%r6169, %r3452, 3;
	setp.eq.s32 	%p1191, %r6169, 0;
	@%p1191 bra 	$L__BB0_593;

$L__BB0_592:
	.pragma "nounroll";
	sub.s64 	%rd3209, %rd6345, %rd490;
	mov.b64 	%fd1653, %rd3209;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3453}, %fd1653;
	}
	setp.lt.s32 	%p1192, %r3453, 0;
	selp.b64 	%rd6348, %rd6345, %rd3209, %p1192;
	shl.b64 	%rd6345, %rd6348, 1;
	add.s32 	%r6173, %r6173, -1;
	add.s32 	%r6169, %r6169, -1;
	setp.ne.s32 	%p1193, %r6169, 0;
	@%p1193 bra 	$L__BB0_592;

$L__BB0_593:
	mov.u32 	%r3454, 1;
	sub.s32 	%r3455, %r3454, %r6167;
	add.s32 	%r3456, %r3455, %r717;
	setp.lt.u32 	%p1194, %r3456, 3;
	@%p1194 bra 	$L__BB0_598;

	not.b32 	%r3457, %r6173;
	max.s32 	%r3458, %r3457, -4;
	add.s32 	%r3459, %r6173, %r3458;
	add.s32 	%r724, %r3459, 4;
	shr.u32 	%r3460, %r724, 2;
	add.s32 	%r3461, %r3460, 1;
	and.b32  	%r6172, %r3461, 3;
	setp.eq.s32 	%p1195, %r6172, 0;
	@%p1195 bra 	$L__BB0_596;

$L__BB0_595:
	.pragma "nounroll";
	sub.s64 	%rd3211, %rd6345, %rd490;
	mov.b64 	%fd1654, %rd3211;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3462}, %fd1654;
	}
	setp.lt.s32 	%p1196, %r3462, 0;
	selp.b64 	%rd3212, %rd6345, %rd3211, %p1196;
	shl.b64 	%rd3213, %rd3212, 1;
	sub.s64 	%rd3214, %rd3213, %rd490;
	mov.b64 	%fd1655, %rd3214;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3463}, %fd1655;
	}
	setp.lt.s32 	%p1197, %r3463, 0;
	selp.b64 	%rd3215, %rd3213, %rd3214, %p1197;
	shl.b64 	%rd3216, %rd3215, 1;
	sub.s64 	%rd3217, %rd3216, %rd490;
	mov.b64 	%fd1656, %rd3217;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3464}, %fd1656;
	}
	setp.lt.s32 	%p1198, %r3464, 0;
	selp.b64 	%rd3218, %rd3216, %rd3217, %p1198;
	shl.b64 	%rd3219, %rd3218, 1;
	sub.s64 	%rd3220, %rd3219, %rd490;
	mov.b64 	%fd1657, %rd3220;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3465}, %fd1657;
	}
	setp.lt.s32 	%p1199, %r3465, 0;
	selp.b64 	%rd6348, %rd3219, %rd3220, %p1199;
	shl.b64 	%rd6345, %rd6348, 1;
	add.s32 	%r6173, %r6173, -4;
	add.s32 	%r6172, %r6172, -1;
	setp.ne.s32 	%p1200, %r6172, 0;
	@%p1200 bra 	$L__BB0_595;

$L__BB0_596:
	setp.lt.u32 	%p1201, %r724, 12;
	@%p1201 bra 	$L__BB0_598;

$L__BB0_597:
	sub.s64 	%rd3221, %rd6345, %rd490;
	mov.b64 	%fd1658, %rd3221;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3466}, %fd1658;
	}
	setp.lt.s32 	%p1202, %r3466, 0;
	selp.b64 	%rd3222, %rd6345, %rd3221, %p1202;
	shl.b64 	%rd3223, %rd3222, 1;
	sub.s64 	%rd3224, %rd3223, %rd490;
	mov.b64 	%fd1659, %rd3224;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3467}, %fd1659;
	}
	setp.lt.s32 	%p1203, %r3467, 0;
	selp.b64 	%rd3225, %rd3223, %rd3224, %p1203;
	shl.b64 	%rd3226, %rd3225, 1;
	sub.s64 	%rd3227, %rd3226, %rd490;
	mov.b64 	%fd1660, %rd3227;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3468}, %fd1660;
	}
	setp.lt.s32 	%p1204, %r3468, 0;
	selp.b64 	%rd3228, %rd3226, %rd3227, %p1204;
	shl.b64 	%rd3229, %rd3228, 1;
	sub.s64 	%rd3230, %rd3229, %rd490;
	mov.b64 	%fd1661, %rd3230;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3469}, %fd1661;
	}
	setp.lt.s32 	%p1205, %r3469, 0;
	selp.b64 	%rd3231, %rd3229, %rd3230, %p1205;
	shl.b64 	%rd3232, %rd3231, 1;
	sub.s64 	%rd3233, %rd3232, %rd490;
	mov.b64 	%fd1662, %rd3233;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3470}, %fd1662;
	}
	setp.lt.s32 	%p1206, %r3470, 0;
	selp.b64 	%rd3234, %rd3232, %rd3233, %p1206;
	shl.b64 	%rd3235, %rd3234, 1;
	sub.s64 	%rd3236, %rd3235, %rd490;
	mov.b64 	%fd1663, %rd3236;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3471}, %fd1663;
	}
	setp.lt.s32 	%p1207, %r3471, 0;
	selp.b64 	%rd3237, %rd3235, %rd3236, %p1207;
	shl.b64 	%rd3238, %rd3237, 1;
	sub.s64 	%rd3239, %rd3238, %rd490;
	mov.b64 	%fd1664, %rd3239;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3472}, %fd1664;
	}
	setp.lt.s32 	%p1208, %r3472, 0;
	selp.b64 	%rd3240, %rd3238, %rd3239, %p1208;
	shl.b64 	%rd3241, %rd3240, 1;
	sub.s64 	%rd3242, %rd3241, %rd490;
	mov.b64 	%fd1665, %rd3242;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3473}, %fd1665;
	}
	setp.lt.s32 	%p1209, %r3473, 0;
	selp.b64 	%rd3243, %rd3241, %rd3242, %p1209;
	shl.b64 	%rd3244, %rd3243, 1;
	sub.s64 	%rd3245, %rd3244, %rd490;
	mov.b64 	%fd1666, %rd3245;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3474}, %fd1666;
	}
	setp.lt.s32 	%p1210, %r3474, 0;
	selp.b64 	%rd3246, %rd3244, %rd3245, %p1210;
	shl.b64 	%rd3247, %rd3246, 1;
	sub.s64 	%rd3248, %rd3247, %rd490;
	mov.b64 	%fd1667, %rd3248;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3475}, %fd1667;
	}
	setp.lt.s32 	%p1211, %r3475, 0;
	selp.b64 	%rd3249, %rd3247, %rd3248, %p1211;
	shl.b64 	%rd3250, %rd3249, 1;
	sub.s64 	%rd3251, %rd3250, %rd490;
	mov.b64 	%fd1668, %rd3251;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3476}, %fd1668;
	}
	setp.lt.s32 	%p1212, %r3476, 0;
	selp.b64 	%rd3252, %rd3250, %rd3251, %p1212;
	shl.b64 	%rd3253, %rd3252, 1;
	sub.s64 	%rd3254, %rd3253, %rd490;
	mov.b64 	%fd1669, %rd3254;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3477}, %fd1669;
	}
	setp.lt.s32 	%p1213, %r3477, 0;
	selp.b64 	%rd3255, %rd3253, %rd3254, %p1213;
	shl.b64 	%rd3256, %rd3255, 1;
	sub.s64 	%rd3257, %rd3256, %rd490;
	mov.b64 	%fd1670, %rd3257;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3478}, %fd1670;
	}
	setp.lt.s32 	%p1214, %r3478, 0;
	selp.b64 	%rd3258, %rd3256, %rd3257, %p1214;
	shl.b64 	%rd3259, %rd3258, 1;
	sub.s64 	%rd3260, %rd3259, %rd490;
	mov.b64 	%fd1671, %rd3260;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3479}, %fd1671;
	}
	setp.lt.s32 	%p1215, %r3479, 0;
	selp.b64 	%rd3261, %rd3259, %rd3260, %p1215;
	shl.b64 	%rd3262, %rd3261, 1;
	sub.s64 	%rd3263, %rd3262, %rd490;
	mov.b64 	%fd1672, %rd3263;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3480}, %fd1672;
	}
	setp.lt.s32 	%p1216, %r3480, 0;
	selp.b64 	%rd3264, %rd3262, %rd3263, %p1216;
	shl.b64 	%rd3265, %rd3264, 1;
	sub.s64 	%rd3266, %rd3265, %rd490;
	mov.b64 	%fd1673, %rd3266;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3481}, %fd1673;
	}
	setp.lt.s32 	%p1217, %r3481, 0;
	selp.b64 	%rd6348, %rd3265, %rd3266, %p1217;
	shl.b64 	%rd6345, %rd6348, 1;
	add.s32 	%r732, %r6173, -16;
	setp.gt.s32 	%p1218, %r6173, 15;
	mov.u32 	%r6173, %r732;
	@%p1218 bra 	$L__BB0_597;

$L__BB0_598:
	and.b64  	%rd505, %rd6348, 9223372036854775807;
	setp.eq.s64 	%p1219, %rd505, 0;
	mov.f64 	%fd3012, 0d0000000000000000;
	@%p1219 bra 	$L__BB0_600;

	mov.b64 	%fd1675, %rd505;
	mul.f64 	%fd1676, %fd1675, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3482}, %fd1676;
	}
	shr.u32 	%r3483, %r3482, 20;
	mov.u32 	%r3484, 55;
	sub.s32 	%r3485, %r3484, %r3483;
	sub.s32 	%r3486, %r6167, %r3485;
	shl.b64 	%rd3267, %rd505, %r3485;
	setp.lt.s32 	%p1220, %r3486, 1;
	mov.u32 	%r3487, 1;
	sub.s32 	%r3488, %r3487, %r3486;
	shr.u64 	%rd3268, %rd3267, %r3488;
	add.s32 	%r3489, %r3486, -1;
	cvt.u64.u32 	%rd3269, %r3489;
	shl.b64 	%rd3270, %rd3269, 52;
	add.s64 	%rd3271, %rd3270, %rd3267;
	selp.b64 	%rd3272, %rd3268, %rd3271, %p1220;
	mov.b64 	%fd3012, %rd3272;

$L__BB0_600:
	and.b32  	%r3490, %r709, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3491}, %fd3012;
	}
	or.b32  	%r3492, %r3491, %r3490;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3493, %temp}, %fd3012;
	}
	mov.b64 	%fd3013, {%r3493, %r3492};
	bra.uni 	$L__BB0_604;

$L__BB0_602:
	mov.f64 	%fd1677, 0d3FF0000000000000;
	add.rn.f64 	%fd3013, %fd324, %fd1677;

$L__BB0_604:
	mov.f64 	%fd1678, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1679, %fd1678, %fd3013;
	mul.f64 	%fd1680, %fd1679, %fd51;
	mul.f64 	%fd1681, %fd1680, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 91 26
	add.s32 	%r3494, %r6211, 4;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 91 26
	cvt.rn.f64.s32 	%fd1682, %r3494;
	fma.rn.f64 	%fd335, %fd1682, 0d400921FB54442D18, %fd1681;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r733}, %fd335;
	}
	and.b32  	%r3495, %r733, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3496, %temp}, %fd335;
	}
	mov.b64 	%fd3014, {%r3496, %r3495};
	setp.gt.u32 	%p1225, %r3495, 2146435071;
	or.pred  	%p1227, %p1225, %p18;
	@%p1227 bra 	$L__BB0_621;
	bra.uni 	$L__BB0_605;

$L__BB0_621:
	.loc	1 0 9
	setp.le.f64 	%p1262, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1263, %fd3014, 0d7FF0000000000000;
	and.pred  	%p1264, %p1263, %p1262;
	@%p1264 bra 	$L__BB0_623;
	bra.uni 	$L__BB0_622;

$L__BB0_623:
	setp.eq.f64 	%p1265, %fd3014, 0d7FF0000000000000;
	selp.f64 	%fd3017, 0dFFF8000000000000, %fd335, %p1265;
	bra.uni 	$L__BB0_624;

$L__BB0_605:
	.loc	1 0 9
	mov.f64 	%fd3017, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_624;

	setp.ltu.f64 	%p1229, %fd3014, %fd3160;
	mov.f64 	%fd3017, %fd335;
	@%p1229 bra 	$L__BB0_624;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3497}, %fd3014;
	}
	shr.u32 	%r6175, %r3497, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3498}, %fd3160;
	}
	shr.u32 	%r6176, %r3498, 20;
	setp.ne.s32 	%p1230, %r6175, 0;
	@%p1230 bra 	$L__BB0_609;

	mul.f64 	%fd3014, %fd3014, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3499}, %fd3014;
	}
	shr.u32 	%r3500, %r3499, 20;
	add.s32 	%r6175, %r3500, -54;

$L__BB0_609:
	setp.ne.s32 	%p1231, %r6176, 0;
	mov.f64 	%fd3015, %fd3160;
	@%p1231 bra 	$L__BB0_611;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3501}, %fd2;
	}
	shr.u32 	%r3502, %r3501, 20;
	add.s32 	%r6176, %r3502, -54;
	mov.f64 	%fd3015, %fd2;

$L__BB0_611:
	mov.b64 	%rd3274, %fd3014;
	and.b64  	%rd3275, %rd3274, 4503599627370495;
	or.b64  	%rd6353, %rd3275, 4503599627370496;
	mov.b64 	%rd3276, %fd3015;
	and.b64  	%rd3277, %rd3276, 4503599627370495;
	or.b64  	%rd507, %rd3277, 4503599627370496;
	sub.s32 	%r6182, %r6175, %r6176;
	not.b32 	%r3503, %r6175;
	add.s32 	%r3504, %r6176, %r3503;
	max.s32 	%r3505, %r3504, -1;
	add.s32 	%r741, %r3505, %r6175;
	mov.u32 	%r3506, 2;
	sub.s32 	%r3507, %r3506, %r6176;
	add.s32 	%r3508, %r3507, %r741;
	and.b32  	%r6178, %r3508, 3;
	setp.eq.s32 	%p1232, %r6178, 0;
	@%p1232 bra 	$L__BB0_613;

$L__BB0_612:
	.pragma "nounroll";
	sub.s64 	%rd3278, %rd6353, %rd507;
	mov.b64 	%fd1684, %rd3278;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3509}, %fd1684;
	}
	setp.lt.s32 	%p1233, %r3509, 0;
	selp.b64 	%rd6356, %rd6353, %rd3278, %p1233;
	shl.b64 	%rd6353, %rd6356, 1;
	add.s32 	%r6182, %r6182, -1;
	add.s32 	%r6178, %r6178, -1;
	setp.ne.s32 	%p1234, %r6178, 0;
	@%p1234 bra 	$L__BB0_612;

$L__BB0_613:
	mov.u32 	%r3510, 1;
	sub.s32 	%r3511, %r3510, %r6176;
	add.s32 	%r3512, %r3511, %r741;
	setp.lt.u32 	%p1235, %r3512, 3;
	@%p1235 bra 	$L__BB0_618;

	not.b32 	%r3513, %r6182;
	max.s32 	%r3514, %r3513, -4;
	add.s32 	%r3515, %r6182, %r3514;
	add.s32 	%r748, %r3515, 4;
	shr.u32 	%r3516, %r748, 2;
	add.s32 	%r3517, %r3516, 1;
	and.b32  	%r6181, %r3517, 3;
	setp.eq.s32 	%p1236, %r6181, 0;
	@%p1236 bra 	$L__BB0_616;

$L__BB0_615:
	.pragma "nounroll";
	sub.s64 	%rd3280, %rd6353, %rd507;
	mov.b64 	%fd1685, %rd3280;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3518}, %fd1685;
	}
	setp.lt.s32 	%p1237, %r3518, 0;
	selp.b64 	%rd3281, %rd6353, %rd3280, %p1237;
	shl.b64 	%rd3282, %rd3281, 1;
	sub.s64 	%rd3283, %rd3282, %rd507;
	mov.b64 	%fd1686, %rd3283;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3519}, %fd1686;
	}
	setp.lt.s32 	%p1238, %r3519, 0;
	selp.b64 	%rd3284, %rd3282, %rd3283, %p1238;
	shl.b64 	%rd3285, %rd3284, 1;
	sub.s64 	%rd3286, %rd3285, %rd507;
	mov.b64 	%fd1687, %rd3286;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3520}, %fd1687;
	}
	setp.lt.s32 	%p1239, %r3520, 0;
	selp.b64 	%rd3287, %rd3285, %rd3286, %p1239;
	shl.b64 	%rd3288, %rd3287, 1;
	sub.s64 	%rd3289, %rd3288, %rd507;
	mov.b64 	%fd1688, %rd3289;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3521}, %fd1688;
	}
	setp.lt.s32 	%p1240, %r3521, 0;
	selp.b64 	%rd6356, %rd3288, %rd3289, %p1240;
	shl.b64 	%rd6353, %rd6356, 1;
	add.s32 	%r6182, %r6182, -4;
	add.s32 	%r6181, %r6181, -1;
	setp.ne.s32 	%p1241, %r6181, 0;
	@%p1241 bra 	$L__BB0_615;

$L__BB0_616:
	setp.lt.u32 	%p1242, %r748, 12;
	@%p1242 bra 	$L__BB0_618;

$L__BB0_617:
	sub.s64 	%rd3290, %rd6353, %rd507;
	mov.b64 	%fd1689, %rd3290;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3522}, %fd1689;
	}
	setp.lt.s32 	%p1243, %r3522, 0;
	selp.b64 	%rd3291, %rd6353, %rd3290, %p1243;
	shl.b64 	%rd3292, %rd3291, 1;
	sub.s64 	%rd3293, %rd3292, %rd507;
	mov.b64 	%fd1690, %rd3293;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3523}, %fd1690;
	}
	setp.lt.s32 	%p1244, %r3523, 0;
	selp.b64 	%rd3294, %rd3292, %rd3293, %p1244;
	shl.b64 	%rd3295, %rd3294, 1;
	sub.s64 	%rd3296, %rd3295, %rd507;
	mov.b64 	%fd1691, %rd3296;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3524}, %fd1691;
	}
	setp.lt.s32 	%p1245, %r3524, 0;
	selp.b64 	%rd3297, %rd3295, %rd3296, %p1245;
	shl.b64 	%rd3298, %rd3297, 1;
	sub.s64 	%rd3299, %rd3298, %rd507;
	mov.b64 	%fd1692, %rd3299;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3525}, %fd1692;
	}
	setp.lt.s32 	%p1246, %r3525, 0;
	selp.b64 	%rd3300, %rd3298, %rd3299, %p1246;
	shl.b64 	%rd3301, %rd3300, 1;
	sub.s64 	%rd3302, %rd3301, %rd507;
	mov.b64 	%fd1693, %rd3302;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3526}, %fd1693;
	}
	setp.lt.s32 	%p1247, %r3526, 0;
	selp.b64 	%rd3303, %rd3301, %rd3302, %p1247;
	shl.b64 	%rd3304, %rd3303, 1;
	sub.s64 	%rd3305, %rd3304, %rd507;
	mov.b64 	%fd1694, %rd3305;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3527}, %fd1694;
	}
	setp.lt.s32 	%p1248, %r3527, 0;
	selp.b64 	%rd3306, %rd3304, %rd3305, %p1248;
	shl.b64 	%rd3307, %rd3306, 1;
	sub.s64 	%rd3308, %rd3307, %rd507;
	mov.b64 	%fd1695, %rd3308;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3528}, %fd1695;
	}
	setp.lt.s32 	%p1249, %r3528, 0;
	selp.b64 	%rd3309, %rd3307, %rd3308, %p1249;
	shl.b64 	%rd3310, %rd3309, 1;
	sub.s64 	%rd3311, %rd3310, %rd507;
	mov.b64 	%fd1696, %rd3311;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3529}, %fd1696;
	}
	setp.lt.s32 	%p1250, %r3529, 0;
	selp.b64 	%rd3312, %rd3310, %rd3311, %p1250;
	shl.b64 	%rd3313, %rd3312, 1;
	sub.s64 	%rd3314, %rd3313, %rd507;
	mov.b64 	%fd1697, %rd3314;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3530}, %fd1697;
	}
	setp.lt.s32 	%p1251, %r3530, 0;
	selp.b64 	%rd3315, %rd3313, %rd3314, %p1251;
	shl.b64 	%rd3316, %rd3315, 1;
	sub.s64 	%rd3317, %rd3316, %rd507;
	mov.b64 	%fd1698, %rd3317;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3531}, %fd1698;
	}
	setp.lt.s32 	%p1252, %r3531, 0;
	selp.b64 	%rd3318, %rd3316, %rd3317, %p1252;
	shl.b64 	%rd3319, %rd3318, 1;
	sub.s64 	%rd3320, %rd3319, %rd507;
	mov.b64 	%fd1699, %rd3320;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3532}, %fd1699;
	}
	setp.lt.s32 	%p1253, %r3532, 0;
	selp.b64 	%rd3321, %rd3319, %rd3320, %p1253;
	shl.b64 	%rd3322, %rd3321, 1;
	sub.s64 	%rd3323, %rd3322, %rd507;
	mov.b64 	%fd1700, %rd3323;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3533}, %fd1700;
	}
	setp.lt.s32 	%p1254, %r3533, 0;
	selp.b64 	%rd3324, %rd3322, %rd3323, %p1254;
	shl.b64 	%rd3325, %rd3324, 1;
	sub.s64 	%rd3326, %rd3325, %rd507;
	mov.b64 	%fd1701, %rd3326;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3534}, %fd1701;
	}
	setp.lt.s32 	%p1255, %r3534, 0;
	selp.b64 	%rd3327, %rd3325, %rd3326, %p1255;
	shl.b64 	%rd3328, %rd3327, 1;
	sub.s64 	%rd3329, %rd3328, %rd507;
	mov.b64 	%fd1702, %rd3329;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3535}, %fd1702;
	}
	setp.lt.s32 	%p1256, %r3535, 0;
	selp.b64 	%rd3330, %rd3328, %rd3329, %p1256;
	shl.b64 	%rd3331, %rd3330, 1;
	sub.s64 	%rd3332, %rd3331, %rd507;
	mov.b64 	%fd1703, %rd3332;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3536}, %fd1703;
	}
	setp.lt.s32 	%p1257, %r3536, 0;
	selp.b64 	%rd3333, %rd3331, %rd3332, %p1257;
	shl.b64 	%rd3334, %rd3333, 1;
	sub.s64 	%rd3335, %rd3334, %rd507;
	mov.b64 	%fd1704, %rd3335;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3537}, %fd1704;
	}
	setp.lt.s32 	%p1258, %r3537, 0;
	selp.b64 	%rd6356, %rd3334, %rd3335, %p1258;
	shl.b64 	%rd6353, %rd6356, 1;
	add.s32 	%r756, %r6182, -16;
	setp.gt.s32 	%p1259, %r6182, 15;
	mov.u32 	%r6182, %r756;
	@%p1259 bra 	$L__BB0_617;

$L__BB0_618:
	and.b64  	%rd522, %rd6356, 9223372036854775807;
	setp.eq.s64 	%p1260, %rd522, 0;
	mov.f64 	%fd3016, 0d0000000000000000;
	@%p1260 bra 	$L__BB0_620;

	mov.b64 	%fd1706, %rd522;
	mul.f64 	%fd1707, %fd1706, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3538}, %fd1707;
	}
	shr.u32 	%r3539, %r3538, 20;
	mov.u32 	%r3540, 55;
	sub.s32 	%r3541, %r3540, %r3539;
	sub.s32 	%r3542, %r6176, %r3541;
	shl.b64 	%rd3336, %rd522, %r3541;
	setp.lt.s32 	%p1261, %r3542, 1;
	mov.u32 	%r3543, 1;
	sub.s32 	%r3544, %r3543, %r3542;
	shr.u64 	%rd3337, %rd3336, %r3544;
	add.s32 	%r3545, %r3542, -1;
	cvt.u64.u32 	%rd3338, %r3545;
	shl.b64 	%rd3339, %rd3338, 52;
	add.s64 	%rd3340, %rd3339, %rd3336;
	selp.b64 	%rd3341, %rd3337, %rd3340, %p1261;
	mov.b64 	%fd3016, %rd3341;

$L__BB0_620:
	and.b32  	%r3546, %r733, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3547}, %fd3016;
	}
	or.b32  	%r3548, %r3547, %r3546;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3549, %temp}, %fd3016;
	}
	mov.b64 	%fd3017, {%r3549, %r3548};
	bra.uni 	$L__BB0_624;

$L__BB0_622:
	mov.f64 	%fd1708, 0d3FF0000000000000;
	add.rn.f64 	%fd3017, %fd335, %fd1708;

$L__BB0_624:
	mov.f64 	%fd1709, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1710, %fd1709, %fd3017;
	mul.f64 	%fd1711, %fd1710, %fd63;
	mul.f64 	%fd1712, %fd1711, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 91 26
	add.s32 	%r3550, %r6211, 3;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 91 26
	cvt.rn.f64.s32 	%fd1713, %r3550;
	fma.rn.f64 	%fd346, %fd1713, 0d400921FB54442D18, %fd1712;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r757}, %fd346;
	}
	and.b32  	%r3551, %r757, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3552, %temp}, %fd346;
	}
	mov.b64 	%fd3018, {%r3552, %r3551};
	setp.gt.u32 	%p1266, %r3551, 2146435071;
	or.pred  	%p1268, %p1266, %p18;
	@%p1268 bra 	$L__BB0_641;
	bra.uni 	$L__BB0_625;

$L__BB0_641:
	.loc	1 0 9
	setp.le.f64 	%p1303, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1304, %fd3018, 0d7FF0000000000000;
	and.pred  	%p1305, %p1304, %p1303;
	@%p1305 bra 	$L__BB0_643;
	bra.uni 	$L__BB0_642;

$L__BB0_643:
	setp.eq.f64 	%p1306, %fd3018, 0d7FF0000000000000;
	selp.f64 	%fd3021, 0dFFF8000000000000, %fd346, %p1306;
	bra.uni 	$L__BB0_644;

$L__BB0_625:
	.loc	1 0 9
	mov.f64 	%fd3021, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_644;

	setp.ltu.f64 	%p1270, %fd3018, %fd3160;
	mov.f64 	%fd3021, %fd346;
	@%p1270 bra 	$L__BB0_644;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3553}, %fd3018;
	}
	shr.u32 	%r6184, %r3553, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3554}, %fd3160;
	}
	shr.u32 	%r6185, %r3554, 20;
	setp.ne.s32 	%p1271, %r6184, 0;
	@%p1271 bra 	$L__BB0_629;

	mul.f64 	%fd3018, %fd3018, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3555}, %fd3018;
	}
	shr.u32 	%r3556, %r3555, 20;
	add.s32 	%r6184, %r3556, -54;

$L__BB0_629:
	setp.ne.s32 	%p1272, %r6185, 0;
	mov.f64 	%fd3019, %fd3160;
	@%p1272 bra 	$L__BB0_631;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3557}, %fd2;
	}
	shr.u32 	%r3558, %r3557, 20;
	add.s32 	%r6185, %r3558, -54;
	mov.f64 	%fd3019, %fd2;

$L__BB0_631:
	mov.b64 	%rd3343, %fd3018;
	and.b64  	%rd3344, %rd3343, 4503599627370495;
	or.b64  	%rd6361, %rd3344, 4503599627370496;
	mov.b64 	%rd3345, %fd3019;
	and.b64  	%rd3346, %rd3345, 4503599627370495;
	or.b64  	%rd524, %rd3346, 4503599627370496;
	sub.s32 	%r6191, %r6184, %r6185;
	not.b32 	%r3559, %r6184;
	add.s32 	%r3560, %r6185, %r3559;
	max.s32 	%r3561, %r3560, -1;
	add.s32 	%r765, %r3561, %r6184;
	mov.u32 	%r3562, 2;
	sub.s32 	%r3563, %r3562, %r6185;
	add.s32 	%r3564, %r3563, %r765;
	and.b32  	%r6187, %r3564, 3;
	setp.eq.s32 	%p1273, %r6187, 0;
	@%p1273 bra 	$L__BB0_633;

$L__BB0_632:
	.pragma "nounroll";
	sub.s64 	%rd3347, %rd6361, %rd524;
	mov.b64 	%fd1715, %rd3347;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3565}, %fd1715;
	}
	setp.lt.s32 	%p1274, %r3565, 0;
	selp.b64 	%rd6364, %rd6361, %rd3347, %p1274;
	shl.b64 	%rd6361, %rd6364, 1;
	add.s32 	%r6191, %r6191, -1;
	add.s32 	%r6187, %r6187, -1;
	setp.ne.s32 	%p1275, %r6187, 0;
	@%p1275 bra 	$L__BB0_632;

$L__BB0_633:
	mov.u32 	%r3566, 1;
	sub.s32 	%r3567, %r3566, %r6185;
	add.s32 	%r3568, %r3567, %r765;
	setp.lt.u32 	%p1276, %r3568, 3;
	@%p1276 bra 	$L__BB0_638;

	not.b32 	%r3569, %r6191;
	max.s32 	%r3570, %r3569, -4;
	add.s32 	%r3571, %r6191, %r3570;
	add.s32 	%r772, %r3571, 4;
	shr.u32 	%r3572, %r772, 2;
	add.s32 	%r3573, %r3572, 1;
	and.b32  	%r6190, %r3573, 3;
	setp.eq.s32 	%p1277, %r6190, 0;
	@%p1277 bra 	$L__BB0_636;

$L__BB0_635:
	.pragma "nounroll";
	sub.s64 	%rd3349, %rd6361, %rd524;
	mov.b64 	%fd1716, %rd3349;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3574}, %fd1716;
	}
	setp.lt.s32 	%p1278, %r3574, 0;
	selp.b64 	%rd3350, %rd6361, %rd3349, %p1278;
	shl.b64 	%rd3351, %rd3350, 1;
	sub.s64 	%rd3352, %rd3351, %rd524;
	mov.b64 	%fd1717, %rd3352;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3575}, %fd1717;
	}
	setp.lt.s32 	%p1279, %r3575, 0;
	selp.b64 	%rd3353, %rd3351, %rd3352, %p1279;
	shl.b64 	%rd3354, %rd3353, 1;
	sub.s64 	%rd3355, %rd3354, %rd524;
	mov.b64 	%fd1718, %rd3355;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3576}, %fd1718;
	}
	setp.lt.s32 	%p1280, %r3576, 0;
	selp.b64 	%rd3356, %rd3354, %rd3355, %p1280;
	shl.b64 	%rd3357, %rd3356, 1;
	sub.s64 	%rd3358, %rd3357, %rd524;
	mov.b64 	%fd1719, %rd3358;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3577}, %fd1719;
	}
	setp.lt.s32 	%p1281, %r3577, 0;
	selp.b64 	%rd6364, %rd3357, %rd3358, %p1281;
	shl.b64 	%rd6361, %rd6364, 1;
	add.s32 	%r6191, %r6191, -4;
	add.s32 	%r6190, %r6190, -1;
	setp.ne.s32 	%p1282, %r6190, 0;
	@%p1282 bra 	$L__BB0_635;

$L__BB0_636:
	setp.lt.u32 	%p1283, %r772, 12;
	@%p1283 bra 	$L__BB0_638;

$L__BB0_637:
	sub.s64 	%rd3359, %rd6361, %rd524;
	mov.b64 	%fd1720, %rd3359;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3578}, %fd1720;
	}
	setp.lt.s32 	%p1284, %r3578, 0;
	selp.b64 	%rd3360, %rd6361, %rd3359, %p1284;
	shl.b64 	%rd3361, %rd3360, 1;
	sub.s64 	%rd3362, %rd3361, %rd524;
	mov.b64 	%fd1721, %rd3362;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3579}, %fd1721;
	}
	setp.lt.s32 	%p1285, %r3579, 0;
	selp.b64 	%rd3363, %rd3361, %rd3362, %p1285;
	shl.b64 	%rd3364, %rd3363, 1;
	sub.s64 	%rd3365, %rd3364, %rd524;
	mov.b64 	%fd1722, %rd3365;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3580}, %fd1722;
	}
	setp.lt.s32 	%p1286, %r3580, 0;
	selp.b64 	%rd3366, %rd3364, %rd3365, %p1286;
	shl.b64 	%rd3367, %rd3366, 1;
	sub.s64 	%rd3368, %rd3367, %rd524;
	mov.b64 	%fd1723, %rd3368;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3581}, %fd1723;
	}
	setp.lt.s32 	%p1287, %r3581, 0;
	selp.b64 	%rd3369, %rd3367, %rd3368, %p1287;
	shl.b64 	%rd3370, %rd3369, 1;
	sub.s64 	%rd3371, %rd3370, %rd524;
	mov.b64 	%fd1724, %rd3371;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3582}, %fd1724;
	}
	setp.lt.s32 	%p1288, %r3582, 0;
	selp.b64 	%rd3372, %rd3370, %rd3371, %p1288;
	shl.b64 	%rd3373, %rd3372, 1;
	sub.s64 	%rd3374, %rd3373, %rd524;
	mov.b64 	%fd1725, %rd3374;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3583}, %fd1725;
	}
	setp.lt.s32 	%p1289, %r3583, 0;
	selp.b64 	%rd3375, %rd3373, %rd3374, %p1289;
	shl.b64 	%rd3376, %rd3375, 1;
	sub.s64 	%rd3377, %rd3376, %rd524;
	mov.b64 	%fd1726, %rd3377;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3584}, %fd1726;
	}
	setp.lt.s32 	%p1290, %r3584, 0;
	selp.b64 	%rd3378, %rd3376, %rd3377, %p1290;
	shl.b64 	%rd3379, %rd3378, 1;
	sub.s64 	%rd3380, %rd3379, %rd524;
	mov.b64 	%fd1727, %rd3380;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3585}, %fd1727;
	}
	setp.lt.s32 	%p1291, %r3585, 0;
	selp.b64 	%rd3381, %rd3379, %rd3380, %p1291;
	shl.b64 	%rd3382, %rd3381, 1;
	sub.s64 	%rd3383, %rd3382, %rd524;
	mov.b64 	%fd1728, %rd3383;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3586}, %fd1728;
	}
	setp.lt.s32 	%p1292, %r3586, 0;
	selp.b64 	%rd3384, %rd3382, %rd3383, %p1292;
	shl.b64 	%rd3385, %rd3384, 1;
	sub.s64 	%rd3386, %rd3385, %rd524;
	mov.b64 	%fd1729, %rd3386;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3587}, %fd1729;
	}
	setp.lt.s32 	%p1293, %r3587, 0;
	selp.b64 	%rd3387, %rd3385, %rd3386, %p1293;
	shl.b64 	%rd3388, %rd3387, 1;
	sub.s64 	%rd3389, %rd3388, %rd524;
	mov.b64 	%fd1730, %rd3389;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3588}, %fd1730;
	}
	setp.lt.s32 	%p1294, %r3588, 0;
	selp.b64 	%rd3390, %rd3388, %rd3389, %p1294;
	shl.b64 	%rd3391, %rd3390, 1;
	sub.s64 	%rd3392, %rd3391, %rd524;
	mov.b64 	%fd1731, %rd3392;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3589}, %fd1731;
	}
	setp.lt.s32 	%p1295, %r3589, 0;
	selp.b64 	%rd3393, %rd3391, %rd3392, %p1295;
	shl.b64 	%rd3394, %rd3393, 1;
	sub.s64 	%rd3395, %rd3394, %rd524;
	mov.b64 	%fd1732, %rd3395;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3590}, %fd1732;
	}
	setp.lt.s32 	%p1296, %r3590, 0;
	selp.b64 	%rd3396, %rd3394, %rd3395, %p1296;
	shl.b64 	%rd3397, %rd3396, 1;
	sub.s64 	%rd3398, %rd3397, %rd524;
	mov.b64 	%fd1733, %rd3398;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3591}, %fd1733;
	}
	setp.lt.s32 	%p1297, %r3591, 0;
	selp.b64 	%rd3399, %rd3397, %rd3398, %p1297;
	shl.b64 	%rd3400, %rd3399, 1;
	sub.s64 	%rd3401, %rd3400, %rd524;
	mov.b64 	%fd1734, %rd3401;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3592}, %fd1734;
	}
	setp.lt.s32 	%p1298, %r3592, 0;
	selp.b64 	%rd3402, %rd3400, %rd3401, %p1298;
	shl.b64 	%rd3403, %rd3402, 1;
	sub.s64 	%rd3404, %rd3403, %rd524;
	mov.b64 	%fd1735, %rd3404;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3593}, %fd1735;
	}
	setp.lt.s32 	%p1299, %r3593, 0;
	selp.b64 	%rd6364, %rd3403, %rd3404, %p1299;
	shl.b64 	%rd6361, %rd6364, 1;
	add.s32 	%r780, %r6191, -16;
	setp.gt.s32 	%p1300, %r6191, 15;
	mov.u32 	%r6191, %r780;
	@%p1300 bra 	$L__BB0_637;

$L__BB0_638:
	and.b64  	%rd539, %rd6364, 9223372036854775807;
	setp.eq.s64 	%p1301, %rd539, 0;
	mov.f64 	%fd3020, 0d0000000000000000;
	@%p1301 bra 	$L__BB0_640;

	mov.b64 	%fd1737, %rd539;
	mul.f64 	%fd1738, %fd1737, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3594}, %fd1738;
	}
	shr.u32 	%r3595, %r3594, 20;
	mov.u32 	%r3596, 55;
	sub.s32 	%r3597, %r3596, %r3595;
	sub.s32 	%r3598, %r6185, %r3597;
	shl.b64 	%rd3405, %rd539, %r3597;
	setp.lt.s32 	%p1302, %r3598, 1;
	mov.u32 	%r3599, 1;
	sub.s32 	%r3600, %r3599, %r3598;
	shr.u64 	%rd3406, %rd3405, %r3600;
	add.s32 	%r3601, %r3598, -1;
	cvt.u64.u32 	%rd3407, %r3601;
	shl.b64 	%rd3408, %rd3407, 52;
	add.s64 	%rd3409, %rd3408, %rd3405;
	selp.b64 	%rd3410, %rd3406, %rd3409, %p1302;
	mov.b64 	%fd3020, %rd3410;

$L__BB0_640:
	and.b32  	%r3602, %r757, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3603}, %fd3020;
	}
	or.b32  	%r3604, %r3603, %r3602;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3605, %temp}, %fd3020;
	}
	mov.b64 	%fd3021, {%r3605, %r3604};
	bra.uni 	$L__BB0_644;

$L__BB0_642:
	mov.f64 	%fd1739, 0d3FF0000000000000;
	add.rn.f64 	%fd3021, %fd346, %fd1739;

$L__BB0_644:
	mov.f64 	%fd1740, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1741, %fd1740, %fd3021;
	mul.f64 	%fd1742, %fd1741, %fd75;
	mul.f64 	%fd1743, %fd1742, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 91 26
	add.s32 	%r3606, %r6211, 2;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 91 26
	cvt.rn.f64.s32 	%fd1744, %r3606;
	fma.rn.f64 	%fd357, %fd1744, 0d400921FB54442D18, %fd1743;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r781}, %fd357;
	}
	and.b32  	%r3607, %r781, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3608, %temp}, %fd357;
	}
	mov.b64 	%fd3022, {%r3608, %r3607};
	setp.gt.u32 	%p1307, %r3607, 2146435071;
	or.pred  	%p1309, %p1307, %p18;
	@%p1309 bra 	$L__BB0_661;
	bra.uni 	$L__BB0_645;

$L__BB0_661:
	.loc	1 0 9
	setp.le.f64 	%p1344, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1345, %fd3022, 0d7FF0000000000000;
	and.pred  	%p1346, %p1345, %p1344;
	@%p1346 bra 	$L__BB0_663;
	bra.uni 	$L__BB0_662;

$L__BB0_663:
	setp.eq.f64 	%p1347, %fd3022, 0d7FF0000000000000;
	selp.f64 	%fd3025, 0dFFF8000000000000, %fd357, %p1347;
	bra.uni 	$L__BB0_664;

$L__BB0_645:
	.loc	1 0 9
	mov.f64 	%fd3025, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_664;

	setp.ltu.f64 	%p1311, %fd3022, %fd3160;
	mov.f64 	%fd3025, %fd357;
	@%p1311 bra 	$L__BB0_664;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3609}, %fd3022;
	}
	shr.u32 	%r6193, %r3609, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3610}, %fd3160;
	}
	shr.u32 	%r6194, %r3610, 20;
	setp.ne.s32 	%p1312, %r6193, 0;
	@%p1312 bra 	$L__BB0_649;

	mul.f64 	%fd3022, %fd3022, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3611}, %fd3022;
	}
	shr.u32 	%r3612, %r3611, 20;
	add.s32 	%r6193, %r3612, -54;

$L__BB0_649:
	setp.ne.s32 	%p1313, %r6194, 0;
	mov.f64 	%fd3023, %fd3160;
	@%p1313 bra 	$L__BB0_651;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3613}, %fd2;
	}
	shr.u32 	%r3614, %r3613, 20;
	add.s32 	%r6194, %r3614, -54;
	mov.f64 	%fd3023, %fd2;

$L__BB0_651:
	mov.b64 	%rd3412, %fd3022;
	and.b64  	%rd3413, %rd3412, 4503599627370495;
	or.b64  	%rd6369, %rd3413, 4503599627370496;
	mov.b64 	%rd3414, %fd3023;
	and.b64  	%rd3415, %rd3414, 4503599627370495;
	or.b64  	%rd541, %rd3415, 4503599627370496;
	sub.s32 	%r6200, %r6193, %r6194;
	not.b32 	%r3615, %r6193;
	add.s32 	%r3616, %r6194, %r3615;
	max.s32 	%r3617, %r3616, -1;
	add.s32 	%r789, %r3617, %r6193;
	mov.u32 	%r3618, 2;
	sub.s32 	%r3619, %r3618, %r6194;
	add.s32 	%r3620, %r3619, %r789;
	and.b32  	%r6196, %r3620, 3;
	setp.eq.s32 	%p1314, %r6196, 0;
	@%p1314 bra 	$L__BB0_653;

$L__BB0_652:
	.pragma "nounroll";
	sub.s64 	%rd3416, %rd6369, %rd541;
	mov.b64 	%fd1746, %rd3416;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3621}, %fd1746;
	}
	setp.lt.s32 	%p1315, %r3621, 0;
	selp.b64 	%rd6372, %rd6369, %rd3416, %p1315;
	shl.b64 	%rd6369, %rd6372, 1;
	add.s32 	%r6200, %r6200, -1;
	add.s32 	%r6196, %r6196, -1;
	setp.ne.s32 	%p1316, %r6196, 0;
	@%p1316 bra 	$L__BB0_652;

$L__BB0_653:
	mov.u32 	%r3622, 1;
	sub.s32 	%r3623, %r3622, %r6194;
	add.s32 	%r3624, %r3623, %r789;
	setp.lt.u32 	%p1317, %r3624, 3;
	@%p1317 bra 	$L__BB0_658;

	not.b32 	%r3625, %r6200;
	max.s32 	%r3626, %r3625, -4;
	add.s32 	%r3627, %r6200, %r3626;
	add.s32 	%r796, %r3627, 4;
	shr.u32 	%r3628, %r796, 2;
	add.s32 	%r3629, %r3628, 1;
	and.b32  	%r6199, %r3629, 3;
	setp.eq.s32 	%p1318, %r6199, 0;
	@%p1318 bra 	$L__BB0_656;

$L__BB0_655:
	.pragma "nounroll";
	sub.s64 	%rd3418, %rd6369, %rd541;
	mov.b64 	%fd1747, %rd3418;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3630}, %fd1747;
	}
	setp.lt.s32 	%p1319, %r3630, 0;
	selp.b64 	%rd3419, %rd6369, %rd3418, %p1319;
	shl.b64 	%rd3420, %rd3419, 1;
	sub.s64 	%rd3421, %rd3420, %rd541;
	mov.b64 	%fd1748, %rd3421;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3631}, %fd1748;
	}
	setp.lt.s32 	%p1320, %r3631, 0;
	selp.b64 	%rd3422, %rd3420, %rd3421, %p1320;
	shl.b64 	%rd3423, %rd3422, 1;
	sub.s64 	%rd3424, %rd3423, %rd541;
	mov.b64 	%fd1749, %rd3424;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3632}, %fd1749;
	}
	setp.lt.s32 	%p1321, %r3632, 0;
	selp.b64 	%rd3425, %rd3423, %rd3424, %p1321;
	shl.b64 	%rd3426, %rd3425, 1;
	sub.s64 	%rd3427, %rd3426, %rd541;
	mov.b64 	%fd1750, %rd3427;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3633}, %fd1750;
	}
	setp.lt.s32 	%p1322, %r3633, 0;
	selp.b64 	%rd6372, %rd3426, %rd3427, %p1322;
	shl.b64 	%rd6369, %rd6372, 1;
	add.s32 	%r6200, %r6200, -4;
	add.s32 	%r6199, %r6199, -1;
	setp.ne.s32 	%p1323, %r6199, 0;
	@%p1323 bra 	$L__BB0_655;

$L__BB0_656:
	setp.lt.u32 	%p1324, %r796, 12;
	@%p1324 bra 	$L__BB0_658;

$L__BB0_657:
	sub.s64 	%rd3428, %rd6369, %rd541;
	mov.b64 	%fd1751, %rd3428;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3634}, %fd1751;
	}
	setp.lt.s32 	%p1325, %r3634, 0;
	selp.b64 	%rd3429, %rd6369, %rd3428, %p1325;
	shl.b64 	%rd3430, %rd3429, 1;
	sub.s64 	%rd3431, %rd3430, %rd541;
	mov.b64 	%fd1752, %rd3431;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3635}, %fd1752;
	}
	setp.lt.s32 	%p1326, %r3635, 0;
	selp.b64 	%rd3432, %rd3430, %rd3431, %p1326;
	shl.b64 	%rd3433, %rd3432, 1;
	sub.s64 	%rd3434, %rd3433, %rd541;
	mov.b64 	%fd1753, %rd3434;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3636}, %fd1753;
	}
	setp.lt.s32 	%p1327, %r3636, 0;
	selp.b64 	%rd3435, %rd3433, %rd3434, %p1327;
	shl.b64 	%rd3436, %rd3435, 1;
	sub.s64 	%rd3437, %rd3436, %rd541;
	mov.b64 	%fd1754, %rd3437;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3637}, %fd1754;
	}
	setp.lt.s32 	%p1328, %r3637, 0;
	selp.b64 	%rd3438, %rd3436, %rd3437, %p1328;
	shl.b64 	%rd3439, %rd3438, 1;
	sub.s64 	%rd3440, %rd3439, %rd541;
	mov.b64 	%fd1755, %rd3440;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3638}, %fd1755;
	}
	setp.lt.s32 	%p1329, %r3638, 0;
	selp.b64 	%rd3441, %rd3439, %rd3440, %p1329;
	shl.b64 	%rd3442, %rd3441, 1;
	sub.s64 	%rd3443, %rd3442, %rd541;
	mov.b64 	%fd1756, %rd3443;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3639}, %fd1756;
	}
	setp.lt.s32 	%p1330, %r3639, 0;
	selp.b64 	%rd3444, %rd3442, %rd3443, %p1330;
	shl.b64 	%rd3445, %rd3444, 1;
	sub.s64 	%rd3446, %rd3445, %rd541;
	mov.b64 	%fd1757, %rd3446;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3640}, %fd1757;
	}
	setp.lt.s32 	%p1331, %r3640, 0;
	selp.b64 	%rd3447, %rd3445, %rd3446, %p1331;
	shl.b64 	%rd3448, %rd3447, 1;
	sub.s64 	%rd3449, %rd3448, %rd541;
	mov.b64 	%fd1758, %rd3449;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3641}, %fd1758;
	}
	setp.lt.s32 	%p1332, %r3641, 0;
	selp.b64 	%rd3450, %rd3448, %rd3449, %p1332;
	shl.b64 	%rd3451, %rd3450, 1;
	sub.s64 	%rd3452, %rd3451, %rd541;
	mov.b64 	%fd1759, %rd3452;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3642}, %fd1759;
	}
	setp.lt.s32 	%p1333, %r3642, 0;
	selp.b64 	%rd3453, %rd3451, %rd3452, %p1333;
	shl.b64 	%rd3454, %rd3453, 1;
	sub.s64 	%rd3455, %rd3454, %rd541;
	mov.b64 	%fd1760, %rd3455;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3643}, %fd1760;
	}
	setp.lt.s32 	%p1334, %r3643, 0;
	selp.b64 	%rd3456, %rd3454, %rd3455, %p1334;
	shl.b64 	%rd3457, %rd3456, 1;
	sub.s64 	%rd3458, %rd3457, %rd541;
	mov.b64 	%fd1761, %rd3458;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3644}, %fd1761;
	}
	setp.lt.s32 	%p1335, %r3644, 0;
	selp.b64 	%rd3459, %rd3457, %rd3458, %p1335;
	shl.b64 	%rd3460, %rd3459, 1;
	sub.s64 	%rd3461, %rd3460, %rd541;
	mov.b64 	%fd1762, %rd3461;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3645}, %fd1762;
	}
	setp.lt.s32 	%p1336, %r3645, 0;
	selp.b64 	%rd3462, %rd3460, %rd3461, %p1336;
	shl.b64 	%rd3463, %rd3462, 1;
	sub.s64 	%rd3464, %rd3463, %rd541;
	mov.b64 	%fd1763, %rd3464;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3646}, %fd1763;
	}
	setp.lt.s32 	%p1337, %r3646, 0;
	selp.b64 	%rd3465, %rd3463, %rd3464, %p1337;
	shl.b64 	%rd3466, %rd3465, 1;
	sub.s64 	%rd3467, %rd3466, %rd541;
	mov.b64 	%fd1764, %rd3467;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3647}, %fd1764;
	}
	setp.lt.s32 	%p1338, %r3647, 0;
	selp.b64 	%rd3468, %rd3466, %rd3467, %p1338;
	shl.b64 	%rd3469, %rd3468, 1;
	sub.s64 	%rd3470, %rd3469, %rd541;
	mov.b64 	%fd1765, %rd3470;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3648}, %fd1765;
	}
	setp.lt.s32 	%p1339, %r3648, 0;
	selp.b64 	%rd3471, %rd3469, %rd3470, %p1339;
	shl.b64 	%rd3472, %rd3471, 1;
	sub.s64 	%rd3473, %rd3472, %rd541;
	mov.b64 	%fd1766, %rd3473;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3649}, %fd1766;
	}
	setp.lt.s32 	%p1340, %r3649, 0;
	selp.b64 	%rd6372, %rd3472, %rd3473, %p1340;
	shl.b64 	%rd6369, %rd6372, 1;
	add.s32 	%r804, %r6200, -16;
	setp.gt.s32 	%p1341, %r6200, 15;
	mov.u32 	%r6200, %r804;
	@%p1341 bra 	$L__BB0_657;

$L__BB0_658:
	and.b64  	%rd556, %rd6372, 9223372036854775807;
	setp.eq.s64 	%p1342, %rd556, 0;
	mov.f64 	%fd3024, 0d0000000000000000;
	@%p1342 bra 	$L__BB0_660;

	mov.b64 	%fd1768, %rd556;
	mul.f64 	%fd1769, %fd1768, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3650}, %fd1769;
	}
	shr.u32 	%r3651, %r3650, 20;
	mov.u32 	%r3652, 55;
	sub.s32 	%r3653, %r3652, %r3651;
	sub.s32 	%r3654, %r6194, %r3653;
	shl.b64 	%rd3474, %rd556, %r3653;
	setp.lt.s32 	%p1343, %r3654, 1;
	mov.u32 	%r3655, 1;
	sub.s32 	%r3656, %r3655, %r3654;
	shr.u64 	%rd3475, %rd3474, %r3656;
	add.s32 	%r3657, %r3654, -1;
	cvt.u64.u32 	%rd3476, %r3657;
	shl.b64 	%rd3477, %rd3476, 52;
	add.s64 	%rd3478, %rd3477, %rd3474;
	selp.b64 	%rd3479, %rd3475, %rd3478, %p1343;
	mov.b64 	%fd3024, %rd3479;

$L__BB0_660:
	and.b32  	%r3658, %r781, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3659}, %fd3024;
	}
	or.b32  	%r3660, %r3659, %r3658;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3661, %temp}, %fd3024;
	}
	mov.b64 	%fd3025, {%r3661, %r3660};
	bra.uni 	$L__BB0_664;

$L__BB0_662:
	mov.f64 	%fd1770, 0d3FF0000000000000;
	add.rn.f64 	%fd3025, %fd357, %fd1770;

$L__BB0_664:
	mov.f64 	%fd1771, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1772, %fd1771, %fd3025;
	mul.f64 	%fd1773, %fd1772, %fd87;
	mul.f64 	%fd1774, %fd1773, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 91 26
	add.s32 	%r3662, %r6211, 1;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 91 26
	cvt.rn.f64.s32 	%fd1775, %r3662;
	fma.rn.f64 	%fd368, %fd1775, 0d400921FB54442D18, %fd1774;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r805}, %fd368;
	}
	and.b32  	%r3663, %r805, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3664, %temp}, %fd368;
	}
	mov.b64 	%fd3026, {%r3664, %r3663};
	setp.gt.u32 	%p1348, %r3663, 2146435071;
	or.pred  	%p1350, %p1348, %p18;
	@%p1350 bra 	$L__BB0_681;
	bra.uni 	$L__BB0_665;

$L__BB0_681:
	.loc	1 0 9
	setp.le.f64 	%p1385, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1386, %fd3026, 0d7FF0000000000000;
	and.pred  	%p1387, %p1386, %p1385;
	@%p1387 bra 	$L__BB0_683;
	bra.uni 	$L__BB0_682;

$L__BB0_683:
	setp.eq.f64 	%p1388, %fd3026, 0d7FF0000000000000;
	selp.f64 	%fd3034, 0dFFF8000000000000, %fd368, %p1388;
	bra.uni 	$L__BB0_684;

$L__BB0_665:
	.loc	1 0 9
	mov.f64 	%fd3034, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_684;

	setp.ltu.f64 	%p1352, %fd3026, %fd3160;
	mov.f64 	%fd3034, %fd368;
	@%p1352 bra 	$L__BB0_684;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3665}, %fd3026;
	}
	shr.u32 	%r6202, %r3665, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3666}, %fd3160;
	}
	shr.u32 	%r6203, %r3666, 20;
	setp.ne.s32 	%p1353, %r6202, 0;
	@%p1353 bra 	$L__BB0_669;

	mul.f64 	%fd3026, %fd3026, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3667}, %fd3026;
	}
	shr.u32 	%r3668, %r3667, 20;
	add.s32 	%r6202, %r3668, -54;

$L__BB0_669:
	setp.ne.s32 	%p1354, %r6203, 0;
	mov.f64 	%fd3027, %fd3160;
	@%p1354 bra 	$L__BB0_671;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3669}, %fd2;
	}
	shr.u32 	%r3670, %r3669, 20;
	add.s32 	%r6203, %r3670, -54;
	mov.f64 	%fd3027, %fd2;

$L__BB0_671:
	mov.b64 	%rd3481, %fd3026;
	and.b64  	%rd3482, %rd3481, 4503599627370495;
	or.b64  	%rd6377, %rd3482, 4503599627370496;
	mov.b64 	%rd3483, %fd3027;
	and.b64  	%rd3484, %rd3483, 4503599627370495;
	or.b64  	%rd558, %rd3484, 4503599627370496;
	sub.s32 	%r6209, %r6202, %r6203;
	not.b32 	%r3671, %r6202;
	add.s32 	%r3672, %r6203, %r3671;
	max.s32 	%r3673, %r3672, -1;
	add.s32 	%r813, %r3673, %r6202;
	mov.u32 	%r3674, 2;
	sub.s32 	%r3675, %r3674, %r6203;
	add.s32 	%r3676, %r3675, %r813;
	and.b32  	%r6205, %r3676, 3;
	setp.eq.s32 	%p1355, %r6205, 0;
	@%p1355 bra 	$L__BB0_673;

$L__BB0_672:
	.pragma "nounroll";
	sub.s64 	%rd3485, %rd6377, %rd558;
	mov.b64 	%fd1777, %rd3485;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3677}, %fd1777;
	}
	setp.lt.s32 	%p1356, %r3677, 0;
	selp.b64 	%rd6380, %rd6377, %rd3485, %p1356;
	shl.b64 	%rd6377, %rd6380, 1;
	add.s32 	%r6209, %r6209, -1;
	add.s32 	%r6205, %r6205, -1;
	setp.ne.s32 	%p1357, %r6205, 0;
	@%p1357 bra 	$L__BB0_672;

$L__BB0_673:
	mov.u32 	%r3678, 1;
	sub.s32 	%r3679, %r3678, %r6203;
	add.s32 	%r3680, %r3679, %r813;
	setp.lt.u32 	%p1358, %r3680, 3;
	@%p1358 bra 	$L__BB0_678;

	not.b32 	%r3681, %r6209;
	max.s32 	%r3682, %r3681, -4;
	add.s32 	%r3683, %r6209, %r3682;
	add.s32 	%r820, %r3683, 4;
	shr.u32 	%r3684, %r820, 2;
	add.s32 	%r3685, %r3684, 1;
	and.b32  	%r6208, %r3685, 3;
	setp.eq.s32 	%p1359, %r6208, 0;
	@%p1359 bra 	$L__BB0_676;

$L__BB0_675:
	.pragma "nounroll";
	sub.s64 	%rd3487, %rd6377, %rd558;
	mov.b64 	%fd1778, %rd3487;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3686}, %fd1778;
	}
	setp.lt.s32 	%p1360, %r3686, 0;
	selp.b64 	%rd3488, %rd6377, %rd3487, %p1360;
	shl.b64 	%rd3489, %rd3488, 1;
	sub.s64 	%rd3490, %rd3489, %rd558;
	mov.b64 	%fd1779, %rd3490;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3687}, %fd1779;
	}
	setp.lt.s32 	%p1361, %r3687, 0;
	selp.b64 	%rd3491, %rd3489, %rd3490, %p1361;
	shl.b64 	%rd3492, %rd3491, 1;
	sub.s64 	%rd3493, %rd3492, %rd558;
	mov.b64 	%fd1780, %rd3493;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3688}, %fd1780;
	}
	setp.lt.s32 	%p1362, %r3688, 0;
	selp.b64 	%rd3494, %rd3492, %rd3493, %p1362;
	shl.b64 	%rd3495, %rd3494, 1;
	sub.s64 	%rd3496, %rd3495, %rd558;
	mov.b64 	%fd1781, %rd3496;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3689}, %fd1781;
	}
	setp.lt.s32 	%p1363, %r3689, 0;
	selp.b64 	%rd6380, %rd3495, %rd3496, %p1363;
	shl.b64 	%rd6377, %rd6380, 1;
	add.s32 	%r6209, %r6209, -4;
	add.s32 	%r6208, %r6208, -1;
	setp.ne.s32 	%p1364, %r6208, 0;
	@%p1364 bra 	$L__BB0_675;

$L__BB0_676:
	setp.lt.u32 	%p1365, %r820, 12;
	@%p1365 bra 	$L__BB0_678;

$L__BB0_677:
	sub.s64 	%rd3497, %rd6377, %rd558;
	mov.b64 	%fd1782, %rd3497;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3690}, %fd1782;
	}
	setp.lt.s32 	%p1366, %r3690, 0;
	selp.b64 	%rd3498, %rd6377, %rd3497, %p1366;
	shl.b64 	%rd3499, %rd3498, 1;
	sub.s64 	%rd3500, %rd3499, %rd558;
	mov.b64 	%fd1783, %rd3500;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3691}, %fd1783;
	}
	setp.lt.s32 	%p1367, %r3691, 0;
	selp.b64 	%rd3501, %rd3499, %rd3500, %p1367;
	shl.b64 	%rd3502, %rd3501, 1;
	sub.s64 	%rd3503, %rd3502, %rd558;
	mov.b64 	%fd1784, %rd3503;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3692}, %fd1784;
	}
	setp.lt.s32 	%p1368, %r3692, 0;
	selp.b64 	%rd3504, %rd3502, %rd3503, %p1368;
	shl.b64 	%rd3505, %rd3504, 1;
	sub.s64 	%rd3506, %rd3505, %rd558;
	mov.b64 	%fd1785, %rd3506;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3693}, %fd1785;
	}
	setp.lt.s32 	%p1369, %r3693, 0;
	selp.b64 	%rd3507, %rd3505, %rd3506, %p1369;
	shl.b64 	%rd3508, %rd3507, 1;
	sub.s64 	%rd3509, %rd3508, %rd558;
	mov.b64 	%fd1786, %rd3509;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3694}, %fd1786;
	}
	setp.lt.s32 	%p1370, %r3694, 0;
	selp.b64 	%rd3510, %rd3508, %rd3509, %p1370;
	shl.b64 	%rd3511, %rd3510, 1;
	sub.s64 	%rd3512, %rd3511, %rd558;
	mov.b64 	%fd1787, %rd3512;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3695}, %fd1787;
	}
	setp.lt.s32 	%p1371, %r3695, 0;
	selp.b64 	%rd3513, %rd3511, %rd3512, %p1371;
	shl.b64 	%rd3514, %rd3513, 1;
	sub.s64 	%rd3515, %rd3514, %rd558;
	mov.b64 	%fd1788, %rd3515;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3696}, %fd1788;
	}
	setp.lt.s32 	%p1372, %r3696, 0;
	selp.b64 	%rd3516, %rd3514, %rd3515, %p1372;
	shl.b64 	%rd3517, %rd3516, 1;
	sub.s64 	%rd3518, %rd3517, %rd558;
	mov.b64 	%fd1789, %rd3518;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3697}, %fd1789;
	}
	setp.lt.s32 	%p1373, %r3697, 0;
	selp.b64 	%rd3519, %rd3517, %rd3518, %p1373;
	shl.b64 	%rd3520, %rd3519, 1;
	sub.s64 	%rd3521, %rd3520, %rd558;
	mov.b64 	%fd1790, %rd3521;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3698}, %fd1790;
	}
	setp.lt.s32 	%p1374, %r3698, 0;
	selp.b64 	%rd3522, %rd3520, %rd3521, %p1374;
	shl.b64 	%rd3523, %rd3522, 1;
	sub.s64 	%rd3524, %rd3523, %rd558;
	mov.b64 	%fd1791, %rd3524;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3699}, %fd1791;
	}
	setp.lt.s32 	%p1375, %r3699, 0;
	selp.b64 	%rd3525, %rd3523, %rd3524, %p1375;
	shl.b64 	%rd3526, %rd3525, 1;
	sub.s64 	%rd3527, %rd3526, %rd558;
	mov.b64 	%fd1792, %rd3527;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3700}, %fd1792;
	}
	setp.lt.s32 	%p1376, %r3700, 0;
	selp.b64 	%rd3528, %rd3526, %rd3527, %p1376;
	shl.b64 	%rd3529, %rd3528, 1;
	sub.s64 	%rd3530, %rd3529, %rd558;
	mov.b64 	%fd1793, %rd3530;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3701}, %fd1793;
	}
	setp.lt.s32 	%p1377, %r3701, 0;
	selp.b64 	%rd3531, %rd3529, %rd3530, %p1377;
	shl.b64 	%rd3532, %rd3531, 1;
	sub.s64 	%rd3533, %rd3532, %rd558;
	mov.b64 	%fd1794, %rd3533;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3702}, %fd1794;
	}
	setp.lt.s32 	%p1378, %r3702, 0;
	selp.b64 	%rd3534, %rd3532, %rd3533, %p1378;
	shl.b64 	%rd3535, %rd3534, 1;
	sub.s64 	%rd3536, %rd3535, %rd558;
	mov.b64 	%fd1795, %rd3536;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3703}, %fd1795;
	}
	setp.lt.s32 	%p1379, %r3703, 0;
	selp.b64 	%rd3537, %rd3535, %rd3536, %p1379;
	shl.b64 	%rd3538, %rd3537, 1;
	sub.s64 	%rd3539, %rd3538, %rd558;
	mov.b64 	%fd1796, %rd3539;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3704}, %fd1796;
	}
	setp.lt.s32 	%p1380, %r3704, 0;
	selp.b64 	%rd3540, %rd3538, %rd3539, %p1380;
	shl.b64 	%rd3541, %rd3540, 1;
	sub.s64 	%rd3542, %rd3541, %rd558;
	mov.b64 	%fd1797, %rd3542;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3705}, %fd1797;
	}
	setp.lt.s32 	%p1381, %r3705, 0;
	selp.b64 	%rd6380, %rd3541, %rd3542, %p1381;
	shl.b64 	%rd6377, %rd6380, 1;
	add.s32 	%r828, %r6209, -16;
	setp.gt.s32 	%p1382, %r6209, 15;
	mov.u32 	%r6209, %r828;
	@%p1382 bra 	$L__BB0_677;

$L__BB0_678:
	and.b64  	%rd573, %rd6380, 9223372036854775807;
	setp.eq.s64 	%p1383, %rd573, 0;
	mov.f64 	%fd3028, 0d0000000000000000;
	@%p1383 bra 	$L__BB0_680;

	mov.b64 	%fd1799, %rd573;
	mul.f64 	%fd1800, %fd1799, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3706}, %fd1800;
	}
	shr.u32 	%r3707, %r3706, 20;
	mov.u32 	%r3708, 55;
	sub.s32 	%r3709, %r3708, %r3707;
	sub.s32 	%r3710, %r6203, %r3709;
	shl.b64 	%rd3543, %rd573, %r3709;
	setp.lt.s32 	%p1384, %r3710, 1;
	mov.u32 	%r3711, 1;
	sub.s32 	%r3712, %r3711, %r3710;
	shr.u64 	%rd3544, %rd3543, %r3712;
	add.s32 	%r3713, %r3710, -1;
	cvt.u64.u32 	%rd3545, %r3713;
	shl.b64 	%rd3546, %rd3545, 52;
	add.s64 	%rd3547, %rd3546, %rd3543;
	selp.b64 	%rd3548, %rd3544, %rd3547, %p1384;
	mov.b64 	%fd3028, %rd3548;

$L__BB0_680:
	and.b32  	%r3714, %r805, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3715}, %fd3028;
	}
	or.b32  	%r3716, %r3715, %r3714;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3717, %temp}, %fd3028;
	}
	mov.b64 	%fd3034, {%r3717, %r3716};
	bra.uni 	$L__BB0_684;

$L__BB0_682:
	mov.f64 	%fd1801, 0d3FF0000000000000;
	add.rn.f64 	%fd3034, %fd368, %fd1801;

$L__BB0_684:
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 91 26
	setp.lt.s32 	%p1389, %r6211, 1;
	@%p1389 bra 	$L__BB0_707;

	.loc	1 92 9, function_name $L__info_string3, inlined_at 1 249 17
	cvt.u64.u32 	%rd574, %r635;

$L__BB0_686:
	.loc	1 0 9
	mov.u32 	%r829, %r6211;
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 91 26
	add.s32 	%r3718, %r829, -1;
	.loc	1 62 9, function_name $L__info_string6, inlined_at 1 91 26
	cvt.s64.s32 	%rd3549, %r3718;
	add.s64 	%rd3550, %rd3549, %rd574;
	add.s64 	%rd3551, %rd9, %rd3550;
	ld.global.u8 	%rs81, [%rd3551];
	cvt.rn.f64.u16 	%fd1802, %rs81;
	.loc	1 63 9, function_name $L__info_string6, inlined_at 1 91 26
	mov.f64 	%fd1803, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1804, %fd1803, %fd3034;
	mul.f64 	%fd1805, %fd1804, %fd1802;
	mul.f64 	%fd1806, %fd1805, 0d400921FB54442D18;
	cvt.rn.f64.s32 	%fd1807, %r829;
	fma.rn.f64 	%fd380, %fd1807, 0d400921FB54442D18, %fd1806;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r830}, %fd380;
	}
	and.b32  	%r3719, %r830, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3720, %temp}, %fd380;
	}
	mov.b64 	%fd3031, {%r3720, %r3719};
	setp.gt.u32 	%p1390, %r3719, 2146435071;
	or.pred  	%p1392, %p1390, %p18;
	@%p1392 bra 	$L__BB0_703;
	bra.uni 	$L__BB0_687;

$L__BB0_703:
	.loc	1 0 9
	setp.le.f64 	%p1427, %fd3160, 0d7FF0000000000000;
	.loc	1 63 9
	setp.le.f64 	%p1428, %fd3031, 0d7FF0000000000000;
	and.pred  	%p1429, %p1428, %p1427;
	@%p1429 bra 	$L__BB0_705;
	bra.uni 	$L__BB0_704;

$L__BB0_705:
	setp.eq.f64 	%p1430, %fd3031, 0d7FF0000000000000;
	selp.f64 	%fd3034, 0dFFF8000000000000, %fd380, %p1430;
	bra.uni 	$L__BB0_706;

$L__BB0_687:
	.loc	1 0 9
	mov.f64 	%fd3034, 0dFFF8000000000000;
	.loc	1 63 9
	@%p309 bra 	$L__BB0_706;

	setp.ltu.f64 	%p1394, %fd3031, %fd3160;
	mov.f64 	%fd3034, %fd380;
	@%p1394 bra 	$L__BB0_706;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3721}, %fd3031;
	}
	shr.u32 	%r6212, %r3721, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3722}, %fd3160;
	}
	shr.u32 	%r6213, %r3722, 20;
	setp.ne.s32 	%p1395, %r6212, 0;
	@%p1395 bra 	$L__BB0_691;

	mul.f64 	%fd3031, %fd3031, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3723}, %fd3031;
	}
	shr.u32 	%r3724, %r3723, 20;
	add.s32 	%r6212, %r3724, -54;

$L__BB0_691:
	setp.ne.s32 	%p1396, %r6213, 0;
	mov.f64 	%fd3032, %fd3160;
	@%p1396 bra 	$L__BB0_693;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3725}, %fd2;
	}
	shr.u32 	%r3726, %r3725, 20;
	add.s32 	%r6213, %r3726, -54;
	mov.f64 	%fd3032, %fd2;

$L__BB0_693:
	mov.b64 	%rd3553, %fd3031;
	and.b64  	%rd3554, %rd3553, 4503599627370495;
	or.b64  	%rd6385, %rd3554, 4503599627370496;
	mov.b64 	%rd3555, %fd3032;
	and.b64  	%rd3556, %rd3555, 4503599627370495;
	or.b64  	%rd576, %rd3556, 4503599627370496;
	sub.s32 	%r6219, %r6212, %r6213;
	not.b32 	%r3727, %r6212;
	add.s32 	%r3728, %r6213, %r3727;
	max.s32 	%r3729, %r3728, -1;
	add.s32 	%r838, %r3729, %r6212;
	mov.u32 	%r3730, 2;
	sub.s32 	%r3731, %r3730, %r6213;
	add.s32 	%r3732, %r3731, %r838;
	and.b32  	%r6215, %r3732, 3;
	setp.eq.s32 	%p1397, %r6215, 0;
	@%p1397 bra 	$L__BB0_695;

$L__BB0_694:
	.pragma "nounroll";
	sub.s64 	%rd3557, %rd6385, %rd576;
	mov.b64 	%fd1809, %rd3557;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3733}, %fd1809;
	}
	setp.lt.s32 	%p1398, %r3733, 0;
	selp.b64 	%rd6388, %rd6385, %rd3557, %p1398;
	shl.b64 	%rd6385, %rd6388, 1;
	add.s32 	%r6219, %r6219, -1;
	add.s32 	%r6215, %r6215, -1;
	setp.ne.s32 	%p1399, %r6215, 0;
	@%p1399 bra 	$L__BB0_694;

$L__BB0_695:
	mov.u32 	%r3734, 1;
	sub.s32 	%r3735, %r3734, %r6213;
	add.s32 	%r3736, %r3735, %r838;
	setp.lt.u32 	%p1400, %r3736, 3;
	@%p1400 bra 	$L__BB0_700;

	not.b32 	%r3737, %r6219;
	max.s32 	%r3738, %r3737, -4;
	add.s32 	%r3739, %r6219, %r3738;
	add.s32 	%r845, %r3739, 4;
	shr.u32 	%r3740, %r845, 2;
	add.s32 	%r3741, %r3740, 1;
	and.b32  	%r6218, %r3741, 3;
	setp.eq.s32 	%p1401, %r6218, 0;
	@%p1401 bra 	$L__BB0_698;

$L__BB0_697:
	.pragma "nounroll";
	sub.s64 	%rd3559, %rd6385, %rd576;
	mov.b64 	%fd1810, %rd3559;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3742}, %fd1810;
	}
	setp.lt.s32 	%p1402, %r3742, 0;
	selp.b64 	%rd3560, %rd6385, %rd3559, %p1402;
	shl.b64 	%rd3561, %rd3560, 1;
	sub.s64 	%rd3562, %rd3561, %rd576;
	mov.b64 	%fd1811, %rd3562;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3743}, %fd1811;
	}
	setp.lt.s32 	%p1403, %r3743, 0;
	selp.b64 	%rd3563, %rd3561, %rd3562, %p1403;
	shl.b64 	%rd3564, %rd3563, 1;
	sub.s64 	%rd3565, %rd3564, %rd576;
	mov.b64 	%fd1812, %rd3565;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3744}, %fd1812;
	}
	setp.lt.s32 	%p1404, %r3744, 0;
	selp.b64 	%rd3566, %rd3564, %rd3565, %p1404;
	shl.b64 	%rd3567, %rd3566, 1;
	sub.s64 	%rd3568, %rd3567, %rd576;
	mov.b64 	%fd1813, %rd3568;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3745}, %fd1813;
	}
	setp.lt.s32 	%p1405, %r3745, 0;
	selp.b64 	%rd6388, %rd3567, %rd3568, %p1405;
	shl.b64 	%rd6385, %rd6388, 1;
	add.s32 	%r6219, %r6219, -4;
	add.s32 	%r6218, %r6218, -1;
	setp.ne.s32 	%p1406, %r6218, 0;
	@%p1406 bra 	$L__BB0_697;

$L__BB0_698:
	setp.lt.u32 	%p1407, %r845, 12;
	@%p1407 bra 	$L__BB0_700;

$L__BB0_699:
	sub.s64 	%rd3569, %rd6385, %rd576;
	mov.b64 	%fd1814, %rd3569;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3746}, %fd1814;
	}
	setp.lt.s32 	%p1408, %r3746, 0;
	selp.b64 	%rd3570, %rd6385, %rd3569, %p1408;
	shl.b64 	%rd3571, %rd3570, 1;
	sub.s64 	%rd3572, %rd3571, %rd576;
	mov.b64 	%fd1815, %rd3572;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3747}, %fd1815;
	}
	setp.lt.s32 	%p1409, %r3747, 0;
	selp.b64 	%rd3573, %rd3571, %rd3572, %p1409;
	shl.b64 	%rd3574, %rd3573, 1;
	sub.s64 	%rd3575, %rd3574, %rd576;
	mov.b64 	%fd1816, %rd3575;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3748}, %fd1816;
	}
	setp.lt.s32 	%p1410, %r3748, 0;
	selp.b64 	%rd3576, %rd3574, %rd3575, %p1410;
	shl.b64 	%rd3577, %rd3576, 1;
	sub.s64 	%rd3578, %rd3577, %rd576;
	mov.b64 	%fd1817, %rd3578;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3749}, %fd1817;
	}
	setp.lt.s32 	%p1411, %r3749, 0;
	selp.b64 	%rd3579, %rd3577, %rd3578, %p1411;
	shl.b64 	%rd3580, %rd3579, 1;
	sub.s64 	%rd3581, %rd3580, %rd576;
	mov.b64 	%fd1818, %rd3581;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3750}, %fd1818;
	}
	setp.lt.s32 	%p1412, %r3750, 0;
	selp.b64 	%rd3582, %rd3580, %rd3581, %p1412;
	shl.b64 	%rd3583, %rd3582, 1;
	sub.s64 	%rd3584, %rd3583, %rd576;
	mov.b64 	%fd1819, %rd3584;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3751}, %fd1819;
	}
	setp.lt.s32 	%p1413, %r3751, 0;
	selp.b64 	%rd3585, %rd3583, %rd3584, %p1413;
	shl.b64 	%rd3586, %rd3585, 1;
	sub.s64 	%rd3587, %rd3586, %rd576;
	mov.b64 	%fd1820, %rd3587;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3752}, %fd1820;
	}
	setp.lt.s32 	%p1414, %r3752, 0;
	selp.b64 	%rd3588, %rd3586, %rd3587, %p1414;
	shl.b64 	%rd3589, %rd3588, 1;
	sub.s64 	%rd3590, %rd3589, %rd576;
	mov.b64 	%fd1821, %rd3590;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3753}, %fd1821;
	}
	setp.lt.s32 	%p1415, %r3753, 0;
	selp.b64 	%rd3591, %rd3589, %rd3590, %p1415;
	shl.b64 	%rd3592, %rd3591, 1;
	sub.s64 	%rd3593, %rd3592, %rd576;
	mov.b64 	%fd1822, %rd3593;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3754}, %fd1822;
	}
	setp.lt.s32 	%p1416, %r3754, 0;
	selp.b64 	%rd3594, %rd3592, %rd3593, %p1416;
	shl.b64 	%rd3595, %rd3594, 1;
	sub.s64 	%rd3596, %rd3595, %rd576;
	mov.b64 	%fd1823, %rd3596;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3755}, %fd1823;
	}
	setp.lt.s32 	%p1417, %r3755, 0;
	selp.b64 	%rd3597, %rd3595, %rd3596, %p1417;
	shl.b64 	%rd3598, %rd3597, 1;
	sub.s64 	%rd3599, %rd3598, %rd576;
	mov.b64 	%fd1824, %rd3599;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3756}, %fd1824;
	}
	setp.lt.s32 	%p1418, %r3756, 0;
	selp.b64 	%rd3600, %rd3598, %rd3599, %p1418;
	shl.b64 	%rd3601, %rd3600, 1;
	sub.s64 	%rd3602, %rd3601, %rd576;
	mov.b64 	%fd1825, %rd3602;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3757}, %fd1825;
	}
	setp.lt.s32 	%p1419, %r3757, 0;
	selp.b64 	%rd3603, %rd3601, %rd3602, %p1419;
	shl.b64 	%rd3604, %rd3603, 1;
	sub.s64 	%rd3605, %rd3604, %rd576;
	mov.b64 	%fd1826, %rd3605;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3758}, %fd1826;
	}
	setp.lt.s32 	%p1420, %r3758, 0;
	selp.b64 	%rd3606, %rd3604, %rd3605, %p1420;
	shl.b64 	%rd3607, %rd3606, 1;
	sub.s64 	%rd3608, %rd3607, %rd576;
	mov.b64 	%fd1827, %rd3608;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3759}, %fd1827;
	}
	setp.lt.s32 	%p1421, %r3759, 0;
	selp.b64 	%rd3609, %rd3607, %rd3608, %p1421;
	shl.b64 	%rd3610, %rd3609, 1;
	sub.s64 	%rd3611, %rd3610, %rd576;
	mov.b64 	%fd1828, %rd3611;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3760}, %fd1828;
	}
	setp.lt.s32 	%p1422, %r3760, 0;
	selp.b64 	%rd3612, %rd3610, %rd3611, %p1422;
	shl.b64 	%rd3613, %rd3612, 1;
	sub.s64 	%rd3614, %rd3613, %rd576;
	mov.b64 	%fd1829, %rd3614;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3761}, %fd1829;
	}
	setp.lt.s32 	%p1423, %r3761, 0;
	selp.b64 	%rd6388, %rd3613, %rd3614, %p1423;
	shl.b64 	%rd6385, %rd6388, 1;
	add.s32 	%r853, %r6219, -16;
	setp.gt.s32 	%p1424, %r6219, 15;
	mov.u32 	%r6219, %r853;
	@%p1424 bra 	$L__BB0_699;

$L__BB0_700:
	and.b64  	%rd591, %rd6388, 9223372036854775807;
	setp.eq.s64 	%p1425, %rd591, 0;
	mov.f64 	%fd3033, 0d0000000000000000;
	@%p1425 bra 	$L__BB0_702;

	mov.b64 	%fd1831, %rd591;
	mul.f64 	%fd1832, %fd1831, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3762}, %fd1832;
	}
	shr.u32 	%r3763, %r3762, 20;
	mov.u32 	%r3764, 55;
	sub.s32 	%r3765, %r3764, %r3763;
	sub.s32 	%r3766, %r6213, %r3765;
	shl.b64 	%rd3615, %rd591, %r3765;
	setp.lt.s32 	%p1426, %r3766, 1;
	mov.u32 	%r3767, 1;
	sub.s32 	%r3768, %r3767, %r3766;
	shr.u64 	%rd3616, %rd3615, %r3768;
	add.s32 	%r3769, %r3766, -1;
	cvt.u64.u32 	%rd3617, %r3769;
	shl.b64 	%rd3618, %rd3617, 52;
	add.s64 	%rd3619, %rd3618, %rd3615;
	selp.b64 	%rd3620, %rd3616, %rd3619, %p1426;
	mov.b64 	%fd3033, %rd3620;

$L__BB0_702:
	and.b32  	%r3770, %r830, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3771}, %fd3033;
	}
	or.b32  	%r3772, %r3771, %r3770;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3773, %temp}, %fd3033;
	}
	mov.b64 	%fd3034, {%r3773, %r3772};
	bra.uni 	$L__BB0_706;

$L__BB0_704:
	mov.f64 	%fd1833, 0d3FF0000000000000;
	add.rn.f64 	%fd3034, %fd380, %fd1833;

$L__BB0_706:
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 91 26
	add.s32 	%r6211, %r829, -1;
	setp.gt.s32 	%p1431, %r829, 1;
	@%p1431 bra 	$L__BB0_686;

$L__BB0_707:
	.loc	1 98 9, function_name $L__info_string3, inlined_at 1 249 17
	ld.global.u8 	%r3774, [%rd1206+60];
	ld.global.u8 	%r3775, [%rd1206+61];
	prmt.b32 	%r3776, %r3775, %r3774, 30212;
	ld.global.u8 	%r3777, [%rd1206+62];
	ld.global.u8 	%r3778, [%rd1206+63];
	prmt.b32 	%r3779, %r3778, %r3777, 30212;
	prmt.b32 	%r855, %r3779, %r3776, 4180;
	.loc	1 99 9, function_name $L__info_string3, inlined_at 1 249 17
	ld.global.u8 	%r3780, [%rd1206+64];
	ld.global.u8 	%r3781, [%rd1206+65];
	prmt.b32 	%r3782, %r3781, %r3780, 30212;
	ld.global.u8 	%r3783, [%rd1206+66];
	ld.global.u8 	%r3784, [%rd1206+67];
	prmt.b32 	%r3785, %r3784, %r3783, 30212;
	prmt.b32 	%r6293, %r3785, %r3782, 4180;
	.loc	1 97 30, function_name $L__info_string3, inlined_at 1 249 17
	.loc	1 53 5, function_name $L__info_string6, inlined_at 1 97 30
	add.s32 	%r3786, %r6293, 8;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 97 30
	cvt.rn.f64.s32 	%fd1834, %r3786;
	fma.rn.f64 	%fd392, %fd1834, 0d400921FB54442D18, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r857}, %fd392;
	}
	and.b32  	%r3787, %r857, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3788, %temp}, %fd392;
	}
	mov.b64 	%fd3036, {%r3788, %r3787};
	setp.gt.u32 	%p1432, %r3787, 2146435071;
	or.pred  	%p1434, %p1432, %p18;
	@%p1434 bra 	$L__BB0_724;
	bra.uni 	$L__BB0_708;

$L__BB0_724:
	.loc	1 0 9
	setp.le.f64 	%p1469, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1470, %fd3036, 0d7FF0000000000000;
	and.pred  	%p1471, %p1470, %p1469;
	@%p1471 bra 	$L__BB0_726;
	bra.uni 	$L__BB0_725;

$L__BB0_726:
	setp.eq.f64 	%p1472, %fd3036, 0d7FF0000000000000;
	selp.f64 	%fd3039, 0dFFF8000000000000, %fd392, %p1472;
	bra.uni 	$L__BB0_727;

$L__BB0_708:
	.loc	1 0 9
	mov.f64 	%fd3039, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_727;

	setp.ltu.f64 	%p1436, %fd3036, %fd3160;
	mov.f64 	%fd3039, %fd392;
	@%p1436 bra 	$L__BB0_727;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3789}, %fd3036;
	}
	shr.u32 	%r6221, %r3789, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3790}, %fd3160;
	}
	shr.u32 	%r6222, %r3790, 20;
	setp.ne.s32 	%p1437, %r6221, 0;
	@%p1437 bra 	$L__BB0_712;

	mul.f64 	%fd3036, %fd3036, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3791}, %fd3036;
	}
	shr.u32 	%r3792, %r3791, 20;
	add.s32 	%r6221, %r3792, -54;

$L__BB0_712:
	setp.ne.s32 	%p1438, %r6222, 0;
	mov.f64 	%fd3037, %fd3160;
	@%p1438 bra 	$L__BB0_714;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3793}, %fd2;
	}
	shr.u32 	%r3794, %r3793, 20;
	add.s32 	%r6222, %r3794, -54;
	mov.f64 	%fd3037, %fd2;

$L__BB0_714:
	mov.b64 	%rd3622, %fd3036;
	and.b64  	%rd3623, %rd3622, 4503599627370495;
	or.b64  	%rd6393, %rd3623, 4503599627370496;
	mov.b64 	%rd3624, %fd3037;
	and.b64  	%rd3625, %rd3624, 4503599627370495;
	or.b64  	%rd593, %rd3625, 4503599627370496;
	sub.s32 	%r6228, %r6221, %r6222;
	not.b32 	%r3795, %r6221;
	add.s32 	%r3796, %r6222, %r3795;
	max.s32 	%r3797, %r3796, -1;
	add.s32 	%r865, %r3797, %r6221;
	mov.u32 	%r3798, 2;
	sub.s32 	%r3799, %r3798, %r6222;
	add.s32 	%r3800, %r3799, %r865;
	and.b32  	%r6224, %r3800, 3;
	setp.eq.s32 	%p1439, %r6224, 0;
	@%p1439 bra 	$L__BB0_716;

$L__BB0_715:
	.pragma "nounroll";
	sub.s64 	%rd3626, %rd6393, %rd593;
	mov.b64 	%fd1836, %rd3626;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3801}, %fd1836;
	}
	setp.lt.s32 	%p1440, %r3801, 0;
	selp.b64 	%rd6396, %rd6393, %rd3626, %p1440;
	shl.b64 	%rd6393, %rd6396, 1;
	add.s32 	%r6228, %r6228, -1;
	add.s32 	%r6224, %r6224, -1;
	setp.ne.s32 	%p1441, %r6224, 0;
	@%p1441 bra 	$L__BB0_715;

$L__BB0_716:
	mov.u32 	%r3802, 1;
	sub.s32 	%r3803, %r3802, %r6222;
	add.s32 	%r3804, %r3803, %r865;
	setp.lt.u32 	%p1442, %r3804, 3;
	@%p1442 bra 	$L__BB0_721;

	not.b32 	%r3805, %r6228;
	max.s32 	%r3806, %r3805, -4;
	add.s32 	%r3807, %r6228, %r3806;
	add.s32 	%r872, %r3807, 4;
	shr.u32 	%r3808, %r872, 2;
	add.s32 	%r3809, %r3808, 1;
	and.b32  	%r6227, %r3809, 3;
	setp.eq.s32 	%p1443, %r6227, 0;
	@%p1443 bra 	$L__BB0_719;

$L__BB0_718:
	.pragma "nounroll";
	sub.s64 	%rd3628, %rd6393, %rd593;
	mov.b64 	%fd1837, %rd3628;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3810}, %fd1837;
	}
	setp.lt.s32 	%p1444, %r3810, 0;
	selp.b64 	%rd3629, %rd6393, %rd3628, %p1444;
	shl.b64 	%rd3630, %rd3629, 1;
	sub.s64 	%rd3631, %rd3630, %rd593;
	mov.b64 	%fd1838, %rd3631;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3811}, %fd1838;
	}
	setp.lt.s32 	%p1445, %r3811, 0;
	selp.b64 	%rd3632, %rd3630, %rd3631, %p1445;
	shl.b64 	%rd3633, %rd3632, 1;
	sub.s64 	%rd3634, %rd3633, %rd593;
	mov.b64 	%fd1839, %rd3634;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3812}, %fd1839;
	}
	setp.lt.s32 	%p1446, %r3812, 0;
	selp.b64 	%rd3635, %rd3633, %rd3634, %p1446;
	shl.b64 	%rd3636, %rd3635, 1;
	sub.s64 	%rd3637, %rd3636, %rd593;
	mov.b64 	%fd1840, %rd3637;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3813}, %fd1840;
	}
	setp.lt.s32 	%p1447, %r3813, 0;
	selp.b64 	%rd6396, %rd3636, %rd3637, %p1447;
	shl.b64 	%rd6393, %rd6396, 1;
	add.s32 	%r6228, %r6228, -4;
	add.s32 	%r6227, %r6227, -1;
	setp.ne.s32 	%p1448, %r6227, 0;
	@%p1448 bra 	$L__BB0_718;

$L__BB0_719:
	setp.lt.u32 	%p1449, %r872, 12;
	@%p1449 bra 	$L__BB0_721;

$L__BB0_720:
	sub.s64 	%rd3638, %rd6393, %rd593;
	mov.b64 	%fd1841, %rd3638;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3814}, %fd1841;
	}
	setp.lt.s32 	%p1450, %r3814, 0;
	selp.b64 	%rd3639, %rd6393, %rd3638, %p1450;
	shl.b64 	%rd3640, %rd3639, 1;
	sub.s64 	%rd3641, %rd3640, %rd593;
	mov.b64 	%fd1842, %rd3641;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3815}, %fd1842;
	}
	setp.lt.s32 	%p1451, %r3815, 0;
	selp.b64 	%rd3642, %rd3640, %rd3641, %p1451;
	shl.b64 	%rd3643, %rd3642, 1;
	sub.s64 	%rd3644, %rd3643, %rd593;
	mov.b64 	%fd1843, %rd3644;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3816}, %fd1843;
	}
	setp.lt.s32 	%p1452, %r3816, 0;
	selp.b64 	%rd3645, %rd3643, %rd3644, %p1452;
	shl.b64 	%rd3646, %rd3645, 1;
	sub.s64 	%rd3647, %rd3646, %rd593;
	mov.b64 	%fd1844, %rd3647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3817}, %fd1844;
	}
	setp.lt.s32 	%p1453, %r3817, 0;
	selp.b64 	%rd3648, %rd3646, %rd3647, %p1453;
	shl.b64 	%rd3649, %rd3648, 1;
	sub.s64 	%rd3650, %rd3649, %rd593;
	mov.b64 	%fd1845, %rd3650;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3818}, %fd1845;
	}
	setp.lt.s32 	%p1454, %r3818, 0;
	selp.b64 	%rd3651, %rd3649, %rd3650, %p1454;
	shl.b64 	%rd3652, %rd3651, 1;
	sub.s64 	%rd3653, %rd3652, %rd593;
	mov.b64 	%fd1846, %rd3653;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3819}, %fd1846;
	}
	setp.lt.s32 	%p1455, %r3819, 0;
	selp.b64 	%rd3654, %rd3652, %rd3653, %p1455;
	shl.b64 	%rd3655, %rd3654, 1;
	sub.s64 	%rd3656, %rd3655, %rd593;
	mov.b64 	%fd1847, %rd3656;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3820}, %fd1847;
	}
	setp.lt.s32 	%p1456, %r3820, 0;
	selp.b64 	%rd3657, %rd3655, %rd3656, %p1456;
	shl.b64 	%rd3658, %rd3657, 1;
	sub.s64 	%rd3659, %rd3658, %rd593;
	mov.b64 	%fd1848, %rd3659;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3821}, %fd1848;
	}
	setp.lt.s32 	%p1457, %r3821, 0;
	selp.b64 	%rd3660, %rd3658, %rd3659, %p1457;
	shl.b64 	%rd3661, %rd3660, 1;
	sub.s64 	%rd3662, %rd3661, %rd593;
	mov.b64 	%fd1849, %rd3662;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3822}, %fd1849;
	}
	setp.lt.s32 	%p1458, %r3822, 0;
	selp.b64 	%rd3663, %rd3661, %rd3662, %p1458;
	shl.b64 	%rd3664, %rd3663, 1;
	sub.s64 	%rd3665, %rd3664, %rd593;
	mov.b64 	%fd1850, %rd3665;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3823}, %fd1850;
	}
	setp.lt.s32 	%p1459, %r3823, 0;
	selp.b64 	%rd3666, %rd3664, %rd3665, %p1459;
	shl.b64 	%rd3667, %rd3666, 1;
	sub.s64 	%rd3668, %rd3667, %rd593;
	mov.b64 	%fd1851, %rd3668;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3824}, %fd1851;
	}
	setp.lt.s32 	%p1460, %r3824, 0;
	selp.b64 	%rd3669, %rd3667, %rd3668, %p1460;
	shl.b64 	%rd3670, %rd3669, 1;
	sub.s64 	%rd3671, %rd3670, %rd593;
	mov.b64 	%fd1852, %rd3671;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3825}, %fd1852;
	}
	setp.lt.s32 	%p1461, %r3825, 0;
	selp.b64 	%rd3672, %rd3670, %rd3671, %p1461;
	shl.b64 	%rd3673, %rd3672, 1;
	sub.s64 	%rd3674, %rd3673, %rd593;
	mov.b64 	%fd1853, %rd3674;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3826}, %fd1853;
	}
	setp.lt.s32 	%p1462, %r3826, 0;
	selp.b64 	%rd3675, %rd3673, %rd3674, %p1462;
	shl.b64 	%rd3676, %rd3675, 1;
	sub.s64 	%rd3677, %rd3676, %rd593;
	mov.b64 	%fd1854, %rd3677;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3827}, %fd1854;
	}
	setp.lt.s32 	%p1463, %r3827, 0;
	selp.b64 	%rd3678, %rd3676, %rd3677, %p1463;
	shl.b64 	%rd3679, %rd3678, 1;
	sub.s64 	%rd3680, %rd3679, %rd593;
	mov.b64 	%fd1855, %rd3680;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3828}, %fd1855;
	}
	setp.lt.s32 	%p1464, %r3828, 0;
	selp.b64 	%rd3681, %rd3679, %rd3680, %p1464;
	shl.b64 	%rd3682, %rd3681, 1;
	sub.s64 	%rd3683, %rd3682, %rd593;
	mov.b64 	%fd1856, %rd3683;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3829}, %fd1856;
	}
	setp.lt.s32 	%p1465, %r3829, 0;
	selp.b64 	%rd6396, %rd3682, %rd3683, %p1465;
	shl.b64 	%rd6393, %rd6396, 1;
	add.s32 	%r880, %r6228, -16;
	setp.gt.s32 	%p1466, %r6228, 15;
	mov.u32 	%r6228, %r880;
	@%p1466 bra 	$L__BB0_720;

$L__BB0_721:
	and.b64  	%rd608, %rd6396, 9223372036854775807;
	setp.eq.s64 	%p1467, %rd608, 0;
	mov.f64 	%fd3038, 0d0000000000000000;
	@%p1467 bra 	$L__BB0_723;

	mov.b64 	%fd1858, %rd608;
	mul.f64 	%fd1859, %fd1858, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3830}, %fd1859;
	}
	shr.u32 	%r3831, %r3830, 20;
	mov.u32 	%r3832, 55;
	sub.s32 	%r3833, %r3832, %r3831;
	sub.s32 	%r3834, %r6222, %r3833;
	shl.b64 	%rd3684, %rd608, %r3833;
	setp.lt.s32 	%p1468, %r3834, 1;
	mov.u32 	%r3835, 1;
	sub.s32 	%r3836, %r3835, %r3834;
	shr.u64 	%rd3685, %rd3684, %r3836;
	add.s32 	%r3837, %r3834, -1;
	cvt.u64.u32 	%rd3686, %r3837;
	shl.b64 	%rd3687, %rd3686, 52;
	add.s64 	%rd3688, %rd3687, %rd3684;
	selp.b64 	%rd3689, %rd3685, %rd3688, %p1468;
	mov.b64 	%fd3038, %rd3689;

$L__BB0_723:
	and.b32  	%r3838, %r857, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3839}, %fd3038;
	}
	or.b32  	%r3840, %r3839, %r3838;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3841, %temp}, %fd3038;
	}
	mov.b64 	%fd3039, {%r3841, %r3840};
	bra.uni 	$L__BB0_727;

$L__BB0_725:
	mov.f64 	%fd1860, 0d3FF0000000000000;
	add.rn.f64 	%fd3039, %fd392, %fd1860;

$L__BB0_727:
	mov.f64 	%fd1861, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1862, %fd1861, %fd3039;
	mul.f64 	%fd1863, %fd1862, %fd15;
	mul.f64 	%fd1864, %fd1863, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 97 30
	add.s32 	%r3842, %r6293, 7;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 97 30
	cvt.rn.f64.s32 	%fd1865, %r3842;
	fma.rn.f64 	%fd403, %fd1865, 0d400921FB54442D18, %fd1864;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r881}, %fd403;
	}
	and.b32  	%r3843, %r881, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3844, %temp}, %fd403;
	}
	mov.b64 	%fd3040, {%r3844, %r3843};
	setp.gt.u32 	%p1473, %r3843, 2146435071;
	or.pred  	%p1475, %p1473, %p18;
	@%p1475 bra 	$L__BB0_744;
	bra.uni 	$L__BB0_728;

$L__BB0_744:
	.loc	1 0 9
	setp.le.f64 	%p1510, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1511, %fd3040, 0d7FF0000000000000;
	and.pred  	%p1512, %p1511, %p1510;
	@%p1512 bra 	$L__BB0_746;
	bra.uni 	$L__BB0_745;

$L__BB0_746:
	setp.eq.f64 	%p1513, %fd3040, 0d7FF0000000000000;
	selp.f64 	%fd3043, 0dFFF8000000000000, %fd403, %p1513;
	bra.uni 	$L__BB0_747;

$L__BB0_728:
	.loc	1 0 9
	mov.f64 	%fd3043, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_747;

	setp.ltu.f64 	%p1477, %fd3040, %fd3160;
	mov.f64 	%fd3043, %fd403;
	@%p1477 bra 	$L__BB0_747;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3845}, %fd3040;
	}
	shr.u32 	%r6230, %r3845, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3846}, %fd3160;
	}
	shr.u32 	%r6231, %r3846, 20;
	setp.ne.s32 	%p1478, %r6230, 0;
	@%p1478 bra 	$L__BB0_732;

	mul.f64 	%fd3040, %fd3040, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3847}, %fd3040;
	}
	shr.u32 	%r3848, %r3847, 20;
	add.s32 	%r6230, %r3848, -54;

$L__BB0_732:
	setp.ne.s32 	%p1479, %r6231, 0;
	mov.f64 	%fd3041, %fd3160;
	@%p1479 bra 	$L__BB0_734;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3849}, %fd2;
	}
	shr.u32 	%r3850, %r3849, 20;
	add.s32 	%r6231, %r3850, -54;
	mov.f64 	%fd3041, %fd2;

$L__BB0_734:
	mov.b64 	%rd3691, %fd3040;
	and.b64  	%rd3692, %rd3691, 4503599627370495;
	or.b64  	%rd6401, %rd3692, 4503599627370496;
	mov.b64 	%rd3693, %fd3041;
	and.b64  	%rd3694, %rd3693, 4503599627370495;
	or.b64  	%rd610, %rd3694, 4503599627370496;
	sub.s32 	%r6237, %r6230, %r6231;
	not.b32 	%r3851, %r6230;
	add.s32 	%r3852, %r6231, %r3851;
	max.s32 	%r3853, %r3852, -1;
	add.s32 	%r889, %r3853, %r6230;
	mov.u32 	%r3854, 2;
	sub.s32 	%r3855, %r3854, %r6231;
	add.s32 	%r3856, %r3855, %r889;
	and.b32  	%r6233, %r3856, 3;
	setp.eq.s32 	%p1480, %r6233, 0;
	@%p1480 bra 	$L__BB0_736;

$L__BB0_735:
	.pragma "nounroll";
	sub.s64 	%rd3695, %rd6401, %rd610;
	mov.b64 	%fd1867, %rd3695;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3857}, %fd1867;
	}
	setp.lt.s32 	%p1481, %r3857, 0;
	selp.b64 	%rd6404, %rd6401, %rd3695, %p1481;
	shl.b64 	%rd6401, %rd6404, 1;
	add.s32 	%r6237, %r6237, -1;
	add.s32 	%r6233, %r6233, -1;
	setp.ne.s32 	%p1482, %r6233, 0;
	@%p1482 bra 	$L__BB0_735;

$L__BB0_736:
	mov.u32 	%r3858, 1;
	sub.s32 	%r3859, %r3858, %r6231;
	add.s32 	%r3860, %r3859, %r889;
	setp.lt.u32 	%p1483, %r3860, 3;
	@%p1483 bra 	$L__BB0_741;

	not.b32 	%r3861, %r6237;
	max.s32 	%r3862, %r3861, -4;
	add.s32 	%r3863, %r6237, %r3862;
	add.s32 	%r896, %r3863, 4;
	shr.u32 	%r3864, %r896, 2;
	add.s32 	%r3865, %r3864, 1;
	and.b32  	%r6236, %r3865, 3;
	setp.eq.s32 	%p1484, %r6236, 0;
	@%p1484 bra 	$L__BB0_739;

$L__BB0_738:
	.pragma "nounroll";
	sub.s64 	%rd3697, %rd6401, %rd610;
	mov.b64 	%fd1868, %rd3697;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3866}, %fd1868;
	}
	setp.lt.s32 	%p1485, %r3866, 0;
	selp.b64 	%rd3698, %rd6401, %rd3697, %p1485;
	shl.b64 	%rd3699, %rd3698, 1;
	sub.s64 	%rd3700, %rd3699, %rd610;
	mov.b64 	%fd1869, %rd3700;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3867}, %fd1869;
	}
	setp.lt.s32 	%p1486, %r3867, 0;
	selp.b64 	%rd3701, %rd3699, %rd3700, %p1486;
	shl.b64 	%rd3702, %rd3701, 1;
	sub.s64 	%rd3703, %rd3702, %rd610;
	mov.b64 	%fd1870, %rd3703;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3868}, %fd1870;
	}
	setp.lt.s32 	%p1487, %r3868, 0;
	selp.b64 	%rd3704, %rd3702, %rd3703, %p1487;
	shl.b64 	%rd3705, %rd3704, 1;
	sub.s64 	%rd3706, %rd3705, %rd610;
	mov.b64 	%fd1871, %rd3706;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3869}, %fd1871;
	}
	setp.lt.s32 	%p1488, %r3869, 0;
	selp.b64 	%rd6404, %rd3705, %rd3706, %p1488;
	shl.b64 	%rd6401, %rd6404, 1;
	add.s32 	%r6237, %r6237, -4;
	add.s32 	%r6236, %r6236, -1;
	setp.ne.s32 	%p1489, %r6236, 0;
	@%p1489 bra 	$L__BB0_738;

$L__BB0_739:
	setp.lt.u32 	%p1490, %r896, 12;
	@%p1490 bra 	$L__BB0_741;

$L__BB0_740:
	sub.s64 	%rd3707, %rd6401, %rd610;
	mov.b64 	%fd1872, %rd3707;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3870}, %fd1872;
	}
	setp.lt.s32 	%p1491, %r3870, 0;
	selp.b64 	%rd3708, %rd6401, %rd3707, %p1491;
	shl.b64 	%rd3709, %rd3708, 1;
	sub.s64 	%rd3710, %rd3709, %rd610;
	mov.b64 	%fd1873, %rd3710;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3871}, %fd1873;
	}
	setp.lt.s32 	%p1492, %r3871, 0;
	selp.b64 	%rd3711, %rd3709, %rd3710, %p1492;
	shl.b64 	%rd3712, %rd3711, 1;
	sub.s64 	%rd3713, %rd3712, %rd610;
	mov.b64 	%fd1874, %rd3713;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3872}, %fd1874;
	}
	setp.lt.s32 	%p1493, %r3872, 0;
	selp.b64 	%rd3714, %rd3712, %rd3713, %p1493;
	shl.b64 	%rd3715, %rd3714, 1;
	sub.s64 	%rd3716, %rd3715, %rd610;
	mov.b64 	%fd1875, %rd3716;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3873}, %fd1875;
	}
	setp.lt.s32 	%p1494, %r3873, 0;
	selp.b64 	%rd3717, %rd3715, %rd3716, %p1494;
	shl.b64 	%rd3718, %rd3717, 1;
	sub.s64 	%rd3719, %rd3718, %rd610;
	mov.b64 	%fd1876, %rd3719;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3874}, %fd1876;
	}
	setp.lt.s32 	%p1495, %r3874, 0;
	selp.b64 	%rd3720, %rd3718, %rd3719, %p1495;
	shl.b64 	%rd3721, %rd3720, 1;
	sub.s64 	%rd3722, %rd3721, %rd610;
	mov.b64 	%fd1877, %rd3722;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3875}, %fd1877;
	}
	setp.lt.s32 	%p1496, %r3875, 0;
	selp.b64 	%rd3723, %rd3721, %rd3722, %p1496;
	shl.b64 	%rd3724, %rd3723, 1;
	sub.s64 	%rd3725, %rd3724, %rd610;
	mov.b64 	%fd1878, %rd3725;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3876}, %fd1878;
	}
	setp.lt.s32 	%p1497, %r3876, 0;
	selp.b64 	%rd3726, %rd3724, %rd3725, %p1497;
	shl.b64 	%rd3727, %rd3726, 1;
	sub.s64 	%rd3728, %rd3727, %rd610;
	mov.b64 	%fd1879, %rd3728;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3877}, %fd1879;
	}
	setp.lt.s32 	%p1498, %r3877, 0;
	selp.b64 	%rd3729, %rd3727, %rd3728, %p1498;
	shl.b64 	%rd3730, %rd3729, 1;
	sub.s64 	%rd3731, %rd3730, %rd610;
	mov.b64 	%fd1880, %rd3731;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3878}, %fd1880;
	}
	setp.lt.s32 	%p1499, %r3878, 0;
	selp.b64 	%rd3732, %rd3730, %rd3731, %p1499;
	shl.b64 	%rd3733, %rd3732, 1;
	sub.s64 	%rd3734, %rd3733, %rd610;
	mov.b64 	%fd1881, %rd3734;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3879}, %fd1881;
	}
	setp.lt.s32 	%p1500, %r3879, 0;
	selp.b64 	%rd3735, %rd3733, %rd3734, %p1500;
	shl.b64 	%rd3736, %rd3735, 1;
	sub.s64 	%rd3737, %rd3736, %rd610;
	mov.b64 	%fd1882, %rd3737;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3880}, %fd1882;
	}
	setp.lt.s32 	%p1501, %r3880, 0;
	selp.b64 	%rd3738, %rd3736, %rd3737, %p1501;
	shl.b64 	%rd3739, %rd3738, 1;
	sub.s64 	%rd3740, %rd3739, %rd610;
	mov.b64 	%fd1883, %rd3740;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3881}, %fd1883;
	}
	setp.lt.s32 	%p1502, %r3881, 0;
	selp.b64 	%rd3741, %rd3739, %rd3740, %p1502;
	shl.b64 	%rd3742, %rd3741, 1;
	sub.s64 	%rd3743, %rd3742, %rd610;
	mov.b64 	%fd1884, %rd3743;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3882}, %fd1884;
	}
	setp.lt.s32 	%p1503, %r3882, 0;
	selp.b64 	%rd3744, %rd3742, %rd3743, %p1503;
	shl.b64 	%rd3745, %rd3744, 1;
	sub.s64 	%rd3746, %rd3745, %rd610;
	mov.b64 	%fd1885, %rd3746;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3883}, %fd1885;
	}
	setp.lt.s32 	%p1504, %r3883, 0;
	selp.b64 	%rd3747, %rd3745, %rd3746, %p1504;
	shl.b64 	%rd3748, %rd3747, 1;
	sub.s64 	%rd3749, %rd3748, %rd610;
	mov.b64 	%fd1886, %rd3749;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3884}, %fd1886;
	}
	setp.lt.s32 	%p1505, %r3884, 0;
	selp.b64 	%rd3750, %rd3748, %rd3749, %p1505;
	shl.b64 	%rd3751, %rd3750, 1;
	sub.s64 	%rd3752, %rd3751, %rd610;
	mov.b64 	%fd1887, %rd3752;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3885}, %fd1887;
	}
	setp.lt.s32 	%p1506, %r3885, 0;
	selp.b64 	%rd6404, %rd3751, %rd3752, %p1506;
	shl.b64 	%rd6401, %rd6404, 1;
	add.s32 	%r904, %r6237, -16;
	setp.gt.s32 	%p1507, %r6237, 15;
	mov.u32 	%r6237, %r904;
	@%p1507 bra 	$L__BB0_740;

$L__BB0_741:
	and.b64  	%rd625, %rd6404, 9223372036854775807;
	setp.eq.s64 	%p1508, %rd625, 0;
	mov.f64 	%fd3042, 0d0000000000000000;
	@%p1508 bra 	$L__BB0_743;

	mov.b64 	%fd1889, %rd625;
	mul.f64 	%fd1890, %fd1889, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3886}, %fd1890;
	}
	shr.u32 	%r3887, %r3886, 20;
	mov.u32 	%r3888, 55;
	sub.s32 	%r3889, %r3888, %r3887;
	sub.s32 	%r3890, %r6231, %r3889;
	shl.b64 	%rd3753, %rd625, %r3889;
	setp.lt.s32 	%p1509, %r3890, 1;
	mov.u32 	%r3891, 1;
	sub.s32 	%r3892, %r3891, %r3890;
	shr.u64 	%rd3754, %rd3753, %r3892;
	add.s32 	%r3893, %r3890, -1;
	cvt.u64.u32 	%rd3755, %r3893;
	shl.b64 	%rd3756, %rd3755, 52;
	add.s64 	%rd3757, %rd3756, %rd3753;
	selp.b64 	%rd3758, %rd3754, %rd3757, %p1509;
	mov.b64 	%fd3042, %rd3758;

$L__BB0_743:
	and.b32  	%r3894, %r881, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3895}, %fd3042;
	}
	or.b32  	%r3896, %r3895, %r3894;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3897, %temp}, %fd3042;
	}
	mov.b64 	%fd3043, {%r3897, %r3896};
	bra.uni 	$L__BB0_747;

$L__BB0_745:
	mov.f64 	%fd1891, 0d3FF0000000000000;
	add.rn.f64 	%fd3043, %fd403, %fd1891;

$L__BB0_747:
	mov.f64 	%fd1892, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1893, %fd1892, %fd3043;
	mul.f64 	%fd1894, %fd1893, %fd27;
	mul.f64 	%fd1895, %fd1894, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 97 30
	add.s32 	%r3898, %r6293, 6;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 97 30
	cvt.rn.f64.s32 	%fd1896, %r3898;
	fma.rn.f64 	%fd414, %fd1896, 0d400921FB54442D18, %fd1895;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r905}, %fd414;
	}
	and.b32  	%r3899, %r905, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3900, %temp}, %fd414;
	}
	mov.b64 	%fd3044, {%r3900, %r3899};
	setp.gt.u32 	%p1514, %r3899, 2146435071;
	or.pred  	%p1516, %p1514, %p18;
	@%p1516 bra 	$L__BB0_764;
	bra.uni 	$L__BB0_748;

$L__BB0_764:
	.loc	1 0 9
	setp.le.f64 	%p1551, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1552, %fd3044, 0d7FF0000000000000;
	and.pred  	%p1553, %p1552, %p1551;
	@%p1553 bra 	$L__BB0_766;
	bra.uni 	$L__BB0_765;

$L__BB0_766:
	setp.eq.f64 	%p1554, %fd3044, 0d7FF0000000000000;
	selp.f64 	%fd3047, 0dFFF8000000000000, %fd414, %p1554;
	bra.uni 	$L__BB0_767;

$L__BB0_748:
	.loc	1 0 9
	mov.f64 	%fd3047, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_767;

	setp.ltu.f64 	%p1518, %fd3044, %fd3160;
	mov.f64 	%fd3047, %fd414;
	@%p1518 bra 	$L__BB0_767;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3901}, %fd3044;
	}
	shr.u32 	%r6239, %r3901, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3902}, %fd3160;
	}
	shr.u32 	%r6240, %r3902, 20;
	setp.ne.s32 	%p1519, %r6239, 0;
	@%p1519 bra 	$L__BB0_752;

	mul.f64 	%fd3044, %fd3044, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3903}, %fd3044;
	}
	shr.u32 	%r3904, %r3903, 20;
	add.s32 	%r6239, %r3904, -54;

$L__BB0_752:
	setp.ne.s32 	%p1520, %r6240, 0;
	mov.f64 	%fd3045, %fd3160;
	@%p1520 bra 	$L__BB0_754;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3905}, %fd2;
	}
	shr.u32 	%r3906, %r3905, 20;
	add.s32 	%r6240, %r3906, -54;
	mov.f64 	%fd3045, %fd2;

$L__BB0_754:
	mov.b64 	%rd3760, %fd3044;
	and.b64  	%rd3761, %rd3760, 4503599627370495;
	or.b64  	%rd6409, %rd3761, 4503599627370496;
	mov.b64 	%rd3762, %fd3045;
	and.b64  	%rd3763, %rd3762, 4503599627370495;
	or.b64  	%rd627, %rd3763, 4503599627370496;
	sub.s32 	%r6246, %r6239, %r6240;
	not.b32 	%r3907, %r6239;
	add.s32 	%r3908, %r6240, %r3907;
	max.s32 	%r3909, %r3908, -1;
	add.s32 	%r913, %r3909, %r6239;
	mov.u32 	%r3910, 2;
	sub.s32 	%r3911, %r3910, %r6240;
	add.s32 	%r3912, %r3911, %r913;
	and.b32  	%r6242, %r3912, 3;
	setp.eq.s32 	%p1521, %r6242, 0;
	@%p1521 bra 	$L__BB0_756;

$L__BB0_755:
	.pragma "nounroll";
	sub.s64 	%rd3764, %rd6409, %rd627;
	mov.b64 	%fd1898, %rd3764;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3913}, %fd1898;
	}
	setp.lt.s32 	%p1522, %r3913, 0;
	selp.b64 	%rd6412, %rd6409, %rd3764, %p1522;
	shl.b64 	%rd6409, %rd6412, 1;
	add.s32 	%r6246, %r6246, -1;
	add.s32 	%r6242, %r6242, -1;
	setp.ne.s32 	%p1523, %r6242, 0;
	@%p1523 bra 	$L__BB0_755;

$L__BB0_756:
	mov.u32 	%r3914, 1;
	sub.s32 	%r3915, %r3914, %r6240;
	add.s32 	%r3916, %r3915, %r913;
	setp.lt.u32 	%p1524, %r3916, 3;
	@%p1524 bra 	$L__BB0_761;

	not.b32 	%r3917, %r6246;
	max.s32 	%r3918, %r3917, -4;
	add.s32 	%r3919, %r6246, %r3918;
	add.s32 	%r920, %r3919, 4;
	shr.u32 	%r3920, %r920, 2;
	add.s32 	%r3921, %r3920, 1;
	and.b32  	%r6245, %r3921, 3;
	setp.eq.s32 	%p1525, %r6245, 0;
	@%p1525 bra 	$L__BB0_759;

$L__BB0_758:
	.pragma "nounroll";
	sub.s64 	%rd3766, %rd6409, %rd627;
	mov.b64 	%fd1899, %rd3766;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3922}, %fd1899;
	}
	setp.lt.s32 	%p1526, %r3922, 0;
	selp.b64 	%rd3767, %rd6409, %rd3766, %p1526;
	shl.b64 	%rd3768, %rd3767, 1;
	sub.s64 	%rd3769, %rd3768, %rd627;
	mov.b64 	%fd1900, %rd3769;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3923}, %fd1900;
	}
	setp.lt.s32 	%p1527, %r3923, 0;
	selp.b64 	%rd3770, %rd3768, %rd3769, %p1527;
	shl.b64 	%rd3771, %rd3770, 1;
	sub.s64 	%rd3772, %rd3771, %rd627;
	mov.b64 	%fd1901, %rd3772;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3924}, %fd1901;
	}
	setp.lt.s32 	%p1528, %r3924, 0;
	selp.b64 	%rd3773, %rd3771, %rd3772, %p1528;
	shl.b64 	%rd3774, %rd3773, 1;
	sub.s64 	%rd3775, %rd3774, %rd627;
	mov.b64 	%fd1902, %rd3775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3925}, %fd1902;
	}
	setp.lt.s32 	%p1529, %r3925, 0;
	selp.b64 	%rd6412, %rd3774, %rd3775, %p1529;
	shl.b64 	%rd6409, %rd6412, 1;
	add.s32 	%r6246, %r6246, -4;
	add.s32 	%r6245, %r6245, -1;
	setp.ne.s32 	%p1530, %r6245, 0;
	@%p1530 bra 	$L__BB0_758;

$L__BB0_759:
	setp.lt.u32 	%p1531, %r920, 12;
	@%p1531 bra 	$L__BB0_761;

$L__BB0_760:
	sub.s64 	%rd3776, %rd6409, %rd627;
	mov.b64 	%fd1903, %rd3776;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3926}, %fd1903;
	}
	setp.lt.s32 	%p1532, %r3926, 0;
	selp.b64 	%rd3777, %rd6409, %rd3776, %p1532;
	shl.b64 	%rd3778, %rd3777, 1;
	sub.s64 	%rd3779, %rd3778, %rd627;
	mov.b64 	%fd1904, %rd3779;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3927}, %fd1904;
	}
	setp.lt.s32 	%p1533, %r3927, 0;
	selp.b64 	%rd3780, %rd3778, %rd3779, %p1533;
	shl.b64 	%rd3781, %rd3780, 1;
	sub.s64 	%rd3782, %rd3781, %rd627;
	mov.b64 	%fd1905, %rd3782;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3928}, %fd1905;
	}
	setp.lt.s32 	%p1534, %r3928, 0;
	selp.b64 	%rd3783, %rd3781, %rd3782, %p1534;
	shl.b64 	%rd3784, %rd3783, 1;
	sub.s64 	%rd3785, %rd3784, %rd627;
	mov.b64 	%fd1906, %rd3785;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3929}, %fd1906;
	}
	setp.lt.s32 	%p1535, %r3929, 0;
	selp.b64 	%rd3786, %rd3784, %rd3785, %p1535;
	shl.b64 	%rd3787, %rd3786, 1;
	sub.s64 	%rd3788, %rd3787, %rd627;
	mov.b64 	%fd1907, %rd3788;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3930}, %fd1907;
	}
	setp.lt.s32 	%p1536, %r3930, 0;
	selp.b64 	%rd3789, %rd3787, %rd3788, %p1536;
	shl.b64 	%rd3790, %rd3789, 1;
	sub.s64 	%rd3791, %rd3790, %rd627;
	mov.b64 	%fd1908, %rd3791;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3931}, %fd1908;
	}
	setp.lt.s32 	%p1537, %r3931, 0;
	selp.b64 	%rd3792, %rd3790, %rd3791, %p1537;
	shl.b64 	%rd3793, %rd3792, 1;
	sub.s64 	%rd3794, %rd3793, %rd627;
	mov.b64 	%fd1909, %rd3794;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3932}, %fd1909;
	}
	setp.lt.s32 	%p1538, %r3932, 0;
	selp.b64 	%rd3795, %rd3793, %rd3794, %p1538;
	shl.b64 	%rd3796, %rd3795, 1;
	sub.s64 	%rd3797, %rd3796, %rd627;
	mov.b64 	%fd1910, %rd3797;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3933}, %fd1910;
	}
	setp.lt.s32 	%p1539, %r3933, 0;
	selp.b64 	%rd3798, %rd3796, %rd3797, %p1539;
	shl.b64 	%rd3799, %rd3798, 1;
	sub.s64 	%rd3800, %rd3799, %rd627;
	mov.b64 	%fd1911, %rd3800;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3934}, %fd1911;
	}
	setp.lt.s32 	%p1540, %r3934, 0;
	selp.b64 	%rd3801, %rd3799, %rd3800, %p1540;
	shl.b64 	%rd3802, %rd3801, 1;
	sub.s64 	%rd3803, %rd3802, %rd627;
	mov.b64 	%fd1912, %rd3803;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3935}, %fd1912;
	}
	setp.lt.s32 	%p1541, %r3935, 0;
	selp.b64 	%rd3804, %rd3802, %rd3803, %p1541;
	shl.b64 	%rd3805, %rd3804, 1;
	sub.s64 	%rd3806, %rd3805, %rd627;
	mov.b64 	%fd1913, %rd3806;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3936}, %fd1913;
	}
	setp.lt.s32 	%p1542, %r3936, 0;
	selp.b64 	%rd3807, %rd3805, %rd3806, %p1542;
	shl.b64 	%rd3808, %rd3807, 1;
	sub.s64 	%rd3809, %rd3808, %rd627;
	mov.b64 	%fd1914, %rd3809;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3937}, %fd1914;
	}
	setp.lt.s32 	%p1543, %r3937, 0;
	selp.b64 	%rd3810, %rd3808, %rd3809, %p1543;
	shl.b64 	%rd3811, %rd3810, 1;
	sub.s64 	%rd3812, %rd3811, %rd627;
	mov.b64 	%fd1915, %rd3812;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3938}, %fd1915;
	}
	setp.lt.s32 	%p1544, %r3938, 0;
	selp.b64 	%rd3813, %rd3811, %rd3812, %p1544;
	shl.b64 	%rd3814, %rd3813, 1;
	sub.s64 	%rd3815, %rd3814, %rd627;
	mov.b64 	%fd1916, %rd3815;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3939}, %fd1916;
	}
	setp.lt.s32 	%p1545, %r3939, 0;
	selp.b64 	%rd3816, %rd3814, %rd3815, %p1545;
	shl.b64 	%rd3817, %rd3816, 1;
	sub.s64 	%rd3818, %rd3817, %rd627;
	mov.b64 	%fd1917, %rd3818;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3940}, %fd1917;
	}
	setp.lt.s32 	%p1546, %r3940, 0;
	selp.b64 	%rd3819, %rd3817, %rd3818, %p1546;
	shl.b64 	%rd3820, %rd3819, 1;
	sub.s64 	%rd3821, %rd3820, %rd627;
	mov.b64 	%fd1918, %rd3821;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3941}, %fd1918;
	}
	setp.lt.s32 	%p1547, %r3941, 0;
	selp.b64 	%rd6412, %rd3820, %rd3821, %p1547;
	shl.b64 	%rd6409, %rd6412, 1;
	add.s32 	%r928, %r6246, -16;
	setp.gt.s32 	%p1548, %r6246, 15;
	mov.u32 	%r6246, %r928;
	@%p1548 bra 	$L__BB0_760;

$L__BB0_761:
	and.b64  	%rd642, %rd6412, 9223372036854775807;
	setp.eq.s64 	%p1549, %rd642, 0;
	mov.f64 	%fd3046, 0d0000000000000000;
	@%p1549 bra 	$L__BB0_763;

	mov.b64 	%fd1920, %rd642;
	mul.f64 	%fd1921, %fd1920, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3942}, %fd1921;
	}
	shr.u32 	%r3943, %r3942, 20;
	mov.u32 	%r3944, 55;
	sub.s32 	%r3945, %r3944, %r3943;
	sub.s32 	%r3946, %r6240, %r3945;
	shl.b64 	%rd3822, %rd642, %r3945;
	setp.lt.s32 	%p1550, %r3946, 1;
	mov.u32 	%r3947, 1;
	sub.s32 	%r3948, %r3947, %r3946;
	shr.u64 	%rd3823, %rd3822, %r3948;
	add.s32 	%r3949, %r3946, -1;
	cvt.u64.u32 	%rd3824, %r3949;
	shl.b64 	%rd3825, %rd3824, 52;
	add.s64 	%rd3826, %rd3825, %rd3822;
	selp.b64 	%rd3827, %rd3823, %rd3826, %p1550;
	mov.b64 	%fd3046, %rd3827;

$L__BB0_763:
	and.b32  	%r3950, %r905, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3951}, %fd3046;
	}
	or.b32  	%r3952, %r3951, %r3950;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3953, %temp}, %fd3046;
	}
	mov.b64 	%fd3047, {%r3953, %r3952};
	bra.uni 	$L__BB0_767;

$L__BB0_765:
	mov.f64 	%fd1922, 0d3FF0000000000000;
	add.rn.f64 	%fd3047, %fd414, %fd1922;

$L__BB0_767:
	mov.f64 	%fd1923, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1924, %fd1923, %fd3047;
	mul.f64 	%fd1925, %fd1924, %fd39;
	mul.f64 	%fd1926, %fd1925, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 97 30
	add.s32 	%r3954, %r6293, 5;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 97 30
	cvt.rn.f64.s32 	%fd1927, %r3954;
	fma.rn.f64 	%fd425, %fd1927, 0d400921FB54442D18, %fd1926;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r929}, %fd425;
	}
	and.b32  	%r3955, %r929, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3956, %temp}, %fd425;
	}
	mov.b64 	%fd3048, {%r3956, %r3955};
	setp.gt.u32 	%p1555, %r3955, 2146435071;
	or.pred  	%p1557, %p1555, %p18;
	@%p1557 bra 	$L__BB0_784;
	bra.uni 	$L__BB0_768;

$L__BB0_784:
	.loc	1 0 9
	setp.le.f64 	%p1592, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1593, %fd3048, 0d7FF0000000000000;
	and.pred  	%p1594, %p1593, %p1592;
	@%p1594 bra 	$L__BB0_786;
	bra.uni 	$L__BB0_785;

$L__BB0_786:
	setp.eq.f64 	%p1595, %fd3048, 0d7FF0000000000000;
	selp.f64 	%fd3051, 0dFFF8000000000000, %fd425, %p1595;
	bra.uni 	$L__BB0_787;

$L__BB0_768:
	.loc	1 0 9
	mov.f64 	%fd3051, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_787;

	setp.ltu.f64 	%p1559, %fd3048, %fd3160;
	mov.f64 	%fd3051, %fd425;
	@%p1559 bra 	$L__BB0_787;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3957}, %fd3048;
	}
	shr.u32 	%r6248, %r3957, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3958}, %fd3160;
	}
	shr.u32 	%r6249, %r3958, 20;
	setp.ne.s32 	%p1560, %r6248, 0;
	@%p1560 bra 	$L__BB0_772;

	mul.f64 	%fd3048, %fd3048, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3959}, %fd3048;
	}
	shr.u32 	%r3960, %r3959, 20;
	add.s32 	%r6248, %r3960, -54;

$L__BB0_772:
	setp.ne.s32 	%p1561, %r6249, 0;
	mov.f64 	%fd3049, %fd3160;
	@%p1561 bra 	$L__BB0_774;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3961}, %fd2;
	}
	shr.u32 	%r3962, %r3961, 20;
	add.s32 	%r6249, %r3962, -54;
	mov.f64 	%fd3049, %fd2;

$L__BB0_774:
	mov.b64 	%rd3829, %fd3048;
	and.b64  	%rd3830, %rd3829, 4503599627370495;
	or.b64  	%rd6417, %rd3830, 4503599627370496;
	mov.b64 	%rd3831, %fd3049;
	and.b64  	%rd3832, %rd3831, 4503599627370495;
	or.b64  	%rd644, %rd3832, 4503599627370496;
	sub.s32 	%r6255, %r6248, %r6249;
	not.b32 	%r3963, %r6248;
	add.s32 	%r3964, %r6249, %r3963;
	max.s32 	%r3965, %r3964, -1;
	add.s32 	%r937, %r3965, %r6248;
	mov.u32 	%r3966, 2;
	sub.s32 	%r3967, %r3966, %r6249;
	add.s32 	%r3968, %r3967, %r937;
	and.b32  	%r6251, %r3968, 3;
	setp.eq.s32 	%p1562, %r6251, 0;
	@%p1562 bra 	$L__BB0_776;

$L__BB0_775:
	.pragma "nounroll";
	sub.s64 	%rd3833, %rd6417, %rd644;
	mov.b64 	%fd1929, %rd3833;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3969}, %fd1929;
	}
	setp.lt.s32 	%p1563, %r3969, 0;
	selp.b64 	%rd6420, %rd6417, %rd3833, %p1563;
	shl.b64 	%rd6417, %rd6420, 1;
	add.s32 	%r6255, %r6255, -1;
	add.s32 	%r6251, %r6251, -1;
	setp.ne.s32 	%p1564, %r6251, 0;
	@%p1564 bra 	$L__BB0_775;

$L__BB0_776:
	mov.u32 	%r3970, 1;
	sub.s32 	%r3971, %r3970, %r6249;
	add.s32 	%r3972, %r3971, %r937;
	setp.lt.u32 	%p1565, %r3972, 3;
	@%p1565 bra 	$L__BB0_781;

	not.b32 	%r3973, %r6255;
	max.s32 	%r3974, %r3973, -4;
	add.s32 	%r3975, %r6255, %r3974;
	add.s32 	%r944, %r3975, 4;
	shr.u32 	%r3976, %r944, 2;
	add.s32 	%r3977, %r3976, 1;
	and.b32  	%r6254, %r3977, 3;
	setp.eq.s32 	%p1566, %r6254, 0;
	@%p1566 bra 	$L__BB0_779;

$L__BB0_778:
	.pragma "nounroll";
	sub.s64 	%rd3835, %rd6417, %rd644;
	mov.b64 	%fd1930, %rd3835;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3978}, %fd1930;
	}
	setp.lt.s32 	%p1567, %r3978, 0;
	selp.b64 	%rd3836, %rd6417, %rd3835, %p1567;
	shl.b64 	%rd3837, %rd3836, 1;
	sub.s64 	%rd3838, %rd3837, %rd644;
	mov.b64 	%fd1931, %rd3838;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3979}, %fd1931;
	}
	setp.lt.s32 	%p1568, %r3979, 0;
	selp.b64 	%rd3839, %rd3837, %rd3838, %p1568;
	shl.b64 	%rd3840, %rd3839, 1;
	sub.s64 	%rd3841, %rd3840, %rd644;
	mov.b64 	%fd1932, %rd3841;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3980}, %fd1932;
	}
	setp.lt.s32 	%p1569, %r3980, 0;
	selp.b64 	%rd3842, %rd3840, %rd3841, %p1569;
	shl.b64 	%rd3843, %rd3842, 1;
	sub.s64 	%rd3844, %rd3843, %rd644;
	mov.b64 	%fd1933, %rd3844;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3981}, %fd1933;
	}
	setp.lt.s32 	%p1570, %r3981, 0;
	selp.b64 	%rd6420, %rd3843, %rd3844, %p1570;
	shl.b64 	%rd6417, %rd6420, 1;
	add.s32 	%r6255, %r6255, -4;
	add.s32 	%r6254, %r6254, -1;
	setp.ne.s32 	%p1571, %r6254, 0;
	@%p1571 bra 	$L__BB0_778;

$L__BB0_779:
	setp.lt.u32 	%p1572, %r944, 12;
	@%p1572 bra 	$L__BB0_781;

$L__BB0_780:
	sub.s64 	%rd3845, %rd6417, %rd644;
	mov.b64 	%fd1934, %rd3845;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3982}, %fd1934;
	}
	setp.lt.s32 	%p1573, %r3982, 0;
	selp.b64 	%rd3846, %rd6417, %rd3845, %p1573;
	shl.b64 	%rd3847, %rd3846, 1;
	sub.s64 	%rd3848, %rd3847, %rd644;
	mov.b64 	%fd1935, %rd3848;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3983}, %fd1935;
	}
	setp.lt.s32 	%p1574, %r3983, 0;
	selp.b64 	%rd3849, %rd3847, %rd3848, %p1574;
	shl.b64 	%rd3850, %rd3849, 1;
	sub.s64 	%rd3851, %rd3850, %rd644;
	mov.b64 	%fd1936, %rd3851;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3984}, %fd1936;
	}
	setp.lt.s32 	%p1575, %r3984, 0;
	selp.b64 	%rd3852, %rd3850, %rd3851, %p1575;
	shl.b64 	%rd3853, %rd3852, 1;
	sub.s64 	%rd3854, %rd3853, %rd644;
	mov.b64 	%fd1937, %rd3854;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3985}, %fd1937;
	}
	setp.lt.s32 	%p1576, %r3985, 0;
	selp.b64 	%rd3855, %rd3853, %rd3854, %p1576;
	shl.b64 	%rd3856, %rd3855, 1;
	sub.s64 	%rd3857, %rd3856, %rd644;
	mov.b64 	%fd1938, %rd3857;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3986}, %fd1938;
	}
	setp.lt.s32 	%p1577, %r3986, 0;
	selp.b64 	%rd3858, %rd3856, %rd3857, %p1577;
	shl.b64 	%rd3859, %rd3858, 1;
	sub.s64 	%rd3860, %rd3859, %rd644;
	mov.b64 	%fd1939, %rd3860;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3987}, %fd1939;
	}
	setp.lt.s32 	%p1578, %r3987, 0;
	selp.b64 	%rd3861, %rd3859, %rd3860, %p1578;
	shl.b64 	%rd3862, %rd3861, 1;
	sub.s64 	%rd3863, %rd3862, %rd644;
	mov.b64 	%fd1940, %rd3863;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3988}, %fd1940;
	}
	setp.lt.s32 	%p1579, %r3988, 0;
	selp.b64 	%rd3864, %rd3862, %rd3863, %p1579;
	shl.b64 	%rd3865, %rd3864, 1;
	sub.s64 	%rd3866, %rd3865, %rd644;
	mov.b64 	%fd1941, %rd3866;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3989}, %fd1941;
	}
	setp.lt.s32 	%p1580, %r3989, 0;
	selp.b64 	%rd3867, %rd3865, %rd3866, %p1580;
	shl.b64 	%rd3868, %rd3867, 1;
	sub.s64 	%rd3869, %rd3868, %rd644;
	mov.b64 	%fd1942, %rd3869;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3990}, %fd1942;
	}
	setp.lt.s32 	%p1581, %r3990, 0;
	selp.b64 	%rd3870, %rd3868, %rd3869, %p1581;
	shl.b64 	%rd3871, %rd3870, 1;
	sub.s64 	%rd3872, %rd3871, %rd644;
	mov.b64 	%fd1943, %rd3872;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3991}, %fd1943;
	}
	setp.lt.s32 	%p1582, %r3991, 0;
	selp.b64 	%rd3873, %rd3871, %rd3872, %p1582;
	shl.b64 	%rd3874, %rd3873, 1;
	sub.s64 	%rd3875, %rd3874, %rd644;
	mov.b64 	%fd1944, %rd3875;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3992}, %fd1944;
	}
	setp.lt.s32 	%p1583, %r3992, 0;
	selp.b64 	%rd3876, %rd3874, %rd3875, %p1583;
	shl.b64 	%rd3877, %rd3876, 1;
	sub.s64 	%rd3878, %rd3877, %rd644;
	mov.b64 	%fd1945, %rd3878;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3993}, %fd1945;
	}
	setp.lt.s32 	%p1584, %r3993, 0;
	selp.b64 	%rd3879, %rd3877, %rd3878, %p1584;
	shl.b64 	%rd3880, %rd3879, 1;
	sub.s64 	%rd3881, %rd3880, %rd644;
	mov.b64 	%fd1946, %rd3881;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3994}, %fd1946;
	}
	setp.lt.s32 	%p1585, %r3994, 0;
	selp.b64 	%rd3882, %rd3880, %rd3881, %p1585;
	shl.b64 	%rd3883, %rd3882, 1;
	sub.s64 	%rd3884, %rd3883, %rd644;
	mov.b64 	%fd1947, %rd3884;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3995}, %fd1947;
	}
	setp.lt.s32 	%p1586, %r3995, 0;
	selp.b64 	%rd3885, %rd3883, %rd3884, %p1586;
	shl.b64 	%rd3886, %rd3885, 1;
	sub.s64 	%rd3887, %rd3886, %rd644;
	mov.b64 	%fd1948, %rd3887;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3996}, %fd1948;
	}
	setp.lt.s32 	%p1587, %r3996, 0;
	selp.b64 	%rd3888, %rd3886, %rd3887, %p1587;
	shl.b64 	%rd3889, %rd3888, 1;
	sub.s64 	%rd3890, %rd3889, %rd644;
	mov.b64 	%fd1949, %rd3890;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3997}, %fd1949;
	}
	setp.lt.s32 	%p1588, %r3997, 0;
	selp.b64 	%rd6420, %rd3889, %rd3890, %p1588;
	shl.b64 	%rd6417, %rd6420, 1;
	add.s32 	%r952, %r6255, -16;
	setp.gt.s32 	%p1589, %r6255, 15;
	mov.u32 	%r6255, %r952;
	@%p1589 bra 	$L__BB0_780;

$L__BB0_781:
	and.b64  	%rd659, %rd6420, 9223372036854775807;
	setp.eq.s64 	%p1590, %rd659, 0;
	mov.f64 	%fd3050, 0d0000000000000000;
	@%p1590 bra 	$L__BB0_783;

	mov.b64 	%fd1951, %rd659;
	mul.f64 	%fd1952, %fd1951, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3998}, %fd1952;
	}
	shr.u32 	%r3999, %r3998, 20;
	mov.u32 	%r4000, 55;
	sub.s32 	%r4001, %r4000, %r3999;
	sub.s32 	%r4002, %r6249, %r4001;
	shl.b64 	%rd3891, %rd659, %r4001;
	setp.lt.s32 	%p1591, %r4002, 1;
	mov.u32 	%r4003, 1;
	sub.s32 	%r4004, %r4003, %r4002;
	shr.u64 	%rd3892, %rd3891, %r4004;
	add.s32 	%r4005, %r4002, -1;
	cvt.u64.u32 	%rd3893, %r4005;
	shl.b64 	%rd3894, %rd3893, 52;
	add.s64 	%rd3895, %rd3894, %rd3891;
	selp.b64 	%rd3896, %rd3892, %rd3895, %p1591;
	mov.b64 	%fd3050, %rd3896;

$L__BB0_783:
	and.b32  	%r4006, %r929, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4007}, %fd3050;
	}
	or.b32  	%r4008, %r4007, %r4006;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4009, %temp}, %fd3050;
	}
	mov.b64 	%fd3051, {%r4009, %r4008};
	bra.uni 	$L__BB0_787;

$L__BB0_785:
	mov.f64 	%fd1953, 0d3FF0000000000000;
	add.rn.f64 	%fd3051, %fd425, %fd1953;

$L__BB0_787:
	mov.f64 	%fd1954, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1955, %fd1954, %fd3051;
	mul.f64 	%fd1956, %fd1955, %fd51;
	mul.f64 	%fd1957, %fd1956, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 97 30
	add.s32 	%r4010, %r6293, 4;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 97 30
	cvt.rn.f64.s32 	%fd1958, %r4010;
	fma.rn.f64 	%fd436, %fd1958, 0d400921FB54442D18, %fd1957;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r953}, %fd436;
	}
	and.b32  	%r4011, %r953, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4012, %temp}, %fd436;
	}
	mov.b64 	%fd3052, {%r4012, %r4011};
	setp.gt.u32 	%p1596, %r4011, 2146435071;
	or.pred  	%p1598, %p1596, %p18;
	@%p1598 bra 	$L__BB0_804;
	bra.uni 	$L__BB0_788;

$L__BB0_804:
	.loc	1 0 9
	setp.le.f64 	%p1633, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1634, %fd3052, 0d7FF0000000000000;
	and.pred  	%p1635, %p1634, %p1633;
	@%p1635 bra 	$L__BB0_806;
	bra.uni 	$L__BB0_805;

$L__BB0_806:
	setp.eq.f64 	%p1636, %fd3052, 0d7FF0000000000000;
	selp.f64 	%fd3055, 0dFFF8000000000000, %fd436, %p1636;
	bra.uni 	$L__BB0_807;

$L__BB0_788:
	.loc	1 0 9
	mov.f64 	%fd3055, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_807;

	setp.ltu.f64 	%p1600, %fd3052, %fd3160;
	mov.f64 	%fd3055, %fd436;
	@%p1600 bra 	$L__BB0_807;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4013}, %fd3052;
	}
	shr.u32 	%r6257, %r4013, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4014}, %fd3160;
	}
	shr.u32 	%r6258, %r4014, 20;
	setp.ne.s32 	%p1601, %r6257, 0;
	@%p1601 bra 	$L__BB0_792;

	mul.f64 	%fd3052, %fd3052, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4015}, %fd3052;
	}
	shr.u32 	%r4016, %r4015, 20;
	add.s32 	%r6257, %r4016, -54;

$L__BB0_792:
	setp.ne.s32 	%p1602, %r6258, 0;
	mov.f64 	%fd3053, %fd3160;
	@%p1602 bra 	$L__BB0_794;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4017}, %fd2;
	}
	shr.u32 	%r4018, %r4017, 20;
	add.s32 	%r6258, %r4018, -54;
	mov.f64 	%fd3053, %fd2;

$L__BB0_794:
	mov.b64 	%rd3898, %fd3052;
	and.b64  	%rd3899, %rd3898, 4503599627370495;
	or.b64  	%rd6425, %rd3899, 4503599627370496;
	mov.b64 	%rd3900, %fd3053;
	and.b64  	%rd3901, %rd3900, 4503599627370495;
	or.b64  	%rd661, %rd3901, 4503599627370496;
	sub.s32 	%r6264, %r6257, %r6258;
	not.b32 	%r4019, %r6257;
	add.s32 	%r4020, %r6258, %r4019;
	max.s32 	%r4021, %r4020, -1;
	add.s32 	%r961, %r4021, %r6257;
	mov.u32 	%r4022, 2;
	sub.s32 	%r4023, %r4022, %r6258;
	add.s32 	%r4024, %r4023, %r961;
	and.b32  	%r6260, %r4024, 3;
	setp.eq.s32 	%p1603, %r6260, 0;
	@%p1603 bra 	$L__BB0_796;

$L__BB0_795:
	.pragma "nounroll";
	sub.s64 	%rd3902, %rd6425, %rd661;
	mov.b64 	%fd1960, %rd3902;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4025}, %fd1960;
	}
	setp.lt.s32 	%p1604, %r4025, 0;
	selp.b64 	%rd6428, %rd6425, %rd3902, %p1604;
	shl.b64 	%rd6425, %rd6428, 1;
	add.s32 	%r6264, %r6264, -1;
	add.s32 	%r6260, %r6260, -1;
	setp.ne.s32 	%p1605, %r6260, 0;
	@%p1605 bra 	$L__BB0_795;

$L__BB0_796:
	mov.u32 	%r4026, 1;
	sub.s32 	%r4027, %r4026, %r6258;
	add.s32 	%r4028, %r4027, %r961;
	setp.lt.u32 	%p1606, %r4028, 3;
	@%p1606 bra 	$L__BB0_801;

	not.b32 	%r4029, %r6264;
	max.s32 	%r4030, %r4029, -4;
	add.s32 	%r4031, %r6264, %r4030;
	add.s32 	%r968, %r4031, 4;
	shr.u32 	%r4032, %r968, 2;
	add.s32 	%r4033, %r4032, 1;
	and.b32  	%r6263, %r4033, 3;
	setp.eq.s32 	%p1607, %r6263, 0;
	@%p1607 bra 	$L__BB0_799;

$L__BB0_798:
	.pragma "nounroll";
	sub.s64 	%rd3904, %rd6425, %rd661;
	mov.b64 	%fd1961, %rd3904;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4034}, %fd1961;
	}
	setp.lt.s32 	%p1608, %r4034, 0;
	selp.b64 	%rd3905, %rd6425, %rd3904, %p1608;
	shl.b64 	%rd3906, %rd3905, 1;
	sub.s64 	%rd3907, %rd3906, %rd661;
	mov.b64 	%fd1962, %rd3907;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4035}, %fd1962;
	}
	setp.lt.s32 	%p1609, %r4035, 0;
	selp.b64 	%rd3908, %rd3906, %rd3907, %p1609;
	shl.b64 	%rd3909, %rd3908, 1;
	sub.s64 	%rd3910, %rd3909, %rd661;
	mov.b64 	%fd1963, %rd3910;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4036}, %fd1963;
	}
	setp.lt.s32 	%p1610, %r4036, 0;
	selp.b64 	%rd3911, %rd3909, %rd3910, %p1610;
	shl.b64 	%rd3912, %rd3911, 1;
	sub.s64 	%rd3913, %rd3912, %rd661;
	mov.b64 	%fd1964, %rd3913;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4037}, %fd1964;
	}
	setp.lt.s32 	%p1611, %r4037, 0;
	selp.b64 	%rd6428, %rd3912, %rd3913, %p1611;
	shl.b64 	%rd6425, %rd6428, 1;
	add.s32 	%r6264, %r6264, -4;
	add.s32 	%r6263, %r6263, -1;
	setp.ne.s32 	%p1612, %r6263, 0;
	@%p1612 bra 	$L__BB0_798;

$L__BB0_799:
	setp.lt.u32 	%p1613, %r968, 12;
	@%p1613 bra 	$L__BB0_801;

$L__BB0_800:
	sub.s64 	%rd3914, %rd6425, %rd661;
	mov.b64 	%fd1965, %rd3914;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4038}, %fd1965;
	}
	setp.lt.s32 	%p1614, %r4038, 0;
	selp.b64 	%rd3915, %rd6425, %rd3914, %p1614;
	shl.b64 	%rd3916, %rd3915, 1;
	sub.s64 	%rd3917, %rd3916, %rd661;
	mov.b64 	%fd1966, %rd3917;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4039}, %fd1966;
	}
	setp.lt.s32 	%p1615, %r4039, 0;
	selp.b64 	%rd3918, %rd3916, %rd3917, %p1615;
	shl.b64 	%rd3919, %rd3918, 1;
	sub.s64 	%rd3920, %rd3919, %rd661;
	mov.b64 	%fd1967, %rd3920;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4040}, %fd1967;
	}
	setp.lt.s32 	%p1616, %r4040, 0;
	selp.b64 	%rd3921, %rd3919, %rd3920, %p1616;
	shl.b64 	%rd3922, %rd3921, 1;
	sub.s64 	%rd3923, %rd3922, %rd661;
	mov.b64 	%fd1968, %rd3923;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4041}, %fd1968;
	}
	setp.lt.s32 	%p1617, %r4041, 0;
	selp.b64 	%rd3924, %rd3922, %rd3923, %p1617;
	shl.b64 	%rd3925, %rd3924, 1;
	sub.s64 	%rd3926, %rd3925, %rd661;
	mov.b64 	%fd1969, %rd3926;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4042}, %fd1969;
	}
	setp.lt.s32 	%p1618, %r4042, 0;
	selp.b64 	%rd3927, %rd3925, %rd3926, %p1618;
	shl.b64 	%rd3928, %rd3927, 1;
	sub.s64 	%rd3929, %rd3928, %rd661;
	mov.b64 	%fd1970, %rd3929;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4043}, %fd1970;
	}
	setp.lt.s32 	%p1619, %r4043, 0;
	selp.b64 	%rd3930, %rd3928, %rd3929, %p1619;
	shl.b64 	%rd3931, %rd3930, 1;
	sub.s64 	%rd3932, %rd3931, %rd661;
	mov.b64 	%fd1971, %rd3932;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4044}, %fd1971;
	}
	setp.lt.s32 	%p1620, %r4044, 0;
	selp.b64 	%rd3933, %rd3931, %rd3932, %p1620;
	shl.b64 	%rd3934, %rd3933, 1;
	sub.s64 	%rd3935, %rd3934, %rd661;
	mov.b64 	%fd1972, %rd3935;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4045}, %fd1972;
	}
	setp.lt.s32 	%p1621, %r4045, 0;
	selp.b64 	%rd3936, %rd3934, %rd3935, %p1621;
	shl.b64 	%rd3937, %rd3936, 1;
	sub.s64 	%rd3938, %rd3937, %rd661;
	mov.b64 	%fd1973, %rd3938;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4046}, %fd1973;
	}
	setp.lt.s32 	%p1622, %r4046, 0;
	selp.b64 	%rd3939, %rd3937, %rd3938, %p1622;
	shl.b64 	%rd3940, %rd3939, 1;
	sub.s64 	%rd3941, %rd3940, %rd661;
	mov.b64 	%fd1974, %rd3941;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4047}, %fd1974;
	}
	setp.lt.s32 	%p1623, %r4047, 0;
	selp.b64 	%rd3942, %rd3940, %rd3941, %p1623;
	shl.b64 	%rd3943, %rd3942, 1;
	sub.s64 	%rd3944, %rd3943, %rd661;
	mov.b64 	%fd1975, %rd3944;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4048}, %fd1975;
	}
	setp.lt.s32 	%p1624, %r4048, 0;
	selp.b64 	%rd3945, %rd3943, %rd3944, %p1624;
	shl.b64 	%rd3946, %rd3945, 1;
	sub.s64 	%rd3947, %rd3946, %rd661;
	mov.b64 	%fd1976, %rd3947;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4049}, %fd1976;
	}
	setp.lt.s32 	%p1625, %r4049, 0;
	selp.b64 	%rd3948, %rd3946, %rd3947, %p1625;
	shl.b64 	%rd3949, %rd3948, 1;
	sub.s64 	%rd3950, %rd3949, %rd661;
	mov.b64 	%fd1977, %rd3950;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4050}, %fd1977;
	}
	setp.lt.s32 	%p1626, %r4050, 0;
	selp.b64 	%rd3951, %rd3949, %rd3950, %p1626;
	shl.b64 	%rd3952, %rd3951, 1;
	sub.s64 	%rd3953, %rd3952, %rd661;
	mov.b64 	%fd1978, %rd3953;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4051}, %fd1978;
	}
	setp.lt.s32 	%p1627, %r4051, 0;
	selp.b64 	%rd3954, %rd3952, %rd3953, %p1627;
	shl.b64 	%rd3955, %rd3954, 1;
	sub.s64 	%rd3956, %rd3955, %rd661;
	mov.b64 	%fd1979, %rd3956;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4052}, %fd1979;
	}
	setp.lt.s32 	%p1628, %r4052, 0;
	selp.b64 	%rd3957, %rd3955, %rd3956, %p1628;
	shl.b64 	%rd3958, %rd3957, 1;
	sub.s64 	%rd3959, %rd3958, %rd661;
	mov.b64 	%fd1980, %rd3959;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4053}, %fd1980;
	}
	setp.lt.s32 	%p1629, %r4053, 0;
	selp.b64 	%rd6428, %rd3958, %rd3959, %p1629;
	shl.b64 	%rd6425, %rd6428, 1;
	add.s32 	%r976, %r6264, -16;
	setp.gt.s32 	%p1630, %r6264, 15;
	mov.u32 	%r6264, %r976;
	@%p1630 bra 	$L__BB0_800;

$L__BB0_801:
	and.b64  	%rd676, %rd6428, 9223372036854775807;
	setp.eq.s64 	%p1631, %rd676, 0;
	mov.f64 	%fd3054, 0d0000000000000000;
	@%p1631 bra 	$L__BB0_803;

	mov.b64 	%fd1982, %rd676;
	mul.f64 	%fd1983, %fd1982, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4054}, %fd1983;
	}
	shr.u32 	%r4055, %r4054, 20;
	mov.u32 	%r4056, 55;
	sub.s32 	%r4057, %r4056, %r4055;
	sub.s32 	%r4058, %r6258, %r4057;
	shl.b64 	%rd3960, %rd676, %r4057;
	setp.lt.s32 	%p1632, %r4058, 1;
	mov.u32 	%r4059, 1;
	sub.s32 	%r4060, %r4059, %r4058;
	shr.u64 	%rd3961, %rd3960, %r4060;
	add.s32 	%r4061, %r4058, -1;
	cvt.u64.u32 	%rd3962, %r4061;
	shl.b64 	%rd3963, %rd3962, 52;
	add.s64 	%rd3964, %rd3963, %rd3960;
	selp.b64 	%rd3965, %rd3961, %rd3964, %p1632;
	mov.b64 	%fd3054, %rd3965;

$L__BB0_803:
	and.b32  	%r4062, %r953, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4063}, %fd3054;
	}
	or.b32  	%r4064, %r4063, %r4062;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4065, %temp}, %fd3054;
	}
	mov.b64 	%fd3055, {%r4065, %r4064};
	bra.uni 	$L__BB0_807;

$L__BB0_805:
	mov.f64 	%fd1984, 0d3FF0000000000000;
	add.rn.f64 	%fd3055, %fd436, %fd1984;

$L__BB0_807:
	mov.f64 	%fd1985, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd1986, %fd1985, %fd3055;
	mul.f64 	%fd1987, %fd1986, %fd63;
	mul.f64 	%fd1988, %fd1987, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 97 30
	add.s32 	%r4066, %r6293, 3;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 97 30
	cvt.rn.f64.s32 	%fd1989, %r4066;
	fma.rn.f64 	%fd447, %fd1989, 0d400921FB54442D18, %fd1988;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r977}, %fd447;
	}
	and.b32  	%r4067, %r977, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4068, %temp}, %fd447;
	}
	mov.b64 	%fd3056, {%r4068, %r4067};
	setp.gt.u32 	%p1637, %r4067, 2146435071;
	or.pred  	%p1639, %p1637, %p18;
	@%p1639 bra 	$L__BB0_824;
	bra.uni 	$L__BB0_808;

$L__BB0_824:
	.loc	1 0 9
	setp.le.f64 	%p1674, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1675, %fd3056, 0d7FF0000000000000;
	and.pred  	%p1676, %p1675, %p1674;
	@%p1676 bra 	$L__BB0_826;
	bra.uni 	$L__BB0_825;

$L__BB0_826:
	setp.eq.f64 	%p1677, %fd3056, 0d7FF0000000000000;
	selp.f64 	%fd3059, 0dFFF8000000000000, %fd447, %p1677;
	bra.uni 	$L__BB0_827;

$L__BB0_808:
	.loc	1 0 9
	mov.f64 	%fd3059, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_827;

	setp.ltu.f64 	%p1641, %fd3056, %fd3160;
	mov.f64 	%fd3059, %fd447;
	@%p1641 bra 	$L__BB0_827;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4069}, %fd3056;
	}
	shr.u32 	%r6266, %r4069, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4070}, %fd3160;
	}
	shr.u32 	%r6267, %r4070, 20;
	setp.ne.s32 	%p1642, %r6266, 0;
	@%p1642 bra 	$L__BB0_812;

	mul.f64 	%fd3056, %fd3056, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4071}, %fd3056;
	}
	shr.u32 	%r4072, %r4071, 20;
	add.s32 	%r6266, %r4072, -54;

$L__BB0_812:
	setp.ne.s32 	%p1643, %r6267, 0;
	mov.f64 	%fd3057, %fd3160;
	@%p1643 bra 	$L__BB0_814;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4073}, %fd2;
	}
	shr.u32 	%r4074, %r4073, 20;
	add.s32 	%r6267, %r4074, -54;
	mov.f64 	%fd3057, %fd2;

$L__BB0_814:
	mov.b64 	%rd3967, %fd3056;
	and.b64  	%rd3968, %rd3967, 4503599627370495;
	or.b64  	%rd6433, %rd3968, 4503599627370496;
	mov.b64 	%rd3969, %fd3057;
	and.b64  	%rd3970, %rd3969, 4503599627370495;
	or.b64  	%rd678, %rd3970, 4503599627370496;
	sub.s32 	%r6273, %r6266, %r6267;
	not.b32 	%r4075, %r6266;
	add.s32 	%r4076, %r6267, %r4075;
	max.s32 	%r4077, %r4076, -1;
	add.s32 	%r985, %r4077, %r6266;
	mov.u32 	%r4078, 2;
	sub.s32 	%r4079, %r4078, %r6267;
	add.s32 	%r4080, %r4079, %r985;
	and.b32  	%r6269, %r4080, 3;
	setp.eq.s32 	%p1644, %r6269, 0;
	@%p1644 bra 	$L__BB0_816;

$L__BB0_815:
	.pragma "nounroll";
	sub.s64 	%rd3971, %rd6433, %rd678;
	mov.b64 	%fd1991, %rd3971;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4081}, %fd1991;
	}
	setp.lt.s32 	%p1645, %r4081, 0;
	selp.b64 	%rd6436, %rd6433, %rd3971, %p1645;
	shl.b64 	%rd6433, %rd6436, 1;
	add.s32 	%r6273, %r6273, -1;
	add.s32 	%r6269, %r6269, -1;
	setp.ne.s32 	%p1646, %r6269, 0;
	@%p1646 bra 	$L__BB0_815;

$L__BB0_816:
	mov.u32 	%r4082, 1;
	sub.s32 	%r4083, %r4082, %r6267;
	add.s32 	%r4084, %r4083, %r985;
	setp.lt.u32 	%p1647, %r4084, 3;
	@%p1647 bra 	$L__BB0_821;

	not.b32 	%r4085, %r6273;
	max.s32 	%r4086, %r4085, -4;
	add.s32 	%r4087, %r6273, %r4086;
	add.s32 	%r992, %r4087, 4;
	shr.u32 	%r4088, %r992, 2;
	add.s32 	%r4089, %r4088, 1;
	and.b32  	%r6272, %r4089, 3;
	setp.eq.s32 	%p1648, %r6272, 0;
	@%p1648 bra 	$L__BB0_819;

$L__BB0_818:
	.pragma "nounroll";
	sub.s64 	%rd3973, %rd6433, %rd678;
	mov.b64 	%fd1992, %rd3973;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4090}, %fd1992;
	}
	setp.lt.s32 	%p1649, %r4090, 0;
	selp.b64 	%rd3974, %rd6433, %rd3973, %p1649;
	shl.b64 	%rd3975, %rd3974, 1;
	sub.s64 	%rd3976, %rd3975, %rd678;
	mov.b64 	%fd1993, %rd3976;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4091}, %fd1993;
	}
	setp.lt.s32 	%p1650, %r4091, 0;
	selp.b64 	%rd3977, %rd3975, %rd3976, %p1650;
	shl.b64 	%rd3978, %rd3977, 1;
	sub.s64 	%rd3979, %rd3978, %rd678;
	mov.b64 	%fd1994, %rd3979;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4092}, %fd1994;
	}
	setp.lt.s32 	%p1651, %r4092, 0;
	selp.b64 	%rd3980, %rd3978, %rd3979, %p1651;
	shl.b64 	%rd3981, %rd3980, 1;
	sub.s64 	%rd3982, %rd3981, %rd678;
	mov.b64 	%fd1995, %rd3982;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4093}, %fd1995;
	}
	setp.lt.s32 	%p1652, %r4093, 0;
	selp.b64 	%rd6436, %rd3981, %rd3982, %p1652;
	shl.b64 	%rd6433, %rd6436, 1;
	add.s32 	%r6273, %r6273, -4;
	add.s32 	%r6272, %r6272, -1;
	setp.ne.s32 	%p1653, %r6272, 0;
	@%p1653 bra 	$L__BB0_818;

$L__BB0_819:
	setp.lt.u32 	%p1654, %r992, 12;
	@%p1654 bra 	$L__BB0_821;

$L__BB0_820:
	sub.s64 	%rd3983, %rd6433, %rd678;
	mov.b64 	%fd1996, %rd3983;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4094}, %fd1996;
	}
	setp.lt.s32 	%p1655, %r4094, 0;
	selp.b64 	%rd3984, %rd6433, %rd3983, %p1655;
	shl.b64 	%rd3985, %rd3984, 1;
	sub.s64 	%rd3986, %rd3985, %rd678;
	mov.b64 	%fd1997, %rd3986;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4095}, %fd1997;
	}
	setp.lt.s32 	%p1656, %r4095, 0;
	selp.b64 	%rd3987, %rd3985, %rd3986, %p1656;
	shl.b64 	%rd3988, %rd3987, 1;
	sub.s64 	%rd3989, %rd3988, %rd678;
	mov.b64 	%fd1998, %rd3989;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4096}, %fd1998;
	}
	setp.lt.s32 	%p1657, %r4096, 0;
	selp.b64 	%rd3990, %rd3988, %rd3989, %p1657;
	shl.b64 	%rd3991, %rd3990, 1;
	sub.s64 	%rd3992, %rd3991, %rd678;
	mov.b64 	%fd1999, %rd3992;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4097}, %fd1999;
	}
	setp.lt.s32 	%p1658, %r4097, 0;
	selp.b64 	%rd3993, %rd3991, %rd3992, %p1658;
	shl.b64 	%rd3994, %rd3993, 1;
	sub.s64 	%rd3995, %rd3994, %rd678;
	mov.b64 	%fd2000, %rd3995;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4098}, %fd2000;
	}
	setp.lt.s32 	%p1659, %r4098, 0;
	selp.b64 	%rd3996, %rd3994, %rd3995, %p1659;
	shl.b64 	%rd3997, %rd3996, 1;
	sub.s64 	%rd3998, %rd3997, %rd678;
	mov.b64 	%fd2001, %rd3998;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4099}, %fd2001;
	}
	setp.lt.s32 	%p1660, %r4099, 0;
	selp.b64 	%rd3999, %rd3997, %rd3998, %p1660;
	shl.b64 	%rd4000, %rd3999, 1;
	sub.s64 	%rd4001, %rd4000, %rd678;
	mov.b64 	%fd2002, %rd4001;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4100}, %fd2002;
	}
	setp.lt.s32 	%p1661, %r4100, 0;
	selp.b64 	%rd4002, %rd4000, %rd4001, %p1661;
	shl.b64 	%rd4003, %rd4002, 1;
	sub.s64 	%rd4004, %rd4003, %rd678;
	mov.b64 	%fd2003, %rd4004;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4101}, %fd2003;
	}
	setp.lt.s32 	%p1662, %r4101, 0;
	selp.b64 	%rd4005, %rd4003, %rd4004, %p1662;
	shl.b64 	%rd4006, %rd4005, 1;
	sub.s64 	%rd4007, %rd4006, %rd678;
	mov.b64 	%fd2004, %rd4007;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4102}, %fd2004;
	}
	setp.lt.s32 	%p1663, %r4102, 0;
	selp.b64 	%rd4008, %rd4006, %rd4007, %p1663;
	shl.b64 	%rd4009, %rd4008, 1;
	sub.s64 	%rd4010, %rd4009, %rd678;
	mov.b64 	%fd2005, %rd4010;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4103}, %fd2005;
	}
	setp.lt.s32 	%p1664, %r4103, 0;
	selp.b64 	%rd4011, %rd4009, %rd4010, %p1664;
	shl.b64 	%rd4012, %rd4011, 1;
	sub.s64 	%rd4013, %rd4012, %rd678;
	mov.b64 	%fd2006, %rd4013;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4104}, %fd2006;
	}
	setp.lt.s32 	%p1665, %r4104, 0;
	selp.b64 	%rd4014, %rd4012, %rd4013, %p1665;
	shl.b64 	%rd4015, %rd4014, 1;
	sub.s64 	%rd4016, %rd4015, %rd678;
	mov.b64 	%fd2007, %rd4016;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4105}, %fd2007;
	}
	setp.lt.s32 	%p1666, %r4105, 0;
	selp.b64 	%rd4017, %rd4015, %rd4016, %p1666;
	shl.b64 	%rd4018, %rd4017, 1;
	sub.s64 	%rd4019, %rd4018, %rd678;
	mov.b64 	%fd2008, %rd4019;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4106}, %fd2008;
	}
	setp.lt.s32 	%p1667, %r4106, 0;
	selp.b64 	%rd4020, %rd4018, %rd4019, %p1667;
	shl.b64 	%rd4021, %rd4020, 1;
	sub.s64 	%rd4022, %rd4021, %rd678;
	mov.b64 	%fd2009, %rd4022;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4107}, %fd2009;
	}
	setp.lt.s32 	%p1668, %r4107, 0;
	selp.b64 	%rd4023, %rd4021, %rd4022, %p1668;
	shl.b64 	%rd4024, %rd4023, 1;
	sub.s64 	%rd4025, %rd4024, %rd678;
	mov.b64 	%fd2010, %rd4025;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4108}, %fd2010;
	}
	setp.lt.s32 	%p1669, %r4108, 0;
	selp.b64 	%rd4026, %rd4024, %rd4025, %p1669;
	shl.b64 	%rd4027, %rd4026, 1;
	sub.s64 	%rd4028, %rd4027, %rd678;
	mov.b64 	%fd2011, %rd4028;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4109}, %fd2011;
	}
	setp.lt.s32 	%p1670, %r4109, 0;
	selp.b64 	%rd6436, %rd4027, %rd4028, %p1670;
	shl.b64 	%rd6433, %rd6436, 1;
	add.s32 	%r1000, %r6273, -16;
	setp.gt.s32 	%p1671, %r6273, 15;
	mov.u32 	%r6273, %r1000;
	@%p1671 bra 	$L__BB0_820;

$L__BB0_821:
	and.b64  	%rd693, %rd6436, 9223372036854775807;
	setp.eq.s64 	%p1672, %rd693, 0;
	mov.f64 	%fd3058, 0d0000000000000000;
	@%p1672 bra 	$L__BB0_823;

	mov.b64 	%fd2013, %rd693;
	mul.f64 	%fd2014, %fd2013, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4110}, %fd2014;
	}
	shr.u32 	%r4111, %r4110, 20;
	mov.u32 	%r4112, 55;
	sub.s32 	%r4113, %r4112, %r4111;
	sub.s32 	%r4114, %r6267, %r4113;
	shl.b64 	%rd4029, %rd693, %r4113;
	setp.lt.s32 	%p1673, %r4114, 1;
	mov.u32 	%r4115, 1;
	sub.s32 	%r4116, %r4115, %r4114;
	shr.u64 	%rd4030, %rd4029, %r4116;
	add.s32 	%r4117, %r4114, -1;
	cvt.u64.u32 	%rd4031, %r4117;
	shl.b64 	%rd4032, %rd4031, 52;
	add.s64 	%rd4033, %rd4032, %rd4029;
	selp.b64 	%rd4034, %rd4030, %rd4033, %p1673;
	mov.b64 	%fd3058, %rd4034;

$L__BB0_823:
	and.b32  	%r4118, %r977, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4119}, %fd3058;
	}
	or.b32  	%r4120, %r4119, %r4118;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4121, %temp}, %fd3058;
	}
	mov.b64 	%fd3059, {%r4121, %r4120};
	bra.uni 	$L__BB0_827;

$L__BB0_825:
	mov.f64 	%fd2015, 0d3FF0000000000000;
	add.rn.f64 	%fd3059, %fd447, %fd2015;

$L__BB0_827:
	mov.f64 	%fd2016, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2017, %fd2016, %fd3059;
	mul.f64 	%fd2018, %fd2017, %fd75;
	mul.f64 	%fd2019, %fd2018, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 97 30
	add.s32 	%r4122, %r6293, 2;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 97 30
	cvt.rn.f64.s32 	%fd2020, %r4122;
	fma.rn.f64 	%fd458, %fd2020, 0d400921FB54442D18, %fd2019;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1001}, %fd458;
	}
	and.b32  	%r4123, %r1001, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4124, %temp}, %fd458;
	}
	mov.b64 	%fd3060, {%r4124, %r4123};
	setp.gt.u32 	%p1678, %r4123, 2146435071;
	or.pred  	%p1680, %p1678, %p18;
	@%p1680 bra 	$L__BB0_844;
	bra.uni 	$L__BB0_828;

$L__BB0_844:
	.loc	1 0 9
	setp.le.f64 	%p1715, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1716, %fd3060, 0d7FF0000000000000;
	and.pred  	%p1717, %p1716, %p1715;
	@%p1717 bra 	$L__BB0_846;
	bra.uni 	$L__BB0_845;

$L__BB0_846:
	setp.eq.f64 	%p1718, %fd3060, 0d7FF0000000000000;
	selp.f64 	%fd3063, 0dFFF8000000000000, %fd458, %p1718;
	bra.uni 	$L__BB0_847;

$L__BB0_828:
	.loc	1 0 9
	mov.f64 	%fd3063, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_847;

	setp.ltu.f64 	%p1682, %fd3060, %fd3160;
	mov.f64 	%fd3063, %fd458;
	@%p1682 bra 	$L__BB0_847;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4125}, %fd3060;
	}
	shr.u32 	%r6275, %r4125, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4126}, %fd3160;
	}
	shr.u32 	%r6276, %r4126, 20;
	setp.ne.s32 	%p1683, %r6275, 0;
	@%p1683 bra 	$L__BB0_832;

	mul.f64 	%fd3060, %fd3060, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4127}, %fd3060;
	}
	shr.u32 	%r4128, %r4127, 20;
	add.s32 	%r6275, %r4128, -54;

$L__BB0_832:
	setp.ne.s32 	%p1684, %r6276, 0;
	mov.f64 	%fd3061, %fd3160;
	@%p1684 bra 	$L__BB0_834;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4129}, %fd2;
	}
	shr.u32 	%r4130, %r4129, 20;
	add.s32 	%r6276, %r4130, -54;
	mov.f64 	%fd3061, %fd2;

$L__BB0_834:
	mov.b64 	%rd4036, %fd3060;
	and.b64  	%rd4037, %rd4036, 4503599627370495;
	or.b64  	%rd6441, %rd4037, 4503599627370496;
	mov.b64 	%rd4038, %fd3061;
	and.b64  	%rd4039, %rd4038, 4503599627370495;
	or.b64  	%rd695, %rd4039, 4503599627370496;
	sub.s32 	%r6282, %r6275, %r6276;
	not.b32 	%r4131, %r6275;
	add.s32 	%r4132, %r6276, %r4131;
	max.s32 	%r4133, %r4132, -1;
	add.s32 	%r1009, %r4133, %r6275;
	mov.u32 	%r4134, 2;
	sub.s32 	%r4135, %r4134, %r6276;
	add.s32 	%r4136, %r4135, %r1009;
	and.b32  	%r6278, %r4136, 3;
	setp.eq.s32 	%p1685, %r6278, 0;
	@%p1685 bra 	$L__BB0_836;

$L__BB0_835:
	.pragma "nounroll";
	sub.s64 	%rd4040, %rd6441, %rd695;
	mov.b64 	%fd2022, %rd4040;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4137}, %fd2022;
	}
	setp.lt.s32 	%p1686, %r4137, 0;
	selp.b64 	%rd6444, %rd6441, %rd4040, %p1686;
	shl.b64 	%rd6441, %rd6444, 1;
	add.s32 	%r6282, %r6282, -1;
	add.s32 	%r6278, %r6278, -1;
	setp.ne.s32 	%p1687, %r6278, 0;
	@%p1687 bra 	$L__BB0_835;

$L__BB0_836:
	mov.u32 	%r4138, 1;
	sub.s32 	%r4139, %r4138, %r6276;
	add.s32 	%r4140, %r4139, %r1009;
	setp.lt.u32 	%p1688, %r4140, 3;
	@%p1688 bra 	$L__BB0_841;

	not.b32 	%r4141, %r6282;
	max.s32 	%r4142, %r4141, -4;
	add.s32 	%r4143, %r6282, %r4142;
	add.s32 	%r1016, %r4143, 4;
	shr.u32 	%r4144, %r1016, 2;
	add.s32 	%r4145, %r4144, 1;
	and.b32  	%r6281, %r4145, 3;
	setp.eq.s32 	%p1689, %r6281, 0;
	@%p1689 bra 	$L__BB0_839;

$L__BB0_838:
	.pragma "nounroll";
	sub.s64 	%rd4042, %rd6441, %rd695;
	mov.b64 	%fd2023, %rd4042;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4146}, %fd2023;
	}
	setp.lt.s32 	%p1690, %r4146, 0;
	selp.b64 	%rd4043, %rd6441, %rd4042, %p1690;
	shl.b64 	%rd4044, %rd4043, 1;
	sub.s64 	%rd4045, %rd4044, %rd695;
	mov.b64 	%fd2024, %rd4045;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4147}, %fd2024;
	}
	setp.lt.s32 	%p1691, %r4147, 0;
	selp.b64 	%rd4046, %rd4044, %rd4045, %p1691;
	shl.b64 	%rd4047, %rd4046, 1;
	sub.s64 	%rd4048, %rd4047, %rd695;
	mov.b64 	%fd2025, %rd4048;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4148}, %fd2025;
	}
	setp.lt.s32 	%p1692, %r4148, 0;
	selp.b64 	%rd4049, %rd4047, %rd4048, %p1692;
	shl.b64 	%rd4050, %rd4049, 1;
	sub.s64 	%rd4051, %rd4050, %rd695;
	mov.b64 	%fd2026, %rd4051;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4149}, %fd2026;
	}
	setp.lt.s32 	%p1693, %r4149, 0;
	selp.b64 	%rd6444, %rd4050, %rd4051, %p1693;
	shl.b64 	%rd6441, %rd6444, 1;
	add.s32 	%r6282, %r6282, -4;
	add.s32 	%r6281, %r6281, -1;
	setp.ne.s32 	%p1694, %r6281, 0;
	@%p1694 bra 	$L__BB0_838;

$L__BB0_839:
	setp.lt.u32 	%p1695, %r1016, 12;
	@%p1695 bra 	$L__BB0_841;

$L__BB0_840:
	sub.s64 	%rd4052, %rd6441, %rd695;
	mov.b64 	%fd2027, %rd4052;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4150}, %fd2027;
	}
	setp.lt.s32 	%p1696, %r4150, 0;
	selp.b64 	%rd4053, %rd6441, %rd4052, %p1696;
	shl.b64 	%rd4054, %rd4053, 1;
	sub.s64 	%rd4055, %rd4054, %rd695;
	mov.b64 	%fd2028, %rd4055;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4151}, %fd2028;
	}
	setp.lt.s32 	%p1697, %r4151, 0;
	selp.b64 	%rd4056, %rd4054, %rd4055, %p1697;
	shl.b64 	%rd4057, %rd4056, 1;
	sub.s64 	%rd4058, %rd4057, %rd695;
	mov.b64 	%fd2029, %rd4058;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4152}, %fd2029;
	}
	setp.lt.s32 	%p1698, %r4152, 0;
	selp.b64 	%rd4059, %rd4057, %rd4058, %p1698;
	shl.b64 	%rd4060, %rd4059, 1;
	sub.s64 	%rd4061, %rd4060, %rd695;
	mov.b64 	%fd2030, %rd4061;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4153}, %fd2030;
	}
	setp.lt.s32 	%p1699, %r4153, 0;
	selp.b64 	%rd4062, %rd4060, %rd4061, %p1699;
	shl.b64 	%rd4063, %rd4062, 1;
	sub.s64 	%rd4064, %rd4063, %rd695;
	mov.b64 	%fd2031, %rd4064;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4154}, %fd2031;
	}
	setp.lt.s32 	%p1700, %r4154, 0;
	selp.b64 	%rd4065, %rd4063, %rd4064, %p1700;
	shl.b64 	%rd4066, %rd4065, 1;
	sub.s64 	%rd4067, %rd4066, %rd695;
	mov.b64 	%fd2032, %rd4067;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4155}, %fd2032;
	}
	setp.lt.s32 	%p1701, %r4155, 0;
	selp.b64 	%rd4068, %rd4066, %rd4067, %p1701;
	shl.b64 	%rd4069, %rd4068, 1;
	sub.s64 	%rd4070, %rd4069, %rd695;
	mov.b64 	%fd2033, %rd4070;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4156}, %fd2033;
	}
	setp.lt.s32 	%p1702, %r4156, 0;
	selp.b64 	%rd4071, %rd4069, %rd4070, %p1702;
	shl.b64 	%rd4072, %rd4071, 1;
	sub.s64 	%rd4073, %rd4072, %rd695;
	mov.b64 	%fd2034, %rd4073;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4157}, %fd2034;
	}
	setp.lt.s32 	%p1703, %r4157, 0;
	selp.b64 	%rd4074, %rd4072, %rd4073, %p1703;
	shl.b64 	%rd4075, %rd4074, 1;
	sub.s64 	%rd4076, %rd4075, %rd695;
	mov.b64 	%fd2035, %rd4076;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4158}, %fd2035;
	}
	setp.lt.s32 	%p1704, %r4158, 0;
	selp.b64 	%rd4077, %rd4075, %rd4076, %p1704;
	shl.b64 	%rd4078, %rd4077, 1;
	sub.s64 	%rd4079, %rd4078, %rd695;
	mov.b64 	%fd2036, %rd4079;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4159}, %fd2036;
	}
	setp.lt.s32 	%p1705, %r4159, 0;
	selp.b64 	%rd4080, %rd4078, %rd4079, %p1705;
	shl.b64 	%rd4081, %rd4080, 1;
	sub.s64 	%rd4082, %rd4081, %rd695;
	mov.b64 	%fd2037, %rd4082;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4160}, %fd2037;
	}
	setp.lt.s32 	%p1706, %r4160, 0;
	selp.b64 	%rd4083, %rd4081, %rd4082, %p1706;
	shl.b64 	%rd4084, %rd4083, 1;
	sub.s64 	%rd4085, %rd4084, %rd695;
	mov.b64 	%fd2038, %rd4085;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4161}, %fd2038;
	}
	setp.lt.s32 	%p1707, %r4161, 0;
	selp.b64 	%rd4086, %rd4084, %rd4085, %p1707;
	shl.b64 	%rd4087, %rd4086, 1;
	sub.s64 	%rd4088, %rd4087, %rd695;
	mov.b64 	%fd2039, %rd4088;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4162}, %fd2039;
	}
	setp.lt.s32 	%p1708, %r4162, 0;
	selp.b64 	%rd4089, %rd4087, %rd4088, %p1708;
	shl.b64 	%rd4090, %rd4089, 1;
	sub.s64 	%rd4091, %rd4090, %rd695;
	mov.b64 	%fd2040, %rd4091;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4163}, %fd2040;
	}
	setp.lt.s32 	%p1709, %r4163, 0;
	selp.b64 	%rd4092, %rd4090, %rd4091, %p1709;
	shl.b64 	%rd4093, %rd4092, 1;
	sub.s64 	%rd4094, %rd4093, %rd695;
	mov.b64 	%fd2041, %rd4094;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4164}, %fd2041;
	}
	setp.lt.s32 	%p1710, %r4164, 0;
	selp.b64 	%rd4095, %rd4093, %rd4094, %p1710;
	shl.b64 	%rd4096, %rd4095, 1;
	sub.s64 	%rd4097, %rd4096, %rd695;
	mov.b64 	%fd2042, %rd4097;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4165}, %fd2042;
	}
	setp.lt.s32 	%p1711, %r4165, 0;
	selp.b64 	%rd6444, %rd4096, %rd4097, %p1711;
	shl.b64 	%rd6441, %rd6444, 1;
	add.s32 	%r1024, %r6282, -16;
	setp.gt.s32 	%p1712, %r6282, 15;
	mov.u32 	%r6282, %r1024;
	@%p1712 bra 	$L__BB0_840;

$L__BB0_841:
	and.b64  	%rd710, %rd6444, 9223372036854775807;
	setp.eq.s64 	%p1713, %rd710, 0;
	mov.f64 	%fd3062, 0d0000000000000000;
	@%p1713 bra 	$L__BB0_843;

	mov.b64 	%fd2044, %rd710;
	mul.f64 	%fd2045, %fd2044, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4166}, %fd2045;
	}
	shr.u32 	%r4167, %r4166, 20;
	mov.u32 	%r4168, 55;
	sub.s32 	%r4169, %r4168, %r4167;
	sub.s32 	%r4170, %r6276, %r4169;
	shl.b64 	%rd4098, %rd710, %r4169;
	setp.lt.s32 	%p1714, %r4170, 1;
	mov.u32 	%r4171, 1;
	sub.s32 	%r4172, %r4171, %r4170;
	shr.u64 	%rd4099, %rd4098, %r4172;
	add.s32 	%r4173, %r4170, -1;
	cvt.u64.u32 	%rd4100, %r4173;
	shl.b64 	%rd4101, %rd4100, 52;
	add.s64 	%rd4102, %rd4101, %rd4098;
	selp.b64 	%rd4103, %rd4099, %rd4102, %p1714;
	mov.b64 	%fd3062, %rd4103;

$L__BB0_843:
	and.b32  	%r4174, %r1001, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4175}, %fd3062;
	}
	or.b32  	%r4176, %r4175, %r4174;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4177, %temp}, %fd3062;
	}
	mov.b64 	%fd3063, {%r4177, %r4176};
	bra.uni 	$L__BB0_847;

$L__BB0_845:
	mov.f64 	%fd2046, 0d3FF0000000000000;
	add.rn.f64 	%fd3063, %fd458, %fd2046;

$L__BB0_847:
	mov.f64 	%fd2047, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2048, %fd2047, %fd3063;
	mul.f64 	%fd2049, %fd2048, %fd87;
	mul.f64 	%fd2050, %fd2049, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 97 30
	add.s32 	%r4178, %r6293, 1;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 97 30
	cvt.rn.f64.s32 	%fd2051, %r4178;
	fma.rn.f64 	%fd469, %fd2051, 0d400921FB54442D18, %fd2050;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1025}, %fd469;
	}
	and.b32  	%r4179, %r1025, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4180, %temp}, %fd469;
	}
	mov.b64 	%fd3064, {%r4180, %r4179};
	setp.gt.u32 	%p1719, %r4179, 2146435071;
	or.pred  	%p1721, %p1719, %p18;
	@%p1721 bra 	$L__BB0_864;
	bra.uni 	$L__BB0_848;

$L__BB0_864:
	.loc	1 0 9
	setp.le.f64 	%p1756, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1757, %fd3064, 0d7FF0000000000000;
	and.pred  	%p1758, %p1757, %p1756;
	@%p1758 bra 	$L__BB0_866;
	bra.uni 	$L__BB0_865;

$L__BB0_866:
	setp.eq.f64 	%p1759, %fd3064, 0d7FF0000000000000;
	selp.f64 	%fd3072, 0dFFF8000000000000, %fd469, %p1759;
	bra.uni 	$L__BB0_867;

$L__BB0_848:
	.loc	1 0 9
	mov.f64 	%fd3072, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_867;

	setp.ltu.f64 	%p1723, %fd3064, %fd3160;
	mov.f64 	%fd3072, %fd469;
	@%p1723 bra 	$L__BB0_867;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4181}, %fd3064;
	}
	shr.u32 	%r6284, %r4181, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4182}, %fd3160;
	}
	shr.u32 	%r6285, %r4182, 20;
	setp.ne.s32 	%p1724, %r6284, 0;
	@%p1724 bra 	$L__BB0_852;

	mul.f64 	%fd3064, %fd3064, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4183}, %fd3064;
	}
	shr.u32 	%r4184, %r4183, 20;
	add.s32 	%r6284, %r4184, -54;

$L__BB0_852:
	setp.ne.s32 	%p1725, %r6285, 0;
	mov.f64 	%fd3065, %fd3160;
	@%p1725 bra 	$L__BB0_854;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4185}, %fd2;
	}
	shr.u32 	%r4186, %r4185, 20;
	add.s32 	%r6285, %r4186, -54;
	mov.f64 	%fd3065, %fd2;

$L__BB0_854:
	mov.b64 	%rd4105, %fd3064;
	and.b64  	%rd4106, %rd4105, 4503599627370495;
	or.b64  	%rd6449, %rd4106, 4503599627370496;
	mov.b64 	%rd4107, %fd3065;
	and.b64  	%rd4108, %rd4107, 4503599627370495;
	or.b64  	%rd712, %rd4108, 4503599627370496;
	sub.s32 	%r6291, %r6284, %r6285;
	not.b32 	%r4187, %r6284;
	add.s32 	%r4188, %r6285, %r4187;
	max.s32 	%r4189, %r4188, -1;
	add.s32 	%r1033, %r4189, %r6284;
	mov.u32 	%r4190, 2;
	sub.s32 	%r4191, %r4190, %r6285;
	add.s32 	%r4192, %r4191, %r1033;
	and.b32  	%r6287, %r4192, 3;
	setp.eq.s32 	%p1726, %r6287, 0;
	@%p1726 bra 	$L__BB0_856;

$L__BB0_855:
	.pragma "nounroll";
	sub.s64 	%rd4109, %rd6449, %rd712;
	mov.b64 	%fd2053, %rd4109;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4193}, %fd2053;
	}
	setp.lt.s32 	%p1727, %r4193, 0;
	selp.b64 	%rd6452, %rd6449, %rd4109, %p1727;
	shl.b64 	%rd6449, %rd6452, 1;
	add.s32 	%r6291, %r6291, -1;
	add.s32 	%r6287, %r6287, -1;
	setp.ne.s32 	%p1728, %r6287, 0;
	@%p1728 bra 	$L__BB0_855;

$L__BB0_856:
	mov.u32 	%r4194, 1;
	sub.s32 	%r4195, %r4194, %r6285;
	add.s32 	%r4196, %r4195, %r1033;
	setp.lt.u32 	%p1729, %r4196, 3;
	@%p1729 bra 	$L__BB0_861;

	not.b32 	%r4197, %r6291;
	max.s32 	%r4198, %r4197, -4;
	add.s32 	%r4199, %r6291, %r4198;
	add.s32 	%r1040, %r4199, 4;
	shr.u32 	%r4200, %r1040, 2;
	add.s32 	%r4201, %r4200, 1;
	and.b32  	%r6290, %r4201, 3;
	setp.eq.s32 	%p1730, %r6290, 0;
	@%p1730 bra 	$L__BB0_859;

$L__BB0_858:
	.pragma "nounroll";
	sub.s64 	%rd4111, %rd6449, %rd712;
	mov.b64 	%fd2054, %rd4111;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4202}, %fd2054;
	}
	setp.lt.s32 	%p1731, %r4202, 0;
	selp.b64 	%rd4112, %rd6449, %rd4111, %p1731;
	shl.b64 	%rd4113, %rd4112, 1;
	sub.s64 	%rd4114, %rd4113, %rd712;
	mov.b64 	%fd2055, %rd4114;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4203}, %fd2055;
	}
	setp.lt.s32 	%p1732, %r4203, 0;
	selp.b64 	%rd4115, %rd4113, %rd4114, %p1732;
	shl.b64 	%rd4116, %rd4115, 1;
	sub.s64 	%rd4117, %rd4116, %rd712;
	mov.b64 	%fd2056, %rd4117;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4204}, %fd2056;
	}
	setp.lt.s32 	%p1733, %r4204, 0;
	selp.b64 	%rd4118, %rd4116, %rd4117, %p1733;
	shl.b64 	%rd4119, %rd4118, 1;
	sub.s64 	%rd4120, %rd4119, %rd712;
	mov.b64 	%fd2057, %rd4120;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4205}, %fd2057;
	}
	setp.lt.s32 	%p1734, %r4205, 0;
	selp.b64 	%rd6452, %rd4119, %rd4120, %p1734;
	shl.b64 	%rd6449, %rd6452, 1;
	add.s32 	%r6291, %r6291, -4;
	add.s32 	%r6290, %r6290, -1;
	setp.ne.s32 	%p1735, %r6290, 0;
	@%p1735 bra 	$L__BB0_858;

$L__BB0_859:
	setp.lt.u32 	%p1736, %r1040, 12;
	@%p1736 bra 	$L__BB0_861;

$L__BB0_860:
	sub.s64 	%rd4121, %rd6449, %rd712;
	mov.b64 	%fd2058, %rd4121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4206}, %fd2058;
	}
	setp.lt.s32 	%p1737, %r4206, 0;
	selp.b64 	%rd4122, %rd6449, %rd4121, %p1737;
	shl.b64 	%rd4123, %rd4122, 1;
	sub.s64 	%rd4124, %rd4123, %rd712;
	mov.b64 	%fd2059, %rd4124;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4207}, %fd2059;
	}
	setp.lt.s32 	%p1738, %r4207, 0;
	selp.b64 	%rd4125, %rd4123, %rd4124, %p1738;
	shl.b64 	%rd4126, %rd4125, 1;
	sub.s64 	%rd4127, %rd4126, %rd712;
	mov.b64 	%fd2060, %rd4127;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4208}, %fd2060;
	}
	setp.lt.s32 	%p1739, %r4208, 0;
	selp.b64 	%rd4128, %rd4126, %rd4127, %p1739;
	shl.b64 	%rd4129, %rd4128, 1;
	sub.s64 	%rd4130, %rd4129, %rd712;
	mov.b64 	%fd2061, %rd4130;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4209}, %fd2061;
	}
	setp.lt.s32 	%p1740, %r4209, 0;
	selp.b64 	%rd4131, %rd4129, %rd4130, %p1740;
	shl.b64 	%rd4132, %rd4131, 1;
	sub.s64 	%rd4133, %rd4132, %rd712;
	mov.b64 	%fd2062, %rd4133;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4210}, %fd2062;
	}
	setp.lt.s32 	%p1741, %r4210, 0;
	selp.b64 	%rd4134, %rd4132, %rd4133, %p1741;
	shl.b64 	%rd4135, %rd4134, 1;
	sub.s64 	%rd4136, %rd4135, %rd712;
	mov.b64 	%fd2063, %rd4136;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4211}, %fd2063;
	}
	setp.lt.s32 	%p1742, %r4211, 0;
	selp.b64 	%rd4137, %rd4135, %rd4136, %p1742;
	shl.b64 	%rd4138, %rd4137, 1;
	sub.s64 	%rd4139, %rd4138, %rd712;
	mov.b64 	%fd2064, %rd4139;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4212}, %fd2064;
	}
	setp.lt.s32 	%p1743, %r4212, 0;
	selp.b64 	%rd4140, %rd4138, %rd4139, %p1743;
	shl.b64 	%rd4141, %rd4140, 1;
	sub.s64 	%rd4142, %rd4141, %rd712;
	mov.b64 	%fd2065, %rd4142;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4213}, %fd2065;
	}
	setp.lt.s32 	%p1744, %r4213, 0;
	selp.b64 	%rd4143, %rd4141, %rd4142, %p1744;
	shl.b64 	%rd4144, %rd4143, 1;
	sub.s64 	%rd4145, %rd4144, %rd712;
	mov.b64 	%fd2066, %rd4145;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4214}, %fd2066;
	}
	setp.lt.s32 	%p1745, %r4214, 0;
	selp.b64 	%rd4146, %rd4144, %rd4145, %p1745;
	shl.b64 	%rd4147, %rd4146, 1;
	sub.s64 	%rd4148, %rd4147, %rd712;
	mov.b64 	%fd2067, %rd4148;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4215}, %fd2067;
	}
	setp.lt.s32 	%p1746, %r4215, 0;
	selp.b64 	%rd4149, %rd4147, %rd4148, %p1746;
	shl.b64 	%rd4150, %rd4149, 1;
	sub.s64 	%rd4151, %rd4150, %rd712;
	mov.b64 	%fd2068, %rd4151;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4216}, %fd2068;
	}
	setp.lt.s32 	%p1747, %r4216, 0;
	selp.b64 	%rd4152, %rd4150, %rd4151, %p1747;
	shl.b64 	%rd4153, %rd4152, 1;
	sub.s64 	%rd4154, %rd4153, %rd712;
	mov.b64 	%fd2069, %rd4154;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4217}, %fd2069;
	}
	setp.lt.s32 	%p1748, %r4217, 0;
	selp.b64 	%rd4155, %rd4153, %rd4154, %p1748;
	shl.b64 	%rd4156, %rd4155, 1;
	sub.s64 	%rd4157, %rd4156, %rd712;
	mov.b64 	%fd2070, %rd4157;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4218}, %fd2070;
	}
	setp.lt.s32 	%p1749, %r4218, 0;
	selp.b64 	%rd4158, %rd4156, %rd4157, %p1749;
	shl.b64 	%rd4159, %rd4158, 1;
	sub.s64 	%rd4160, %rd4159, %rd712;
	mov.b64 	%fd2071, %rd4160;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4219}, %fd2071;
	}
	setp.lt.s32 	%p1750, %r4219, 0;
	selp.b64 	%rd4161, %rd4159, %rd4160, %p1750;
	shl.b64 	%rd4162, %rd4161, 1;
	sub.s64 	%rd4163, %rd4162, %rd712;
	mov.b64 	%fd2072, %rd4163;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4220}, %fd2072;
	}
	setp.lt.s32 	%p1751, %r4220, 0;
	selp.b64 	%rd4164, %rd4162, %rd4163, %p1751;
	shl.b64 	%rd4165, %rd4164, 1;
	sub.s64 	%rd4166, %rd4165, %rd712;
	mov.b64 	%fd2073, %rd4166;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4221}, %fd2073;
	}
	setp.lt.s32 	%p1752, %r4221, 0;
	selp.b64 	%rd6452, %rd4165, %rd4166, %p1752;
	shl.b64 	%rd6449, %rd6452, 1;
	add.s32 	%r1048, %r6291, -16;
	setp.gt.s32 	%p1753, %r6291, 15;
	mov.u32 	%r6291, %r1048;
	@%p1753 bra 	$L__BB0_860;

$L__BB0_861:
	and.b64  	%rd727, %rd6452, 9223372036854775807;
	setp.eq.s64 	%p1754, %rd727, 0;
	mov.f64 	%fd3066, 0d0000000000000000;
	@%p1754 bra 	$L__BB0_863;

	mov.b64 	%fd2075, %rd727;
	mul.f64 	%fd2076, %fd2075, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4222}, %fd2076;
	}
	shr.u32 	%r4223, %r4222, 20;
	mov.u32 	%r4224, 55;
	sub.s32 	%r4225, %r4224, %r4223;
	sub.s32 	%r4226, %r6285, %r4225;
	shl.b64 	%rd4167, %rd727, %r4225;
	setp.lt.s32 	%p1755, %r4226, 1;
	mov.u32 	%r4227, 1;
	sub.s32 	%r4228, %r4227, %r4226;
	shr.u64 	%rd4168, %rd4167, %r4228;
	add.s32 	%r4229, %r4226, -1;
	cvt.u64.u32 	%rd4169, %r4229;
	shl.b64 	%rd4170, %rd4169, 52;
	add.s64 	%rd4171, %rd4170, %rd4167;
	selp.b64 	%rd4172, %rd4168, %rd4171, %p1755;
	mov.b64 	%fd3066, %rd4172;

$L__BB0_863:
	and.b32  	%r4230, %r1025, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4231}, %fd3066;
	}
	or.b32  	%r4232, %r4231, %r4230;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4233, %temp}, %fd3066;
	}
	mov.b64 	%fd3072, {%r4233, %r4232};
	bra.uni 	$L__BB0_867;

$L__BB0_865:
	mov.f64 	%fd2077, 0d3FF0000000000000;
	add.rn.f64 	%fd3072, %fd469, %fd2077;

$L__BB0_867:
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 97 30
	setp.lt.s32 	%p1760, %r6293, 1;
	@%p1760 bra 	$L__BB0_890;

	.loc	1 98 9, function_name $L__info_string3, inlined_at 1 249 17
	cvt.u64.u32 	%rd728, %r855;

$L__BB0_869:
	.loc	1 0 9
	mov.u32 	%r1049, %r6293;
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 97 30
	add.s32 	%r4234, %r1049, -1;
	.loc	1 62 9, function_name $L__info_string6, inlined_at 1 97 30
	cvt.s64.s32 	%rd4173, %r4234;
	add.s64 	%rd4174, %rd4173, %rd728;
	add.s64 	%rd4175, %rd9, %rd4174;
	ld.global.u8 	%rs82, [%rd4175];
	cvt.rn.f64.u16 	%fd2078, %rs82;
	.loc	1 63 9, function_name $L__info_string6, inlined_at 1 97 30
	mov.f64 	%fd2079, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2080, %fd2079, %fd3072;
	mul.f64 	%fd2081, %fd2080, %fd2078;
	mul.f64 	%fd2082, %fd2081, 0d400921FB54442D18;
	cvt.rn.f64.s32 	%fd2083, %r1049;
	fma.rn.f64 	%fd481, %fd2083, 0d400921FB54442D18, %fd2082;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1050}, %fd481;
	}
	and.b32  	%r4235, %r1050, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4236, %temp}, %fd481;
	}
	mov.b64 	%fd3069, {%r4236, %r4235};
	setp.gt.u32 	%p1761, %r4235, 2146435071;
	or.pred  	%p1763, %p1761, %p18;
	@%p1763 bra 	$L__BB0_886;
	bra.uni 	$L__BB0_870;

$L__BB0_886:
	.loc	1 0 9
	setp.le.f64 	%p1798, %fd3160, 0d7FF0000000000000;
	.loc	1 63 9
	setp.le.f64 	%p1799, %fd3069, 0d7FF0000000000000;
	and.pred  	%p1800, %p1799, %p1798;
	@%p1800 bra 	$L__BB0_888;
	bra.uni 	$L__BB0_887;

$L__BB0_888:
	setp.eq.f64 	%p1801, %fd3069, 0d7FF0000000000000;
	selp.f64 	%fd3072, 0dFFF8000000000000, %fd481, %p1801;
	bra.uni 	$L__BB0_889;

$L__BB0_870:
	.loc	1 0 9
	mov.f64 	%fd3072, 0dFFF8000000000000;
	.loc	1 63 9
	@%p309 bra 	$L__BB0_889;

	setp.ltu.f64 	%p1765, %fd3069, %fd3160;
	mov.f64 	%fd3072, %fd481;
	@%p1765 bra 	$L__BB0_889;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4237}, %fd3069;
	}
	shr.u32 	%r6294, %r4237, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4238}, %fd3160;
	}
	shr.u32 	%r6295, %r4238, 20;
	setp.ne.s32 	%p1766, %r6294, 0;
	@%p1766 bra 	$L__BB0_874;

	mul.f64 	%fd3069, %fd3069, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4239}, %fd3069;
	}
	shr.u32 	%r4240, %r4239, 20;
	add.s32 	%r6294, %r4240, -54;

$L__BB0_874:
	setp.ne.s32 	%p1767, %r6295, 0;
	mov.f64 	%fd3070, %fd3160;
	@%p1767 bra 	$L__BB0_876;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4241}, %fd2;
	}
	shr.u32 	%r4242, %r4241, 20;
	add.s32 	%r6295, %r4242, -54;
	mov.f64 	%fd3070, %fd2;

$L__BB0_876:
	mov.b64 	%rd4177, %fd3069;
	and.b64  	%rd4178, %rd4177, 4503599627370495;
	or.b64  	%rd6457, %rd4178, 4503599627370496;
	mov.b64 	%rd4179, %fd3070;
	and.b64  	%rd4180, %rd4179, 4503599627370495;
	or.b64  	%rd730, %rd4180, 4503599627370496;
	sub.s32 	%r6301, %r6294, %r6295;
	not.b32 	%r4243, %r6294;
	add.s32 	%r4244, %r6295, %r4243;
	max.s32 	%r4245, %r4244, -1;
	add.s32 	%r1058, %r4245, %r6294;
	mov.u32 	%r4246, 2;
	sub.s32 	%r4247, %r4246, %r6295;
	add.s32 	%r4248, %r4247, %r1058;
	and.b32  	%r6297, %r4248, 3;
	setp.eq.s32 	%p1768, %r6297, 0;
	@%p1768 bra 	$L__BB0_878;

$L__BB0_877:
	.pragma "nounroll";
	sub.s64 	%rd4181, %rd6457, %rd730;
	mov.b64 	%fd2085, %rd4181;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4249}, %fd2085;
	}
	setp.lt.s32 	%p1769, %r4249, 0;
	selp.b64 	%rd6460, %rd6457, %rd4181, %p1769;
	shl.b64 	%rd6457, %rd6460, 1;
	add.s32 	%r6301, %r6301, -1;
	add.s32 	%r6297, %r6297, -1;
	setp.ne.s32 	%p1770, %r6297, 0;
	@%p1770 bra 	$L__BB0_877;

$L__BB0_878:
	mov.u32 	%r4250, 1;
	sub.s32 	%r4251, %r4250, %r6295;
	add.s32 	%r4252, %r4251, %r1058;
	setp.lt.u32 	%p1771, %r4252, 3;
	@%p1771 bra 	$L__BB0_883;

	not.b32 	%r4253, %r6301;
	max.s32 	%r4254, %r4253, -4;
	add.s32 	%r4255, %r6301, %r4254;
	add.s32 	%r1065, %r4255, 4;
	shr.u32 	%r4256, %r1065, 2;
	add.s32 	%r4257, %r4256, 1;
	and.b32  	%r6300, %r4257, 3;
	setp.eq.s32 	%p1772, %r6300, 0;
	@%p1772 bra 	$L__BB0_881;

$L__BB0_880:
	.pragma "nounroll";
	sub.s64 	%rd4183, %rd6457, %rd730;
	mov.b64 	%fd2086, %rd4183;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4258}, %fd2086;
	}
	setp.lt.s32 	%p1773, %r4258, 0;
	selp.b64 	%rd4184, %rd6457, %rd4183, %p1773;
	shl.b64 	%rd4185, %rd4184, 1;
	sub.s64 	%rd4186, %rd4185, %rd730;
	mov.b64 	%fd2087, %rd4186;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4259}, %fd2087;
	}
	setp.lt.s32 	%p1774, %r4259, 0;
	selp.b64 	%rd4187, %rd4185, %rd4186, %p1774;
	shl.b64 	%rd4188, %rd4187, 1;
	sub.s64 	%rd4189, %rd4188, %rd730;
	mov.b64 	%fd2088, %rd4189;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4260}, %fd2088;
	}
	setp.lt.s32 	%p1775, %r4260, 0;
	selp.b64 	%rd4190, %rd4188, %rd4189, %p1775;
	shl.b64 	%rd4191, %rd4190, 1;
	sub.s64 	%rd4192, %rd4191, %rd730;
	mov.b64 	%fd2089, %rd4192;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4261}, %fd2089;
	}
	setp.lt.s32 	%p1776, %r4261, 0;
	selp.b64 	%rd6460, %rd4191, %rd4192, %p1776;
	shl.b64 	%rd6457, %rd6460, 1;
	add.s32 	%r6301, %r6301, -4;
	add.s32 	%r6300, %r6300, -1;
	setp.ne.s32 	%p1777, %r6300, 0;
	@%p1777 bra 	$L__BB0_880;

$L__BB0_881:
	setp.lt.u32 	%p1778, %r1065, 12;
	@%p1778 bra 	$L__BB0_883;

$L__BB0_882:
	sub.s64 	%rd4193, %rd6457, %rd730;
	mov.b64 	%fd2090, %rd4193;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4262}, %fd2090;
	}
	setp.lt.s32 	%p1779, %r4262, 0;
	selp.b64 	%rd4194, %rd6457, %rd4193, %p1779;
	shl.b64 	%rd4195, %rd4194, 1;
	sub.s64 	%rd4196, %rd4195, %rd730;
	mov.b64 	%fd2091, %rd4196;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4263}, %fd2091;
	}
	setp.lt.s32 	%p1780, %r4263, 0;
	selp.b64 	%rd4197, %rd4195, %rd4196, %p1780;
	shl.b64 	%rd4198, %rd4197, 1;
	sub.s64 	%rd4199, %rd4198, %rd730;
	mov.b64 	%fd2092, %rd4199;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4264}, %fd2092;
	}
	setp.lt.s32 	%p1781, %r4264, 0;
	selp.b64 	%rd4200, %rd4198, %rd4199, %p1781;
	shl.b64 	%rd4201, %rd4200, 1;
	sub.s64 	%rd4202, %rd4201, %rd730;
	mov.b64 	%fd2093, %rd4202;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4265}, %fd2093;
	}
	setp.lt.s32 	%p1782, %r4265, 0;
	selp.b64 	%rd4203, %rd4201, %rd4202, %p1782;
	shl.b64 	%rd4204, %rd4203, 1;
	sub.s64 	%rd4205, %rd4204, %rd730;
	mov.b64 	%fd2094, %rd4205;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4266}, %fd2094;
	}
	setp.lt.s32 	%p1783, %r4266, 0;
	selp.b64 	%rd4206, %rd4204, %rd4205, %p1783;
	shl.b64 	%rd4207, %rd4206, 1;
	sub.s64 	%rd4208, %rd4207, %rd730;
	mov.b64 	%fd2095, %rd4208;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4267}, %fd2095;
	}
	setp.lt.s32 	%p1784, %r4267, 0;
	selp.b64 	%rd4209, %rd4207, %rd4208, %p1784;
	shl.b64 	%rd4210, %rd4209, 1;
	sub.s64 	%rd4211, %rd4210, %rd730;
	mov.b64 	%fd2096, %rd4211;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4268}, %fd2096;
	}
	setp.lt.s32 	%p1785, %r4268, 0;
	selp.b64 	%rd4212, %rd4210, %rd4211, %p1785;
	shl.b64 	%rd4213, %rd4212, 1;
	sub.s64 	%rd4214, %rd4213, %rd730;
	mov.b64 	%fd2097, %rd4214;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4269}, %fd2097;
	}
	setp.lt.s32 	%p1786, %r4269, 0;
	selp.b64 	%rd4215, %rd4213, %rd4214, %p1786;
	shl.b64 	%rd4216, %rd4215, 1;
	sub.s64 	%rd4217, %rd4216, %rd730;
	mov.b64 	%fd2098, %rd4217;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4270}, %fd2098;
	}
	setp.lt.s32 	%p1787, %r4270, 0;
	selp.b64 	%rd4218, %rd4216, %rd4217, %p1787;
	shl.b64 	%rd4219, %rd4218, 1;
	sub.s64 	%rd4220, %rd4219, %rd730;
	mov.b64 	%fd2099, %rd4220;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4271}, %fd2099;
	}
	setp.lt.s32 	%p1788, %r4271, 0;
	selp.b64 	%rd4221, %rd4219, %rd4220, %p1788;
	shl.b64 	%rd4222, %rd4221, 1;
	sub.s64 	%rd4223, %rd4222, %rd730;
	mov.b64 	%fd2100, %rd4223;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4272}, %fd2100;
	}
	setp.lt.s32 	%p1789, %r4272, 0;
	selp.b64 	%rd4224, %rd4222, %rd4223, %p1789;
	shl.b64 	%rd4225, %rd4224, 1;
	sub.s64 	%rd4226, %rd4225, %rd730;
	mov.b64 	%fd2101, %rd4226;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4273}, %fd2101;
	}
	setp.lt.s32 	%p1790, %r4273, 0;
	selp.b64 	%rd4227, %rd4225, %rd4226, %p1790;
	shl.b64 	%rd4228, %rd4227, 1;
	sub.s64 	%rd4229, %rd4228, %rd730;
	mov.b64 	%fd2102, %rd4229;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4274}, %fd2102;
	}
	setp.lt.s32 	%p1791, %r4274, 0;
	selp.b64 	%rd4230, %rd4228, %rd4229, %p1791;
	shl.b64 	%rd4231, %rd4230, 1;
	sub.s64 	%rd4232, %rd4231, %rd730;
	mov.b64 	%fd2103, %rd4232;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4275}, %fd2103;
	}
	setp.lt.s32 	%p1792, %r4275, 0;
	selp.b64 	%rd4233, %rd4231, %rd4232, %p1792;
	shl.b64 	%rd4234, %rd4233, 1;
	sub.s64 	%rd4235, %rd4234, %rd730;
	mov.b64 	%fd2104, %rd4235;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4276}, %fd2104;
	}
	setp.lt.s32 	%p1793, %r4276, 0;
	selp.b64 	%rd4236, %rd4234, %rd4235, %p1793;
	shl.b64 	%rd4237, %rd4236, 1;
	sub.s64 	%rd4238, %rd4237, %rd730;
	mov.b64 	%fd2105, %rd4238;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4277}, %fd2105;
	}
	setp.lt.s32 	%p1794, %r4277, 0;
	selp.b64 	%rd6460, %rd4237, %rd4238, %p1794;
	shl.b64 	%rd6457, %rd6460, 1;
	add.s32 	%r1073, %r6301, -16;
	setp.gt.s32 	%p1795, %r6301, 15;
	mov.u32 	%r6301, %r1073;
	@%p1795 bra 	$L__BB0_882;

$L__BB0_883:
	and.b64  	%rd745, %rd6460, 9223372036854775807;
	setp.eq.s64 	%p1796, %rd745, 0;
	mov.f64 	%fd3071, 0d0000000000000000;
	@%p1796 bra 	$L__BB0_885;

	mov.b64 	%fd2107, %rd745;
	mul.f64 	%fd2108, %fd2107, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4278}, %fd2108;
	}
	shr.u32 	%r4279, %r4278, 20;
	mov.u32 	%r4280, 55;
	sub.s32 	%r4281, %r4280, %r4279;
	sub.s32 	%r4282, %r6295, %r4281;
	shl.b64 	%rd4239, %rd745, %r4281;
	setp.lt.s32 	%p1797, %r4282, 1;
	mov.u32 	%r4283, 1;
	sub.s32 	%r4284, %r4283, %r4282;
	shr.u64 	%rd4240, %rd4239, %r4284;
	add.s32 	%r4285, %r4282, -1;
	cvt.u64.u32 	%rd4241, %r4285;
	shl.b64 	%rd4242, %rd4241, 52;
	add.s64 	%rd4243, %rd4242, %rd4239;
	selp.b64 	%rd4244, %rd4240, %rd4243, %p1797;
	mov.b64 	%fd3071, %rd4244;

$L__BB0_885:
	and.b32  	%r4286, %r1050, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4287}, %fd3071;
	}
	or.b32  	%r4288, %r4287, %r4286;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4289, %temp}, %fd3071;
	}
	mov.b64 	%fd3072, {%r4289, %r4288};
	bra.uni 	$L__BB0_889;

$L__BB0_887:
	mov.f64 	%fd2109, 0d3FF0000000000000;
	add.rn.f64 	%fd3072, %fd481, %fd2109;

$L__BB0_889:
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 97 30
	add.s32 	%r6293, %r1049, -1;
	setp.gt.s32 	%p1802, %r1049, 1;
	@%p1802 bra 	$L__BB0_869;

$L__BB0_890:
	.loc	1 104 9, function_name $L__info_string3, inlined_at 1 249 17
	ld.global.u8 	%r4290, [%rd1206+80];
	ld.global.u8 	%r4291, [%rd1206+81];
	prmt.b32 	%r4292, %r4291, %r4290, 30212;
	ld.global.u8 	%r4293, [%rd1206+82];
	ld.global.u8 	%r4294, [%rd1206+83];
	prmt.b32 	%r4295, %r4294, %r4293, 30212;
	prmt.b32 	%r1075, %r4295, %r4292, 4180;
	.loc	1 105 9, function_name $L__info_string3, inlined_at 1 249 17
	ld.global.u8 	%r4296, [%rd1206+84];
	ld.global.u8 	%r4297, [%rd1206+85];
	prmt.b32 	%r4298, %r4297, %r4296, 30212;
	ld.global.u8 	%r4299, [%rd1206+86];
	ld.global.u8 	%r4300, [%rd1206+87];
	prmt.b32 	%r4301, %r4300, %r4299, 30212;
	prmt.b32 	%r6375, %r4301, %r4298, 4180;
	.loc	1 103 28, function_name $L__info_string3, inlined_at 1 249 17
	.loc	1 53 5, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r4302, %r6375, 8;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 103 28
	cvt.rn.f64.s32 	%fd2110, %r4302;
	fma.rn.f64 	%fd493, %fd2110, 0d400921FB54442D18, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1077}, %fd493;
	}
	and.b32  	%r4303, %r1077, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4304, %temp}, %fd493;
	}
	mov.b64 	%fd3074, {%r4304, %r4303};
	setp.gt.u32 	%p1803, %r4303, 2146435071;
	or.pred  	%p1805, %p1803, %p18;
	@%p1805 bra 	$L__BB0_907;
	bra.uni 	$L__BB0_891;

$L__BB0_907:
	.loc	1 0 9
	setp.le.f64 	%p1840, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1841, %fd3074, 0d7FF0000000000000;
	and.pred  	%p1842, %p1841, %p1840;
	@%p1842 bra 	$L__BB0_909;
	bra.uni 	$L__BB0_908;

$L__BB0_909:
	setp.eq.f64 	%p1843, %fd3074, 0d7FF0000000000000;
	selp.f64 	%fd3077, 0dFFF8000000000000, %fd493, %p1843;
	bra.uni 	$L__BB0_910;

$L__BB0_891:
	.loc	1 0 9
	mov.f64 	%fd3077, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_910;

	setp.ltu.f64 	%p1807, %fd3074, %fd3160;
	mov.f64 	%fd3077, %fd493;
	@%p1807 bra 	$L__BB0_910;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4305}, %fd3074;
	}
	shr.u32 	%r6303, %r4305, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4306}, %fd3160;
	}
	shr.u32 	%r6304, %r4306, 20;
	setp.ne.s32 	%p1808, %r6303, 0;
	@%p1808 bra 	$L__BB0_895;

	mul.f64 	%fd3074, %fd3074, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4307}, %fd3074;
	}
	shr.u32 	%r4308, %r4307, 20;
	add.s32 	%r6303, %r4308, -54;

$L__BB0_895:
	setp.ne.s32 	%p1809, %r6304, 0;
	mov.f64 	%fd3075, %fd3160;
	@%p1809 bra 	$L__BB0_897;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4309}, %fd2;
	}
	shr.u32 	%r4310, %r4309, 20;
	add.s32 	%r6304, %r4310, -54;
	mov.f64 	%fd3075, %fd2;

$L__BB0_897:
	mov.b64 	%rd4246, %fd3074;
	and.b64  	%rd4247, %rd4246, 4503599627370495;
	or.b64  	%rd6465, %rd4247, 4503599627370496;
	mov.b64 	%rd4248, %fd3075;
	and.b64  	%rd4249, %rd4248, 4503599627370495;
	or.b64  	%rd747, %rd4249, 4503599627370496;
	sub.s32 	%r6310, %r6303, %r6304;
	not.b32 	%r4311, %r6303;
	add.s32 	%r4312, %r6304, %r4311;
	max.s32 	%r4313, %r4312, -1;
	add.s32 	%r1085, %r4313, %r6303;
	mov.u32 	%r4314, 2;
	sub.s32 	%r4315, %r4314, %r6304;
	add.s32 	%r4316, %r4315, %r1085;
	and.b32  	%r6306, %r4316, 3;
	setp.eq.s32 	%p1810, %r6306, 0;
	@%p1810 bra 	$L__BB0_899;

$L__BB0_898:
	.pragma "nounroll";
	sub.s64 	%rd4250, %rd6465, %rd747;
	mov.b64 	%fd2112, %rd4250;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4317}, %fd2112;
	}
	setp.lt.s32 	%p1811, %r4317, 0;
	selp.b64 	%rd6468, %rd6465, %rd4250, %p1811;
	shl.b64 	%rd6465, %rd6468, 1;
	add.s32 	%r6310, %r6310, -1;
	add.s32 	%r6306, %r6306, -1;
	setp.ne.s32 	%p1812, %r6306, 0;
	@%p1812 bra 	$L__BB0_898;

$L__BB0_899:
	mov.u32 	%r4318, 1;
	sub.s32 	%r4319, %r4318, %r6304;
	add.s32 	%r4320, %r4319, %r1085;
	setp.lt.u32 	%p1813, %r4320, 3;
	@%p1813 bra 	$L__BB0_904;

	not.b32 	%r4321, %r6310;
	max.s32 	%r4322, %r4321, -4;
	add.s32 	%r4323, %r6310, %r4322;
	add.s32 	%r1092, %r4323, 4;
	shr.u32 	%r4324, %r1092, 2;
	add.s32 	%r4325, %r4324, 1;
	and.b32  	%r6309, %r4325, 3;
	setp.eq.s32 	%p1814, %r6309, 0;
	@%p1814 bra 	$L__BB0_902;

$L__BB0_901:
	.pragma "nounroll";
	sub.s64 	%rd4252, %rd6465, %rd747;
	mov.b64 	%fd2113, %rd4252;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4326}, %fd2113;
	}
	setp.lt.s32 	%p1815, %r4326, 0;
	selp.b64 	%rd4253, %rd6465, %rd4252, %p1815;
	shl.b64 	%rd4254, %rd4253, 1;
	sub.s64 	%rd4255, %rd4254, %rd747;
	mov.b64 	%fd2114, %rd4255;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4327}, %fd2114;
	}
	setp.lt.s32 	%p1816, %r4327, 0;
	selp.b64 	%rd4256, %rd4254, %rd4255, %p1816;
	shl.b64 	%rd4257, %rd4256, 1;
	sub.s64 	%rd4258, %rd4257, %rd747;
	mov.b64 	%fd2115, %rd4258;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4328}, %fd2115;
	}
	setp.lt.s32 	%p1817, %r4328, 0;
	selp.b64 	%rd4259, %rd4257, %rd4258, %p1817;
	shl.b64 	%rd4260, %rd4259, 1;
	sub.s64 	%rd4261, %rd4260, %rd747;
	mov.b64 	%fd2116, %rd4261;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4329}, %fd2116;
	}
	setp.lt.s32 	%p1818, %r4329, 0;
	selp.b64 	%rd6468, %rd4260, %rd4261, %p1818;
	shl.b64 	%rd6465, %rd6468, 1;
	add.s32 	%r6310, %r6310, -4;
	add.s32 	%r6309, %r6309, -1;
	setp.ne.s32 	%p1819, %r6309, 0;
	@%p1819 bra 	$L__BB0_901;

$L__BB0_902:
	setp.lt.u32 	%p1820, %r1092, 12;
	@%p1820 bra 	$L__BB0_904;

$L__BB0_903:
	sub.s64 	%rd4262, %rd6465, %rd747;
	mov.b64 	%fd2117, %rd4262;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4330}, %fd2117;
	}
	setp.lt.s32 	%p1821, %r4330, 0;
	selp.b64 	%rd4263, %rd6465, %rd4262, %p1821;
	shl.b64 	%rd4264, %rd4263, 1;
	sub.s64 	%rd4265, %rd4264, %rd747;
	mov.b64 	%fd2118, %rd4265;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4331}, %fd2118;
	}
	setp.lt.s32 	%p1822, %r4331, 0;
	selp.b64 	%rd4266, %rd4264, %rd4265, %p1822;
	shl.b64 	%rd4267, %rd4266, 1;
	sub.s64 	%rd4268, %rd4267, %rd747;
	mov.b64 	%fd2119, %rd4268;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4332}, %fd2119;
	}
	setp.lt.s32 	%p1823, %r4332, 0;
	selp.b64 	%rd4269, %rd4267, %rd4268, %p1823;
	shl.b64 	%rd4270, %rd4269, 1;
	sub.s64 	%rd4271, %rd4270, %rd747;
	mov.b64 	%fd2120, %rd4271;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4333}, %fd2120;
	}
	setp.lt.s32 	%p1824, %r4333, 0;
	selp.b64 	%rd4272, %rd4270, %rd4271, %p1824;
	shl.b64 	%rd4273, %rd4272, 1;
	sub.s64 	%rd4274, %rd4273, %rd747;
	mov.b64 	%fd2121, %rd4274;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4334}, %fd2121;
	}
	setp.lt.s32 	%p1825, %r4334, 0;
	selp.b64 	%rd4275, %rd4273, %rd4274, %p1825;
	shl.b64 	%rd4276, %rd4275, 1;
	sub.s64 	%rd4277, %rd4276, %rd747;
	mov.b64 	%fd2122, %rd4277;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4335}, %fd2122;
	}
	setp.lt.s32 	%p1826, %r4335, 0;
	selp.b64 	%rd4278, %rd4276, %rd4277, %p1826;
	shl.b64 	%rd4279, %rd4278, 1;
	sub.s64 	%rd4280, %rd4279, %rd747;
	mov.b64 	%fd2123, %rd4280;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4336}, %fd2123;
	}
	setp.lt.s32 	%p1827, %r4336, 0;
	selp.b64 	%rd4281, %rd4279, %rd4280, %p1827;
	shl.b64 	%rd4282, %rd4281, 1;
	sub.s64 	%rd4283, %rd4282, %rd747;
	mov.b64 	%fd2124, %rd4283;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4337}, %fd2124;
	}
	setp.lt.s32 	%p1828, %r4337, 0;
	selp.b64 	%rd4284, %rd4282, %rd4283, %p1828;
	shl.b64 	%rd4285, %rd4284, 1;
	sub.s64 	%rd4286, %rd4285, %rd747;
	mov.b64 	%fd2125, %rd4286;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4338}, %fd2125;
	}
	setp.lt.s32 	%p1829, %r4338, 0;
	selp.b64 	%rd4287, %rd4285, %rd4286, %p1829;
	shl.b64 	%rd4288, %rd4287, 1;
	sub.s64 	%rd4289, %rd4288, %rd747;
	mov.b64 	%fd2126, %rd4289;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4339}, %fd2126;
	}
	setp.lt.s32 	%p1830, %r4339, 0;
	selp.b64 	%rd4290, %rd4288, %rd4289, %p1830;
	shl.b64 	%rd4291, %rd4290, 1;
	sub.s64 	%rd4292, %rd4291, %rd747;
	mov.b64 	%fd2127, %rd4292;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4340}, %fd2127;
	}
	setp.lt.s32 	%p1831, %r4340, 0;
	selp.b64 	%rd4293, %rd4291, %rd4292, %p1831;
	shl.b64 	%rd4294, %rd4293, 1;
	sub.s64 	%rd4295, %rd4294, %rd747;
	mov.b64 	%fd2128, %rd4295;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4341}, %fd2128;
	}
	setp.lt.s32 	%p1832, %r4341, 0;
	selp.b64 	%rd4296, %rd4294, %rd4295, %p1832;
	shl.b64 	%rd4297, %rd4296, 1;
	sub.s64 	%rd4298, %rd4297, %rd747;
	mov.b64 	%fd2129, %rd4298;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4342}, %fd2129;
	}
	setp.lt.s32 	%p1833, %r4342, 0;
	selp.b64 	%rd4299, %rd4297, %rd4298, %p1833;
	shl.b64 	%rd4300, %rd4299, 1;
	sub.s64 	%rd4301, %rd4300, %rd747;
	mov.b64 	%fd2130, %rd4301;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4343}, %fd2130;
	}
	setp.lt.s32 	%p1834, %r4343, 0;
	selp.b64 	%rd4302, %rd4300, %rd4301, %p1834;
	shl.b64 	%rd4303, %rd4302, 1;
	sub.s64 	%rd4304, %rd4303, %rd747;
	mov.b64 	%fd2131, %rd4304;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4344}, %fd2131;
	}
	setp.lt.s32 	%p1835, %r4344, 0;
	selp.b64 	%rd4305, %rd4303, %rd4304, %p1835;
	shl.b64 	%rd4306, %rd4305, 1;
	sub.s64 	%rd4307, %rd4306, %rd747;
	mov.b64 	%fd2132, %rd4307;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4345}, %fd2132;
	}
	setp.lt.s32 	%p1836, %r4345, 0;
	selp.b64 	%rd6468, %rd4306, %rd4307, %p1836;
	shl.b64 	%rd6465, %rd6468, 1;
	add.s32 	%r1100, %r6310, -16;
	setp.gt.s32 	%p1837, %r6310, 15;
	mov.u32 	%r6310, %r1100;
	@%p1837 bra 	$L__BB0_903;

$L__BB0_904:
	and.b64  	%rd762, %rd6468, 9223372036854775807;
	setp.eq.s64 	%p1838, %rd762, 0;
	mov.f64 	%fd3076, 0d0000000000000000;
	@%p1838 bra 	$L__BB0_906;

	mov.b64 	%fd2134, %rd762;
	mul.f64 	%fd2135, %fd2134, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4346}, %fd2135;
	}
	shr.u32 	%r4347, %r4346, 20;
	mov.u32 	%r4348, 55;
	sub.s32 	%r4349, %r4348, %r4347;
	sub.s32 	%r4350, %r6304, %r4349;
	shl.b64 	%rd4308, %rd762, %r4349;
	setp.lt.s32 	%p1839, %r4350, 1;
	mov.u32 	%r4351, 1;
	sub.s32 	%r4352, %r4351, %r4350;
	shr.u64 	%rd4309, %rd4308, %r4352;
	add.s32 	%r4353, %r4350, -1;
	cvt.u64.u32 	%rd4310, %r4353;
	shl.b64 	%rd4311, %rd4310, 52;
	add.s64 	%rd4312, %rd4311, %rd4308;
	selp.b64 	%rd4313, %rd4309, %rd4312, %p1839;
	mov.b64 	%fd3076, %rd4313;

$L__BB0_906:
	and.b32  	%r4354, %r1077, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4355}, %fd3076;
	}
	or.b32  	%r4356, %r4355, %r4354;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4357, %temp}, %fd3076;
	}
	mov.b64 	%fd3077, {%r4357, %r4356};
	bra.uni 	$L__BB0_910;

$L__BB0_908:
	mov.f64 	%fd2136, 0d3FF0000000000000;
	add.rn.f64 	%fd3077, %fd493, %fd2136;

$L__BB0_910:
	mov.f64 	%fd2137, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2138, %fd2137, %fd3077;
	mul.f64 	%fd2139, %fd2138, %fd15;
	mul.f64 	%fd2140, %fd2139, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r4358, %r6375, 7;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 103 28
	cvt.rn.f64.s32 	%fd2141, %r4358;
	fma.rn.f64 	%fd504, %fd2141, 0d400921FB54442D18, %fd2140;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1101}, %fd504;
	}
	and.b32  	%r4359, %r1101, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4360, %temp}, %fd504;
	}
	mov.b64 	%fd3078, {%r4360, %r4359};
	setp.gt.u32 	%p1844, %r4359, 2146435071;
	or.pred  	%p1846, %p1844, %p18;
	@%p1846 bra 	$L__BB0_927;
	bra.uni 	$L__BB0_911;

$L__BB0_927:
	.loc	1 0 9
	setp.le.f64 	%p1881, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1882, %fd3078, 0d7FF0000000000000;
	and.pred  	%p1883, %p1882, %p1881;
	@%p1883 bra 	$L__BB0_929;
	bra.uni 	$L__BB0_928;

$L__BB0_929:
	setp.eq.f64 	%p1884, %fd3078, 0d7FF0000000000000;
	selp.f64 	%fd3081, 0dFFF8000000000000, %fd504, %p1884;
	bra.uni 	$L__BB0_930;

$L__BB0_911:
	.loc	1 0 9
	mov.f64 	%fd3081, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_930;

	setp.ltu.f64 	%p1848, %fd3078, %fd3160;
	mov.f64 	%fd3081, %fd504;
	@%p1848 bra 	$L__BB0_930;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4361}, %fd3078;
	}
	shr.u32 	%r6312, %r4361, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4362}, %fd3160;
	}
	shr.u32 	%r6313, %r4362, 20;
	setp.ne.s32 	%p1849, %r6312, 0;
	@%p1849 bra 	$L__BB0_915;

	mul.f64 	%fd3078, %fd3078, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4363}, %fd3078;
	}
	shr.u32 	%r4364, %r4363, 20;
	add.s32 	%r6312, %r4364, -54;

$L__BB0_915:
	setp.ne.s32 	%p1850, %r6313, 0;
	mov.f64 	%fd3079, %fd3160;
	@%p1850 bra 	$L__BB0_917;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4365}, %fd2;
	}
	shr.u32 	%r4366, %r4365, 20;
	add.s32 	%r6313, %r4366, -54;
	mov.f64 	%fd3079, %fd2;

$L__BB0_917:
	mov.b64 	%rd4315, %fd3078;
	and.b64  	%rd4316, %rd4315, 4503599627370495;
	or.b64  	%rd6473, %rd4316, 4503599627370496;
	mov.b64 	%rd4317, %fd3079;
	and.b64  	%rd4318, %rd4317, 4503599627370495;
	or.b64  	%rd764, %rd4318, 4503599627370496;
	sub.s32 	%r6319, %r6312, %r6313;
	not.b32 	%r4367, %r6312;
	add.s32 	%r4368, %r6313, %r4367;
	max.s32 	%r4369, %r4368, -1;
	add.s32 	%r1109, %r4369, %r6312;
	mov.u32 	%r4370, 2;
	sub.s32 	%r4371, %r4370, %r6313;
	add.s32 	%r4372, %r4371, %r1109;
	and.b32  	%r6315, %r4372, 3;
	setp.eq.s32 	%p1851, %r6315, 0;
	@%p1851 bra 	$L__BB0_919;

$L__BB0_918:
	.pragma "nounroll";
	sub.s64 	%rd4319, %rd6473, %rd764;
	mov.b64 	%fd2143, %rd4319;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4373}, %fd2143;
	}
	setp.lt.s32 	%p1852, %r4373, 0;
	selp.b64 	%rd6476, %rd6473, %rd4319, %p1852;
	shl.b64 	%rd6473, %rd6476, 1;
	add.s32 	%r6319, %r6319, -1;
	add.s32 	%r6315, %r6315, -1;
	setp.ne.s32 	%p1853, %r6315, 0;
	@%p1853 bra 	$L__BB0_918;

$L__BB0_919:
	mov.u32 	%r4374, 1;
	sub.s32 	%r4375, %r4374, %r6313;
	add.s32 	%r4376, %r4375, %r1109;
	setp.lt.u32 	%p1854, %r4376, 3;
	@%p1854 bra 	$L__BB0_924;

	not.b32 	%r4377, %r6319;
	max.s32 	%r4378, %r4377, -4;
	add.s32 	%r4379, %r6319, %r4378;
	add.s32 	%r1116, %r4379, 4;
	shr.u32 	%r4380, %r1116, 2;
	add.s32 	%r4381, %r4380, 1;
	and.b32  	%r6318, %r4381, 3;
	setp.eq.s32 	%p1855, %r6318, 0;
	@%p1855 bra 	$L__BB0_922;

$L__BB0_921:
	.pragma "nounroll";
	sub.s64 	%rd4321, %rd6473, %rd764;
	mov.b64 	%fd2144, %rd4321;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4382}, %fd2144;
	}
	setp.lt.s32 	%p1856, %r4382, 0;
	selp.b64 	%rd4322, %rd6473, %rd4321, %p1856;
	shl.b64 	%rd4323, %rd4322, 1;
	sub.s64 	%rd4324, %rd4323, %rd764;
	mov.b64 	%fd2145, %rd4324;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4383}, %fd2145;
	}
	setp.lt.s32 	%p1857, %r4383, 0;
	selp.b64 	%rd4325, %rd4323, %rd4324, %p1857;
	shl.b64 	%rd4326, %rd4325, 1;
	sub.s64 	%rd4327, %rd4326, %rd764;
	mov.b64 	%fd2146, %rd4327;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4384}, %fd2146;
	}
	setp.lt.s32 	%p1858, %r4384, 0;
	selp.b64 	%rd4328, %rd4326, %rd4327, %p1858;
	shl.b64 	%rd4329, %rd4328, 1;
	sub.s64 	%rd4330, %rd4329, %rd764;
	mov.b64 	%fd2147, %rd4330;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4385}, %fd2147;
	}
	setp.lt.s32 	%p1859, %r4385, 0;
	selp.b64 	%rd6476, %rd4329, %rd4330, %p1859;
	shl.b64 	%rd6473, %rd6476, 1;
	add.s32 	%r6319, %r6319, -4;
	add.s32 	%r6318, %r6318, -1;
	setp.ne.s32 	%p1860, %r6318, 0;
	@%p1860 bra 	$L__BB0_921;

$L__BB0_922:
	setp.lt.u32 	%p1861, %r1116, 12;
	@%p1861 bra 	$L__BB0_924;

$L__BB0_923:
	sub.s64 	%rd4331, %rd6473, %rd764;
	mov.b64 	%fd2148, %rd4331;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4386}, %fd2148;
	}
	setp.lt.s32 	%p1862, %r4386, 0;
	selp.b64 	%rd4332, %rd6473, %rd4331, %p1862;
	shl.b64 	%rd4333, %rd4332, 1;
	sub.s64 	%rd4334, %rd4333, %rd764;
	mov.b64 	%fd2149, %rd4334;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4387}, %fd2149;
	}
	setp.lt.s32 	%p1863, %r4387, 0;
	selp.b64 	%rd4335, %rd4333, %rd4334, %p1863;
	shl.b64 	%rd4336, %rd4335, 1;
	sub.s64 	%rd4337, %rd4336, %rd764;
	mov.b64 	%fd2150, %rd4337;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4388}, %fd2150;
	}
	setp.lt.s32 	%p1864, %r4388, 0;
	selp.b64 	%rd4338, %rd4336, %rd4337, %p1864;
	shl.b64 	%rd4339, %rd4338, 1;
	sub.s64 	%rd4340, %rd4339, %rd764;
	mov.b64 	%fd2151, %rd4340;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4389}, %fd2151;
	}
	setp.lt.s32 	%p1865, %r4389, 0;
	selp.b64 	%rd4341, %rd4339, %rd4340, %p1865;
	shl.b64 	%rd4342, %rd4341, 1;
	sub.s64 	%rd4343, %rd4342, %rd764;
	mov.b64 	%fd2152, %rd4343;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4390}, %fd2152;
	}
	setp.lt.s32 	%p1866, %r4390, 0;
	selp.b64 	%rd4344, %rd4342, %rd4343, %p1866;
	shl.b64 	%rd4345, %rd4344, 1;
	sub.s64 	%rd4346, %rd4345, %rd764;
	mov.b64 	%fd2153, %rd4346;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4391}, %fd2153;
	}
	setp.lt.s32 	%p1867, %r4391, 0;
	selp.b64 	%rd4347, %rd4345, %rd4346, %p1867;
	shl.b64 	%rd4348, %rd4347, 1;
	sub.s64 	%rd4349, %rd4348, %rd764;
	mov.b64 	%fd2154, %rd4349;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4392}, %fd2154;
	}
	setp.lt.s32 	%p1868, %r4392, 0;
	selp.b64 	%rd4350, %rd4348, %rd4349, %p1868;
	shl.b64 	%rd4351, %rd4350, 1;
	sub.s64 	%rd4352, %rd4351, %rd764;
	mov.b64 	%fd2155, %rd4352;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4393}, %fd2155;
	}
	setp.lt.s32 	%p1869, %r4393, 0;
	selp.b64 	%rd4353, %rd4351, %rd4352, %p1869;
	shl.b64 	%rd4354, %rd4353, 1;
	sub.s64 	%rd4355, %rd4354, %rd764;
	mov.b64 	%fd2156, %rd4355;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4394}, %fd2156;
	}
	setp.lt.s32 	%p1870, %r4394, 0;
	selp.b64 	%rd4356, %rd4354, %rd4355, %p1870;
	shl.b64 	%rd4357, %rd4356, 1;
	sub.s64 	%rd4358, %rd4357, %rd764;
	mov.b64 	%fd2157, %rd4358;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4395}, %fd2157;
	}
	setp.lt.s32 	%p1871, %r4395, 0;
	selp.b64 	%rd4359, %rd4357, %rd4358, %p1871;
	shl.b64 	%rd4360, %rd4359, 1;
	sub.s64 	%rd4361, %rd4360, %rd764;
	mov.b64 	%fd2158, %rd4361;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4396}, %fd2158;
	}
	setp.lt.s32 	%p1872, %r4396, 0;
	selp.b64 	%rd4362, %rd4360, %rd4361, %p1872;
	shl.b64 	%rd4363, %rd4362, 1;
	sub.s64 	%rd4364, %rd4363, %rd764;
	mov.b64 	%fd2159, %rd4364;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4397}, %fd2159;
	}
	setp.lt.s32 	%p1873, %r4397, 0;
	selp.b64 	%rd4365, %rd4363, %rd4364, %p1873;
	shl.b64 	%rd4366, %rd4365, 1;
	sub.s64 	%rd4367, %rd4366, %rd764;
	mov.b64 	%fd2160, %rd4367;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4398}, %fd2160;
	}
	setp.lt.s32 	%p1874, %r4398, 0;
	selp.b64 	%rd4368, %rd4366, %rd4367, %p1874;
	shl.b64 	%rd4369, %rd4368, 1;
	sub.s64 	%rd4370, %rd4369, %rd764;
	mov.b64 	%fd2161, %rd4370;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4399}, %fd2161;
	}
	setp.lt.s32 	%p1875, %r4399, 0;
	selp.b64 	%rd4371, %rd4369, %rd4370, %p1875;
	shl.b64 	%rd4372, %rd4371, 1;
	sub.s64 	%rd4373, %rd4372, %rd764;
	mov.b64 	%fd2162, %rd4373;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4400}, %fd2162;
	}
	setp.lt.s32 	%p1876, %r4400, 0;
	selp.b64 	%rd4374, %rd4372, %rd4373, %p1876;
	shl.b64 	%rd4375, %rd4374, 1;
	sub.s64 	%rd4376, %rd4375, %rd764;
	mov.b64 	%fd2163, %rd4376;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4401}, %fd2163;
	}
	setp.lt.s32 	%p1877, %r4401, 0;
	selp.b64 	%rd6476, %rd4375, %rd4376, %p1877;
	shl.b64 	%rd6473, %rd6476, 1;
	add.s32 	%r1124, %r6319, -16;
	setp.gt.s32 	%p1878, %r6319, 15;
	mov.u32 	%r6319, %r1124;
	@%p1878 bra 	$L__BB0_923;

$L__BB0_924:
	and.b64  	%rd779, %rd6476, 9223372036854775807;
	setp.eq.s64 	%p1879, %rd779, 0;
	mov.f64 	%fd3080, 0d0000000000000000;
	@%p1879 bra 	$L__BB0_926;

	mov.b64 	%fd2165, %rd779;
	mul.f64 	%fd2166, %fd2165, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4402}, %fd2166;
	}
	shr.u32 	%r4403, %r4402, 20;
	mov.u32 	%r4404, 55;
	sub.s32 	%r4405, %r4404, %r4403;
	sub.s32 	%r4406, %r6313, %r4405;
	shl.b64 	%rd4377, %rd779, %r4405;
	setp.lt.s32 	%p1880, %r4406, 1;
	mov.u32 	%r4407, 1;
	sub.s32 	%r4408, %r4407, %r4406;
	shr.u64 	%rd4378, %rd4377, %r4408;
	add.s32 	%r4409, %r4406, -1;
	cvt.u64.u32 	%rd4379, %r4409;
	shl.b64 	%rd4380, %rd4379, 52;
	add.s64 	%rd4381, %rd4380, %rd4377;
	selp.b64 	%rd4382, %rd4378, %rd4381, %p1880;
	mov.b64 	%fd3080, %rd4382;

$L__BB0_926:
	and.b32  	%r4410, %r1101, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4411}, %fd3080;
	}
	or.b32  	%r4412, %r4411, %r4410;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4413, %temp}, %fd3080;
	}
	mov.b64 	%fd3081, {%r4413, %r4412};
	bra.uni 	$L__BB0_930;

$L__BB0_928:
	mov.f64 	%fd2167, 0d3FF0000000000000;
	add.rn.f64 	%fd3081, %fd504, %fd2167;

$L__BB0_930:
	mov.f64 	%fd2168, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2169, %fd2168, %fd3081;
	mul.f64 	%fd2170, %fd2169, %fd27;
	mul.f64 	%fd2171, %fd2170, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r4414, %r6375, 6;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 103 28
	cvt.rn.f64.s32 	%fd2172, %r4414;
	fma.rn.f64 	%fd515, %fd2172, 0d400921FB54442D18, %fd2171;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1125}, %fd515;
	}
	and.b32  	%r4415, %r1125, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4416, %temp}, %fd515;
	}
	mov.b64 	%fd3082, {%r4416, %r4415};
	setp.gt.u32 	%p1885, %r4415, 2146435071;
	or.pred  	%p1887, %p1885, %p18;
	@%p1887 bra 	$L__BB0_947;
	bra.uni 	$L__BB0_931;

$L__BB0_947:
	.loc	1 0 9
	setp.le.f64 	%p1922, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1923, %fd3082, 0d7FF0000000000000;
	and.pred  	%p1924, %p1923, %p1922;
	@%p1924 bra 	$L__BB0_949;
	bra.uni 	$L__BB0_948;

$L__BB0_949:
	setp.eq.f64 	%p1925, %fd3082, 0d7FF0000000000000;
	selp.f64 	%fd3085, 0dFFF8000000000000, %fd515, %p1925;
	bra.uni 	$L__BB0_950;

$L__BB0_931:
	.loc	1 0 9
	mov.f64 	%fd3085, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_950;

	setp.ltu.f64 	%p1889, %fd3082, %fd3160;
	mov.f64 	%fd3085, %fd515;
	@%p1889 bra 	$L__BB0_950;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4417}, %fd3082;
	}
	shr.u32 	%r6321, %r4417, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4418}, %fd3160;
	}
	shr.u32 	%r6322, %r4418, 20;
	setp.ne.s32 	%p1890, %r6321, 0;
	@%p1890 bra 	$L__BB0_935;

	mul.f64 	%fd3082, %fd3082, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4419}, %fd3082;
	}
	shr.u32 	%r4420, %r4419, 20;
	add.s32 	%r6321, %r4420, -54;

$L__BB0_935:
	setp.ne.s32 	%p1891, %r6322, 0;
	mov.f64 	%fd3083, %fd3160;
	@%p1891 bra 	$L__BB0_937;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4421}, %fd2;
	}
	shr.u32 	%r4422, %r4421, 20;
	add.s32 	%r6322, %r4422, -54;
	mov.f64 	%fd3083, %fd2;

$L__BB0_937:
	mov.b64 	%rd4384, %fd3082;
	and.b64  	%rd4385, %rd4384, 4503599627370495;
	or.b64  	%rd6481, %rd4385, 4503599627370496;
	mov.b64 	%rd4386, %fd3083;
	and.b64  	%rd4387, %rd4386, 4503599627370495;
	or.b64  	%rd781, %rd4387, 4503599627370496;
	sub.s32 	%r6328, %r6321, %r6322;
	not.b32 	%r4423, %r6321;
	add.s32 	%r4424, %r6322, %r4423;
	max.s32 	%r4425, %r4424, -1;
	add.s32 	%r1133, %r4425, %r6321;
	mov.u32 	%r4426, 2;
	sub.s32 	%r4427, %r4426, %r6322;
	add.s32 	%r4428, %r4427, %r1133;
	and.b32  	%r6324, %r4428, 3;
	setp.eq.s32 	%p1892, %r6324, 0;
	@%p1892 bra 	$L__BB0_939;

$L__BB0_938:
	.pragma "nounroll";
	sub.s64 	%rd4388, %rd6481, %rd781;
	mov.b64 	%fd2174, %rd4388;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4429}, %fd2174;
	}
	setp.lt.s32 	%p1893, %r4429, 0;
	selp.b64 	%rd6484, %rd6481, %rd4388, %p1893;
	shl.b64 	%rd6481, %rd6484, 1;
	add.s32 	%r6328, %r6328, -1;
	add.s32 	%r6324, %r6324, -1;
	setp.ne.s32 	%p1894, %r6324, 0;
	@%p1894 bra 	$L__BB0_938;

$L__BB0_939:
	mov.u32 	%r4430, 1;
	sub.s32 	%r4431, %r4430, %r6322;
	add.s32 	%r4432, %r4431, %r1133;
	setp.lt.u32 	%p1895, %r4432, 3;
	@%p1895 bra 	$L__BB0_944;

	not.b32 	%r4433, %r6328;
	max.s32 	%r4434, %r4433, -4;
	add.s32 	%r4435, %r6328, %r4434;
	add.s32 	%r1140, %r4435, 4;
	shr.u32 	%r4436, %r1140, 2;
	add.s32 	%r4437, %r4436, 1;
	and.b32  	%r6327, %r4437, 3;
	setp.eq.s32 	%p1896, %r6327, 0;
	@%p1896 bra 	$L__BB0_942;

$L__BB0_941:
	.pragma "nounroll";
	sub.s64 	%rd4390, %rd6481, %rd781;
	mov.b64 	%fd2175, %rd4390;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4438}, %fd2175;
	}
	setp.lt.s32 	%p1897, %r4438, 0;
	selp.b64 	%rd4391, %rd6481, %rd4390, %p1897;
	shl.b64 	%rd4392, %rd4391, 1;
	sub.s64 	%rd4393, %rd4392, %rd781;
	mov.b64 	%fd2176, %rd4393;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4439}, %fd2176;
	}
	setp.lt.s32 	%p1898, %r4439, 0;
	selp.b64 	%rd4394, %rd4392, %rd4393, %p1898;
	shl.b64 	%rd4395, %rd4394, 1;
	sub.s64 	%rd4396, %rd4395, %rd781;
	mov.b64 	%fd2177, %rd4396;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4440}, %fd2177;
	}
	setp.lt.s32 	%p1899, %r4440, 0;
	selp.b64 	%rd4397, %rd4395, %rd4396, %p1899;
	shl.b64 	%rd4398, %rd4397, 1;
	sub.s64 	%rd4399, %rd4398, %rd781;
	mov.b64 	%fd2178, %rd4399;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4441}, %fd2178;
	}
	setp.lt.s32 	%p1900, %r4441, 0;
	selp.b64 	%rd6484, %rd4398, %rd4399, %p1900;
	shl.b64 	%rd6481, %rd6484, 1;
	add.s32 	%r6328, %r6328, -4;
	add.s32 	%r6327, %r6327, -1;
	setp.ne.s32 	%p1901, %r6327, 0;
	@%p1901 bra 	$L__BB0_941;

$L__BB0_942:
	setp.lt.u32 	%p1902, %r1140, 12;
	@%p1902 bra 	$L__BB0_944;

$L__BB0_943:
	sub.s64 	%rd4400, %rd6481, %rd781;
	mov.b64 	%fd2179, %rd4400;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4442}, %fd2179;
	}
	setp.lt.s32 	%p1903, %r4442, 0;
	selp.b64 	%rd4401, %rd6481, %rd4400, %p1903;
	shl.b64 	%rd4402, %rd4401, 1;
	sub.s64 	%rd4403, %rd4402, %rd781;
	mov.b64 	%fd2180, %rd4403;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4443}, %fd2180;
	}
	setp.lt.s32 	%p1904, %r4443, 0;
	selp.b64 	%rd4404, %rd4402, %rd4403, %p1904;
	shl.b64 	%rd4405, %rd4404, 1;
	sub.s64 	%rd4406, %rd4405, %rd781;
	mov.b64 	%fd2181, %rd4406;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4444}, %fd2181;
	}
	setp.lt.s32 	%p1905, %r4444, 0;
	selp.b64 	%rd4407, %rd4405, %rd4406, %p1905;
	shl.b64 	%rd4408, %rd4407, 1;
	sub.s64 	%rd4409, %rd4408, %rd781;
	mov.b64 	%fd2182, %rd4409;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4445}, %fd2182;
	}
	setp.lt.s32 	%p1906, %r4445, 0;
	selp.b64 	%rd4410, %rd4408, %rd4409, %p1906;
	shl.b64 	%rd4411, %rd4410, 1;
	sub.s64 	%rd4412, %rd4411, %rd781;
	mov.b64 	%fd2183, %rd4412;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4446}, %fd2183;
	}
	setp.lt.s32 	%p1907, %r4446, 0;
	selp.b64 	%rd4413, %rd4411, %rd4412, %p1907;
	shl.b64 	%rd4414, %rd4413, 1;
	sub.s64 	%rd4415, %rd4414, %rd781;
	mov.b64 	%fd2184, %rd4415;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4447}, %fd2184;
	}
	setp.lt.s32 	%p1908, %r4447, 0;
	selp.b64 	%rd4416, %rd4414, %rd4415, %p1908;
	shl.b64 	%rd4417, %rd4416, 1;
	sub.s64 	%rd4418, %rd4417, %rd781;
	mov.b64 	%fd2185, %rd4418;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4448}, %fd2185;
	}
	setp.lt.s32 	%p1909, %r4448, 0;
	selp.b64 	%rd4419, %rd4417, %rd4418, %p1909;
	shl.b64 	%rd4420, %rd4419, 1;
	sub.s64 	%rd4421, %rd4420, %rd781;
	mov.b64 	%fd2186, %rd4421;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4449}, %fd2186;
	}
	setp.lt.s32 	%p1910, %r4449, 0;
	selp.b64 	%rd4422, %rd4420, %rd4421, %p1910;
	shl.b64 	%rd4423, %rd4422, 1;
	sub.s64 	%rd4424, %rd4423, %rd781;
	mov.b64 	%fd2187, %rd4424;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4450}, %fd2187;
	}
	setp.lt.s32 	%p1911, %r4450, 0;
	selp.b64 	%rd4425, %rd4423, %rd4424, %p1911;
	shl.b64 	%rd4426, %rd4425, 1;
	sub.s64 	%rd4427, %rd4426, %rd781;
	mov.b64 	%fd2188, %rd4427;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4451}, %fd2188;
	}
	setp.lt.s32 	%p1912, %r4451, 0;
	selp.b64 	%rd4428, %rd4426, %rd4427, %p1912;
	shl.b64 	%rd4429, %rd4428, 1;
	sub.s64 	%rd4430, %rd4429, %rd781;
	mov.b64 	%fd2189, %rd4430;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4452}, %fd2189;
	}
	setp.lt.s32 	%p1913, %r4452, 0;
	selp.b64 	%rd4431, %rd4429, %rd4430, %p1913;
	shl.b64 	%rd4432, %rd4431, 1;
	sub.s64 	%rd4433, %rd4432, %rd781;
	mov.b64 	%fd2190, %rd4433;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4453}, %fd2190;
	}
	setp.lt.s32 	%p1914, %r4453, 0;
	selp.b64 	%rd4434, %rd4432, %rd4433, %p1914;
	shl.b64 	%rd4435, %rd4434, 1;
	sub.s64 	%rd4436, %rd4435, %rd781;
	mov.b64 	%fd2191, %rd4436;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4454}, %fd2191;
	}
	setp.lt.s32 	%p1915, %r4454, 0;
	selp.b64 	%rd4437, %rd4435, %rd4436, %p1915;
	shl.b64 	%rd4438, %rd4437, 1;
	sub.s64 	%rd4439, %rd4438, %rd781;
	mov.b64 	%fd2192, %rd4439;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4455}, %fd2192;
	}
	setp.lt.s32 	%p1916, %r4455, 0;
	selp.b64 	%rd4440, %rd4438, %rd4439, %p1916;
	shl.b64 	%rd4441, %rd4440, 1;
	sub.s64 	%rd4442, %rd4441, %rd781;
	mov.b64 	%fd2193, %rd4442;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4456}, %fd2193;
	}
	setp.lt.s32 	%p1917, %r4456, 0;
	selp.b64 	%rd4443, %rd4441, %rd4442, %p1917;
	shl.b64 	%rd4444, %rd4443, 1;
	sub.s64 	%rd4445, %rd4444, %rd781;
	mov.b64 	%fd2194, %rd4445;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4457}, %fd2194;
	}
	setp.lt.s32 	%p1918, %r4457, 0;
	selp.b64 	%rd6484, %rd4444, %rd4445, %p1918;
	shl.b64 	%rd6481, %rd6484, 1;
	add.s32 	%r1148, %r6328, -16;
	setp.gt.s32 	%p1919, %r6328, 15;
	mov.u32 	%r6328, %r1148;
	@%p1919 bra 	$L__BB0_943;

$L__BB0_944:
	and.b64  	%rd796, %rd6484, 9223372036854775807;
	setp.eq.s64 	%p1920, %rd796, 0;
	mov.f64 	%fd3084, 0d0000000000000000;
	@%p1920 bra 	$L__BB0_946;

	mov.b64 	%fd2196, %rd796;
	mul.f64 	%fd2197, %fd2196, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4458}, %fd2197;
	}
	shr.u32 	%r4459, %r4458, 20;
	mov.u32 	%r4460, 55;
	sub.s32 	%r4461, %r4460, %r4459;
	sub.s32 	%r4462, %r6322, %r4461;
	shl.b64 	%rd4446, %rd796, %r4461;
	setp.lt.s32 	%p1921, %r4462, 1;
	mov.u32 	%r4463, 1;
	sub.s32 	%r4464, %r4463, %r4462;
	shr.u64 	%rd4447, %rd4446, %r4464;
	add.s32 	%r4465, %r4462, -1;
	cvt.u64.u32 	%rd4448, %r4465;
	shl.b64 	%rd4449, %rd4448, 52;
	add.s64 	%rd4450, %rd4449, %rd4446;
	selp.b64 	%rd4451, %rd4447, %rd4450, %p1921;
	mov.b64 	%fd3084, %rd4451;

$L__BB0_946:
	and.b32  	%r4466, %r1125, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4467}, %fd3084;
	}
	or.b32  	%r4468, %r4467, %r4466;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4469, %temp}, %fd3084;
	}
	mov.b64 	%fd3085, {%r4469, %r4468};
	bra.uni 	$L__BB0_950;

$L__BB0_948:
	mov.f64 	%fd2198, 0d3FF0000000000000;
	add.rn.f64 	%fd3085, %fd515, %fd2198;

$L__BB0_950:
	mov.f64 	%fd2199, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2200, %fd2199, %fd3085;
	mul.f64 	%fd2201, %fd2200, %fd39;
	mul.f64 	%fd2202, %fd2201, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r4470, %r6375, 5;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 103 28
	cvt.rn.f64.s32 	%fd2203, %r4470;
	fma.rn.f64 	%fd526, %fd2203, 0d400921FB54442D18, %fd2202;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1149}, %fd526;
	}
	and.b32  	%r4471, %r1149, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4472, %temp}, %fd526;
	}
	mov.b64 	%fd3086, {%r4472, %r4471};
	setp.gt.u32 	%p1926, %r4471, 2146435071;
	or.pred  	%p1928, %p1926, %p18;
	@%p1928 bra 	$L__BB0_967;
	bra.uni 	$L__BB0_951;

$L__BB0_967:
	.loc	1 0 9
	setp.le.f64 	%p1963, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p1964, %fd3086, 0d7FF0000000000000;
	and.pred  	%p1965, %p1964, %p1963;
	@%p1965 bra 	$L__BB0_969;
	bra.uni 	$L__BB0_968;

$L__BB0_969:
	setp.eq.f64 	%p1966, %fd3086, 0d7FF0000000000000;
	selp.f64 	%fd3089, 0dFFF8000000000000, %fd526, %p1966;
	bra.uni 	$L__BB0_970;

$L__BB0_951:
	.loc	1 0 9
	mov.f64 	%fd3089, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_970;

	setp.ltu.f64 	%p1930, %fd3086, %fd3160;
	mov.f64 	%fd3089, %fd526;
	@%p1930 bra 	$L__BB0_970;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4473}, %fd3086;
	}
	shr.u32 	%r6330, %r4473, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4474}, %fd3160;
	}
	shr.u32 	%r6331, %r4474, 20;
	setp.ne.s32 	%p1931, %r6330, 0;
	@%p1931 bra 	$L__BB0_955;

	mul.f64 	%fd3086, %fd3086, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4475}, %fd3086;
	}
	shr.u32 	%r4476, %r4475, 20;
	add.s32 	%r6330, %r4476, -54;

$L__BB0_955:
	setp.ne.s32 	%p1932, %r6331, 0;
	mov.f64 	%fd3087, %fd3160;
	@%p1932 bra 	$L__BB0_957;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4477}, %fd2;
	}
	shr.u32 	%r4478, %r4477, 20;
	add.s32 	%r6331, %r4478, -54;
	mov.f64 	%fd3087, %fd2;

$L__BB0_957:
	mov.b64 	%rd4453, %fd3086;
	and.b64  	%rd4454, %rd4453, 4503599627370495;
	or.b64  	%rd6489, %rd4454, 4503599627370496;
	mov.b64 	%rd4455, %fd3087;
	and.b64  	%rd4456, %rd4455, 4503599627370495;
	or.b64  	%rd798, %rd4456, 4503599627370496;
	sub.s32 	%r6337, %r6330, %r6331;
	not.b32 	%r4479, %r6330;
	add.s32 	%r4480, %r6331, %r4479;
	max.s32 	%r4481, %r4480, -1;
	add.s32 	%r1157, %r4481, %r6330;
	mov.u32 	%r4482, 2;
	sub.s32 	%r4483, %r4482, %r6331;
	add.s32 	%r4484, %r4483, %r1157;
	and.b32  	%r6333, %r4484, 3;
	setp.eq.s32 	%p1933, %r6333, 0;
	@%p1933 bra 	$L__BB0_959;

$L__BB0_958:
	.pragma "nounroll";
	sub.s64 	%rd4457, %rd6489, %rd798;
	mov.b64 	%fd2205, %rd4457;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4485}, %fd2205;
	}
	setp.lt.s32 	%p1934, %r4485, 0;
	selp.b64 	%rd6492, %rd6489, %rd4457, %p1934;
	shl.b64 	%rd6489, %rd6492, 1;
	add.s32 	%r6337, %r6337, -1;
	add.s32 	%r6333, %r6333, -1;
	setp.ne.s32 	%p1935, %r6333, 0;
	@%p1935 bra 	$L__BB0_958;

$L__BB0_959:
	mov.u32 	%r4486, 1;
	sub.s32 	%r4487, %r4486, %r6331;
	add.s32 	%r4488, %r4487, %r1157;
	setp.lt.u32 	%p1936, %r4488, 3;
	@%p1936 bra 	$L__BB0_964;

	not.b32 	%r4489, %r6337;
	max.s32 	%r4490, %r4489, -4;
	add.s32 	%r4491, %r6337, %r4490;
	add.s32 	%r1164, %r4491, 4;
	shr.u32 	%r4492, %r1164, 2;
	add.s32 	%r4493, %r4492, 1;
	and.b32  	%r6336, %r4493, 3;
	setp.eq.s32 	%p1937, %r6336, 0;
	@%p1937 bra 	$L__BB0_962;

$L__BB0_961:
	.pragma "nounroll";
	sub.s64 	%rd4459, %rd6489, %rd798;
	mov.b64 	%fd2206, %rd4459;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4494}, %fd2206;
	}
	setp.lt.s32 	%p1938, %r4494, 0;
	selp.b64 	%rd4460, %rd6489, %rd4459, %p1938;
	shl.b64 	%rd4461, %rd4460, 1;
	sub.s64 	%rd4462, %rd4461, %rd798;
	mov.b64 	%fd2207, %rd4462;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4495}, %fd2207;
	}
	setp.lt.s32 	%p1939, %r4495, 0;
	selp.b64 	%rd4463, %rd4461, %rd4462, %p1939;
	shl.b64 	%rd4464, %rd4463, 1;
	sub.s64 	%rd4465, %rd4464, %rd798;
	mov.b64 	%fd2208, %rd4465;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4496}, %fd2208;
	}
	setp.lt.s32 	%p1940, %r4496, 0;
	selp.b64 	%rd4466, %rd4464, %rd4465, %p1940;
	shl.b64 	%rd4467, %rd4466, 1;
	sub.s64 	%rd4468, %rd4467, %rd798;
	mov.b64 	%fd2209, %rd4468;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4497}, %fd2209;
	}
	setp.lt.s32 	%p1941, %r4497, 0;
	selp.b64 	%rd6492, %rd4467, %rd4468, %p1941;
	shl.b64 	%rd6489, %rd6492, 1;
	add.s32 	%r6337, %r6337, -4;
	add.s32 	%r6336, %r6336, -1;
	setp.ne.s32 	%p1942, %r6336, 0;
	@%p1942 bra 	$L__BB0_961;

$L__BB0_962:
	setp.lt.u32 	%p1943, %r1164, 12;
	@%p1943 bra 	$L__BB0_964;

$L__BB0_963:
	sub.s64 	%rd4469, %rd6489, %rd798;
	mov.b64 	%fd2210, %rd4469;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4498}, %fd2210;
	}
	setp.lt.s32 	%p1944, %r4498, 0;
	selp.b64 	%rd4470, %rd6489, %rd4469, %p1944;
	shl.b64 	%rd4471, %rd4470, 1;
	sub.s64 	%rd4472, %rd4471, %rd798;
	mov.b64 	%fd2211, %rd4472;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4499}, %fd2211;
	}
	setp.lt.s32 	%p1945, %r4499, 0;
	selp.b64 	%rd4473, %rd4471, %rd4472, %p1945;
	shl.b64 	%rd4474, %rd4473, 1;
	sub.s64 	%rd4475, %rd4474, %rd798;
	mov.b64 	%fd2212, %rd4475;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4500}, %fd2212;
	}
	setp.lt.s32 	%p1946, %r4500, 0;
	selp.b64 	%rd4476, %rd4474, %rd4475, %p1946;
	shl.b64 	%rd4477, %rd4476, 1;
	sub.s64 	%rd4478, %rd4477, %rd798;
	mov.b64 	%fd2213, %rd4478;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4501}, %fd2213;
	}
	setp.lt.s32 	%p1947, %r4501, 0;
	selp.b64 	%rd4479, %rd4477, %rd4478, %p1947;
	shl.b64 	%rd4480, %rd4479, 1;
	sub.s64 	%rd4481, %rd4480, %rd798;
	mov.b64 	%fd2214, %rd4481;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4502}, %fd2214;
	}
	setp.lt.s32 	%p1948, %r4502, 0;
	selp.b64 	%rd4482, %rd4480, %rd4481, %p1948;
	shl.b64 	%rd4483, %rd4482, 1;
	sub.s64 	%rd4484, %rd4483, %rd798;
	mov.b64 	%fd2215, %rd4484;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4503}, %fd2215;
	}
	setp.lt.s32 	%p1949, %r4503, 0;
	selp.b64 	%rd4485, %rd4483, %rd4484, %p1949;
	shl.b64 	%rd4486, %rd4485, 1;
	sub.s64 	%rd4487, %rd4486, %rd798;
	mov.b64 	%fd2216, %rd4487;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4504}, %fd2216;
	}
	setp.lt.s32 	%p1950, %r4504, 0;
	selp.b64 	%rd4488, %rd4486, %rd4487, %p1950;
	shl.b64 	%rd4489, %rd4488, 1;
	sub.s64 	%rd4490, %rd4489, %rd798;
	mov.b64 	%fd2217, %rd4490;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4505}, %fd2217;
	}
	setp.lt.s32 	%p1951, %r4505, 0;
	selp.b64 	%rd4491, %rd4489, %rd4490, %p1951;
	shl.b64 	%rd4492, %rd4491, 1;
	sub.s64 	%rd4493, %rd4492, %rd798;
	mov.b64 	%fd2218, %rd4493;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4506}, %fd2218;
	}
	setp.lt.s32 	%p1952, %r4506, 0;
	selp.b64 	%rd4494, %rd4492, %rd4493, %p1952;
	shl.b64 	%rd4495, %rd4494, 1;
	sub.s64 	%rd4496, %rd4495, %rd798;
	mov.b64 	%fd2219, %rd4496;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4507}, %fd2219;
	}
	setp.lt.s32 	%p1953, %r4507, 0;
	selp.b64 	%rd4497, %rd4495, %rd4496, %p1953;
	shl.b64 	%rd4498, %rd4497, 1;
	sub.s64 	%rd4499, %rd4498, %rd798;
	mov.b64 	%fd2220, %rd4499;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4508}, %fd2220;
	}
	setp.lt.s32 	%p1954, %r4508, 0;
	selp.b64 	%rd4500, %rd4498, %rd4499, %p1954;
	shl.b64 	%rd4501, %rd4500, 1;
	sub.s64 	%rd4502, %rd4501, %rd798;
	mov.b64 	%fd2221, %rd4502;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4509}, %fd2221;
	}
	setp.lt.s32 	%p1955, %r4509, 0;
	selp.b64 	%rd4503, %rd4501, %rd4502, %p1955;
	shl.b64 	%rd4504, %rd4503, 1;
	sub.s64 	%rd4505, %rd4504, %rd798;
	mov.b64 	%fd2222, %rd4505;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4510}, %fd2222;
	}
	setp.lt.s32 	%p1956, %r4510, 0;
	selp.b64 	%rd4506, %rd4504, %rd4505, %p1956;
	shl.b64 	%rd4507, %rd4506, 1;
	sub.s64 	%rd4508, %rd4507, %rd798;
	mov.b64 	%fd2223, %rd4508;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4511}, %fd2223;
	}
	setp.lt.s32 	%p1957, %r4511, 0;
	selp.b64 	%rd4509, %rd4507, %rd4508, %p1957;
	shl.b64 	%rd4510, %rd4509, 1;
	sub.s64 	%rd4511, %rd4510, %rd798;
	mov.b64 	%fd2224, %rd4511;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4512}, %fd2224;
	}
	setp.lt.s32 	%p1958, %r4512, 0;
	selp.b64 	%rd4512, %rd4510, %rd4511, %p1958;
	shl.b64 	%rd4513, %rd4512, 1;
	sub.s64 	%rd4514, %rd4513, %rd798;
	mov.b64 	%fd2225, %rd4514;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4513}, %fd2225;
	}
	setp.lt.s32 	%p1959, %r4513, 0;
	selp.b64 	%rd6492, %rd4513, %rd4514, %p1959;
	shl.b64 	%rd6489, %rd6492, 1;
	add.s32 	%r1172, %r6337, -16;
	setp.gt.s32 	%p1960, %r6337, 15;
	mov.u32 	%r6337, %r1172;
	@%p1960 bra 	$L__BB0_963;

$L__BB0_964:
	and.b64  	%rd813, %rd6492, 9223372036854775807;
	setp.eq.s64 	%p1961, %rd813, 0;
	mov.f64 	%fd3088, 0d0000000000000000;
	@%p1961 bra 	$L__BB0_966;

	mov.b64 	%fd2227, %rd813;
	mul.f64 	%fd2228, %fd2227, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4514}, %fd2228;
	}
	shr.u32 	%r4515, %r4514, 20;
	mov.u32 	%r4516, 55;
	sub.s32 	%r4517, %r4516, %r4515;
	sub.s32 	%r4518, %r6331, %r4517;
	shl.b64 	%rd4515, %rd813, %r4517;
	setp.lt.s32 	%p1962, %r4518, 1;
	mov.u32 	%r4519, 1;
	sub.s32 	%r4520, %r4519, %r4518;
	shr.u64 	%rd4516, %rd4515, %r4520;
	add.s32 	%r4521, %r4518, -1;
	cvt.u64.u32 	%rd4517, %r4521;
	shl.b64 	%rd4518, %rd4517, 52;
	add.s64 	%rd4519, %rd4518, %rd4515;
	selp.b64 	%rd4520, %rd4516, %rd4519, %p1962;
	mov.b64 	%fd3088, %rd4520;

$L__BB0_966:
	and.b32  	%r4522, %r1149, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4523}, %fd3088;
	}
	or.b32  	%r4524, %r4523, %r4522;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4525, %temp}, %fd3088;
	}
	mov.b64 	%fd3089, {%r4525, %r4524};
	bra.uni 	$L__BB0_970;

$L__BB0_968:
	mov.f64 	%fd2229, 0d3FF0000000000000;
	add.rn.f64 	%fd3089, %fd526, %fd2229;

$L__BB0_970:
	mov.f64 	%fd2230, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2231, %fd2230, %fd3089;
	mul.f64 	%fd2232, %fd2231, %fd51;
	mul.f64 	%fd2233, %fd2232, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r4526, %r6375, 4;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 103 28
	cvt.rn.f64.s32 	%fd2234, %r4526;
	fma.rn.f64 	%fd537, %fd2234, 0d400921FB54442D18, %fd2233;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1173}, %fd537;
	}
	and.b32  	%r4527, %r1173, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4528, %temp}, %fd537;
	}
	mov.b64 	%fd3090, {%r4528, %r4527};
	setp.gt.u32 	%p1967, %r4527, 2146435071;
	or.pred  	%p1969, %p1967, %p18;
	@%p1969 bra 	$L__BB0_987;
	bra.uni 	$L__BB0_971;

$L__BB0_987:
	.loc	1 0 9
	setp.le.f64 	%p2004, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p2005, %fd3090, 0d7FF0000000000000;
	and.pred  	%p2006, %p2005, %p2004;
	@%p2006 bra 	$L__BB0_989;
	bra.uni 	$L__BB0_988;

$L__BB0_989:
	setp.eq.f64 	%p2007, %fd3090, 0d7FF0000000000000;
	selp.f64 	%fd3093, 0dFFF8000000000000, %fd537, %p2007;
	bra.uni 	$L__BB0_990;

$L__BB0_971:
	.loc	1 0 9
	mov.f64 	%fd3093, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_990;

	setp.ltu.f64 	%p1971, %fd3090, %fd3160;
	mov.f64 	%fd3093, %fd537;
	@%p1971 bra 	$L__BB0_990;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4529}, %fd3090;
	}
	shr.u32 	%r6339, %r4529, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4530}, %fd3160;
	}
	shr.u32 	%r6340, %r4530, 20;
	setp.ne.s32 	%p1972, %r6339, 0;
	@%p1972 bra 	$L__BB0_975;

	mul.f64 	%fd3090, %fd3090, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4531}, %fd3090;
	}
	shr.u32 	%r4532, %r4531, 20;
	add.s32 	%r6339, %r4532, -54;

$L__BB0_975:
	setp.ne.s32 	%p1973, %r6340, 0;
	mov.f64 	%fd3091, %fd3160;
	@%p1973 bra 	$L__BB0_977;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4533}, %fd2;
	}
	shr.u32 	%r4534, %r4533, 20;
	add.s32 	%r6340, %r4534, -54;
	mov.f64 	%fd3091, %fd2;

$L__BB0_977:
	mov.b64 	%rd4522, %fd3090;
	and.b64  	%rd4523, %rd4522, 4503599627370495;
	or.b64  	%rd6497, %rd4523, 4503599627370496;
	mov.b64 	%rd4524, %fd3091;
	and.b64  	%rd4525, %rd4524, 4503599627370495;
	or.b64  	%rd815, %rd4525, 4503599627370496;
	sub.s32 	%r6346, %r6339, %r6340;
	not.b32 	%r4535, %r6339;
	add.s32 	%r4536, %r6340, %r4535;
	max.s32 	%r4537, %r4536, -1;
	add.s32 	%r1181, %r4537, %r6339;
	mov.u32 	%r4538, 2;
	sub.s32 	%r4539, %r4538, %r6340;
	add.s32 	%r4540, %r4539, %r1181;
	and.b32  	%r6342, %r4540, 3;
	setp.eq.s32 	%p1974, %r6342, 0;
	@%p1974 bra 	$L__BB0_979;

$L__BB0_978:
	.pragma "nounroll";
	sub.s64 	%rd4526, %rd6497, %rd815;
	mov.b64 	%fd2236, %rd4526;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4541}, %fd2236;
	}
	setp.lt.s32 	%p1975, %r4541, 0;
	selp.b64 	%rd6500, %rd6497, %rd4526, %p1975;
	shl.b64 	%rd6497, %rd6500, 1;
	add.s32 	%r6346, %r6346, -1;
	add.s32 	%r6342, %r6342, -1;
	setp.ne.s32 	%p1976, %r6342, 0;
	@%p1976 bra 	$L__BB0_978;

$L__BB0_979:
	mov.u32 	%r4542, 1;
	sub.s32 	%r4543, %r4542, %r6340;
	add.s32 	%r4544, %r4543, %r1181;
	setp.lt.u32 	%p1977, %r4544, 3;
	@%p1977 bra 	$L__BB0_984;

	not.b32 	%r4545, %r6346;
	max.s32 	%r4546, %r4545, -4;
	add.s32 	%r4547, %r6346, %r4546;
	add.s32 	%r1188, %r4547, 4;
	shr.u32 	%r4548, %r1188, 2;
	add.s32 	%r4549, %r4548, 1;
	and.b32  	%r6345, %r4549, 3;
	setp.eq.s32 	%p1978, %r6345, 0;
	@%p1978 bra 	$L__BB0_982;

$L__BB0_981:
	.pragma "nounroll";
	sub.s64 	%rd4528, %rd6497, %rd815;
	mov.b64 	%fd2237, %rd4528;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4550}, %fd2237;
	}
	setp.lt.s32 	%p1979, %r4550, 0;
	selp.b64 	%rd4529, %rd6497, %rd4528, %p1979;
	shl.b64 	%rd4530, %rd4529, 1;
	sub.s64 	%rd4531, %rd4530, %rd815;
	mov.b64 	%fd2238, %rd4531;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4551}, %fd2238;
	}
	setp.lt.s32 	%p1980, %r4551, 0;
	selp.b64 	%rd4532, %rd4530, %rd4531, %p1980;
	shl.b64 	%rd4533, %rd4532, 1;
	sub.s64 	%rd4534, %rd4533, %rd815;
	mov.b64 	%fd2239, %rd4534;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4552}, %fd2239;
	}
	setp.lt.s32 	%p1981, %r4552, 0;
	selp.b64 	%rd4535, %rd4533, %rd4534, %p1981;
	shl.b64 	%rd4536, %rd4535, 1;
	sub.s64 	%rd4537, %rd4536, %rd815;
	mov.b64 	%fd2240, %rd4537;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4553}, %fd2240;
	}
	setp.lt.s32 	%p1982, %r4553, 0;
	selp.b64 	%rd6500, %rd4536, %rd4537, %p1982;
	shl.b64 	%rd6497, %rd6500, 1;
	add.s32 	%r6346, %r6346, -4;
	add.s32 	%r6345, %r6345, -1;
	setp.ne.s32 	%p1983, %r6345, 0;
	@%p1983 bra 	$L__BB0_981;

$L__BB0_982:
	setp.lt.u32 	%p1984, %r1188, 12;
	@%p1984 bra 	$L__BB0_984;

$L__BB0_983:
	sub.s64 	%rd4538, %rd6497, %rd815;
	mov.b64 	%fd2241, %rd4538;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4554}, %fd2241;
	}
	setp.lt.s32 	%p1985, %r4554, 0;
	selp.b64 	%rd4539, %rd6497, %rd4538, %p1985;
	shl.b64 	%rd4540, %rd4539, 1;
	sub.s64 	%rd4541, %rd4540, %rd815;
	mov.b64 	%fd2242, %rd4541;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4555}, %fd2242;
	}
	setp.lt.s32 	%p1986, %r4555, 0;
	selp.b64 	%rd4542, %rd4540, %rd4541, %p1986;
	shl.b64 	%rd4543, %rd4542, 1;
	sub.s64 	%rd4544, %rd4543, %rd815;
	mov.b64 	%fd2243, %rd4544;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4556}, %fd2243;
	}
	setp.lt.s32 	%p1987, %r4556, 0;
	selp.b64 	%rd4545, %rd4543, %rd4544, %p1987;
	shl.b64 	%rd4546, %rd4545, 1;
	sub.s64 	%rd4547, %rd4546, %rd815;
	mov.b64 	%fd2244, %rd4547;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4557}, %fd2244;
	}
	setp.lt.s32 	%p1988, %r4557, 0;
	selp.b64 	%rd4548, %rd4546, %rd4547, %p1988;
	shl.b64 	%rd4549, %rd4548, 1;
	sub.s64 	%rd4550, %rd4549, %rd815;
	mov.b64 	%fd2245, %rd4550;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4558}, %fd2245;
	}
	setp.lt.s32 	%p1989, %r4558, 0;
	selp.b64 	%rd4551, %rd4549, %rd4550, %p1989;
	shl.b64 	%rd4552, %rd4551, 1;
	sub.s64 	%rd4553, %rd4552, %rd815;
	mov.b64 	%fd2246, %rd4553;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4559}, %fd2246;
	}
	setp.lt.s32 	%p1990, %r4559, 0;
	selp.b64 	%rd4554, %rd4552, %rd4553, %p1990;
	shl.b64 	%rd4555, %rd4554, 1;
	sub.s64 	%rd4556, %rd4555, %rd815;
	mov.b64 	%fd2247, %rd4556;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4560}, %fd2247;
	}
	setp.lt.s32 	%p1991, %r4560, 0;
	selp.b64 	%rd4557, %rd4555, %rd4556, %p1991;
	shl.b64 	%rd4558, %rd4557, 1;
	sub.s64 	%rd4559, %rd4558, %rd815;
	mov.b64 	%fd2248, %rd4559;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4561}, %fd2248;
	}
	setp.lt.s32 	%p1992, %r4561, 0;
	selp.b64 	%rd4560, %rd4558, %rd4559, %p1992;
	shl.b64 	%rd4561, %rd4560, 1;
	sub.s64 	%rd4562, %rd4561, %rd815;
	mov.b64 	%fd2249, %rd4562;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4562}, %fd2249;
	}
	setp.lt.s32 	%p1993, %r4562, 0;
	selp.b64 	%rd4563, %rd4561, %rd4562, %p1993;
	shl.b64 	%rd4564, %rd4563, 1;
	sub.s64 	%rd4565, %rd4564, %rd815;
	mov.b64 	%fd2250, %rd4565;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4563}, %fd2250;
	}
	setp.lt.s32 	%p1994, %r4563, 0;
	selp.b64 	%rd4566, %rd4564, %rd4565, %p1994;
	shl.b64 	%rd4567, %rd4566, 1;
	sub.s64 	%rd4568, %rd4567, %rd815;
	mov.b64 	%fd2251, %rd4568;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4564}, %fd2251;
	}
	setp.lt.s32 	%p1995, %r4564, 0;
	selp.b64 	%rd4569, %rd4567, %rd4568, %p1995;
	shl.b64 	%rd4570, %rd4569, 1;
	sub.s64 	%rd4571, %rd4570, %rd815;
	mov.b64 	%fd2252, %rd4571;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4565}, %fd2252;
	}
	setp.lt.s32 	%p1996, %r4565, 0;
	selp.b64 	%rd4572, %rd4570, %rd4571, %p1996;
	shl.b64 	%rd4573, %rd4572, 1;
	sub.s64 	%rd4574, %rd4573, %rd815;
	mov.b64 	%fd2253, %rd4574;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4566}, %fd2253;
	}
	setp.lt.s32 	%p1997, %r4566, 0;
	selp.b64 	%rd4575, %rd4573, %rd4574, %p1997;
	shl.b64 	%rd4576, %rd4575, 1;
	sub.s64 	%rd4577, %rd4576, %rd815;
	mov.b64 	%fd2254, %rd4577;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4567}, %fd2254;
	}
	setp.lt.s32 	%p1998, %r4567, 0;
	selp.b64 	%rd4578, %rd4576, %rd4577, %p1998;
	shl.b64 	%rd4579, %rd4578, 1;
	sub.s64 	%rd4580, %rd4579, %rd815;
	mov.b64 	%fd2255, %rd4580;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4568}, %fd2255;
	}
	setp.lt.s32 	%p1999, %r4568, 0;
	selp.b64 	%rd4581, %rd4579, %rd4580, %p1999;
	shl.b64 	%rd4582, %rd4581, 1;
	sub.s64 	%rd4583, %rd4582, %rd815;
	mov.b64 	%fd2256, %rd4583;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4569}, %fd2256;
	}
	setp.lt.s32 	%p2000, %r4569, 0;
	selp.b64 	%rd6500, %rd4582, %rd4583, %p2000;
	shl.b64 	%rd6497, %rd6500, 1;
	add.s32 	%r1196, %r6346, -16;
	setp.gt.s32 	%p2001, %r6346, 15;
	mov.u32 	%r6346, %r1196;
	@%p2001 bra 	$L__BB0_983;

$L__BB0_984:
	and.b64  	%rd830, %rd6500, 9223372036854775807;
	setp.eq.s64 	%p2002, %rd830, 0;
	mov.f64 	%fd3092, 0d0000000000000000;
	@%p2002 bra 	$L__BB0_986;

	mov.b64 	%fd2258, %rd830;
	mul.f64 	%fd2259, %fd2258, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4570}, %fd2259;
	}
	shr.u32 	%r4571, %r4570, 20;
	mov.u32 	%r4572, 55;
	sub.s32 	%r4573, %r4572, %r4571;
	sub.s32 	%r4574, %r6340, %r4573;
	shl.b64 	%rd4584, %rd830, %r4573;
	setp.lt.s32 	%p2003, %r4574, 1;
	mov.u32 	%r4575, 1;
	sub.s32 	%r4576, %r4575, %r4574;
	shr.u64 	%rd4585, %rd4584, %r4576;
	add.s32 	%r4577, %r4574, -1;
	cvt.u64.u32 	%rd4586, %r4577;
	shl.b64 	%rd4587, %rd4586, 52;
	add.s64 	%rd4588, %rd4587, %rd4584;
	selp.b64 	%rd4589, %rd4585, %rd4588, %p2003;
	mov.b64 	%fd3092, %rd4589;

$L__BB0_986:
	and.b32  	%r4578, %r1173, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4579}, %fd3092;
	}
	or.b32  	%r4580, %r4579, %r4578;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4581, %temp}, %fd3092;
	}
	mov.b64 	%fd3093, {%r4581, %r4580};
	bra.uni 	$L__BB0_990;

$L__BB0_988:
	mov.f64 	%fd2260, 0d3FF0000000000000;
	add.rn.f64 	%fd3093, %fd537, %fd2260;

$L__BB0_990:
	mov.f64 	%fd2261, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2262, %fd2261, %fd3093;
	mul.f64 	%fd2263, %fd2262, %fd63;
	mul.f64 	%fd2264, %fd2263, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r4582, %r6375, 3;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 103 28
	cvt.rn.f64.s32 	%fd2265, %r4582;
	fma.rn.f64 	%fd548, %fd2265, 0d400921FB54442D18, %fd2264;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1197}, %fd548;
	}
	and.b32  	%r4583, %r1197, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4584, %temp}, %fd548;
	}
	mov.b64 	%fd3094, {%r4584, %r4583};
	setp.gt.u32 	%p2008, %r4583, 2146435071;
	or.pred  	%p2010, %p2008, %p18;
	@%p2010 bra 	$L__BB0_1007;
	bra.uni 	$L__BB0_991;

$L__BB0_1007:
	.loc	1 0 9
	setp.le.f64 	%p2045, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p2046, %fd3094, 0d7FF0000000000000;
	and.pred  	%p2047, %p2046, %p2045;
	@%p2047 bra 	$L__BB0_1009;
	bra.uni 	$L__BB0_1008;

$L__BB0_1009:
	setp.eq.f64 	%p2048, %fd3094, 0d7FF0000000000000;
	selp.f64 	%fd3097, 0dFFF8000000000000, %fd548, %p2048;
	bra.uni 	$L__BB0_1010;

$L__BB0_991:
	.loc	1 0 9
	mov.f64 	%fd3097, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_1010;

	setp.ltu.f64 	%p2012, %fd3094, %fd3160;
	mov.f64 	%fd3097, %fd548;
	@%p2012 bra 	$L__BB0_1010;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4585}, %fd3094;
	}
	shr.u32 	%r6348, %r4585, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4586}, %fd3160;
	}
	shr.u32 	%r6349, %r4586, 20;
	setp.ne.s32 	%p2013, %r6348, 0;
	@%p2013 bra 	$L__BB0_995;

	mul.f64 	%fd3094, %fd3094, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4587}, %fd3094;
	}
	shr.u32 	%r4588, %r4587, 20;
	add.s32 	%r6348, %r4588, -54;

$L__BB0_995:
	setp.ne.s32 	%p2014, %r6349, 0;
	mov.f64 	%fd3095, %fd3160;
	@%p2014 bra 	$L__BB0_997;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4589}, %fd2;
	}
	shr.u32 	%r4590, %r4589, 20;
	add.s32 	%r6349, %r4590, -54;
	mov.f64 	%fd3095, %fd2;

$L__BB0_997:
	mov.b64 	%rd4591, %fd3094;
	and.b64  	%rd4592, %rd4591, 4503599627370495;
	or.b64  	%rd6505, %rd4592, 4503599627370496;
	mov.b64 	%rd4593, %fd3095;
	and.b64  	%rd4594, %rd4593, 4503599627370495;
	or.b64  	%rd832, %rd4594, 4503599627370496;
	sub.s32 	%r6355, %r6348, %r6349;
	not.b32 	%r4591, %r6348;
	add.s32 	%r4592, %r6349, %r4591;
	max.s32 	%r4593, %r4592, -1;
	add.s32 	%r1205, %r4593, %r6348;
	mov.u32 	%r4594, 2;
	sub.s32 	%r4595, %r4594, %r6349;
	add.s32 	%r4596, %r4595, %r1205;
	and.b32  	%r6351, %r4596, 3;
	setp.eq.s32 	%p2015, %r6351, 0;
	@%p2015 bra 	$L__BB0_999;

$L__BB0_998:
	.pragma "nounroll";
	sub.s64 	%rd4595, %rd6505, %rd832;
	mov.b64 	%fd2267, %rd4595;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4597}, %fd2267;
	}
	setp.lt.s32 	%p2016, %r4597, 0;
	selp.b64 	%rd6508, %rd6505, %rd4595, %p2016;
	shl.b64 	%rd6505, %rd6508, 1;
	add.s32 	%r6355, %r6355, -1;
	add.s32 	%r6351, %r6351, -1;
	setp.ne.s32 	%p2017, %r6351, 0;
	@%p2017 bra 	$L__BB0_998;

$L__BB0_999:
	mov.u32 	%r4598, 1;
	sub.s32 	%r4599, %r4598, %r6349;
	add.s32 	%r4600, %r4599, %r1205;
	setp.lt.u32 	%p2018, %r4600, 3;
	@%p2018 bra 	$L__BB0_1004;

	not.b32 	%r4601, %r6355;
	max.s32 	%r4602, %r4601, -4;
	add.s32 	%r4603, %r6355, %r4602;
	add.s32 	%r1212, %r4603, 4;
	shr.u32 	%r4604, %r1212, 2;
	add.s32 	%r4605, %r4604, 1;
	and.b32  	%r6354, %r4605, 3;
	setp.eq.s32 	%p2019, %r6354, 0;
	@%p2019 bra 	$L__BB0_1002;

$L__BB0_1001:
	.pragma "nounroll";
	sub.s64 	%rd4597, %rd6505, %rd832;
	mov.b64 	%fd2268, %rd4597;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4606}, %fd2268;
	}
	setp.lt.s32 	%p2020, %r4606, 0;
	selp.b64 	%rd4598, %rd6505, %rd4597, %p2020;
	shl.b64 	%rd4599, %rd4598, 1;
	sub.s64 	%rd4600, %rd4599, %rd832;
	mov.b64 	%fd2269, %rd4600;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4607}, %fd2269;
	}
	setp.lt.s32 	%p2021, %r4607, 0;
	selp.b64 	%rd4601, %rd4599, %rd4600, %p2021;
	shl.b64 	%rd4602, %rd4601, 1;
	sub.s64 	%rd4603, %rd4602, %rd832;
	mov.b64 	%fd2270, %rd4603;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4608}, %fd2270;
	}
	setp.lt.s32 	%p2022, %r4608, 0;
	selp.b64 	%rd4604, %rd4602, %rd4603, %p2022;
	shl.b64 	%rd4605, %rd4604, 1;
	sub.s64 	%rd4606, %rd4605, %rd832;
	mov.b64 	%fd2271, %rd4606;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4609}, %fd2271;
	}
	setp.lt.s32 	%p2023, %r4609, 0;
	selp.b64 	%rd6508, %rd4605, %rd4606, %p2023;
	shl.b64 	%rd6505, %rd6508, 1;
	add.s32 	%r6355, %r6355, -4;
	add.s32 	%r6354, %r6354, -1;
	setp.ne.s32 	%p2024, %r6354, 0;
	@%p2024 bra 	$L__BB0_1001;

$L__BB0_1002:
	setp.lt.u32 	%p2025, %r1212, 12;
	@%p2025 bra 	$L__BB0_1004;

$L__BB0_1003:
	sub.s64 	%rd4607, %rd6505, %rd832;
	mov.b64 	%fd2272, %rd4607;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4610}, %fd2272;
	}
	setp.lt.s32 	%p2026, %r4610, 0;
	selp.b64 	%rd4608, %rd6505, %rd4607, %p2026;
	shl.b64 	%rd4609, %rd4608, 1;
	sub.s64 	%rd4610, %rd4609, %rd832;
	mov.b64 	%fd2273, %rd4610;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4611}, %fd2273;
	}
	setp.lt.s32 	%p2027, %r4611, 0;
	selp.b64 	%rd4611, %rd4609, %rd4610, %p2027;
	shl.b64 	%rd4612, %rd4611, 1;
	sub.s64 	%rd4613, %rd4612, %rd832;
	mov.b64 	%fd2274, %rd4613;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4612}, %fd2274;
	}
	setp.lt.s32 	%p2028, %r4612, 0;
	selp.b64 	%rd4614, %rd4612, %rd4613, %p2028;
	shl.b64 	%rd4615, %rd4614, 1;
	sub.s64 	%rd4616, %rd4615, %rd832;
	mov.b64 	%fd2275, %rd4616;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4613}, %fd2275;
	}
	setp.lt.s32 	%p2029, %r4613, 0;
	selp.b64 	%rd4617, %rd4615, %rd4616, %p2029;
	shl.b64 	%rd4618, %rd4617, 1;
	sub.s64 	%rd4619, %rd4618, %rd832;
	mov.b64 	%fd2276, %rd4619;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4614}, %fd2276;
	}
	setp.lt.s32 	%p2030, %r4614, 0;
	selp.b64 	%rd4620, %rd4618, %rd4619, %p2030;
	shl.b64 	%rd4621, %rd4620, 1;
	sub.s64 	%rd4622, %rd4621, %rd832;
	mov.b64 	%fd2277, %rd4622;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4615}, %fd2277;
	}
	setp.lt.s32 	%p2031, %r4615, 0;
	selp.b64 	%rd4623, %rd4621, %rd4622, %p2031;
	shl.b64 	%rd4624, %rd4623, 1;
	sub.s64 	%rd4625, %rd4624, %rd832;
	mov.b64 	%fd2278, %rd4625;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4616}, %fd2278;
	}
	setp.lt.s32 	%p2032, %r4616, 0;
	selp.b64 	%rd4626, %rd4624, %rd4625, %p2032;
	shl.b64 	%rd4627, %rd4626, 1;
	sub.s64 	%rd4628, %rd4627, %rd832;
	mov.b64 	%fd2279, %rd4628;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4617}, %fd2279;
	}
	setp.lt.s32 	%p2033, %r4617, 0;
	selp.b64 	%rd4629, %rd4627, %rd4628, %p2033;
	shl.b64 	%rd4630, %rd4629, 1;
	sub.s64 	%rd4631, %rd4630, %rd832;
	mov.b64 	%fd2280, %rd4631;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4618}, %fd2280;
	}
	setp.lt.s32 	%p2034, %r4618, 0;
	selp.b64 	%rd4632, %rd4630, %rd4631, %p2034;
	shl.b64 	%rd4633, %rd4632, 1;
	sub.s64 	%rd4634, %rd4633, %rd832;
	mov.b64 	%fd2281, %rd4634;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4619}, %fd2281;
	}
	setp.lt.s32 	%p2035, %r4619, 0;
	selp.b64 	%rd4635, %rd4633, %rd4634, %p2035;
	shl.b64 	%rd4636, %rd4635, 1;
	sub.s64 	%rd4637, %rd4636, %rd832;
	mov.b64 	%fd2282, %rd4637;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4620}, %fd2282;
	}
	setp.lt.s32 	%p2036, %r4620, 0;
	selp.b64 	%rd4638, %rd4636, %rd4637, %p2036;
	shl.b64 	%rd4639, %rd4638, 1;
	sub.s64 	%rd4640, %rd4639, %rd832;
	mov.b64 	%fd2283, %rd4640;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4621}, %fd2283;
	}
	setp.lt.s32 	%p2037, %r4621, 0;
	selp.b64 	%rd4641, %rd4639, %rd4640, %p2037;
	shl.b64 	%rd4642, %rd4641, 1;
	sub.s64 	%rd4643, %rd4642, %rd832;
	mov.b64 	%fd2284, %rd4643;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4622}, %fd2284;
	}
	setp.lt.s32 	%p2038, %r4622, 0;
	selp.b64 	%rd4644, %rd4642, %rd4643, %p2038;
	shl.b64 	%rd4645, %rd4644, 1;
	sub.s64 	%rd4646, %rd4645, %rd832;
	mov.b64 	%fd2285, %rd4646;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4623}, %fd2285;
	}
	setp.lt.s32 	%p2039, %r4623, 0;
	selp.b64 	%rd4647, %rd4645, %rd4646, %p2039;
	shl.b64 	%rd4648, %rd4647, 1;
	sub.s64 	%rd4649, %rd4648, %rd832;
	mov.b64 	%fd2286, %rd4649;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4624}, %fd2286;
	}
	setp.lt.s32 	%p2040, %r4624, 0;
	selp.b64 	%rd4650, %rd4648, %rd4649, %p2040;
	shl.b64 	%rd4651, %rd4650, 1;
	sub.s64 	%rd4652, %rd4651, %rd832;
	mov.b64 	%fd2287, %rd4652;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4625}, %fd2287;
	}
	setp.lt.s32 	%p2041, %r4625, 0;
	selp.b64 	%rd6508, %rd4651, %rd4652, %p2041;
	shl.b64 	%rd6505, %rd6508, 1;
	add.s32 	%r1220, %r6355, -16;
	setp.gt.s32 	%p2042, %r6355, 15;
	mov.u32 	%r6355, %r1220;
	@%p2042 bra 	$L__BB0_1003;

$L__BB0_1004:
	and.b64  	%rd847, %rd6508, 9223372036854775807;
	setp.eq.s64 	%p2043, %rd847, 0;
	mov.f64 	%fd3096, 0d0000000000000000;
	@%p2043 bra 	$L__BB0_1006;

	mov.b64 	%fd2289, %rd847;
	mul.f64 	%fd2290, %fd2289, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4626}, %fd2290;
	}
	shr.u32 	%r4627, %r4626, 20;
	mov.u32 	%r4628, 55;
	sub.s32 	%r4629, %r4628, %r4627;
	sub.s32 	%r4630, %r6349, %r4629;
	shl.b64 	%rd4653, %rd847, %r4629;
	setp.lt.s32 	%p2044, %r4630, 1;
	mov.u32 	%r4631, 1;
	sub.s32 	%r4632, %r4631, %r4630;
	shr.u64 	%rd4654, %rd4653, %r4632;
	add.s32 	%r4633, %r4630, -1;
	cvt.u64.u32 	%rd4655, %r4633;
	shl.b64 	%rd4656, %rd4655, 52;
	add.s64 	%rd4657, %rd4656, %rd4653;
	selp.b64 	%rd4658, %rd4654, %rd4657, %p2044;
	mov.b64 	%fd3096, %rd4658;

$L__BB0_1006:
	and.b32  	%r4634, %r1197, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4635}, %fd3096;
	}
	or.b32  	%r4636, %r4635, %r4634;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4637, %temp}, %fd3096;
	}
	mov.b64 	%fd3097, {%r4637, %r4636};
	bra.uni 	$L__BB0_1010;

$L__BB0_1008:
	mov.f64 	%fd2291, 0d3FF0000000000000;
	add.rn.f64 	%fd3097, %fd548, %fd2291;

$L__BB0_1010:
	mov.f64 	%fd2292, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2293, %fd2292, %fd3097;
	mul.f64 	%fd2294, %fd2293, %fd75;
	mul.f64 	%fd2295, %fd2294, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r4638, %r6375, 2;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 103 28
	cvt.rn.f64.s32 	%fd2296, %r4638;
	fma.rn.f64 	%fd559, %fd2296, 0d400921FB54442D18, %fd2295;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1221}, %fd559;
	}
	and.b32  	%r4639, %r1221, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4640, %temp}, %fd559;
	}
	mov.b64 	%fd3098, {%r4640, %r4639};
	setp.gt.u32 	%p2049, %r4639, 2146435071;
	or.pred  	%p2051, %p2049, %p18;
	@%p2051 bra 	$L__BB0_1027;
	bra.uni 	$L__BB0_1011;

$L__BB0_1027:
	.loc	1 0 9
	setp.le.f64 	%p2086, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p2087, %fd3098, 0d7FF0000000000000;
	and.pred  	%p2088, %p2087, %p2086;
	@%p2088 bra 	$L__BB0_1029;
	bra.uni 	$L__BB0_1028;

$L__BB0_1029:
	setp.eq.f64 	%p2089, %fd3098, 0d7FF0000000000000;
	selp.f64 	%fd3101, 0dFFF8000000000000, %fd559, %p2089;
	bra.uni 	$L__BB0_1030;

$L__BB0_1011:
	.loc	1 0 9
	mov.f64 	%fd3101, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_1030;

	setp.ltu.f64 	%p2053, %fd3098, %fd3160;
	mov.f64 	%fd3101, %fd559;
	@%p2053 bra 	$L__BB0_1030;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4641}, %fd3098;
	}
	shr.u32 	%r6357, %r4641, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4642}, %fd3160;
	}
	shr.u32 	%r6358, %r4642, 20;
	setp.ne.s32 	%p2054, %r6357, 0;
	@%p2054 bra 	$L__BB0_1015;

	mul.f64 	%fd3098, %fd3098, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4643}, %fd3098;
	}
	shr.u32 	%r4644, %r4643, 20;
	add.s32 	%r6357, %r4644, -54;

$L__BB0_1015:
	setp.ne.s32 	%p2055, %r6358, 0;
	mov.f64 	%fd3099, %fd3160;
	@%p2055 bra 	$L__BB0_1017;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4645}, %fd2;
	}
	shr.u32 	%r4646, %r4645, 20;
	add.s32 	%r6358, %r4646, -54;
	mov.f64 	%fd3099, %fd2;

$L__BB0_1017:
	mov.b64 	%rd4660, %fd3098;
	and.b64  	%rd4661, %rd4660, 4503599627370495;
	or.b64  	%rd6513, %rd4661, 4503599627370496;
	mov.b64 	%rd4662, %fd3099;
	and.b64  	%rd4663, %rd4662, 4503599627370495;
	or.b64  	%rd849, %rd4663, 4503599627370496;
	sub.s32 	%r6364, %r6357, %r6358;
	not.b32 	%r4647, %r6357;
	add.s32 	%r4648, %r6358, %r4647;
	max.s32 	%r4649, %r4648, -1;
	add.s32 	%r1229, %r4649, %r6357;
	mov.u32 	%r4650, 2;
	sub.s32 	%r4651, %r4650, %r6358;
	add.s32 	%r4652, %r4651, %r1229;
	and.b32  	%r6360, %r4652, 3;
	setp.eq.s32 	%p2056, %r6360, 0;
	@%p2056 bra 	$L__BB0_1019;

$L__BB0_1018:
	.pragma "nounroll";
	sub.s64 	%rd4664, %rd6513, %rd849;
	mov.b64 	%fd2298, %rd4664;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4653}, %fd2298;
	}
	setp.lt.s32 	%p2057, %r4653, 0;
	selp.b64 	%rd6516, %rd6513, %rd4664, %p2057;
	shl.b64 	%rd6513, %rd6516, 1;
	add.s32 	%r6364, %r6364, -1;
	add.s32 	%r6360, %r6360, -1;
	setp.ne.s32 	%p2058, %r6360, 0;
	@%p2058 bra 	$L__BB0_1018;

$L__BB0_1019:
	mov.u32 	%r4654, 1;
	sub.s32 	%r4655, %r4654, %r6358;
	add.s32 	%r4656, %r4655, %r1229;
	setp.lt.u32 	%p2059, %r4656, 3;
	@%p2059 bra 	$L__BB0_1024;

	not.b32 	%r4657, %r6364;
	max.s32 	%r4658, %r4657, -4;
	add.s32 	%r4659, %r6364, %r4658;
	add.s32 	%r1236, %r4659, 4;
	shr.u32 	%r4660, %r1236, 2;
	add.s32 	%r4661, %r4660, 1;
	and.b32  	%r6363, %r4661, 3;
	setp.eq.s32 	%p2060, %r6363, 0;
	@%p2060 bra 	$L__BB0_1022;

$L__BB0_1021:
	.pragma "nounroll";
	sub.s64 	%rd4666, %rd6513, %rd849;
	mov.b64 	%fd2299, %rd4666;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4662}, %fd2299;
	}
	setp.lt.s32 	%p2061, %r4662, 0;
	selp.b64 	%rd4667, %rd6513, %rd4666, %p2061;
	shl.b64 	%rd4668, %rd4667, 1;
	sub.s64 	%rd4669, %rd4668, %rd849;
	mov.b64 	%fd2300, %rd4669;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4663}, %fd2300;
	}
	setp.lt.s32 	%p2062, %r4663, 0;
	selp.b64 	%rd4670, %rd4668, %rd4669, %p2062;
	shl.b64 	%rd4671, %rd4670, 1;
	sub.s64 	%rd4672, %rd4671, %rd849;
	mov.b64 	%fd2301, %rd4672;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4664}, %fd2301;
	}
	setp.lt.s32 	%p2063, %r4664, 0;
	selp.b64 	%rd4673, %rd4671, %rd4672, %p2063;
	shl.b64 	%rd4674, %rd4673, 1;
	sub.s64 	%rd4675, %rd4674, %rd849;
	mov.b64 	%fd2302, %rd4675;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4665}, %fd2302;
	}
	setp.lt.s32 	%p2064, %r4665, 0;
	selp.b64 	%rd6516, %rd4674, %rd4675, %p2064;
	shl.b64 	%rd6513, %rd6516, 1;
	add.s32 	%r6364, %r6364, -4;
	add.s32 	%r6363, %r6363, -1;
	setp.ne.s32 	%p2065, %r6363, 0;
	@%p2065 bra 	$L__BB0_1021;

$L__BB0_1022:
	setp.lt.u32 	%p2066, %r1236, 12;
	@%p2066 bra 	$L__BB0_1024;

$L__BB0_1023:
	sub.s64 	%rd4676, %rd6513, %rd849;
	mov.b64 	%fd2303, %rd4676;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4666}, %fd2303;
	}
	setp.lt.s32 	%p2067, %r4666, 0;
	selp.b64 	%rd4677, %rd6513, %rd4676, %p2067;
	shl.b64 	%rd4678, %rd4677, 1;
	sub.s64 	%rd4679, %rd4678, %rd849;
	mov.b64 	%fd2304, %rd4679;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4667}, %fd2304;
	}
	setp.lt.s32 	%p2068, %r4667, 0;
	selp.b64 	%rd4680, %rd4678, %rd4679, %p2068;
	shl.b64 	%rd4681, %rd4680, 1;
	sub.s64 	%rd4682, %rd4681, %rd849;
	mov.b64 	%fd2305, %rd4682;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4668}, %fd2305;
	}
	setp.lt.s32 	%p2069, %r4668, 0;
	selp.b64 	%rd4683, %rd4681, %rd4682, %p2069;
	shl.b64 	%rd4684, %rd4683, 1;
	sub.s64 	%rd4685, %rd4684, %rd849;
	mov.b64 	%fd2306, %rd4685;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4669}, %fd2306;
	}
	setp.lt.s32 	%p2070, %r4669, 0;
	selp.b64 	%rd4686, %rd4684, %rd4685, %p2070;
	shl.b64 	%rd4687, %rd4686, 1;
	sub.s64 	%rd4688, %rd4687, %rd849;
	mov.b64 	%fd2307, %rd4688;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4670}, %fd2307;
	}
	setp.lt.s32 	%p2071, %r4670, 0;
	selp.b64 	%rd4689, %rd4687, %rd4688, %p2071;
	shl.b64 	%rd4690, %rd4689, 1;
	sub.s64 	%rd4691, %rd4690, %rd849;
	mov.b64 	%fd2308, %rd4691;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4671}, %fd2308;
	}
	setp.lt.s32 	%p2072, %r4671, 0;
	selp.b64 	%rd4692, %rd4690, %rd4691, %p2072;
	shl.b64 	%rd4693, %rd4692, 1;
	sub.s64 	%rd4694, %rd4693, %rd849;
	mov.b64 	%fd2309, %rd4694;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4672}, %fd2309;
	}
	setp.lt.s32 	%p2073, %r4672, 0;
	selp.b64 	%rd4695, %rd4693, %rd4694, %p2073;
	shl.b64 	%rd4696, %rd4695, 1;
	sub.s64 	%rd4697, %rd4696, %rd849;
	mov.b64 	%fd2310, %rd4697;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4673}, %fd2310;
	}
	setp.lt.s32 	%p2074, %r4673, 0;
	selp.b64 	%rd4698, %rd4696, %rd4697, %p2074;
	shl.b64 	%rd4699, %rd4698, 1;
	sub.s64 	%rd4700, %rd4699, %rd849;
	mov.b64 	%fd2311, %rd4700;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4674}, %fd2311;
	}
	setp.lt.s32 	%p2075, %r4674, 0;
	selp.b64 	%rd4701, %rd4699, %rd4700, %p2075;
	shl.b64 	%rd4702, %rd4701, 1;
	sub.s64 	%rd4703, %rd4702, %rd849;
	mov.b64 	%fd2312, %rd4703;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4675}, %fd2312;
	}
	setp.lt.s32 	%p2076, %r4675, 0;
	selp.b64 	%rd4704, %rd4702, %rd4703, %p2076;
	shl.b64 	%rd4705, %rd4704, 1;
	sub.s64 	%rd4706, %rd4705, %rd849;
	mov.b64 	%fd2313, %rd4706;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4676}, %fd2313;
	}
	setp.lt.s32 	%p2077, %r4676, 0;
	selp.b64 	%rd4707, %rd4705, %rd4706, %p2077;
	shl.b64 	%rd4708, %rd4707, 1;
	sub.s64 	%rd4709, %rd4708, %rd849;
	mov.b64 	%fd2314, %rd4709;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4677}, %fd2314;
	}
	setp.lt.s32 	%p2078, %r4677, 0;
	selp.b64 	%rd4710, %rd4708, %rd4709, %p2078;
	shl.b64 	%rd4711, %rd4710, 1;
	sub.s64 	%rd4712, %rd4711, %rd849;
	mov.b64 	%fd2315, %rd4712;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4678}, %fd2315;
	}
	setp.lt.s32 	%p2079, %r4678, 0;
	selp.b64 	%rd4713, %rd4711, %rd4712, %p2079;
	shl.b64 	%rd4714, %rd4713, 1;
	sub.s64 	%rd4715, %rd4714, %rd849;
	mov.b64 	%fd2316, %rd4715;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4679}, %fd2316;
	}
	setp.lt.s32 	%p2080, %r4679, 0;
	selp.b64 	%rd4716, %rd4714, %rd4715, %p2080;
	shl.b64 	%rd4717, %rd4716, 1;
	sub.s64 	%rd4718, %rd4717, %rd849;
	mov.b64 	%fd2317, %rd4718;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4680}, %fd2317;
	}
	setp.lt.s32 	%p2081, %r4680, 0;
	selp.b64 	%rd4719, %rd4717, %rd4718, %p2081;
	shl.b64 	%rd4720, %rd4719, 1;
	sub.s64 	%rd4721, %rd4720, %rd849;
	mov.b64 	%fd2318, %rd4721;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4681}, %fd2318;
	}
	setp.lt.s32 	%p2082, %r4681, 0;
	selp.b64 	%rd6516, %rd4720, %rd4721, %p2082;
	shl.b64 	%rd6513, %rd6516, 1;
	add.s32 	%r1244, %r6364, -16;
	setp.gt.s32 	%p2083, %r6364, 15;
	mov.u32 	%r6364, %r1244;
	@%p2083 bra 	$L__BB0_1023;

$L__BB0_1024:
	and.b64  	%rd864, %rd6516, 9223372036854775807;
	setp.eq.s64 	%p2084, %rd864, 0;
	mov.f64 	%fd3100, 0d0000000000000000;
	@%p2084 bra 	$L__BB0_1026;

	mov.b64 	%fd2320, %rd864;
	mul.f64 	%fd2321, %fd2320, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4682}, %fd2321;
	}
	shr.u32 	%r4683, %r4682, 20;
	mov.u32 	%r4684, 55;
	sub.s32 	%r4685, %r4684, %r4683;
	sub.s32 	%r4686, %r6358, %r4685;
	shl.b64 	%rd4722, %rd864, %r4685;
	setp.lt.s32 	%p2085, %r4686, 1;
	mov.u32 	%r4687, 1;
	sub.s32 	%r4688, %r4687, %r4686;
	shr.u64 	%rd4723, %rd4722, %r4688;
	add.s32 	%r4689, %r4686, -1;
	cvt.u64.u32 	%rd4724, %r4689;
	shl.b64 	%rd4725, %rd4724, 52;
	add.s64 	%rd4726, %rd4725, %rd4722;
	selp.b64 	%rd4727, %rd4723, %rd4726, %p2085;
	mov.b64 	%fd3100, %rd4727;

$L__BB0_1026:
	and.b32  	%r4690, %r1221, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4691}, %fd3100;
	}
	or.b32  	%r4692, %r4691, %r4690;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4693, %temp}, %fd3100;
	}
	mov.b64 	%fd3101, {%r4693, %r4692};
	bra.uni 	$L__BB0_1030;

$L__BB0_1028:
	mov.f64 	%fd2322, 0d3FF0000000000000;
	add.rn.f64 	%fd3101, %fd559, %fd2322;

$L__BB0_1030:
	mov.f64 	%fd2323, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2324, %fd2323, %fd3101;
	mul.f64 	%fd2325, %fd2324, %fd87;
	mul.f64 	%fd2326, %fd2325, 0d400921FB54442D18;
	.loc	1 56 29, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r4694, %r6375, 1;
	.loc	1 58 9, function_name $L__info_string6, inlined_at 1 103 28
	cvt.rn.f64.s32 	%fd2327, %r4694;
	fma.rn.f64 	%fd570, %fd2327, 0d400921FB54442D18, %fd2326;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1245}, %fd570;
	}
	and.b32  	%r4695, %r1245, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4696, %temp}, %fd570;
	}
	mov.b64 	%fd3102, {%r4696, %r4695};
	setp.gt.u32 	%p2090, %r4695, 2146435071;
	or.pred  	%p2092, %p2090, %p18;
	@%p2092 bra 	$L__BB0_1047;
	bra.uni 	$L__BB0_1031;

$L__BB0_1047:
	.loc	1 0 9
	setp.le.f64 	%p2127, %fd3160, 0d7FF0000000000000;
	.loc	1 58 9
	setp.le.f64 	%p2128, %fd3102, 0d7FF0000000000000;
	and.pred  	%p2129, %p2128, %p2127;
	@%p2129 bra 	$L__BB0_1049;
	bra.uni 	$L__BB0_1048;

$L__BB0_1049:
	setp.eq.f64 	%p2130, %fd3102, 0d7FF0000000000000;
	selp.f64 	%fd3110, 0dFFF8000000000000, %fd570, %p2130;
	bra.uni 	$L__BB0_1050;

$L__BB0_1031:
	.loc	1 0 9
	mov.f64 	%fd3110, 0dFFF8000000000000;
	.loc	1 58 9
	@%p309 bra 	$L__BB0_1050;

	setp.ltu.f64 	%p2094, %fd3102, %fd3160;
	mov.f64 	%fd3110, %fd570;
	@%p2094 bra 	$L__BB0_1050;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4697}, %fd3102;
	}
	shr.u32 	%r6366, %r4697, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4698}, %fd3160;
	}
	shr.u32 	%r6367, %r4698, 20;
	setp.ne.s32 	%p2095, %r6366, 0;
	@%p2095 bra 	$L__BB0_1035;

	mul.f64 	%fd3102, %fd3102, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4699}, %fd3102;
	}
	shr.u32 	%r4700, %r4699, 20;
	add.s32 	%r6366, %r4700, -54;

$L__BB0_1035:
	setp.ne.s32 	%p2096, %r6367, 0;
	mov.f64 	%fd3103, %fd3160;
	@%p2096 bra 	$L__BB0_1037;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4701}, %fd2;
	}
	shr.u32 	%r4702, %r4701, 20;
	add.s32 	%r6367, %r4702, -54;
	mov.f64 	%fd3103, %fd2;

$L__BB0_1037:
	mov.b64 	%rd4729, %fd3102;
	and.b64  	%rd4730, %rd4729, 4503599627370495;
	or.b64  	%rd6521, %rd4730, 4503599627370496;
	mov.b64 	%rd4731, %fd3103;
	and.b64  	%rd4732, %rd4731, 4503599627370495;
	or.b64  	%rd866, %rd4732, 4503599627370496;
	sub.s32 	%r6373, %r6366, %r6367;
	not.b32 	%r4703, %r6366;
	add.s32 	%r4704, %r6367, %r4703;
	max.s32 	%r4705, %r4704, -1;
	add.s32 	%r1253, %r4705, %r6366;
	mov.u32 	%r4706, 2;
	sub.s32 	%r4707, %r4706, %r6367;
	add.s32 	%r4708, %r4707, %r1253;
	and.b32  	%r6369, %r4708, 3;
	setp.eq.s32 	%p2097, %r6369, 0;
	@%p2097 bra 	$L__BB0_1039;

$L__BB0_1038:
	.pragma "nounroll";
	sub.s64 	%rd4733, %rd6521, %rd866;
	mov.b64 	%fd2329, %rd4733;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4709}, %fd2329;
	}
	setp.lt.s32 	%p2098, %r4709, 0;
	selp.b64 	%rd6524, %rd6521, %rd4733, %p2098;
	shl.b64 	%rd6521, %rd6524, 1;
	add.s32 	%r6373, %r6373, -1;
	add.s32 	%r6369, %r6369, -1;
	setp.ne.s32 	%p2099, %r6369, 0;
	@%p2099 bra 	$L__BB0_1038;

$L__BB0_1039:
	mov.u32 	%r4710, 1;
	sub.s32 	%r4711, %r4710, %r6367;
	add.s32 	%r4712, %r4711, %r1253;
	setp.lt.u32 	%p2100, %r4712, 3;
	@%p2100 bra 	$L__BB0_1044;

	not.b32 	%r4713, %r6373;
	max.s32 	%r4714, %r4713, -4;
	add.s32 	%r4715, %r6373, %r4714;
	add.s32 	%r1260, %r4715, 4;
	shr.u32 	%r4716, %r1260, 2;
	add.s32 	%r4717, %r4716, 1;
	and.b32  	%r6372, %r4717, 3;
	setp.eq.s32 	%p2101, %r6372, 0;
	@%p2101 bra 	$L__BB0_1042;

$L__BB0_1041:
	.pragma "nounroll";
	sub.s64 	%rd4735, %rd6521, %rd866;
	mov.b64 	%fd2330, %rd4735;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4718}, %fd2330;
	}
	setp.lt.s32 	%p2102, %r4718, 0;
	selp.b64 	%rd4736, %rd6521, %rd4735, %p2102;
	shl.b64 	%rd4737, %rd4736, 1;
	sub.s64 	%rd4738, %rd4737, %rd866;
	mov.b64 	%fd2331, %rd4738;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4719}, %fd2331;
	}
	setp.lt.s32 	%p2103, %r4719, 0;
	selp.b64 	%rd4739, %rd4737, %rd4738, %p2103;
	shl.b64 	%rd4740, %rd4739, 1;
	sub.s64 	%rd4741, %rd4740, %rd866;
	mov.b64 	%fd2332, %rd4741;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4720}, %fd2332;
	}
	setp.lt.s32 	%p2104, %r4720, 0;
	selp.b64 	%rd4742, %rd4740, %rd4741, %p2104;
	shl.b64 	%rd4743, %rd4742, 1;
	sub.s64 	%rd4744, %rd4743, %rd866;
	mov.b64 	%fd2333, %rd4744;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4721}, %fd2333;
	}
	setp.lt.s32 	%p2105, %r4721, 0;
	selp.b64 	%rd6524, %rd4743, %rd4744, %p2105;
	shl.b64 	%rd6521, %rd6524, 1;
	add.s32 	%r6373, %r6373, -4;
	add.s32 	%r6372, %r6372, -1;
	setp.ne.s32 	%p2106, %r6372, 0;
	@%p2106 bra 	$L__BB0_1041;

$L__BB0_1042:
	setp.lt.u32 	%p2107, %r1260, 12;
	@%p2107 bra 	$L__BB0_1044;

$L__BB0_1043:
	sub.s64 	%rd4745, %rd6521, %rd866;
	mov.b64 	%fd2334, %rd4745;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4722}, %fd2334;
	}
	setp.lt.s32 	%p2108, %r4722, 0;
	selp.b64 	%rd4746, %rd6521, %rd4745, %p2108;
	shl.b64 	%rd4747, %rd4746, 1;
	sub.s64 	%rd4748, %rd4747, %rd866;
	mov.b64 	%fd2335, %rd4748;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4723}, %fd2335;
	}
	setp.lt.s32 	%p2109, %r4723, 0;
	selp.b64 	%rd4749, %rd4747, %rd4748, %p2109;
	shl.b64 	%rd4750, %rd4749, 1;
	sub.s64 	%rd4751, %rd4750, %rd866;
	mov.b64 	%fd2336, %rd4751;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4724}, %fd2336;
	}
	setp.lt.s32 	%p2110, %r4724, 0;
	selp.b64 	%rd4752, %rd4750, %rd4751, %p2110;
	shl.b64 	%rd4753, %rd4752, 1;
	sub.s64 	%rd4754, %rd4753, %rd866;
	mov.b64 	%fd2337, %rd4754;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4725}, %fd2337;
	}
	setp.lt.s32 	%p2111, %r4725, 0;
	selp.b64 	%rd4755, %rd4753, %rd4754, %p2111;
	shl.b64 	%rd4756, %rd4755, 1;
	sub.s64 	%rd4757, %rd4756, %rd866;
	mov.b64 	%fd2338, %rd4757;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4726}, %fd2338;
	}
	setp.lt.s32 	%p2112, %r4726, 0;
	selp.b64 	%rd4758, %rd4756, %rd4757, %p2112;
	shl.b64 	%rd4759, %rd4758, 1;
	sub.s64 	%rd4760, %rd4759, %rd866;
	mov.b64 	%fd2339, %rd4760;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4727}, %fd2339;
	}
	setp.lt.s32 	%p2113, %r4727, 0;
	selp.b64 	%rd4761, %rd4759, %rd4760, %p2113;
	shl.b64 	%rd4762, %rd4761, 1;
	sub.s64 	%rd4763, %rd4762, %rd866;
	mov.b64 	%fd2340, %rd4763;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4728}, %fd2340;
	}
	setp.lt.s32 	%p2114, %r4728, 0;
	selp.b64 	%rd4764, %rd4762, %rd4763, %p2114;
	shl.b64 	%rd4765, %rd4764, 1;
	sub.s64 	%rd4766, %rd4765, %rd866;
	mov.b64 	%fd2341, %rd4766;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4729}, %fd2341;
	}
	setp.lt.s32 	%p2115, %r4729, 0;
	selp.b64 	%rd4767, %rd4765, %rd4766, %p2115;
	shl.b64 	%rd4768, %rd4767, 1;
	sub.s64 	%rd4769, %rd4768, %rd866;
	mov.b64 	%fd2342, %rd4769;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4730}, %fd2342;
	}
	setp.lt.s32 	%p2116, %r4730, 0;
	selp.b64 	%rd4770, %rd4768, %rd4769, %p2116;
	shl.b64 	%rd4771, %rd4770, 1;
	sub.s64 	%rd4772, %rd4771, %rd866;
	mov.b64 	%fd2343, %rd4772;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4731}, %fd2343;
	}
	setp.lt.s32 	%p2117, %r4731, 0;
	selp.b64 	%rd4773, %rd4771, %rd4772, %p2117;
	shl.b64 	%rd4774, %rd4773, 1;
	sub.s64 	%rd4775, %rd4774, %rd866;
	mov.b64 	%fd2344, %rd4775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4732}, %fd2344;
	}
	setp.lt.s32 	%p2118, %r4732, 0;
	selp.b64 	%rd4776, %rd4774, %rd4775, %p2118;
	shl.b64 	%rd4777, %rd4776, 1;
	sub.s64 	%rd4778, %rd4777, %rd866;
	mov.b64 	%fd2345, %rd4778;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4733}, %fd2345;
	}
	setp.lt.s32 	%p2119, %r4733, 0;
	selp.b64 	%rd4779, %rd4777, %rd4778, %p2119;
	shl.b64 	%rd4780, %rd4779, 1;
	sub.s64 	%rd4781, %rd4780, %rd866;
	mov.b64 	%fd2346, %rd4781;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4734}, %fd2346;
	}
	setp.lt.s32 	%p2120, %r4734, 0;
	selp.b64 	%rd4782, %rd4780, %rd4781, %p2120;
	shl.b64 	%rd4783, %rd4782, 1;
	sub.s64 	%rd4784, %rd4783, %rd866;
	mov.b64 	%fd2347, %rd4784;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4735}, %fd2347;
	}
	setp.lt.s32 	%p2121, %r4735, 0;
	selp.b64 	%rd4785, %rd4783, %rd4784, %p2121;
	shl.b64 	%rd4786, %rd4785, 1;
	sub.s64 	%rd4787, %rd4786, %rd866;
	mov.b64 	%fd2348, %rd4787;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4736}, %fd2348;
	}
	setp.lt.s32 	%p2122, %r4736, 0;
	selp.b64 	%rd4788, %rd4786, %rd4787, %p2122;
	shl.b64 	%rd4789, %rd4788, 1;
	sub.s64 	%rd4790, %rd4789, %rd866;
	mov.b64 	%fd2349, %rd4790;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4737}, %fd2349;
	}
	setp.lt.s32 	%p2123, %r4737, 0;
	selp.b64 	%rd6524, %rd4789, %rd4790, %p2123;
	shl.b64 	%rd6521, %rd6524, 1;
	add.s32 	%r1268, %r6373, -16;
	setp.gt.s32 	%p2124, %r6373, 15;
	mov.u32 	%r6373, %r1268;
	@%p2124 bra 	$L__BB0_1043;

$L__BB0_1044:
	and.b64  	%rd881, %rd6524, 9223372036854775807;
	setp.eq.s64 	%p2125, %rd881, 0;
	mov.f64 	%fd3104, 0d0000000000000000;
	@%p2125 bra 	$L__BB0_1046;

	mov.b64 	%fd2351, %rd881;
	mul.f64 	%fd2352, %fd2351, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4738}, %fd2352;
	}
	shr.u32 	%r4739, %r4738, 20;
	mov.u32 	%r4740, 55;
	sub.s32 	%r4741, %r4740, %r4739;
	sub.s32 	%r4742, %r6367, %r4741;
	shl.b64 	%rd4791, %rd881, %r4741;
	setp.lt.s32 	%p2126, %r4742, 1;
	mov.u32 	%r4743, 1;
	sub.s32 	%r4744, %r4743, %r4742;
	shr.u64 	%rd4792, %rd4791, %r4744;
	add.s32 	%r4745, %r4742, -1;
	cvt.u64.u32 	%rd4793, %r4745;
	shl.b64 	%rd4794, %rd4793, 52;
	add.s64 	%rd4795, %rd4794, %rd4791;
	selp.b64 	%rd4796, %rd4792, %rd4795, %p2126;
	mov.b64 	%fd3104, %rd4796;

$L__BB0_1046:
	and.b32  	%r4746, %r1245, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4747}, %fd3104;
	}
	or.b32  	%r4748, %r4747, %r4746;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4749, %temp}, %fd3104;
	}
	mov.b64 	%fd3110, {%r4749, %r4748};
	bra.uni 	$L__BB0_1050;

$L__BB0_1048:
	mov.f64 	%fd2353, 0d3FF0000000000000;
	add.rn.f64 	%fd3110, %fd570, %fd2353;

$L__BB0_1050:
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 103 28
	setp.lt.s32 	%p2131, %r6375, 1;
	@%p2131 bra 	$L__BB0_1073;

	.loc	1 104 9, function_name $L__info_string3, inlined_at 1 249 17
	cvt.u64.u32 	%rd882, %r1075;
	mov.u32 	%r6376, %r6375;

$L__BB0_1052:
	.loc	1 0 9
	mov.u32 	%r1269, %r6375;
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r1271, %r1269, -1;
	.loc	1 62 9, function_name $L__info_string6, inlined_at 1 103 28
	cvt.s64.s32 	%rd4797, %r1271;
	add.s64 	%rd4798, %rd4797, %rd882;
	add.s64 	%rd4799, %rd9, %rd4798;
	ld.global.u8 	%rs83, [%rd4799];
	cvt.rn.f64.u16 	%fd2354, %rs83;
	.loc	1 63 9, function_name $L__info_string6, inlined_at 1 103 28
	mov.f64 	%fd2355, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2356, %fd2355, %fd3110;
	mul.f64 	%fd2357, %fd2356, %fd2354;
	mul.f64 	%fd2358, %fd2357, 0d400921FB54442D18;
	cvt.rn.f64.s32 	%fd2359, %r6376;
	fma.rn.f64 	%fd582, %fd2359, 0d400921FB54442D18, %fd2358;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1272}, %fd582;
	}
	and.b32  	%r4750, %r1272, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4751, %temp}, %fd582;
	}
	mov.b64 	%fd3107, {%r4751, %r4750};
	setp.gt.u32 	%p2132, %r4750, 2146435071;
	or.pred  	%p2134, %p2132, %p18;
	@%p2134 bra 	$L__BB0_1069;
	bra.uni 	$L__BB0_1053;

$L__BB0_1069:
	.loc	1 0 9
	setp.le.f64 	%p2169, %fd3160, 0d7FF0000000000000;
	.loc	1 63 9
	setp.le.f64 	%p2170, %fd3107, 0d7FF0000000000000;
	and.pred  	%p2171, %p2170, %p2169;
	@%p2171 bra 	$L__BB0_1071;
	bra.uni 	$L__BB0_1070;

$L__BB0_1071:
	setp.eq.f64 	%p2172, %fd3107, 0d7FF0000000000000;
	selp.f64 	%fd3110, 0dFFF8000000000000, %fd582, %p2172;
	bra.uni 	$L__BB0_1072;

$L__BB0_1053:
	.loc	1 0 9
	mov.f64 	%fd3110, 0dFFF8000000000000;
	.loc	1 63 9
	@%p309 bra 	$L__BB0_1072;

	setp.ltu.f64 	%p2136, %fd3107, %fd3160;
	mov.f64 	%fd3110, %fd582;
	@%p2136 bra 	$L__BB0_1072;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4752}, %fd3107;
	}
	shr.u32 	%r6377, %r4752, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4753}, %fd3160;
	}
	shr.u32 	%r6378, %r4753, 20;
	setp.ne.s32 	%p2137, %r6377, 0;
	@%p2137 bra 	$L__BB0_1057;

	mul.f64 	%fd3107, %fd3107, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4754}, %fd3107;
	}
	shr.u32 	%r4755, %r4754, 20;
	add.s32 	%r6377, %r4755, -54;

$L__BB0_1057:
	setp.ne.s32 	%p2138, %r6378, 0;
	mov.f64 	%fd3108, %fd3160;
	@%p2138 bra 	$L__BB0_1059;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4756}, %fd2;
	}
	shr.u32 	%r4757, %r4756, 20;
	add.s32 	%r6378, %r4757, -54;
	mov.f64 	%fd3108, %fd2;

$L__BB0_1059:
	mov.b64 	%rd4801, %fd3107;
	and.b64  	%rd4802, %rd4801, 4503599627370495;
	or.b64  	%rd6529, %rd4802, 4503599627370496;
	mov.b64 	%rd4803, %fd3108;
	and.b64  	%rd4804, %rd4803, 4503599627370495;
	or.b64  	%rd884, %rd4804, 4503599627370496;
	sub.s32 	%r6384, %r6377, %r6378;
	not.b32 	%r4758, %r6377;
	add.s32 	%r4759, %r6378, %r4758;
	max.s32 	%r4760, %r4759, -1;
	add.s32 	%r1280, %r4760, %r6377;
	mov.u32 	%r4761, 2;
	sub.s32 	%r4762, %r4761, %r6378;
	add.s32 	%r4763, %r4762, %r1280;
	and.b32  	%r6380, %r4763, 3;
	setp.eq.s32 	%p2139, %r6380, 0;
	@%p2139 bra 	$L__BB0_1061;

$L__BB0_1060:
	.pragma "nounroll";
	sub.s64 	%rd4805, %rd6529, %rd884;
	mov.b64 	%fd2361, %rd4805;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4764}, %fd2361;
	}
	setp.lt.s32 	%p2140, %r4764, 0;
	selp.b64 	%rd6532, %rd6529, %rd4805, %p2140;
	shl.b64 	%rd6529, %rd6532, 1;
	add.s32 	%r6384, %r6384, -1;
	add.s32 	%r6380, %r6380, -1;
	setp.ne.s32 	%p2141, %r6380, 0;
	@%p2141 bra 	$L__BB0_1060;

$L__BB0_1061:
	mov.u32 	%r4765, 1;
	sub.s32 	%r4766, %r4765, %r6378;
	add.s32 	%r4767, %r4766, %r1280;
	setp.lt.u32 	%p2142, %r4767, 3;
	@%p2142 bra 	$L__BB0_1066;

	not.b32 	%r4768, %r6384;
	max.s32 	%r4769, %r4768, -4;
	add.s32 	%r4770, %r6384, %r4769;
	add.s32 	%r1287, %r4770, 4;
	shr.u32 	%r4771, %r1287, 2;
	add.s32 	%r4772, %r4771, 1;
	and.b32  	%r6383, %r4772, 3;
	setp.eq.s32 	%p2143, %r6383, 0;
	@%p2143 bra 	$L__BB0_1064;

$L__BB0_1063:
	.pragma "nounroll";
	sub.s64 	%rd4807, %rd6529, %rd884;
	mov.b64 	%fd2362, %rd4807;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4773}, %fd2362;
	}
	setp.lt.s32 	%p2144, %r4773, 0;
	selp.b64 	%rd4808, %rd6529, %rd4807, %p2144;
	shl.b64 	%rd4809, %rd4808, 1;
	sub.s64 	%rd4810, %rd4809, %rd884;
	mov.b64 	%fd2363, %rd4810;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4774}, %fd2363;
	}
	setp.lt.s32 	%p2145, %r4774, 0;
	selp.b64 	%rd4811, %rd4809, %rd4810, %p2145;
	shl.b64 	%rd4812, %rd4811, 1;
	sub.s64 	%rd4813, %rd4812, %rd884;
	mov.b64 	%fd2364, %rd4813;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4775}, %fd2364;
	}
	setp.lt.s32 	%p2146, %r4775, 0;
	selp.b64 	%rd4814, %rd4812, %rd4813, %p2146;
	shl.b64 	%rd4815, %rd4814, 1;
	sub.s64 	%rd4816, %rd4815, %rd884;
	mov.b64 	%fd2365, %rd4816;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4776}, %fd2365;
	}
	setp.lt.s32 	%p2147, %r4776, 0;
	selp.b64 	%rd6532, %rd4815, %rd4816, %p2147;
	shl.b64 	%rd6529, %rd6532, 1;
	add.s32 	%r6384, %r6384, -4;
	add.s32 	%r6383, %r6383, -1;
	setp.ne.s32 	%p2148, %r6383, 0;
	@%p2148 bra 	$L__BB0_1063;

$L__BB0_1064:
	setp.lt.u32 	%p2149, %r1287, 12;
	@%p2149 bra 	$L__BB0_1066;

$L__BB0_1065:
	sub.s64 	%rd4817, %rd6529, %rd884;
	mov.b64 	%fd2366, %rd4817;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4777}, %fd2366;
	}
	setp.lt.s32 	%p2150, %r4777, 0;
	selp.b64 	%rd4818, %rd6529, %rd4817, %p2150;
	shl.b64 	%rd4819, %rd4818, 1;
	sub.s64 	%rd4820, %rd4819, %rd884;
	mov.b64 	%fd2367, %rd4820;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4778}, %fd2367;
	}
	setp.lt.s32 	%p2151, %r4778, 0;
	selp.b64 	%rd4821, %rd4819, %rd4820, %p2151;
	shl.b64 	%rd4822, %rd4821, 1;
	sub.s64 	%rd4823, %rd4822, %rd884;
	mov.b64 	%fd2368, %rd4823;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4779}, %fd2368;
	}
	setp.lt.s32 	%p2152, %r4779, 0;
	selp.b64 	%rd4824, %rd4822, %rd4823, %p2152;
	shl.b64 	%rd4825, %rd4824, 1;
	sub.s64 	%rd4826, %rd4825, %rd884;
	mov.b64 	%fd2369, %rd4826;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4780}, %fd2369;
	}
	setp.lt.s32 	%p2153, %r4780, 0;
	selp.b64 	%rd4827, %rd4825, %rd4826, %p2153;
	shl.b64 	%rd4828, %rd4827, 1;
	sub.s64 	%rd4829, %rd4828, %rd884;
	mov.b64 	%fd2370, %rd4829;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4781}, %fd2370;
	}
	setp.lt.s32 	%p2154, %r4781, 0;
	selp.b64 	%rd4830, %rd4828, %rd4829, %p2154;
	shl.b64 	%rd4831, %rd4830, 1;
	sub.s64 	%rd4832, %rd4831, %rd884;
	mov.b64 	%fd2371, %rd4832;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4782}, %fd2371;
	}
	setp.lt.s32 	%p2155, %r4782, 0;
	selp.b64 	%rd4833, %rd4831, %rd4832, %p2155;
	shl.b64 	%rd4834, %rd4833, 1;
	sub.s64 	%rd4835, %rd4834, %rd884;
	mov.b64 	%fd2372, %rd4835;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4783}, %fd2372;
	}
	setp.lt.s32 	%p2156, %r4783, 0;
	selp.b64 	%rd4836, %rd4834, %rd4835, %p2156;
	shl.b64 	%rd4837, %rd4836, 1;
	sub.s64 	%rd4838, %rd4837, %rd884;
	mov.b64 	%fd2373, %rd4838;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4784}, %fd2373;
	}
	setp.lt.s32 	%p2157, %r4784, 0;
	selp.b64 	%rd4839, %rd4837, %rd4838, %p2157;
	shl.b64 	%rd4840, %rd4839, 1;
	sub.s64 	%rd4841, %rd4840, %rd884;
	mov.b64 	%fd2374, %rd4841;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4785}, %fd2374;
	}
	setp.lt.s32 	%p2158, %r4785, 0;
	selp.b64 	%rd4842, %rd4840, %rd4841, %p2158;
	shl.b64 	%rd4843, %rd4842, 1;
	sub.s64 	%rd4844, %rd4843, %rd884;
	mov.b64 	%fd2375, %rd4844;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4786}, %fd2375;
	}
	setp.lt.s32 	%p2159, %r4786, 0;
	selp.b64 	%rd4845, %rd4843, %rd4844, %p2159;
	shl.b64 	%rd4846, %rd4845, 1;
	sub.s64 	%rd4847, %rd4846, %rd884;
	mov.b64 	%fd2376, %rd4847;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4787}, %fd2376;
	}
	setp.lt.s32 	%p2160, %r4787, 0;
	selp.b64 	%rd4848, %rd4846, %rd4847, %p2160;
	shl.b64 	%rd4849, %rd4848, 1;
	sub.s64 	%rd4850, %rd4849, %rd884;
	mov.b64 	%fd2377, %rd4850;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4788}, %fd2377;
	}
	setp.lt.s32 	%p2161, %r4788, 0;
	selp.b64 	%rd4851, %rd4849, %rd4850, %p2161;
	shl.b64 	%rd4852, %rd4851, 1;
	sub.s64 	%rd4853, %rd4852, %rd884;
	mov.b64 	%fd2378, %rd4853;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4789}, %fd2378;
	}
	setp.lt.s32 	%p2162, %r4789, 0;
	selp.b64 	%rd4854, %rd4852, %rd4853, %p2162;
	shl.b64 	%rd4855, %rd4854, 1;
	sub.s64 	%rd4856, %rd4855, %rd884;
	mov.b64 	%fd2379, %rd4856;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4790}, %fd2379;
	}
	setp.lt.s32 	%p2163, %r4790, 0;
	selp.b64 	%rd4857, %rd4855, %rd4856, %p2163;
	shl.b64 	%rd4858, %rd4857, 1;
	sub.s64 	%rd4859, %rd4858, %rd884;
	mov.b64 	%fd2380, %rd4859;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4791}, %fd2380;
	}
	setp.lt.s32 	%p2164, %r4791, 0;
	selp.b64 	%rd4860, %rd4858, %rd4859, %p2164;
	shl.b64 	%rd4861, %rd4860, 1;
	sub.s64 	%rd4862, %rd4861, %rd884;
	mov.b64 	%fd2381, %rd4862;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4792}, %fd2381;
	}
	setp.lt.s32 	%p2165, %r4792, 0;
	selp.b64 	%rd6532, %rd4861, %rd4862, %p2165;
	shl.b64 	%rd6529, %rd6532, 1;
	add.s32 	%r1295, %r6384, -16;
	setp.gt.s32 	%p2166, %r6384, 15;
	mov.u32 	%r6384, %r1295;
	@%p2166 bra 	$L__BB0_1065;

$L__BB0_1066:
	and.b64  	%rd899, %rd6532, 9223372036854775807;
	setp.eq.s64 	%p2167, %rd899, 0;
	mov.f64 	%fd3109, 0d0000000000000000;
	@%p2167 bra 	$L__BB0_1068;

	mov.b64 	%fd2383, %rd899;
	mul.f64 	%fd2384, %fd2383, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4793}, %fd2384;
	}
	shr.u32 	%r4794, %r4793, 20;
	mov.u32 	%r4795, 55;
	sub.s32 	%r4796, %r4795, %r4794;
	sub.s32 	%r4797, %r6378, %r4796;
	shl.b64 	%rd4863, %rd899, %r4796;
	setp.lt.s32 	%p2168, %r4797, 1;
	mov.u32 	%r4798, 1;
	sub.s32 	%r4799, %r4798, %r4797;
	shr.u64 	%rd4864, %rd4863, %r4799;
	add.s32 	%r4800, %r4797, -1;
	cvt.u64.u32 	%rd4865, %r4800;
	shl.b64 	%rd4866, %rd4865, 52;
	add.s64 	%rd4867, %rd4866, %rd4863;
	selp.b64 	%rd4868, %rd4864, %rd4867, %p2168;
	mov.b64 	%fd3109, %rd4868;

$L__BB0_1068:
	and.b32  	%r4801, %r1272, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4802}, %fd3109;
	}
	or.b32  	%r4803, %r4802, %r4801;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4804, %temp}, %fd3109;
	}
	mov.b64 	%fd3110, {%r4804, %r4803};
	bra.uni 	$L__BB0_1072;

$L__BB0_1070:
	mov.f64 	%fd2385, 0d3FF0000000000000;
	add.rn.f64 	%fd3110, %fd582, %fd2385;

$L__BB0_1072:
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r6375, %r1269, -1;
	.loc	1 61 47, function_name $L__info_string6, inlined_at 1 103 28
	add.s32 	%r6376, %r6376, -1;
	.loc	1 61 5, function_name $L__info_string6, inlined_at 1 103 28
	setp.gt.s32 	%p2173, %r1269, 1;
	@%p2173 bra 	$L__BB0_1052;

$L__BB0_1073:
	.loc	1 252 17
	ld.global.u8 	%r4805, [%rd1206+12];
	ld.global.u8 	%r4806, [%rd1206+13];
	prmt.b32 	%r4807, %r4806, %r4805, 30212;
	ld.global.u8 	%r4808, [%rd1206+14];
	ld.global.u8 	%r4809, [%rd1206+15];
	prmt.b32 	%r4810, %r4809, %r4808, 30212;
	prmt.b32 	%r4811, %r4810, %r4807, 4180;
	setp.eq.s32 	%p2174, %r4811, 0;
	@%p2174 bra 	$L__BB0_1078;

	ld.global.u8 	%r4812, [%rd1206+32];
	ld.global.u8 	%r4813, [%rd1206+33];
	prmt.b32 	%r4814, %r4813, %r4812, 30212;
	ld.global.u8 	%r4815, [%rd1206+34];
	ld.global.u8 	%r4816, [%rd1206+35];
	prmt.b32 	%r4817, %r4816, %r4815, 30212;
	prmt.b32 	%r4818, %r4817, %r4814, 4180;
	setp.eq.s32 	%p2175, %r4818, 0;
	@%p2175 bra 	$L__BB0_1078;

	.loc	1 253 21
	ld.global.u8 	%r4819, [%rd1206+52];
	ld.global.u8 	%r4820, [%rd1206+53];
	prmt.b32 	%r4821, %r4820, %r4819, 30212;
	ld.global.u8 	%r4822, [%rd1206+54];
	ld.global.u8 	%r4823, [%rd1206+55];
	prmt.b32 	%r4824, %r4823, %r4822, 30212;
	prmt.b32 	%r4825, %r4824, %r4821, 4180;
	setp.eq.s32 	%p2176, %r4825, 0;
	@%p2176 bra 	$L__BB0_1078;

	ld.global.u8 	%r4826, [%rd1206+72];
	ld.global.u8 	%r4827, [%rd1206+73];
	prmt.b32 	%r4828, %r4827, %r4826, 30212;
	ld.global.u8 	%r4829, [%rd1206+74];
	ld.global.u8 	%r4830, [%rd1206+75];
	prmt.b32 	%r4831, %r4830, %r4829, 30212;
	prmt.b32 	%r4832, %r4831, %r4828, 4180;
	setp.eq.s32 	%p2177, %r4832, 0;
	@%p2177 bra 	$L__BB0_1078;

	.loc	1 254 21
	ld.global.u8 	%r4833, [%rd1206+92];
	ld.global.u8 	%r4834, [%rd1206+93];
	prmt.b32 	%r4835, %r4834, %r4833, 30212;
	ld.global.u8 	%r4836, [%rd1206+94];
	ld.global.u8 	%r4837, [%rd1206+95];
	prmt.b32 	%r4838, %r4837, %r4836, 30212;
	prmt.b32 	%r4839, %r4838, %r4835, 4180;
	setp.ne.s32 	%p2178, %r4839, 0;
	@%p2178 bra 	$L__BB0_1360;

$L__BB0_1078:
	.loc	1 256 21
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs84, %rs229, -48;
	and.b16  	%rs85, %rs84, 255;
	setp.lt.u16 	%p2179, %rs85, 9;
	mov.u64 	%rd6535, %rd8;
	@%p2179 bra 	$L__BB0_1120;
	bra.uni 	$L__BB0_1079;

$L__BB0_1120:
	.loc	1 185 13, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs126, %rs229, 1;
	st.local.u8 	[%rd6535], %rs126;
	.loc	1 186 13, function_name $L__info_string2, inlined_at 1 256 21
	bra.uni 	$L__BB0_1582;

$L__BB0_1079:
	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.eq.s16 	%p2180, %rs229, 57;
	mov.u64 	%rd6534, %rd8;
	@%p2180 bra 	$L__BB0_1119;
	bra.uni 	$L__BB0_1080;

$L__BB0_1119:
	.loc	1 188 13, function_name $L__info_string2, inlined_at 1 256 21
	mov.u16 	%rs125, 65;
	st.local.u8 	[%rd6534], %rs125;
	.loc	1 189 13, function_name $L__info_string2, inlined_at 1 256 21
	bra.uni 	$L__BB0_1582;

$L__BB0_1080:
	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs86, %rs229, -65;
	and.b16  	%rs87, %rs86, 255;
	setp.lt.u16 	%p2181, %rs87, 25;
	mov.u64 	%rd6533, %rd8;
	@%p2181 bra 	$L__BB0_1118;
	bra.uni 	$L__BB0_1081;

$L__BB0_1118:
	.loc	1 191 13, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs124, %rs229, 1;
	st.local.u8 	[%rd6533], %rs124;
	.loc	1 192 13, function_name $L__info_string2, inlined_at 1 256 21
	bra.uni 	$L__BB0_1582;

$L__BB0_1139:
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	mov.f64 	%fd2414, 0d3FF0000000000000;
	add.rn.f64 	%fd3115, %fd596, %fd2414;

$L__BB0_1141:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 112 5
	ld.local.u8 	%rs223, [%rd7];
	cvt.rn.f64.u16 	%fd2415, %rs223;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	mov.f64 	%fd2416, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2417, %fd2416, %fd3115;
	mul.f64 	%fd2418, %fd2417, %fd2415;
	fma.rn.f64 	%fd607, %fd2418, 0d400921FB54442D18, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1322}, %fd607;
	}
	and.b32  	%r4897, %r1322, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4898, %temp}, %fd607;
	}
	mov.b64 	%fd3116, {%r4898, %r4897};
	setp.gt.u32 	%p2252, %r4897, 2146435071;
	or.pred  	%p2254, %p2252, %p2211;
	@%p2254 bra 	$L__BB0_1158;
	bra.uni 	$L__BB0_1142;

$L__BB0_1158:
	.loc	1 0 9
	setp.le.f64 	%p2289, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2290, %fd3116, 0d7FF0000000000000;
	and.pred  	%p2291, %p2290, %p2289;
	@%p2291 bra 	$L__BB0_1160;
	bra.uni 	$L__BB0_1159;

$L__BB0_1160:
	setp.eq.f64 	%p2292, %fd3116, 0d7FF0000000000000;
	selp.f64 	%fd3119, 0dFFF8000000000000, %fd607, %p2292;
	bra.uni 	$L__BB0_1161;

$L__BB0_1142:
	.loc	1 0 9
	setp.eq.f64 	%p2255, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3119, 0dFFF8000000000000;
	.loc	1 32 9
	@%p2255 bra 	$L__BB0_1161;

	setp.ltu.f64 	%p2256, %fd3116, %fd3160;
	mov.f64 	%fd3119, %fd607;
	@%p2256 bra 	$L__BB0_1161;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4899}, %fd3116;
	}
	shr.u32 	%r6395, %r4899, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4900}, %fd3160;
	}
	shr.u32 	%r6396, %r4900, 20;
	setp.ne.s32 	%p2257, %r6395, 0;
	@%p2257 bra 	$L__BB0_1146;

	mul.f64 	%fd3116, %fd3116, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4901}, %fd3116;
	}
	shr.u32 	%r4902, %r4901, 20;
	add.s32 	%r6395, %r4902, -54;

$L__BB0_1146:
	setp.ne.s32 	%p2258, %r6396, 0;
	mov.f64 	%fd3117, %fd3160;
	@%p2258 bra 	$L__BB0_1148;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4903}, %fd595;
	}
	shr.u32 	%r4904, %r4903, 20;
	add.s32 	%r6396, %r4904, -54;
	mov.f64 	%fd3117, %fd595;

$L__BB0_1148:
	mov.b64 	%rd4939, %fd3116;
	and.b64  	%rd4940, %rd4939, 4503599627370495;
	or.b64  	%rd6548, %rd4940, 4503599627370496;
	mov.b64 	%rd4941, %fd3117;
	and.b64  	%rd4942, %rd4941, 4503599627370495;
	or.b64  	%rd921, %rd4942, 4503599627370496;
	sub.s32 	%r6402, %r6395, %r6396;
	not.b32 	%r4905, %r6395;
	add.s32 	%r4906, %r6396, %r4905;
	max.s32 	%r4907, %r4906, -1;
	add.s32 	%r1330, %r4907, %r6395;
	mov.u32 	%r4908, 2;
	sub.s32 	%r4909, %r4908, %r6396;
	add.s32 	%r4910, %r4909, %r1330;
	and.b32  	%r6398, %r4910, 3;
	setp.eq.s32 	%p2259, %r6398, 0;
	@%p2259 bra 	$L__BB0_1150;

$L__BB0_1149:
	.pragma "nounroll";
	sub.s64 	%rd4943, %rd6548, %rd921;
	mov.b64 	%fd2420, %rd4943;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4911}, %fd2420;
	}
	setp.lt.s32 	%p2260, %r4911, 0;
	selp.b64 	%rd6551, %rd6548, %rd4943, %p2260;
	shl.b64 	%rd6548, %rd6551, 1;
	add.s32 	%r6402, %r6402, -1;
	add.s32 	%r6398, %r6398, -1;
	setp.ne.s32 	%p2261, %r6398, 0;
	@%p2261 bra 	$L__BB0_1149;

$L__BB0_1150:
	mov.u32 	%r4912, 1;
	sub.s32 	%r4913, %r4912, %r6396;
	add.s32 	%r4914, %r4913, %r1330;
	setp.lt.u32 	%p2262, %r4914, 3;
	@%p2262 bra 	$L__BB0_1155;

	not.b32 	%r4915, %r6402;
	max.s32 	%r4916, %r4915, -4;
	add.s32 	%r4917, %r6402, %r4916;
	add.s32 	%r1337, %r4917, 4;
	shr.u32 	%r4918, %r1337, 2;
	add.s32 	%r4919, %r4918, 1;
	and.b32  	%r6401, %r4919, 3;
	setp.eq.s32 	%p2263, %r6401, 0;
	@%p2263 bra 	$L__BB0_1153;

$L__BB0_1152:
	.pragma "nounroll";
	sub.s64 	%rd4945, %rd6548, %rd921;
	mov.b64 	%fd2421, %rd4945;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4920}, %fd2421;
	}
	setp.lt.s32 	%p2264, %r4920, 0;
	selp.b64 	%rd4946, %rd6548, %rd4945, %p2264;
	shl.b64 	%rd4947, %rd4946, 1;
	sub.s64 	%rd4948, %rd4947, %rd921;
	mov.b64 	%fd2422, %rd4948;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4921}, %fd2422;
	}
	setp.lt.s32 	%p2265, %r4921, 0;
	selp.b64 	%rd4949, %rd4947, %rd4948, %p2265;
	shl.b64 	%rd4950, %rd4949, 1;
	sub.s64 	%rd4951, %rd4950, %rd921;
	mov.b64 	%fd2423, %rd4951;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4922}, %fd2423;
	}
	setp.lt.s32 	%p2266, %r4922, 0;
	selp.b64 	%rd4952, %rd4950, %rd4951, %p2266;
	shl.b64 	%rd4953, %rd4952, 1;
	sub.s64 	%rd4954, %rd4953, %rd921;
	mov.b64 	%fd2424, %rd4954;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4923}, %fd2424;
	}
	setp.lt.s32 	%p2267, %r4923, 0;
	selp.b64 	%rd6551, %rd4953, %rd4954, %p2267;
	shl.b64 	%rd6548, %rd6551, 1;
	add.s32 	%r6402, %r6402, -4;
	add.s32 	%r6401, %r6401, -1;
	setp.ne.s32 	%p2268, %r6401, 0;
	@%p2268 bra 	$L__BB0_1152;

$L__BB0_1153:
	setp.lt.u32 	%p2269, %r1337, 12;
	@%p2269 bra 	$L__BB0_1155;

$L__BB0_1154:
	sub.s64 	%rd4955, %rd6548, %rd921;
	mov.b64 	%fd2425, %rd4955;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4924}, %fd2425;
	}
	setp.lt.s32 	%p2270, %r4924, 0;
	selp.b64 	%rd4956, %rd6548, %rd4955, %p2270;
	shl.b64 	%rd4957, %rd4956, 1;
	sub.s64 	%rd4958, %rd4957, %rd921;
	mov.b64 	%fd2426, %rd4958;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4925}, %fd2426;
	}
	setp.lt.s32 	%p2271, %r4925, 0;
	selp.b64 	%rd4959, %rd4957, %rd4958, %p2271;
	shl.b64 	%rd4960, %rd4959, 1;
	sub.s64 	%rd4961, %rd4960, %rd921;
	mov.b64 	%fd2427, %rd4961;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4926}, %fd2427;
	}
	setp.lt.s32 	%p2272, %r4926, 0;
	selp.b64 	%rd4962, %rd4960, %rd4961, %p2272;
	shl.b64 	%rd4963, %rd4962, 1;
	sub.s64 	%rd4964, %rd4963, %rd921;
	mov.b64 	%fd2428, %rd4964;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4927}, %fd2428;
	}
	setp.lt.s32 	%p2273, %r4927, 0;
	selp.b64 	%rd4965, %rd4963, %rd4964, %p2273;
	shl.b64 	%rd4966, %rd4965, 1;
	sub.s64 	%rd4967, %rd4966, %rd921;
	mov.b64 	%fd2429, %rd4967;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4928}, %fd2429;
	}
	setp.lt.s32 	%p2274, %r4928, 0;
	selp.b64 	%rd4968, %rd4966, %rd4967, %p2274;
	shl.b64 	%rd4969, %rd4968, 1;
	sub.s64 	%rd4970, %rd4969, %rd921;
	mov.b64 	%fd2430, %rd4970;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4929}, %fd2430;
	}
	setp.lt.s32 	%p2275, %r4929, 0;
	selp.b64 	%rd4971, %rd4969, %rd4970, %p2275;
	shl.b64 	%rd4972, %rd4971, 1;
	sub.s64 	%rd4973, %rd4972, %rd921;
	mov.b64 	%fd2431, %rd4973;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4930}, %fd2431;
	}
	setp.lt.s32 	%p2276, %r4930, 0;
	selp.b64 	%rd4974, %rd4972, %rd4973, %p2276;
	shl.b64 	%rd4975, %rd4974, 1;
	sub.s64 	%rd4976, %rd4975, %rd921;
	mov.b64 	%fd2432, %rd4976;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4931}, %fd2432;
	}
	setp.lt.s32 	%p2277, %r4931, 0;
	selp.b64 	%rd4977, %rd4975, %rd4976, %p2277;
	shl.b64 	%rd4978, %rd4977, 1;
	sub.s64 	%rd4979, %rd4978, %rd921;
	mov.b64 	%fd2433, %rd4979;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4932}, %fd2433;
	}
	setp.lt.s32 	%p2278, %r4932, 0;
	selp.b64 	%rd4980, %rd4978, %rd4979, %p2278;
	shl.b64 	%rd4981, %rd4980, 1;
	sub.s64 	%rd4982, %rd4981, %rd921;
	mov.b64 	%fd2434, %rd4982;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4933}, %fd2434;
	}
	setp.lt.s32 	%p2279, %r4933, 0;
	selp.b64 	%rd4983, %rd4981, %rd4982, %p2279;
	shl.b64 	%rd4984, %rd4983, 1;
	sub.s64 	%rd4985, %rd4984, %rd921;
	mov.b64 	%fd2435, %rd4985;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4934}, %fd2435;
	}
	setp.lt.s32 	%p2280, %r4934, 0;
	selp.b64 	%rd4986, %rd4984, %rd4985, %p2280;
	shl.b64 	%rd4987, %rd4986, 1;
	sub.s64 	%rd4988, %rd4987, %rd921;
	mov.b64 	%fd2436, %rd4988;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4935}, %fd2436;
	}
	setp.lt.s32 	%p2281, %r4935, 0;
	selp.b64 	%rd4989, %rd4987, %rd4988, %p2281;
	shl.b64 	%rd4990, %rd4989, 1;
	sub.s64 	%rd4991, %rd4990, %rd921;
	mov.b64 	%fd2437, %rd4991;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4936}, %fd2437;
	}
	setp.lt.s32 	%p2282, %r4936, 0;
	selp.b64 	%rd4992, %rd4990, %rd4991, %p2282;
	shl.b64 	%rd4993, %rd4992, 1;
	sub.s64 	%rd4994, %rd4993, %rd921;
	mov.b64 	%fd2438, %rd4994;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4937}, %fd2438;
	}
	setp.lt.s32 	%p2283, %r4937, 0;
	selp.b64 	%rd4995, %rd4993, %rd4994, %p2283;
	shl.b64 	%rd4996, %rd4995, 1;
	sub.s64 	%rd4997, %rd4996, %rd921;
	mov.b64 	%fd2439, %rd4997;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4938}, %fd2439;
	}
	setp.lt.s32 	%p2284, %r4938, 0;
	selp.b64 	%rd4998, %rd4996, %rd4997, %p2284;
	shl.b64 	%rd4999, %rd4998, 1;
	sub.s64 	%rd5000, %rd4999, %rd921;
	mov.b64 	%fd2440, %rd5000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4939}, %fd2440;
	}
	setp.lt.s32 	%p2285, %r4939, 0;
	selp.b64 	%rd6551, %rd4999, %rd5000, %p2285;
	shl.b64 	%rd6548, %rd6551, 1;
	add.s32 	%r1345, %r6402, -16;
	setp.gt.s32 	%p2286, %r6402, 15;
	mov.u32 	%r6402, %r1345;
	@%p2286 bra 	$L__BB0_1154;

$L__BB0_1155:
	and.b64  	%rd936, %rd6551, 9223372036854775807;
	setp.eq.s64 	%p2287, %rd936, 0;
	mov.f64 	%fd3118, 0d0000000000000000;
	@%p2287 bra 	$L__BB0_1157;

	mov.b64 	%fd2442, %rd936;
	mul.f64 	%fd2443, %fd2442, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4940}, %fd2443;
	}
	shr.u32 	%r4941, %r4940, 20;
	mov.u32 	%r4942, 55;
	sub.s32 	%r4943, %r4942, %r4941;
	sub.s32 	%r4944, %r6396, %r4943;
	shl.b64 	%rd5001, %rd936, %r4943;
	setp.lt.s32 	%p2288, %r4944, 1;
	mov.u32 	%r4945, 1;
	sub.s32 	%r4946, %r4945, %r4944;
	shr.u64 	%rd5002, %rd5001, %r4946;
	add.s32 	%r4947, %r4944, -1;
	cvt.u64.u32 	%rd5003, %r4947;
	shl.b64 	%rd5004, %rd5003, 52;
	add.s64 	%rd5005, %rd5004, %rd5001;
	selp.b64 	%rd5006, %rd5002, %rd5005, %p2288;
	mov.b64 	%fd3118, %rd5006;

$L__BB0_1157:
	and.b32  	%r4948, %r1322, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4949}, %fd3118;
	}
	or.b32  	%r4950, %r4949, %r4948;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4951, %temp}, %fd3118;
	}
	mov.b64 	%fd3119, {%r4951, %r4950};
	bra.uni 	$L__BB0_1161;

$L__BB0_1159:
	mov.f64 	%fd2444, 0d3FF0000000000000;
	add.rn.f64 	%fd3119, %fd607, %fd2444;

$L__BB0_1161:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 112 5
	ld.local.u8 	%rs222, [%rd6];
	cvt.rn.f64.u16 	%fd2445, %rs222;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	mov.f64 	%fd2446, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2447, %fd2446, %fd3119;
	mul.f64 	%fd2448, %fd2447, %fd2445;
	fma.rn.f64 	%fd618, %fd2448, 0d400921FB54442D18, 0d4032D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1346}, %fd618;
	}
	and.b32  	%r4952, %r1346, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4953, %temp}, %fd618;
	}
	mov.b64 	%fd3120, {%r4953, %r4952};
	setp.gt.u32 	%p2293, %r4952, 2146435071;
	or.pred  	%p2295, %p2293, %p2211;
	@%p2295 bra 	$L__BB0_1178;
	bra.uni 	$L__BB0_1162;

$L__BB0_1178:
	.loc	1 0 9
	setp.le.f64 	%p2330, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2331, %fd3120, 0d7FF0000000000000;
	and.pred  	%p2332, %p2331, %p2330;
	@%p2332 bra 	$L__BB0_1180;
	bra.uni 	$L__BB0_1179;

$L__BB0_1180:
	setp.eq.f64 	%p2333, %fd3120, 0d7FF0000000000000;
	selp.f64 	%fd3123, 0dFFF8000000000000, %fd618, %p2333;
	bra.uni 	$L__BB0_1181;

$L__BB0_1162:
	.loc	1 0 9
	setp.eq.f64 	%p2296, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3123, 0dFFF8000000000000;
	.loc	1 32 9
	@%p2296 bra 	$L__BB0_1181;

	setp.ltu.f64 	%p2297, %fd3120, %fd3160;
	mov.f64 	%fd3123, %fd618;
	@%p2297 bra 	$L__BB0_1181;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4954}, %fd3120;
	}
	shr.u32 	%r6404, %r4954, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4955}, %fd3160;
	}
	shr.u32 	%r6405, %r4955, 20;
	setp.ne.s32 	%p2298, %r6404, 0;
	@%p2298 bra 	$L__BB0_1166;

	mul.f64 	%fd3120, %fd3120, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4956}, %fd3120;
	}
	shr.u32 	%r4957, %r4956, 20;
	add.s32 	%r6404, %r4957, -54;

$L__BB0_1166:
	setp.ne.s32 	%p2299, %r6405, 0;
	mov.f64 	%fd3121, %fd3160;
	@%p2299 bra 	$L__BB0_1168;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4958}, %fd595;
	}
	shr.u32 	%r4959, %r4958, 20;
	add.s32 	%r6405, %r4959, -54;
	mov.f64 	%fd3121, %fd595;

$L__BB0_1168:
	mov.b64 	%rd5008, %fd3120;
	and.b64  	%rd5009, %rd5008, 4503599627370495;
	or.b64  	%rd6556, %rd5009, 4503599627370496;
	mov.b64 	%rd5010, %fd3121;
	and.b64  	%rd5011, %rd5010, 4503599627370495;
	or.b64  	%rd938, %rd5011, 4503599627370496;
	sub.s32 	%r6411, %r6404, %r6405;
	not.b32 	%r4960, %r6404;
	add.s32 	%r4961, %r6405, %r4960;
	max.s32 	%r4962, %r4961, -1;
	add.s32 	%r1354, %r4962, %r6404;
	mov.u32 	%r4963, 2;
	sub.s32 	%r4964, %r4963, %r6405;
	add.s32 	%r4965, %r4964, %r1354;
	and.b32  	%r6407, %r4965, 3;
	setp.eq.s32 	%p2300, %r6407, 0;
	@%p2300 bra 	$L__BB0_1170;

$L__BB0_1169:
	.pragma "nounroll";
	sub.s64 	%rd5012, %rd6556, %rd938;
	mov.b64 	%fd2450, %rd5012;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4966}, %fd2450;
	}
	setp.lt.s32 	%p2301, %r4966, 0;
	selp.b64 	%rd6559, %rd6556, %rd5012, %p2301;
	shl.b64 	%rd6556, %rd6559, 1;
	add.s32 	%r6411, %r6411, -1;
	add.s32 	%r6407, %r6407, -1;
	setp.ne.s32 	%p2302, %r6407, 0;
	@%p2302 bra 	$L__BB0_1169;

$L__BB0_1170:
	mov.u32 	%r4967, 1;
	sub.s32 	%r4968, %r4967, %r6405;
	add.s32 	%r4969, %r4968, %r1354;
	setp.lt.u32 	%p2303, %r4969, 3;
	@%p2303 bra 	$L__BB0_1175;

	not.b32 	%r4970, %r6411;
	max.s32 	%r4971, %r4970, -4;
	add.s32 	%r4972, %r6411, %r4971;
	add.s32 	%r1361, %r4972, 4;
	shr.u32 	%r4973, %r1361, 2;
	add.s32 	%r4974, %r4973, 1;
	and.b32  	%r6410, %r4974, 3;
	setp.eq.s32 	%p2304, %r6410, 0;
	@%p2304 bra 	$L__BB0_1173;

$L__BB0_1172:
	.pragma "nounroll";
	sub.s64 	%rd5014, %rd6556, %rd938;
	mov.b64 	%fd2451, %rd5014;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4975}, %fd2451;
	}
	setp.lt.s32 	%p2305, %r4975, 0;
	selp.b64 	%rd5015, %rd6556, %rd5014, %p2305;
	shl.b64 	%rd5016, %rd5015, 1;
	sub.s64 	%rd5017, %rd5016, %rd938;
	mov.b64 	%fd2452, %rd5017;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4976}, %fd2452;
	}
	setp.lt.s32 	%p2306, %r4976, 0;
	selp.b64 	%rd5018, %rd5016, %rd5017, %p2306;
	shl.b64 	%rd5019, %rd5018, 1;
	sub.s64 	%rd5020, %rd5019, %rd938;
	mov.b64 	%fd2453, %rd5020;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4977}, %fd2453;
	}
	setp.lt.s32 	%p2307, %r4977, 0;
	selp.b64 	%rd5021, %rd5019, %rd5020, %p2307;
	shl.b64 	%rd5022, %rd5021, 1;
	sub.s64 	%rd5023, %rd5022, %rd938;
	mov.b64 	%fd2454, %rd5023;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4978}, %fd2454;
	}
	setp.lt.s32 	%p2308, %r4978, 0;
	selp.b64 	%rd6559, %rd5022, %rd5023, %p2308;
	shl.b64 	%rd6556, %rd6559, 1;
	add.s32 	%r6411, %r6411, -4;
	add.s32 	%r6410, %r6410, -1;
	setp.ne.s32 	%p2309, %r6410, 0;
	@%p2309 bra 	$L__BB0_1172;

$L__BB0_1173:
	setp.lt.u32 	%p2310, %r1361, 12;
	@%p2310 bra 	$L__BB0_1175;

$L__BB0_1174:
	sub.s64 	%rd5024, %rd6556, %rd938;
	mov.b64 	%fd2455, %rd5024;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4979}, %fd2455;
	}
	setp.lt.s32 	%p2311, %r4979, 0;
	selp.b64 	%rd5025, %rd6556, %rd5024, %p2311;
	shl.b64 	%rd5026, %rd5025, 1;
	sub.s64 	%rd5027, %rd5026, %rd938;
	mov.b64 	%fd2456, %rd5027;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4980}, %fd2456;
	}
	setp.lt.s32 	%p2312, %r4980, 0;
	selp.b64 	%rd5028, %rd5026, %rd5027, %p2312;
	shl.b64 	%rd5029, %rd5028, 1;
	sub.s64 	%rd5030, %rd5029, %rd938;
	mov.b64 	%fd2457, %rd5030;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4981}, %fd2457;
	}
	setp.lt.s32 	%p2313, %r4981, 0;
	selp.b64 	%rd5031, %rd5029, %rd5030, %p2313;
	shl.b64 	%rd5032, %rd5031, 1;
	sub.s64 	%rd5033, %rd5032, %rd938;
	mov.b64 	%fd2458, %rd5033;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4982}, %fd2458;
	}
	setp.lt.s32 	%p2314, %r4982, 0;
	selp.b64 	%rd5034, %rd5032, %rd5033, %p2314;
	shl.b64 	%rd5035, %rd5034, 1;
	sub.s64 	%rd5036, %rd5035, %rd938;
	mov.b64 	%fd2459, %rd5036;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4983}, %fd2459;
	}
	setp.lt.s32 	%p2315, %r4983, 0;
	selp.b64 	%rd5037, %rd5035, %rd5036, %p2315;
	shl.b64 	%rd5038, %rd5037, 1;
	sub.s64 	%rd5039, %rd5038, %rd938;
	mov.b64 	%fd2460, %rd5039;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4984}, %fd2460;
	}
	setp.lt.s32 	%p2316, %r4984, 0;
	selp.b64 	%rd5040, %rd5038, %rd5039, %p2316;
	shl.b64 	%rd5041, %rd5040, 1;
	sub.s64 	%rd5042, %rd5041, %rd938;
	mov.b64 	%fd2461, %rd5042;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4985}, %fd2461;
	}
	setp.lt.s32 	%p2317, %r4985, 0;
	selp.b64 	%rd5043, %rd5041, %rd5042, %p2317;
	shl.b64 	%rd5044, %rd5043, 1;
	sub.s64 	%rd5045, %rd5044, %rd938;
	mov.b64 	%fd2462, %rd5045;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4986}, %fd2462;
	}
	setp.lt.s32 	%p2318, %r4986, 0;
	selp.b64 	%rd5046, %rd5044, %rd5045, %p2318;
	shl.b64 	%rd5047, %rd5046, 1;
	sub.s64 	%rd5048, %rd5047, %rd938;
	mov.b64 	%fd2463, %rd5048;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4987}, %fd2463;
	}
	setp.lt.s32 	%p2319, %r4987, 0;
	selp.b64 	%rd5049, %rd5047, %rd5048, %p2319;
	shl.b64 	%rd5050, %rd5049, 1;
	sub.s64 	%rd5051, %rd5050, %rd938;
	mov.b64 	%fd2464, %rd5051;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4988}, %fd2464;
	}
	setp.lt.s32 	%p2320, %r4988, 0;
	selp.b64 	%rd5052, %rd5050, %rd5051, %p2320;
	shl.b64 	%rd5053, %rd5052, 1;
	sub.s64 	%rd5054, %rd5053, %rd938;
	mov.b64 	%fd2465, %rd5054;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4989}, %fd2465;
	}
	setp.lt.s32 	%p2321, %r4989, 0;
	selp.b64 	%rd5055, %rd5053, %rd5054, %p2321;
	shl.b64 	%rd5056, %rd5055, 1;
	sub.s64 	%rd5057, %rd5056, %rd938;
	mov.b64 	%fd2466, %rd5057;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4990}, %fd2466;
	}
	setp.lt.s32 	%p2322, %r4990, 0;
	selp.b64 	%rd5058, %rd5056, %rd5057, %p2322;
	shl.b64 	%rd5059, %rd5058, 1;
	sub.s64 	%rd5060, %rd5059, %rd938;
	mov.b64 	%fd2467, %rd5060;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4991}, %fd2467;
	}
	setp.lt.s32 	%p2323, %r4991, 0;
	selp.b64 	%rd5061, %rd5059, %rd5060, %p2323;
	shl.b64 	%rd5062, %rd5061, 1;
	sub.s64 	%rd5063, %rd5062, %rd938;
	mov.b64 	%fd2468, %rd5063;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4992}, %fd2468;
	}
	setp.lt.s32 	%p2324, %r4992, 0;
	selp.b64 	%rd5064, %rd5062, %rd5063, %p2324;
	shl.b64 	%rd5065, %rd5064, 1;
	sub.s64 	%rd5066, %rd5065, %rd938;
	mov.b64 	%fd2469, %rd5066;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4993}, %fd2469;
	}
	setp.lt.s32 	%p2325, %r4993, 0;
	selp.b64 	%rd5067, %rd5065, %rd5066, %p2325;
	shl.b64 	%rd5068, %rd5067, 1;
	sub.s64 	%rd5069, %rd5068, %rd938;
	mov.b64 	%fd2470, %rd5069;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4994}, %fd2470;
	}
	setp.lt.s32 	%p2326, %r4994, 0;
	selp.b64 	%rd6559, %rd5068, %rd5069, %p2326;
	shl.b64 	%rd6556, %rd6559, 1;
	add.s32 	%r1369, %r6411, -16;
	setp.gt.s32 	%p2327, %r6411, 15;
	mov.u32 	%r6411, %r1369;
	@%p2327 bra 	$L__BB0_1174;

$L__BB0_1175:
	and.b64  	%rd953, %rd6559, 9223372036854775807;
	setp.eq.s64 	%p2328, %rd953, 0;
	mov.f64 	%fd3122, 0d0000000000000000;
	@%p2328 bra 	$L__BB0_1177;

	mov.b64 	%fd2472, %rd953;
	mul.f64 	%fd2473, %fd2472, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4995}, %fd2473;
	}
	shr.u32 	%r4996, %r4995, 20;
	mov.u32 	%r4997, 55;
	sub.s32 	%r4998, %r4997, %r4996;
	sub.s32 	%r4999, %r6405, %r4998;
	shl.b64 	%rd5070, %rd953, %r4998;
	setp.lt.s32 	%p2329, %r4999, 1;
	mov.u32 	%r5000, 1;
	sub.s32 	%r5001, %r5000, %r4999;
	shr.u64 	%rd5071, %rd5070, %r5001;
	add.s32 	%r5002, %r4999, -1;
	cvt.u64.u32 	%rd5072, %r5002;
	shl.b64 	%rd5073, %rd5072, 52;
	add.s64 	%rd5074, %rd5073, %rd5070;
	selp.b64 	%rd5075, %rd5071, %rd5074, %p2329;
	mov.b64 	%fd3122, %rd5075;

$L__BB0_1177:
	and.b32  	%r5003, %r1346, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5004}, %fd3122;
	}
	or.b32  	%r5005, %r5004, %r5003;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5006, %temp}, %fd3122;
	}
	mov.b64 	%fd3123, {%r5006, %r5005};
	bra.uni 	$L__BB0_1181;

$L__BB0_1179:
	mov.f64 	%fd2474, 0d3FF0000000000000;
	add.rn.f64 	%fd3123, %fd618, %fd2474;

$L__BB0_1181:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 112 5
	ld.local.u8 	%rs221, [%rd5];
	cvt.rn.f64.u16 	%fd2475, %rs221;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	mov.f64 	%fd2476, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2477, %fd2476, %fd3123;
	mul.f64 	%fd2478, %fd2477, %fd2475;
	fma.rn.f64 	%fd629, %fd2478, 0d400921FB54442D18, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1370}, %fd629;
	}
	and.b32  	%r5007, %r1370, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5008, %temp}, %fd629;
	}
	mov.b64 	%fd3124, {%r5008, %r5007};
	setp.gt.u32 	%p2334, %r5007, 2146435071;
	or.pred  	%p2336, %p2334, %p2211;
	@%p2336 bra 	$L__BB0_1198;
	bra.uni 	$L__BB0_1182;

$L__BB0_1198:
	.loc	1 0 9
	setp.le.f64 	%p2371, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2372, %fd3124, 0d7FF0000000000000;
	and.pred  	%p2373, %p2372, %p2371;
	@%p2373 bra 	$L__BB0_1200;
	bra.uni 	$L__BB0_1199;

$L__BB0_1200:
	setp.eq.f64 	%p2374, %fd3124, 0d7FF0000000000000;
	selp.f64 	%fd3127, 0dFFF8000000000000, %fd629, %p2374;
	bra.uni 	$L__BB0_1201;

$L__BB0_1182:
	.loc	1 0 9
	setp.eq.f64 	%p2337, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3127, 0dFFF8000000000000;
	.loc	1 32 9
	@%p2337 bra 	$L__BB0_1201;

	setp.ltu.f64 	%p2338, %fd3124, %fd3160;
	mov.f64 	%fd3127, %fd629;
	@%p2338 bra 	$L__BB0_1201;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5009}, %fd3124;
	}
	shr.u32 	%r6413, %r5009, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5010}, %fd3160;
	}
	shr.u32 	%r6414, %r5010, 20;
	setp.ne.s32 	%p2339, %r6413, 0;
	@%p2339 bra 	$L__BB0_1186;

	mul.f64 	%fd3124, %fd3124, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5011}, %fd3124;
	}
	shr.u32 	%r5012, %r5011, 20;
	add.s32 	%r6413, %r5012, -54;

$L__BB0_1186:
	setp.ne.s32 	%p2340, %r6414, 0;
	mov.f64 	%fd3125, %fd3160;
	@%p2340 bra 	$L__BB0_1188;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5013}, %fd595;
	}
	shr.u32 	%r5014, %r5013, 20;
	add.s32 	%r6414, %r5014, -54;
	mov.f64 	%fd3125, %fd595;

$L__BB0_1188:
	mov.b64 	%rd5077, %fd3124;
	and.b64  	%rd5078, %rd5077, 4503599627370495;
	or.b64  	%rd6564, %rd5078, 4503599627370496;
	mov.b64 	%rd5079, %fd3125;
	and.b64  	%rd5080, %rd5079, 4503599627370495;
	or.b64  	%rd955, %rd5080, 4503599627370496;
	sub.s32 	%r6420, %r6413, %r6414;
	not.b32 	%r5015, %r6413;
	add.s32 	%r5016, %r6414, %r5015;
	max.s32 	%r5017, %r5016, -1;
	add.s32 	%r1378, %r5017, %r6413;
	mov.u32 	%r5018, 2;
	sub.s32 	%r5019, %r5018, %r6414;
	add.s32 	%r5020, %r5019, %r1378;
	and.b32  	%r6416, %r5020, 3;
	setp.eq.s32 	%p2341, %r6416, 0;
	@%p2341 bra 	$L__BB0_1190;

$L__BB0_1189:
	.pragma "nounroll";
	sub.s64 	%rd5081, %rd6564, %rd955;
	mov.b64 	%fd2480, %rd5081;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5021}, %fd2480;
	}
	setp.lt.s32 	%p2342, %r5021, 0;
	selp.b64 	%rd6567, %rd6564, %rd5081, %p2342;
	shl.b64 	%rd6564, %rd6567, 1;
	add.s32 	%r6420, %r6420, -1;
	add.s32 	%r6416, %r6416, -1;
	setp.ne.s32 	%p2343, %r6416, 0;
	@%p2343 bra 	$L__BB0_1189;

$L__BB0_1190:
	mov.u32 	%r5022, 1;
	sub.s32 	%r5023, %r5022, %r6414;
	add.s32 	%r5024, %r5023, %r1378;
	setp.lt.u32 	%p2344, %r5024, 3;
	@%p2344 bra 	$L__BB0_1195;

	not.b32 	%r5025, %r6420;
	max.s32 	%r5026, %r5025, -4;
	add.s32 	%r5027, %r6420, %r5026;
	add.s32 	%r1385, %r5027, 4;
	shr.u32 	%r5028, %r1385, 2;
	add.s32 	%r5029, %r5028, 1;
	and.b32  	%r6419, %r5029, 3;
	setp.eq.s32 	%p2345, %r6419, 0;
	@%p2345 bra 	$L__BB0_1193;

$L__BB0_1192:
	.pragma "nounroll";
	sub.s64 	%rd5083, %rd6564, %rd955;
	mov.b64 	%fd2481, %rd5083;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5030}, %fd2481;
	}
	setp.lt.s32 	%p2346, %r5030, 0;
	selp.b64 	%rd5084, %rd6564, %rd5083, %p2346;
	shl.b64 	%rd5085, %rd5084, 1;
	sub.s64 	%rd5086, %rd5085, %rd955;
	mov.b64 	%fd2482, %rd5086;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5031}, %fd2482;
	}
	setp.lt.s32 	%p2347, %r5031, 0;
	selp.b64 	%rd5087, %rd5085, %rd5086, %p2347;
	shl.b64 	%rd5088, %rd5087, 1;
	sub.s64 	%rd5089, %rd5088, %rd955;
	mov.b64 	%fd2483, %rd5089;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5032}, %fd2483;
	}
	setp.lt.s32 	%p2348, %r5032, 0;
	selp.b64 	%rd5090, %rd5088, %rd5089, %p2348;
	shl.b64 	%rd5091, %rd5090, 1;
	sub.s64 	%rd5092, %rd5091, %rd955;
	mov.b64 	%fd2484, %rd5092;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5033}, %fd2484;
	}
	setp.lt.s32 	%p2349, %r5033, 0;
	selp.b64 	%rd6567, %rd5091, %rd5092, %p2349;
	shl.b64 	%rd6564, %rd6567, 1;
	add.s32 	%r6420, %r6420, -4;
	add.s32 	%r6419, %r6419, -1;
	setp.ne.s32 	%p2350, %r6419, 0;
	@%p2350 bra 	$L__BB0_1192;

$L__BB0_1193:
	setp.lt.u32 	%p2351, %r1385, 12;
	@%p2351 bra 	$L__BB0_1195;

$L__BB0_1194:
	sub.s64 	%rd5093, %rd6564, %rd955;
	mov.b64 	%fd2485, %rd5093;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5034}, %fd2485;
	}
	setp.lt.s32 	%p2352, %r5034, 0;
	selp.b64 	%rd5094, %rd6564, %rd5093, %p2352;
	shl.b64 	%rd5095, %rd5094, 1;
	sub.s64 	%rd5096, %rd5095, %rd955;
	mov.b64 	%fd2486, %rd5096;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5035}, %fd2486;
	}
	setp.lt.s32 	%p2353, %r5035, 0;
	selp.b64 	%rd5097, %rd5095, %rd5096, %p2353;
	shl.b64 	%rd5098, %rd5097, 1;
	sub.s64 	%rd5099, %rd5098, %rd955;
	mov.b64 	%fd2487, %rd5099;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5036}, %fd2487;
	}
	setp.lt.s32 	%p2354, %r5036, 0;
	selp.b64 	%rd5100, %rd5098, %rd5099, %p2354;
	shl.b64 	%rd5101, %rd5100, 1;
	sub.s64 	%rd5102, %rd5101, %rd955;
	mov.b64 	%fd2488, %rd5102;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5037}, %fd2488;
	}
	setp.lt.s32 	%p2355, %r5037, 0;
	selp.b64 	%rd5103, %rd5101, %rd5102, %p2355;
	shl.b64 	%rd5104, %rd5103, 1;
	sub.s64 	%rd5105, %rd5104, %rd955;
	mov.b64 	%fd2489, %rd5105;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5038}, %fd2489;
	}
	setp.lt.s32 	%p2356, %r5038, 0;
	selp.b64 	%rd5106, %rd5104, %rd5105, %p2356;
	shl.b64 	%rd5107, %rd5106, 1;
	sub.s64 	%rd5108, %rd5107, %rd955;
	mov.b64 	%fd2490, %rd5108;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5039}, %fd2490;
	}
	setp.lt.s32 	%p2357, %r5039, 0;
	selp.b64 	%rd5109, %rd5107, %rd5108, %p2357;
	shl.b64 	%rd5110, %rd5109, 1;
	sub.s64 	%rd5111, %rd5110, %rd955;
	mov.b64 	%fd2491, %rd5111;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5040}, %fd2491;
	}
	setp.lt.s32 	%p2358, %r5040, 0;
	selp.b64 	%rd5112, %rd5110, %rd5111, %p2358;
	shl.b64 	%rd5113, %rd5112, 1;
	sub.s64 	%rd5114, %rd5113, %rd955;
	mov.b64 	%fd2492, %rd5114;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5041}, %fd2492;
	}
	setp.lt.s32 	%p2359, %r5041, 0;
	selp.b64 	%rd5115, %rd5113, %rd5114, %p2359;
	shl.b64 	%rd5116, %rd5115, 1;
	sub.s64 	%rd5117, %rd5116, %rd955;
	mov.b64 	%fd2493, %rd5117;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5042}, %fd2493;
	}
	setp.lt.s32 	%p2360, %r5042, 0;
	selp.b64 	%rd5118, %rd5116, %rd5117, %p2360;
	shl.b64 	%rd5119, %rd5118, 1;
	sub.s64 	%rd5120, %rd5119, %rd955;
	mov.b64 	%fd2494, %rd5120;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5043}, %fd2494;
	}
	setp.lt.s32 	%p2361, %r5043, 0;
	selp.b64 	%rd5121, %rd5119, %rd5120, %p2361;
	shl.b64 	%rd5122, %rd5121, 1;
	sub.s64 	%rd5123, %rd5122, %rd955;
	mov.b64 	%fd2495, %rd5123;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5044}, %fd2495;
	}
	setp.lt.s32 	%p2362, %r5044, 0;
	selp.b64 	%rd5124, %rd5122, %rd5123, %p2362;
	shl.b64 	%rd5125, %rd5124, 1;
	sub.s64 	%rd5126, %rd5125, %rd955;
	mov.b64 	%fd2496, %rd5126;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5045}, %fd2496;
	}
	setp.lt.s32 	%p2363, %r5045, 0;
	selp.b64 	%rd5127, %rd5125, %rd5126, %p2363;
	shl.b64 	%rd5128, %rd5127, 1;
	sub.s64 	%rd5129, %rd5128, %rd955;
	mov.b64 	%fd2497, %rd5129;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5046}, %fd2497;
	}
	setp.lt.s32 	%p2364, %r5046, 0;
	selp.b64 	%rd5130, %rd5128, %rd5129, %p2364;
	shl.b64 	%rd5131, %rd5130, 1;
	sub.s64 	%rd5132, %rd5131, %rd955;
	mov.b64 	%fd2498, %rd5132;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5047}, %fd2498;
	}
	setp.lt.s32 	%p2365, %r5047, 0;
	selp.b64 	%rd5133, %rd5131, %rd5132, %p2365;
	shl.b64 	%rd5134, %rd5133, 1;
	sub.s64 	%rd5135, %rd5134, %rd955;
	mov.b64 	%fd2499, %rd5135;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5048}, %fd2499;
	}
	setp.lt.s32 	%p2366, %r5048, 0;
	selp.b64 	%rd5136, %rd5134, %rd5135, %p2366;
	shl.b64 	%rd5137, %rd5136, 1;
	sub.s64 	%rd5138, %rd5137, %rd955;
	mov.b64 	%fd2500, %rd5138;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5049}, %fd2500;
	}
	setp.lt.s32 	%p2367, %r5049, 0;
	selp.b64 	%rd6567, %rd5137, %rd5138, %p2367;
	shl.b64 	%rd6564, %rd6567, 1;
	add.s32 	%r1393, %r6420, -16;
	setp.gt.s32 	%p2368, %r6420, 15;
	mov.u32 	%r6420, %r1393;
	@%p2368 bra 	$L__BB0_1194;

$L__BB0_1195:
	and.b64  	%rd970, %rd6567, 9223372036854775807;
	setp.eq.s64 	%p2369, %rd970, 0;
	mov.f64 	%fd3126, 0d0000000000000000;
	@%p2369 bra 	$L__BB0_1197;

	mov.b64 	%fd2502, %rd970;
	mul.f64 	%fd2503, %fd2502, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5050}, %fd2503;
	}
	shr.u32 	%r5051, %r5050, 20;
	mov.u32 	%r5052, 55;
	sub.s32 	%r5053, %r5052, %r5051;
	sub.s32 	%r5054, %r6414, %r5053;
	shl.b64 	%rd5139, %rd970, %r5053;
	setp.lt.s32 	%p2370, %r5054, 1;
	mov.u32 	%r5055, 1;
	sub.s32 	%r5056, %r5055, %r5054;
	shr.u64 	%rd5140, %rd5139, %r5056;
	add.s32 	%r5057, %r5054, -1;
	cvt.u64.u32 	%rd5141, %r5057;
	shl.b64 	%rd5142, %rd5141, 52;
	add.s64 	%rd5143, %rd5142, %rd5139;
	selp.b64 	%rd5144, %rd5140, %rd5143, %p2370;
	mov.b64 	%fd3126, %rd5144;

$L__BB0_1197:
	and.b32  	%r5058, %r1370, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5059}, %fd3126;
	}
	or.b32  	%r5060, %r5059, %r5058;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5061, %temp}, %fd3126;
	}
	mov.b64 	%fd3127, {%r5061, %r5060};
	bra.uni 	$L__BB0_1201;

$L__BB0_1199:
	mov.f64 	%fd2504, 0d3FF0000000000000;
	add.rn.f64 	%fd3127, %fd629, %fd2504;

$L__BB0_1201:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 112 5
	ld.local.u8 	%rs220, [%rd4];
	cvt.rn.f64.u16 	%fd2505, %rs220;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	mov.f64 	%fd2506, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2507, %fd2506, %fd3127;
	mul.f64 	%fd2508, %fd2507, %fd2505;
	fma.rn.f64 	%fd640, %fd2508, 0d400921FB54442D18, 0d402921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1394}, %fd640;
	}
	and.b32  	%r5062, %r1394, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5063, %temp}, %fd640;
	}
	mov.b64 	%fd3128, {%r5063, %r5062};
	setp.gt.u32 	%p2375, %r5062, 2146435071;
	or.pred  	%p2377, %p2375, %p2211;
	@%p2377 bra 	$L__BB0_1218;
	bra.uni 	$L__BB0_1202;

$L__BB0_1218:
	.loc	1 0 9
	setp.le.f64 	%p2412, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2413, %fd3128, 0d7FF0000000000000;
	and.pred  	%p2414, %p2413, %p2412;
	@%p2414 bra 	$L__BB0_1220;
	bra.uni 	$L__BB0_1219;

$L__BB0_1220:
	setp.eq.f64 	%p2415, %fd3128, 0d7FF0000000000000;
	selp.f64 	%fd3131, 0dFFF8000000000000, %fd640, %p2415;
	bra.uni 	$L__BB0_1221;

$L__BB0_1202:
	.loc	1 0 9
	setp.eq.f64 	%p2378, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3131, 0dFFF8000000000000;
	.loc	1 32 9
	@%p2378 bra 	$L__BB0_1221;

	setp.ltu.f64 	%p2379, %fd3128, %fd3160;
	mov.f64 	%fd3131, %fd640;
	@%p2379 bra 	$L__BB0_1221;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5064}, %fd3128;
	}
	shr.u32 	%r6422, %r5064, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5065}, %fd3160;
	}
	shr.u32 	%r6423, %r5065, 20;
	setp.ne.s32 	%p2380, %r6422, 0;
	@%p2380 bra 	$L__BB0_1206;

	mul.f64 	%fd3128, %fd3128, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5066}, %fd3128;
	}
	shr.u32 	%r5067, %r5066, 20;
	add.s32 	%r6422, %r5067, -54;

$L__BB0_1206:
	setp.ne.s32 	%p2381, %r6423, 0;
	mov.f64 	%fd3129, %fd3160;
	@%p2381 bra 	$L__BB0_1208;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5068}, %fd595;
	}
	shr.u32 	%r5069, %r5068, 20;
	add.s32 	%r6423, %r5069, -54;
	mov.f64 	%fd3129, %fd595;

$L__BB0_1208:
	mov.b64 	%rd5146, %fd3128;
	and.b64  	%rd5147, %rd5146, 4503599627370495;
	or.b64  	%rd6572, %rd5147, 4503599627370496;
	mov.b64 	%rd5148, %fd3129;
	and.b64  	%rd5149, %rd5148, 4503599627370495;
	or.b64  	%rd972, %rd5149, 4503599627370496;
	sub.s32 	%r6429, %r6422, %r6423;
	not.b32 	%r5070, %r6422;
	add.s32 	%r5071, %r6423, %r5070;
	max.s32 	%r5072, %r5071, -1;
	add.s32 	%r1402, %r5072, %r6422;
	mov.u32 	%r5073, 2;
	sub.s32 	%r5074, %r5073, %r6423;
	add.s32 	%r5075, %r5074, %r1402;
	and.b32  	%r6425, %r5075, 3;
	setp.eq.s32 	%p2382, %r6425, 0;
	@%p2382 bra 	$L__BB0_1210;

$L__BB0_1209:
	.pragma "nounroll";
	sub.s64 	%rd5150, %rd6572, %rd972;
	mov.b64 	%fd2510, %rd5150;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5076}, %fd2510;
	}
	setp.lt.s32 	%p2383, %r5076, 0;
	selp.b64 	%rd6575, %rd6572, %rd5150, %p2383;
	shl.b64 	%rd6572, %rd6575, 1;
	add.s32 	%r6429, %r6429, -1;
	add.s32 	%r6425, %r6425, -1;
	setp.ne.s32 	%p2384, %r6425, 0;
	@%p2384 bra 	$L__BB0_1209;

$L__BB0_1210:
	mov.u32 	%r5077, 1;
	sub.s32 	%r5078, %r5077, %r6423;
	add.s32 	%r5079, %r5078, %r1402;
	setp.lt.u32 	%p2385, %r5079, 3;
	@%p2385 bra 	$L__BB0_1215;

	not.b32 	%r5080, %r6429;
	max.s32 	%r5081, %r5080, -4;
	add.s32 	%r5082, %r6429, %r5081;
	add.s32 	%r1409, %r5082, 4;
	shr.u32 	%r5083, %r1409, 2;
	add.s32 	%r5084, %r5083, 1;
	and.b32  	%r6428, %r5084, 3;
	setp.eq.s32 	%p2386, %r6428, 0;
	@%p2386 bra 	$L__BB0_1213;

$L__BB0_1212:
	.pragma "nounroll";
	sub.s64 	%rd5152, %rd6572, %rd972;
	mov.b64 	%fd2511, %rd5152;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5085}, %fd2511;
	}
	setp.lt.s32 	%p2387, %r5085, 0;
	selp.b64 	%rd5153, %rd6572, %rd5152, %p2387;
	shl.b64 	%rd5154, %rd5153, 1;
	sub.s64 	%rd5155, %rd5154, %rd972;
	mov.b64 	%fd2512, %rd5155;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5086}, %fd2512;
	}
	setp.lt.s32 	%p2388, %r5086, 0;
	selp.b64 	%rd5156, %rd5154, %rd5155, %p2388;
	shl.b64 	%rd5157, %rd5156, 1;
	sub.s64 	%rd5158, %rd5157, %rd972;
	mov.b64 	%fd2513, %rd5158;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5087}, %fd2513;
	}
	setp.lt.s32 	%p2389, %r5087, 0;
	selp.b64 	%rd5159, %rd5157, %rd5158, %p2389;
	shl.b64 	%rd5160, %rd5159, 1;
	sub.s64 	%rd5161, %rd5160, %rd972;
	mov.b64 	%fd2514, %rd5161;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5088}, %fd2514;
	}
	setp.lt.s32 	%p2390, %r5088, 0;
	selp.b64 	%rd6575, %rd5160, %rd5161, %p2390;
	shl.b64 	%rd6572, %rd6575, 1;
	add.s32 	%r6429, %r6429, -4;
	add.s32 	%r6428, %r6428, -1;
	setp.ne.s32 	%p2391, %r6428, 0;
	@%p2391 bra 	$L__BB0_1212;

$L__BB0_1213:
	setp.lt.u32 	%p2392, %r1409, 12;
	@%p2392 bra 	$L__BB0_1215;

$L__BB0_1214:
	sub.s64 	%rd5162, %rd6572, %rd972;
	mov.b64 	%fd2515, %rd5162;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5089}, %fd2515;
	}
	setp.lt.s32 	%p2393, %r5089, 0;
	selp.b64 	%rd5163, %rd6572, %rd5162, %p2393;
	shl.b64 	%rd5164, %rd5163, 1;
	sub.s64 	%rd5165, %rd5164, %rd972;
	mov.b64 	%fd2516, %rd5165;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5090}, %fd2516;
	}
	setp.lt.s32 	%p2394, %r5090, 0;
	selp.b64 	%rd5166, %rd5164, %rd5165, %p2394;
	shl.b64 	%rd5167, %rd5166, 1;
	sub.s64 	%rd5168, %rd5167, %rd972;
	mov.b64 	%fd2517, %rd5168;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5091}, %fd2517;
	}
	setp.lt.s32 	%p2395, %r5091, 0;
	selp.b64 	%rd5169, %rd5167, %rd5168, %p2395;
	shl.b64 	%rd5170, %rd5169, 1;
	sub.s64 	%rd5171, %rd5170, %rd972;
	mov.b64 	%fd2518, %rd5171;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5092}, %fd2518;
	}
	setp.lt.s32 	%p2396, %r5092, 0;
	selp.b64 	%rd5172, %rd5170, %rd5171, %p2396;
	shl.b64 	%rd5173, %rd5172, 1;
	sub.s64 	%rd5174, %rd5173, %rd972;
	mov.b64 	%fd2519, %rd5174;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5093}, %fd2519;
	}
	setp.lt.s32 	%p2397, %r5093, 0;
	selp.b64 	%rd5175, %rd5173, %rd5174, %p2397;
	shl.b64 	%rd5176, %rd5175, 1;
	sub.s64 	%rd5177, %rd5176, %rd972;
	mov.b64 	%fd2520, %rd5177;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5094}, %fd2520;
	}
	setp.lt.s32 	%p2398, %r5094, 0;
	selp.b64 	%rd5178, %rd5176, %rd5177, %p2398;
	shl.b64 	%rd5179, %rd5178, 1;
	sub.s64 	%rd5180, %rd5179, %rd972;
	mov.b64 	%fd2521, %rd5180;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5095}, %fd2521;
	}
	setp.lt.s32 	%p2399, %r5095, 0;
	selp.b64 	%rd5181, %rd5179, %rd5180, %p2399;
	shl.b64 	%rd5182, %rd5181, 1;
	sub.s64 	%rd5183, %rd5182, %rd972;
	mov.b64 	%fd2522, %rd5183;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5096}, %fd2522;
	}
	setp.lt.s32 	%p2400, %r5096, 0;
	selp.b64 	%rd5184, %rd5182, %rd5183, %p2400;
	shl.b64 	%rd5185, %rd5184, 1;
	sub.s64 	%rd5186, %rd5185, %rd972;
	mov.b64 	%fd2523, %rd5186;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5097}, %fd2523;
	}
	setp.lt.s32 	%p2401, %r5097, 0;
	selp.b64 	%rd5187, %rd5185, %rd5186, %p2401;
	shl.b64 	%rd5188, %rd5187, 1;
	sub.s64 	%rd5189, %rd5188, %rd972;
	mov.b64 	%fd2524, %rd5189;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5098}, %fd2524;
	}
	setp.lt.s32 	%p2402, %r5098, 0;
	selp.b64 	%rd5190, %rd5188, %rd5189, %p2402;
	shl.b64 	%rd5191, %rd5190, 1;
	sub.s64 	%rd5192, %rd5191, %rd972;
	mov.b64 	%fd2525, %rd5192;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5099}, %fd2525;
	}
	setp.lt.s32 	%p2403, %r5099, 0;
	selp.b64 	%rd5193, %rd5191, %rd5192, %p2403;
	shl.b64 	%rd5194, %rd5193, 1;
	sub.s64 	%rd5195, %rd5194, %rd972;
	mov.b64 	%fd2526, %rd5195;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5100}, %fd2526;
	}
	setp.lt.s32 	%p2404, %r5100, 0;
	selp.b64 	%rd5196, %rd5194, %rd5195, %p2404;
	shl.b64 	%rd5197, %rd5196, 1;
	sub.s64 	%rd5198, %rd5197, %rd972;
	mov.b64 	%fd2527, %rd5198;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5101}, %fd2527;
	}
	setp.lt.s32 	%p2405, %r5101, 0;
	selp.b64 	%rd5199, %rd5197, %rd5198, %p2405;
	shl.b64 	%rd5200, %rd5199, 1;
	sub.s64 	%rd5201, %rd5200, %rd972;
	mov.b64 	%fd2528, %rd5201;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5102}, %fd2528;
	}
	setp.lt.s32 	%p2406, %r5102, 0;
	selp.b64 	%rd5202, %rd5200, %rd5201, %p2406;
	shl.b64 	%rd5203, %rd5202, 1;
	sub.s64 	%rd5204, %rd5203, %rd972;
	mov.b64 	%fd2529, %rd5204;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5103}, %fd2529;
	}
	setp.lt.s32 	%p2407, %r5103, 0;
	selp.b64 	%rd5205, %rd5203, %rd5204, %p2407;
	shl.b64 	%rd5206, %rd5205, 1;
	sub.s64 	%rd5207, %rd5206, %rd972;
	mov.b64 	%fd2530, %rd5207;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5104}, %fd2530;
	}
	setp.lt.s32 	%p2408, %r5104, 0;
	selp.b64 	%rd6575, %rd5206, %rd5207, %p2408;
	shl.b64 	%rd6572, %rd6575, 1;
	add.s32 	%r1417, %r6429, -16;
	setp.gt.s32 	%p2409, %r6429, 15;
	mov.u32 	%r6429, %r1417;
	@%p2409 bra 	$L__BB0_1214;

$L__BB0_1215:
	and.b64  	%rd987, %rd6575, 9223372036854775807;
	setp.eq.s64 	%p2410, %rd987, 0;
	mov.f64 	%fd3130, 0d0000000000000000;
	@%p2410 bra 	$L__BB0_1217;

	mov.b64 	%fd2532, %rd987;
	mul.f64 	%fd2533, %fd2532, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5105}, %fd2533;
	}
	shr.u32 	%r5106, %r5105, 20;
	mov.u32 	%r5107, 55;
	sub.s32 	%r5108, %r5107, %r5106;
	sub.s32 	%r5109, %r6423, %r5108;
	shl.b64 	%rd5208, %rd987, %r5108;
	setp.lt.s32 	%p2411, %r5109, 1;
	mov.u32 	%r5110, 1;
	sub.s32 	%r5111, %r5110, %r5109;
	shr.u64 	%rd5209, %rd5208, %r5111;
	add.s32 	%r5112, %r5109, -1;
	cvt.u64.u32 	%rd5210, %r5112;
	shl.b64 	%rd5211, %rd5210, 52;
	add.s64 	%rd5212, %rd5211, %rd5208;
	selp.b64 	%rd5213, %rd5209, %rd5212, %p2411;
	mov.b64 	%fd3130, %rd5213;

$L__BB0_1217:
	and.b32  	%r5113, %r1394, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5114}, %fd3130;
	}
	or.b32  	%r5115, %r5114, %r5113;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5116, %temp}, %fd3130;
	}
	mov.b64 	%fd3131, {%r5116, %r5115};
	bra.uni 	$L__BB0_1221;

$L__BB0_1219:
	mov.f64 	%fd2534, 0d3FF0000000000000;
	add.rn.f64 	%fd3131, %fd640, %fd2534;

$L__BB0_1221:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 112 5
	ld.local.u8 	%rs219, [%rd3];
	cvt.rn.f64.u16 	%fd2535, %rs219;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	mov.f64 	%fd2536, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2537, %fd2536, %fd3131;
	mul.f64 	%fd2538, %fd2537, %fd2535;
	fma.rn.f64 	%fd651, %fd2538, 0d400921FB54442D18, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1418}, %fd651;
	}
	and.b32  	%r5117, %r1418, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5118, %temp}, %fd651;
	}
	mov.b64 	%fd3132, {%r5118, %r5117};
	setp.gt.u32 	%p2416, %r5117, 2146435071;
	or.pred  	%p2418, %p2416, %p2211;
	@%p2418 bra 	$L__BB0_1238;
	bra.uni 	$L__BB0_1222;

$L__BB0_1238:
	.loc	1 0 9
	setp.le.f64 	%p2453, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2454, %fd3132, 0d7FF0000000000000;
	and.pred  	%p2455, %p2454, %p2453;
	@%p2455 bra 	$L__BB0_1240;
	bra.uni 	$L__BB0_1239;

$L__BB0_1240:
	setp.eq.f64 	%p2456, %fd3132, 0d7FF0000000000000;
	selp.f64 	%fd3135, 0dFFF8000000000000, %fd651, %p2456;
	bra.uni 	$L__BB0_1241;

$L__BB0_1222:
	.loc	1 0 9
	setp.eq.f64 	%p2419, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3135, 0dFFF8000000000000;
	.loc	1 32 9
	@%p2419 bra 	$L__BB0_1241;

	setp.ltu.f64 	%p2420, %fd3132, %fd3160;
	mov.f64 	%fd3135, %fd651;
	@%p2420 bra 	$L__BB0_1241;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5119}, %fd3132;
	}
	shr.u32 	%r6431, %r5119, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5120}, %fd3160;
	}
	shr.u32 	%r6432, %r5120, 20;
	setp.ne.s32 	%p2421, %r6431, 0;
	@%p2421 bra 	$L__BB0_1226;

	mul.f64 	%fd3132, %fd3132, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5121}, %fd3132;
	}
	shr.u32 	%r5122, %r5121, 20;
	add.s32 	%r6431, %r5122, -54;

$L__BB0_1226:
	setp.ne.s32 	%p2422, %r6432, 0;
	mov.f64 	%fd3133, %fd3160;
	@%p2422 bra 	$L__BB0_1228;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5123}, %fd595;
	}
	shr.u32 	%r5124, %r5123, 20;
	add.s32 	%r6432, %r5124, -54;
	mov.f64 	%fd3133, %fd595;

$L__BB0_1228:
	mov.b64 	%rd5215, %fd3132;
	and.b64  	%rd5216, %rd5215, 4503599627370495;
	or.b64  	%rd6580, %rd5216, 4503599627370496;
	mov.b64 	%rd5217, %fd3133;
	and.b64  	%rd5218, %rd5217, 4503599627370495;
	or.b64  	%rd989, %rd5218, 4503599627370496;
	sub.s32 	%r6438, %r6431, %r6432;
	not.b32 	%r5125, %r6431;
	add.s32 	%r5126, %r6432, %r5125;
	max.s32 	%r5127, %r5126, -1;
	add.s32 	%r1426, %r5127, %r6431;
	mov.u32 	%r5128, 2;
	sub.s32 	%r5129, %r5128, %r6432;
	add.s32 	%r5130, %r5129, %r1426;
	and.b32  	%r6434, %r5130, 3;
	setp.eq.s32 	%p2423, %r6434, 0;
	@%p2423 bra 	$L__BB0_1230;

$L__BB0_1229:
	.pragma "nounroll";
	sub.s64 	%rd5219, %rd6580, %rd989;
	mov.b64 	%fd2540, %rd5219;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5131}, %fd2540;
	}
	setp.lt.s32 	%p2424, %r5131, 0;
	selp.b64 	%rd6583, %rd6580, %rd5219, %p2424;
	shl.b64 	%rd6580, %rd6583, 1;
	add.s32 	%r6438, %r6438, -1;
	add.s32 	%r6434, %r6434, -1;
	setp.ne.s32 	%p2425, %r6434, 0;
	@%p2425 bra 	$L__BB0_1229;

$L__BB0_1230:
	mov.u32 	%r5132, 1;
	sub.s32 	%r5133, %r5132, %r6432;
	add.s32 	%r5134, %r5133, %r1426;
	setp.lt.u32 	%p2426, %r5134, 3;
	@%p2426 bra 	$L__BB0_1235;

	not.b32 	%r5135, %r6438;
	max.s32 	%r5136, %r5135, -4;
	add.s32 	%r5137, %r6438, %r5136;
	add.s32 	%r1433, %r5137, 4;
	shr.u32 	%r5138, %r1433, 2;
	add.s32 	%r5139, %r5138, 1;
	and.b32  	%r6437, %r5139, 3;
	setp.eq.s32 	%p2427, %r6437, 0;
	@%p2427 bra 	$L__BB0_1233;

$L__BB0_1232:
	.pragma "nounroll";
	sub.s64 	%rd5221, %rd6580, %rd989;
	mov.b64 	%fd2541, %rd5221;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5140}, %fd2541;
	}
	setp.lt.s32 	%p2428, %r5140, 0;
	selp.b64 	%rd5222, %rd6580, %rd5221, %p2428;
	shl.b64 	%rd5223, %rd5222, 1;
	sub.s64 	%rd5224, %rd5223, %rd989;
	mov.b64 	%fd2542, %rd5224;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5141}, %fd2542;
	}
	setp.lt.s32 	%p2429, %r5141, 0;
	selp.b64 	%rd5225, %rd5223, %rd5224, %p2429;
	shl.b64 	%rd5226, %rd5225, 1;
	sub.s64 	%rd5227, %rd5226, %rd989;
	mov.b64 	%fd2543, %rd5227;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5142}, %fd2543;
	}
	setp.lt.s32 	%p2430, %r5142, 0;
	selp.b64 	%rd5228, %rd5226, %rd5227, %p2430;
	shl.b64 	%rd5229, %rd5228, 1;
	sub.s64 	%rd5230, %rd5229, %rd989;
	mov.b64 	%fd2544, %rd5230;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5143}, %fd2544;
	}
	setp.lt.s32 	%p2431, %r5143, 0;
	selp.b64 	%rd6583, %rd5229, %rd5230, %p2431;
	shl.b64 	%rd6580, %rd6583, 1;
	add.s32 	%r6438, %r6438, -4;
	add.s32 	%r6437, %r6437, -1;
	setp.ne.s32 	%p2432, %r6437, 0;
	@%p2432 bra 	$L__BB0_1232;

$L__BB0_1233:
	setp.lt.u32 	%p2433, %r1433, 12;
	@%p2433 bra 	$L__BB0_1235;

$L__BB0_1234:
	sub.s64 	%rd5231, %rd6580, %rd989;
	mov.b64 	%fd2545, %rd5231;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5144}, %fd2545;
	}
	setp.lt.s32 	%p2434, %r5144, 0;
	selp.b64 	%rd5232, %rd6580, %rd5231, %p2434;
	shl.b64 	%rd5233, %rd5232, 1;
	sub.s64 	%rd5234, %rd5233, %rd989;
	mov.b64 	%fd2546, %rd5234;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5145}, %fd2546;
	}
	setp.lt.s32 	%p2435, %r5145, 0;
	selp.b64 	%rd5235, %rd5233, %rd5234, %p2435;
	shl.b64 	%rd5236, %rd5235, 1;
	sub.s64 	%rd5237, %rd5236, %rd989;
	mov.b64 	%fd2547, %rd5237;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5146}, %fd2547;
	}
	setp.lt.s32 	%p2436, %r5146, 0;
	selp.b64 	%rd5238, %rd5236, %rd5237, %p2436;
	shl.b64 	%rd5239, %rd5238, 1;
	sub.s64 	%rd5240, %rd5239, %rd989;
	mov.b64 	%fd2548, %rd5240;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5147}, %fd2548;
	}
	setp.lt.s32 	%p2437, %r5147, 0;
	selp.b64 	%rd5241, %rd5239, %rd5240, %p2437;
	shl.b64 	%rd5242, %rd5241, 1;
	sub.s64 	%rd5243, %rd5242, %rd989;
	mov.b64 	%fd2549, %rd5243;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5148}, %fd2549;
	}
	setp.lt.s32 	%p2438, %r5148, 0;
	selp.b64 	%rd5244, %rd5242, %rd5243, %p2438;
	shl.b64 	%rd5245, %rd5244, 1;
	sub.s64 	%rd5246, %rd5245, %rd989;
	mov.b64 	%fd2550, %rd5246;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5149}, %fd2550;
	}
	setp.lt.s32 	%p2439, %r5149, 0;
	selp.b64 	%rd5247, %rd5245, %rd5246, %p2439;
	shl.b64 	%rd5248, %rd5247, 1;
	sub.s64 	%rd5249, %rd5248, %rd989;
	mov.b64 	%fd2551, %rd5249;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5150}, %fd2551;
	}
	setp.lt.s32 	%p2440, %r5150, 0;
	selp.b64 	%rd5250, %rd5248, %rd5249, %p2440;
	shl.b64 	%rd5251, %rd5250, 1;
	sub.s64 	%rd5252, %rd5251, %rd989;
	mov.b64 	%fd2552, %rd5252;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5151}, %fd2552;
	}
	setp.lt.s32 	%p2441, %r5151, 0;
	selp.b64 	%rd5253, %rd5251, %rd5252, %p2441;
	shl.b64 	%rd5254, %rd5253, 1;
	sub.s64 	%rd5255, %rd5254, %rd989;
	mov.b64 	%fd2553, %rd5255;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5152}, %fd2553;
	}
	setp.lt.s32 	%p2442, %r5152, 0;
	selp.b64 	%rd5256, %rd5254, %rd5255, %p2442;
	shl.b64 	%rd5257, %rd5256, 1;
	sub.s64 	%rd5258, %rd5257, %rd989;
	mov.b64 	%fd2554, %rd5258;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5153}, %fd2554;
	}
	setp.lt.s32 	%p2443, %r5153, 0;
	selp.b64 	%rd5259, %rd5257, %rd5258, %p2443;
	shl.b64 	%rd5260, %rd5259, 1;
	sub.s64 	%rd5261, %rd5260, %rd989;
	mov.b64 	%fd2555, %rd5261;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5154}, %fd2555;
	}
	setp.lt.s32 	%p2444, %r5154, 0;
	selp.b64 	%rd5262, %rd5260, %rd5261, %p2444;
	shl.b64 	%rd5263, %rd5262, 1;
	sub.s64 	%rd5264, %rd5263, %rd989;
	mov.b64 	%fd2556, %rd5264;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5155}, %fd2556;
	}
	setp.lt.s32 	%p2445, %r5155, 0;
	selp.b64 	%rd5265, %rd5263, %rd5264, %p2445;
	shl.b64 	%rd5266, %rd5265, 1;
	sub.s64 	%rd5267, %rd5266, %rd989;
	mov.b64 	%fd2557, %rd5267;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5156}, %fd2557;
	}
	setp.lt.s32 	%p2446, %r5156, 0;
	selp.b64 	%rd5268, %rd5266, %rd5267, %p2446;
	shl.b64 	%rd5269, %rd5268, 1;
	sub.s64 	%rd5270, %rd5269, %rd989;
	mov.b64 	%fd2558, %rd5270;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5157}, %fd2558;
	}
	setp.lt.s32 	%p2447, %r5157, 0;
	selp.b64 	%rd5271, %rd5269, %rd5270, %p2447;
	shl.b64 	%rd5272, %rd5271, 1;
	sub.s64 	%rd5273, %rd5272, %rd989;
	mov.b64 	%fd2559, %rd5273;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5158}, %fd2559;
	}
	setp.lt.s32 	%p2448, %r5158, 0;
	selp.b64 	%rd5274, %rd5272, %rd5273, %p2448;
	shl.b64 	%rd5275, %rd5274, 1;
	sub.s64 	%rd5276, %rd5275, %rd989;
	mov.b64 	%fd2560, %rd5276;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5159}, %fd2560;
	}
	setp.lt.s32 	%p2449, %r5159, 0;
	selp.b64 	%rd6583, %rd5275, %rd5276, %p2449;
	shl.b64 	%rd6580, %rd6583, 1;
	add.s32 	%r1441, %r6438, -16;
	setp.gt.s32 	%p2450, %r6438, 15;
	mov.u32 	%r6438, %r1441;
	@%p2450 bra 	$L__BB0_1234;

$L__BB0_1235:
	and.b64  	%rd1004, %rd6583, 9223372036854775807;
	setp.eq.s64 	%p2451, %rd1004, 0;
	mov.f64 	%fd3134, 0d0000000000000000;
	@%p2451 bra 	$L__BB0_1237;

	mov.b64 	%fd2562, %rd1004;
	mul.f64 	%fd2563, %fd2562, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5160}, %fd2563;
	}
	shr.u32 	%r5161, %r5160, 20;
	mov.u32 	%r5162, 55;
	sub.s32 	%r5163, %r5162, %r5161;
	sub.s32 	%r5164, %r6432, %r5163;
	shl.b64 	%rd5277, %rd1004, %r5163;
	setp.lt.s32 	%p2452, %r5164, 1;
	mov.u32 	%r5165, 1;
	sub.s32 	%r5166, %r5165, %r5164;
	shr.u64 	%rd5278, %rd5277, %r5166;
	add.s32 	%r5167, %r5164, -1;
	cvt.u64.u32 	%rd5279, %r5167;
	shl.b64 	%rd5280, %rd5279, 52;
	add.s64 	%rd5281, %rd5280, %rd5277;
	selp.b64 	%rd5282, %rd5278, %rd5281, %p2452;
	mov.b64 	%fd3134, %rd5282;

$L__BB0_1237:
	and.b32  	%r5168, %r1418, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5169}, %fd3134;
	}
	or.b32  	%r5170, %r5169, %r5168;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5171, %temp}, %fd3134;
	}
	mov.b64 	%fd3135, {%r5171, %r5170};
	bra.uni 	$L__BB0_1241;

$L__BB0_1239:
	mov.f64 	%fd2564, 0d3FF0000000000000;
	add.rn.f64 	%fd3135, %fd651, %fd2564;

$L__BB0_1241:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 112 5
	ld.local.u8 	%rs218, [%rd2];
	cvt.rn.f64.u16 	%fd2565, %rs218;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	mov.f64 	%fd2566, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2567, %fd2566, %fd3135;
	mul.f64 	%fd2568, %fd2567, %fd2565;
	fma.rn.f64 	%fd662, %fd2568, 0d400921FB54442D18, 0d401921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1442}, %fd662;
	}
	and.b32  	%r5172, %r1442, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5173, %temp}, %fd662;
	}
	mov.b64 	%fd3136, {%r5173, %r5172};
	setp.gt.u32 	%p2457, %r5172, 2146435071;
	or.pred  	%p2459, %p2457, %p2211;
	@%p2459 bra 	$L__BB0_1258;
	bra.uni 	$L__BB0_1242;

$L__BB0_1258:
	.loc	1 0 9
	setp.le.f64 	%p2494, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2495, %fd3136, 0d7FF0000000000000;
	and.pred  	%p2496, %p2495, %p2494;
	@%p2496 bra 	$L__BB0_1260;
	bra.uni 	$L__BB0_1259;

$L__BB0_1260:
	setp.eq.f64 	%p2497, %fd3136, 0d7FF0000000000000;
	selp.f64 	%fd3139, 0dFFF8000000000000, %fd662, %p2497;
	bra.uni 	$L__BB0_1261;

$L__BB0_1242:
	.loc	1 0 9
	setp.eq.f64 	%p2460, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3139, 0dFFF8000000000000;
	.loc	1 32 9
	@%p2460 bra 	$L__BB0_1261;

	setp.ltu.f64 	%p2461, %fd3136, %fd3160;
	mov.f64 	%fd3139, %fd662;
	@%p2461 bra 	$L__BB0_1261;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5174}, %fd3136;
	}
	shr.u32 	%r6440, %r5174, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5175}, %fd3160;
	}
	shr.u32 	%r6441, %r5175, 20;
	setp.ne.s32 	%p2462, %r6440, 0;
	@%p2462 bra 	$L__BB0_1246;

	mul.f64 	%fd3136, %fd3136, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5176}, %fd3136;
	}
	shr.u32 	%r5177, %r5176, 20;
	add.s32 	%r6440, %r5177, -54;

$L__BB0_1246:
	setp.ne.s32 	%p2463, %r6441, 0;
	mov.f64 	%fd3137, %fd3160;
	@%p2463 bra 	$L__BB0_1248;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5178}, %fd595;
	}
	shr.u32 	%r5179, %r5178, 20;
	add.s32 	%r6441, %r5179, -54;
	mov.f64 	%fd3137, %fd595;

$L__BB0_1248:
	mov.b64 	%rd5284, %fd3136;
	and.b64  	%rd5285, %rd5284, 4503599627370495;
	or.b64  	%rd6588, %rd5285, 4503599627370496;
	mov.b64 	%rd5286, %fd3137;
	and.b64  	%rd5287, %rd5286, 4503599627370495;
	or.b64  	%rd1006, %rd5287, 4503599627370496;
	sub.s32 	%r6447, %r6440, %r6441;
	not.b32 	%r5180, %r6440;
	add.s32 	%r5181, %r6441, %r5180;
	max.s32 	%r5182, %r5181, -1;
	add.s32 	%r1450, %r5182, %r6440;
	mov.u32 	%r5183, 2;
	sub.s32 	%r5184, %r5183, %r6441;
	add.s32 	%r5185, %r5184, %r1450;
	and.b32  	%r6443, %r5185, 3;
	setp.eq.s32 	%p2464, %r6443, 0;
	@%p2464 bra 	$L__BB0_1250;

$L__BB0_1249:
	.pragma "nounroll";
	sub.s64 	%rd5288, %rd6588, %rd1006;
	mov.b64 	%fd2570, %rd5288;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5186}, %fd2570;
	}
	setp.lt.s32 	%p2465, %r5186, 0;
	selp.b64 	%rd6591, %rd6588, %rd5288, %p2465;
	shl.b64 	%rd6588, %rd6591, 1;
	add.s32 	%r6447, %r6447, -1;
	add.s32 	%r6443, %r6443, -1;
	setp.ne.s32 	%p2466, %r6443, 0;
	@%p2466 bra 	$L__BB0_1249;

$L__BB0_1250:
	mov.u32 	%r5187, 1;
	sub.s32 	%r5188, %r5187, %r6441;
	add.s32 	%r5189, %r5188, %r1450;
	setp.lt.u32 	%p2467, %r5189, 3;
	@%p2467 bra 	$L__BB0_1255;

	not.b32 	%r5190, %r6447;
	max.s32 	%r5191, %r5190, -4;
	add.s32 	%r5192, %r6447, %r5191;
	add.s32 	%r1457, %r5192, 4;
	shr.u32 	%r5193, %r1457, 2;
	add.s32 	%r5194, %r5193, 1;
	and.b32  	%r6446, %r5194, 3;
	setp.eq.s32 	%p2468, %r6446, 0;
	@%p2468 bra 	$L__BB0_1253;

$L__BB0_1252:
	.pragma "nounroll";
	sub.s64 	%rd5290, %rd6588, %rd1006;
	mov.b64 	%fd2571, %rd5290;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5195}, %fd2571;
	}
	setp.lt.s32 	%p2469, %r5195, 0;
	selp.b64 	%rd5291, %rd6588, %rd5290, %p2469;
	shl.b64 	%rd5292, %rd5291, 1;
	sub.s64 	%rd5293, %rd5292, %rd1006;
	mov.b64 	%fd2572, %rd5293;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5196}, %fd2572;
	}
	setp.lt.s32 	%p2470, %r5196, 0;
	selp.b64 	%rd5294, %rd5292, %rd5293, %p2470;
	shl.b64 	%rd5295, %rd5294, 1;
	sub.s64 	%rd5296, %rd5295, %rd1006;
	mov.b64 	%fd2573, %rd5296;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5197}, %fd2573;
	}
	setp.lt.s32 	%p2471, %r5197, 0;
	selp.b64 	%rd5297, %rd5295, %rd5296, %p2471;
	shl.b64 	%rd5298, %rd5297, 1;
	sub.s64 	%rd5299, %rd5298, %rd1006;
	mov.b64 	%fd2574, %rd5299;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5198}, %fd2574;
	}
	setp.lt.s32 	%p2472, %r5198, 0;
	selp.b64 	%rd6591, %rd5298, %rd5299, %p2472;
	shl.b64 	%rd6588, %rd6591, 1;
	add.s32 	%r6447, %r6447, -4;
	add.s32 	%r6446, %r6446, -1;
	setp.ne.s32 	%p2473, %r6446, 0;
	@%p2473 bra 	$L__BB0_1252;

$L__BB0_1253:
	setp.lt.u32 	%p2474, %r1457, 12;
	@%p2474 bra 	$L__BB0_1255;

$L__BB0_1254:
	sub.s64 	%rd5300, %rd6588, %rd1006;
	mov.b64 	%fd2575, %rd5300;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5199}, %fd2575;
	}
	setp.lt.s32 	%p2475, %r5199, 0;
	selp.b64 	%rd5301, %rd6588, %rd5300, %p2475;
	shl.b64 	%rd5302, %rd5301, 1;
	sub.s64 	%rd5303, %rd5302, %rd1006;
	mov.b64 	%fd2576, %rd5303;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5200}, %fd2576;
	}
	setp.lt.s32 	%p2476, %r5200, 0;
	selp.b64 	%rd5304, %rd5302, %rd5303, %p2476;
	shl.b64 	%rd5305, %rd5304, 1;
	sub.s64 	%rd5306, %rd5305, %rd1006;
	mov.b64 	%fd2577, %rd5306;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5201}, %fd2577;
	}
	setp.lt.s32 	%p2477, %r5201, 0;
	selp.b64 	%rd5307, %rd5305, %rd5306, %p2477;
	shl.b64 	%rd5308, %rd5307, 1;
	sub.s64 	%rd5309, %rd5308, %rd1006;
	mov.b64 	%fd2578, %rd5309;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5202}, %fd2578;
	}
	setp.lt.s32 	%p2478, %r5202, 0;
	selp.b64 	%rd5310, %rd5308, %rd5309, %p2478;
	shl.b64 	%rd5311, %rd5310, 1;
	sub.s64 	%rd5312, %rd5311, %rd1006;
	mov.b64 	%fd2579, %rd5312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5203}, %fd2579;
	}
	setp.lt.s32 	%p2479, %r5203, 0;
	selp.b64 	%rd5313, %rd5311, %rd5312, %p2479;
	shl.b64 	%rd5314, %rd5313, 1;
	sub.s64 	%rd5315, %rd5314, %rd1006;
	mov.b64 	%fd2580, %rd5315;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5204}, %fd2580;
	}
	setp.lt.s32 	%p2480, %r5204, 0;
	selp.b64 	%rd5316, %rd5314, %rd5315, %p2480;
	shl.b64 	%rd5317, %rd5316, 1;
	sub.s64 	%rd5318, %rd5317, %rd1006;
	mov.b64 	%fd2581, %rd5318;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5205}, %fd2581;
	}
	setp.lt.s32 	%p2481, %r5205, 0;
	selp.b64 	%rd5319, %rd5317, %rd5318, %p2481;
	shl.b64 	%rd5320, %rd5319, 1;
	sub.s64 	%rd5321, %rd5320, %rd1006;
	mov.b64 	%fd2582, %rd5321;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5206}, %fd2582;
	}
	setp.lt.s32 	%p2482, %r5206, 0;
	selp.b64 	%rd5322, %rd5320, %rd5321, %p2482;
	shl.b64 	%rd5323, %rd5322, 1;
	sub.s64 	%rd5324, %rd5323, %rd1006;
	mov.b64 	%fd2583, %rd5324;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5207}, %fd2583;
	}
	setp.lt.s32 	%p2483, %r5207, 0;
	selp.b64 	%rd5325, %rd5323, %rd5324, %p2483;
	shl.b64 	%rd5326, %rd5325, 1;
	sub.s64 	%rd5327, %rd5326, %rd1006;
	mov.b64 	%fd2584, %rd5327;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5208}, %fd2584;
	}
	setp.lt.s32 	%p2484, %r5208, 0;
	selp.b64 	%rd5328, %rd5326, %rd5327, %p2484;
	shl.b64 	%rd5329, %rd5328, 1;
	sub.s64 	%rd5330, %rd5329, %rd1006;
	mov.b64 	%fd2585, %rd5330;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5209}, %fd2585;
	}
	setp.lt.s32 	%p2485, %r5209, 0;
	selp.b64 	%rd5331, %rd5329, %rd5330, %p2485;
	shl.b64 	%rd5332, %rd5331, 1;
	sub.s64 	%rd5333, %rd5332, %rd1006;
	mov.b64 	%fd2586, %rd5333;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5210}, %fd2586;
	}
	setp.lt.s32 	%p2486, %r5210, 0;
	selp.b64 	%rd5334, %rd5332, %rd5333, %p2486;
	shl.b64 	%rd5335, %rd5334, 1;
	sub.s64 	%rd5336, %rd5335, %rd1006;
	mov.b64 	%fd2587, %rd5336;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5211}, %fd2587;
	}
	setp.lt.s32 	%p2487, %r5211, 0;
	selp.b64 	%rd5337, %rd5335, %rd5336, %p2487;
	shl.b64 	%rd5338, %rd5337, 1;
	sub.s64 	%rd5339, %rd5338, %rd1006;
	mov.b64 	%fd2588, %rd5339;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5212}, %fd2588;
	}
	setp.lt.s32 	%p2488, %r5212, 0;
	selp.b64 	%rd5340, %rd5338, %rd5339, %p2488;
	shl.b64 	%rd5341, %rd5340, 1;
	sub.s64 	%rd5342, %rd5341, %rd1006;
	mov.b64 	%fd2589, %rd5342;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5213}, %fd2589;
	}
	setp.lt.s32 	%p2489, %r5213, 0;
	selp.b64 	%rd5343, %rd5341, %rd5342, %p2489;
	shl.b64 	%rd5344, %rd5343, 1;
	sub.s64 	%rd5345, %rd5344, %rd1006;
	mov.b64 	%fd2590, %rd5345;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5214}, %fd2590;
	}
	setp.lt.s32 	%p2490, %r5214, 0;
	selp.b64 	%rd6591, %rd5344, %rd5345, %p2490;
	shl.b64 	%rd6588, %rd6591, 1;
	add.s32 	%r1465, %r6447, -16;
	setp.gt.s32 	%p2491, %r6447, 15;
	mov.u32 	%r6447, %r1465;
	@%p2491 bra 	$L__BB0_1254;

$L__BB0_1255:
	and.b64  	%rd1021, %rd6591, 9223372036854775807;
	setp.eq.s64 	%p2492, %rd1021, 0;
	mov.f64 	%fd3138, 0d0000000000000000;
	@%p2492 bra 	$L__BB0_1257;

	mov.b64 	%fd2592, %rd1021;
	mul.f64 	%fd2593, %fd2592, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5215}, %fd2593;
	}
	shr.u32 	%r5216, %r5215, 20;
	mov.u32 	%r5217, 55;
	sub.s32 	%r5218, %r5217, %r5216;
	sub.s32 	%r5219, %r6441, %r5218;
	shl.b64 	%rd5346, %rd1021, %r5218;
	setp.lt.s32 	%p2493, %r5219, 1;
	mov.u32 	%r5220, 1;
	sub.s32 	%r5221, %r5220, %r5219;
	shr.u64 	%rd5347, %rd5346, %r5221;
	add.s32 	%r5222, %r5219, -1;
	cvt.u64.u32 	%rd5348, %r5222;
	shl.b64 	%rd5349, %rd5348, 52;
	add.s64 	%rd5350, %rd5349, %rd5346;
	selp.b64 	%rd5351, %rd5347, %rd5350, %p2493;
	mov.b64 	%fd3138, %rd5351;

$L__BB0_1257:
	and.b32  	%r5223, %r1442, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5224}, %fd3138;
	}
	or.b32  	%r5225, %r5224, %r5223;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5226, %temp}, %fd3138;
	}
	mov.b64 	%fd3139, {%r5226, %r5225};
	bra.uni 	$L__BB0_1261;

$L__BB0_1259:
	mov.f64 	%fd2594, 0d3FF0000000000000;
	add.rn.f64 	%fd3139, %fd662, %fd2594;

$L__BB0_1261:
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 112 5
	ld.local.u8 	%rs217, [%rd1];
	cvt.rn.f64.u16 	%fd2595, %rs217;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 112 5
	mov.f64 	%fd2596, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2597, %fd2596, %fd3139;
	mul.f64 	%fd2598, %fd2597, %fd2595;
	fma.rn.f64 	%fd2599, %fd2598, 0d400921FB54442D18, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5227}, %fd2599;
	}
	and.b32  	%r5228, %r5227, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5229, %temp}, %fd2599;
	}
	mov.b64 	%fd673, {%r5229, %r5228};
	setp.gt.u32 	%p2498, %r5228, 2146435071;
	or.pred  	%p2500, %p2498, %p2211;
	setp.ltu.f64 	%p2501, %fd673, %fd3160;
	setp.eq.f64 	%p2502, %fd3160, 0d0000000000000000;
	or.pred  	%p2503, %p2502, %p2501;
	or.pred  	%p2504, %p2500, %p2503;
	@%p2504 bra 	$L__BB0_1271;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5230}, %fd673;
	}
	shr.u32 	%r6449, %r5230, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5231}, %fd3160;
	}
	shr.u32 	%r6450, %r5231, 20;
	setp.ne.s32 	%p2505, %r6449, 0;
	@%p2505 bra 	$L__BB0_1264;

	mul.f64 	%fd2600, %fd673, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5232}, %fd2600;
	}
	shr.u32 	%r5233, %r5232, 20;
	add.s32 	%r6449, %r5233, -54;

$L__BB0_1264:
	setp.ne.s32 	%p2506, %r6450, 0;
	@%p2506 bra 	$L__BB0_1266;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5234}, %fd595;
	}
	shr.u32 	%r5235, %r5234, 20;
	add.s32 	%r6450, %r5235, -54;

$L__BB0_1266:
	sub.s32 	%r6453, %r6449, %r6450;
	not.b32 	%r5236, %r6449;
	add.s32 	%r5237, %r6450, %r5236;
	max.s32 	%r5238, %r5237, -1;
	add.s32 	%r5239, %r5238, %r6449;
	mov.u32 	%r5240, 2;
	sub.s32 	%r5241, %r5240, %r6450;
	add.s32 	%r5242, %r5241, %r5239;
	mov.u32 	%r5243, 1;
	sub.s32 	%r5244, %r5243, %r6450;
	add.s32 	%r1473, %r5244, %r5239;
	and.b32  	%r6452, %r5242, 3;
	setp.eq.s32 	%p2507, %r6452, 0;
	@%p2507 bra 	$L__BB0_1268;

$L__BB0_1267:
	.pragma "nounroll";
	add.s32 	%r6453, %r6453, -1;
	add.s32 	%r6452, %r6452, -1;
	setp.ne.s32 	%p2508, %r6452, 0;
	@%p2508 bra 	$L__BB0_1267;

$L__BB0_1268:
	setp.lt.u32 	%p2509, %r1473, 3;
	@%p2509 bra 	$L__BB0_1271;

	not.b32 	%r5245, %r6453;
	max.s32 	%r5246, %r5245, -4;
	add.s32 	%r5247, %r6453, %r5246;
	add.s32 	%r5248, %r5247, 4;
	shr.u32 	%r5249, %r5248, 2;
	add.s32 	%r5250, %r5249, 1;
	and.b32  	%r6454, %r5250, 3;
	setp.eq.s32 	%p2510, %r6454, 0;
	@%p2510 bra 	$L__BB0_1271;

$L__BB0_1270:
	.pragma "nounroll";
	add.s32 	%r6454, %r6454, -1;
	setp.ne.s32 	%p2511, %r6454, 0;
	@%p2511 bra 	$L__BB0_1270;

$L__BB0_1271:
	.loc	1 118 5, function_name $L__info_string5, inlined_at 1 260 17
	shl.b16 	%rs127, %rs223, 8;
	or.b16  	%rs128, %rs222, %rs127;
	shl.b16 	%rs129, %rs221, 8;
	or.b16  	%rs130, %rs220, %rs129;
	shl.b16 	%rs131, %rs219, 8;
	or.b16  	%rs132, %rs218, %rs131;
	shl.b16 	%rs133, %rs217, 8;
	or.b16  	%rs134, %rs133, 114;
	mov.u16 	%rs135, 25960;
	mov.u16 	%rs136, 25461;
	mov.u16 	%rs137, 28502;
	add.u64 	%rd1022, %SPL, 0;
	mov.b32 	%r5253, {%rs132, %rs130};
	mov.b32 	%r5254, {%rs137, %rs136};
	mov.b32 	%r5255, {%rs128, %rs229};
	mov.b32 	%r5256, {%rs135, %rs134};
	st.local.v4.u32 	[%rd1022], {%r5254, %r5256, %r5253, %r5255};
	mov.f64 	%fd2958, 0d3FF0000000000000;
	mov.u32 	%r6456, 15;
	mov.u32 	%r6455, 14;

$L__BB0_1272:
	.loc	1 0 5
	mov.u32 	%r1484, %r6456;
	mov.u32 	%r6456, %r6455;
	.loc	1 119 5, function_name $L__info_string5, inlined_at 1 260 17
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 119 5
	cvt.s64.s32 	%rd5353, %r6456;
	add.s64 	%rd5354, %rd1022, %rd5353;
	ld.local.u8 	%rs138, [%rd5354];
	cvt.rn.f64.u16 	%fd2602, %rs138;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 119 5
	mov.f64 	%fd2603, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2604, %fd2603, %fd2958;
	mul.f64 	%fd2605, %fd2604, %fd2602;
	mul.f64 	%fd2606, %fd2605, 0d400921FB54442D18;
	cvt.rn.f64.s32 	%fd2607, %r1484;
	fma.rn.f64 	%fd675, %fd2607, 0d400921FB54442D18, %fd2606;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1485}, %fd675;
	}
	and.b32  	%r5257, %r1485, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5258, %temp}, %fd675;
	}
	mov.b64 	%fd3141, {%r5258, %r5257};
	setp.gt.u32 	%p2512, %r5257, 2146435071;
	or.pred  	%p2514, %p2512, %p2211;
	@%p2514 bra 	$L__BB0_1289;
	bra.uni 	$L__BB0_1273;

$L__BB0_1289:
	.loc	1 0 9
	setp.le.f64 	%p2549, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2550, %fd3141, 0d7FF0000000000000;
	and.pred  	%p2551, %p2550, %p2549;
	@%p2551 bra 	$L__BB0_1291;
	bra.uni 	$L__BB0_1290;

$L__BB0_1291:
	setp.eq.f64 	%p2552, %fd3141, 0d7FF0000000000000;
	selp.f64 	%fd2958, 0dFFF8000000000000, %fd675, %p2552;
	bra.uni 	$L__BB0_1292;

$L__BB0_1273:
	.loc	1 0 9
	mov.f64 	%fd2958, 0dFFF8000000000000;
	.loc	1 32 9
	@%p2502 bra 	$L__BB0_1292;

	setp.ltu.f64 	%p2516, %fd3141, %fd3160;
	mov.f64 	%fd2958, %fd675;
	@%p2516 bra 	$L__BB0_1292;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5259}, %fd3141;
	}
	shr.u32 	%r6457, %r5259, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5260}, %fd3160;
	}
	shr.u32 	%r6458, %r5260, 20;
	setp.ne.s32 	%p2517, %r6457, 0;
	@%p2517 bra 	$L__BB0_1277;

	mul.f64 	%fd3141, %fd3141, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5261}, %fd3141;
	}
	shr.u32 	%r5262, %r5261, 20;
	add.s32 	%r6457, %r5262, -54;

$L__BB0_1277:
	setp.ne.s32 	%p2518, %r6458, 0;
	mov.f64 	%fd3142, %fd3160;
	@%p2518 bra 	$L__BB0_1279;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5263}, %fd595;
	}
	shr.u32 	%r5264, %r5263, 20;
	add.s32 	%r6458, %r5264, -54;
	mov.f64 	%fd3142, %fd595;

$L__BB0_1279:
	mov.b64 	%rd5356, %fd3141;
	and.b64  	%rd5357, %rd5356, 4503599627370495;
	or.b64  	%rd6596, %rd5357, 4503599627370496;
	mov.b64 	%rd5358, %fd3142;
	and.b64  	%rd5359, %rd5358, 4503599627370495;
	or.b64  	%rd1024, %rd5359, 4503599627370496;
	sub.s32 	%r6464, %r6457, %r6458;
	not.b32 	%r5265, %r6457;
	add.s32 	%r5266, %r6458, %r5265;
	max.s32 	%r5267, %r5266, -1;
	add.s32 	%r1493, %r5267, %r6457;
	mov.u32 	%r5268, 2;
	sub.s32 	%r5269, %r5268, %r6458;
	add.s32 	%r5270, %r5269, %r1493;
	and.b32  	%r6460, %r5270, 3;
	setp.eq.s32 	%p2519, %r6460, 0;
	@%p2519 bra 	$L__BB0_1281;

$L__BB0_1280:
	.pragma "nounroll";
	sub.s64 	%rd5360, %rd6596, %rd1024;
	mov.b64 	%fd2609, %rd5360;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5271}, %fd2609;
	}
	setp.lt.s32 	%p2520, %r5271, 0;
	selp.b64 	%rd6599, %rd6596, %rd5360, %p2520;
	shl.b64 	%rd6596, %rd6599, 1;
	add.s32 	%r6464, %r6464, -1;
	add.s32 	%r6460, %r6460, -1;
	setp.ne.s32 	%p2521, %r6460, 0;
	@%p2521 bra 	$L__BB0_1280;

$L__BB0_1281:
	mov.u32 	%r5272, 1;
	sub.s32 	%r5273, %r5272, %r6458;
	add.s32 	%r5274, %r5273, %r1493;
	setp.lt.u32 	%p2522, %r5274, 3;
	@%p2522 bra 	$L__BB0_1286;

	not.b32 	%r5275, %r6464;
	max.s32 	%r5276, %r5275, -4;
	add.s32 	%r5277, %r6464, %r5276;
	add.s32 	%r1500, %r5277, 4;
	shr.u32 	%r5278, %r1500, 2;
	add.s32 	%r5279, %r5278, 1;
	and.b32  	%r6463, %r5279, 3;
	setp.eq.s32 	%p2523, %r6463, 0;
	@%p2523 bra 	$L__BB0_1284;

$L__BB0_1283:
	.pragma "nounroll";
	sub.s64 	%rd5362, %rd6596, %rd1024;
	mov.b64 	%fd2610, %rd5362;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5280}, %fd2610;
	}
	setp.lt.s32 	%p2524, %r5280, 0;
	selp.b64 	%rd5363, %rd6596, %rd5362, %p2524;
	shl.b64 	%rd5364, %rd5363, 1;
	sub.s64 	%rd5365, %rd5364, %rd1024;
	mov.b64 	%fd2611, %rd5365;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5281}, %fd2611;
	}
	setp.lt.s32 	%p2525, %r5281, 0;
	selp.b64 	%rd5366, %rd5364, %rd5365, %p2525;
	shl.b64 	%rd5367, %rd5366, 1;
	sub.s64 	%rd5368, %rd5367, %rd1024;
	mov.b64 	%fd2612, %rd5368;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5282}, %fd2612;
	}
	setp.lt.s32 	%p2526, %r5282, 0;
	selp.b64 	%rd5369, %rd5367, %rd5368, %p2526;
	shl.b64 	%rd5370, %rd5369, 1;
	sub.s64 	%rd5371, %rd5370, %rd1024;
	mov.b64 	%fd2613, %rd5371;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5283}, %fd2613;
	}
	setp.lt.s32 	%p2527, %r5283, 0;
	selp.b64 	%rd6599, %rd5370, %rd5371, %p2527;
	shl.b64 	%rd6596, %rd6599, 1;
	add.s32 	%r6464, %r6464, -4;
	add.s32 	%r6463, %r6463, -1;
	setp.ne.s32 	%p2528, %r6463, 0;
	@%p2528 bra 	$L__BB0_1283;

$L__BB0_1284:
	setp.lt.u32 	%p2529, %r1500, 12;
	@%p2529 bra 	$L__BB0_1286;

$L__BB0_1285:
	sub.s64 	%rd5372, %rd6596, %rd1024;
	mov.b64 	%fd2614, %rd5372;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5284}, %fd2614;
	}
	setp.lt.s32 	%p2530, %r5284, 0;
	selp.b64 	%rd5373, %rd6596, %rd5372, %p2530;
	shl.b64 	%rd5374, %rd5373, 1;
	sub.s64 	%rd5375, %rd5374, %rd1024;
	mov.b64 	%fd2615, %rd5375;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5285}, %fd2615;
	}
	setp.lt.s32 	%p2531, %r5285, 0;
	selp.b64 	%rd5376, %rd5374, %rd5375, %p2531;
	shl.b64 	%rd5377, %rd5376, 1;
	sub.s64 	%rd5378, %rd5377, %rd1024;
	mov.b64 	%fd2616, %rd5378;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5286}, %fd2616;
	}
	setp.lt.s32 	%p2532, %r5286, 0;
	selp.b64 	%rd5379, %rd5377, %rd5378, %p2532;
	shl.b64 	%rd5380, %rd5379, 1;
	sub.s64 	%rd5381, %rd5380, %rd1024;
	mov.b64 	%fd2617, %rd5381;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5287}, %fd2617;
	}
	setp.lt.s32 	%p2533, %r5287, 0;
	selp.b64 	%rd5382, %rd5380, %rd5381, %p2533;
	shl.b64 	%rd5383, %rd5382, 1;
	sub.s64 	%rd5384, %rd5383, %rd1024;
	mov.b64 	%fd2618, %rd5384;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5288}, %fd2618;
	}
	setp.lt.s32 	%p2534, %r5288, 0;
	selp.b64 	%rd5385, %rd5383, %rd5384, %p2534;
	shl.b64 	%rd5386, %rd5385, 1;
	sub.s64 	%rd5387, %rd5386, %rd1024;
	mov.b64 	%fd2619, %rd5387;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5289}, %fd2619;
	}
	setp.lt.s32 	%p2535, %r5289, 0;
	selp.b64 	%rd5388, %rd5386, %rd5387, %p2535;
	shl.b64 	%rd5389, %rd5388, 1;
	sub.s64 	%rd5390, %rd5389, %rd1024;
	mov.b64 	%fd2620, %rd5390;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5290}, %fd2620;
	}
	setp.lt.s32 	%p2536, %r5290, 0;
	selp.b64 	%rd5391, %rd5389, %rd5390, %p2536;
	shl.b64 	%rd5392, %rd5391, 1;
	sub.s64 	%rd5393, %rd5392, %rd1024;
	mov.b64 	%fd2621, %rd5393;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5291}, %fd2621;
	}
	setp.lt.s32 	%p2537, %r5291, 0;
	selp.b64 	%rd5394, %rd5392, %rd5393, %p2537;
	shl.b64 	%rd5395, %rd5394, 1;
	sub.s64 	%rd5396, %rd5395, %rd1024;
	mov.b64 	%fd2622, %rd5396;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5292}, %fd2622;
	}
	setp.lt.s32 	%p2538, %r5292, 0;
	selp.b64 	%rd5397, %rd5395, %rd5396, %p2538;
	shl.b64 	%rd5398, %rd5397, 1;
	sub.s64 	%rd5399, %rd5398, %rd1024;
	mov.b64 	%fd2623, %rd5399;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5293}, %fd2623;
	}
	setp.lt.s32 	%p2539, %r5293, 0;
	selp.b64 	%rd5400, %rd5398, %rd5399, %p2539;
	shl.b64 	%rd5401, %rd5400, 1;
	sub.s64 	%rd5402, %rd5401, %rd1024;
	mov.b64 	%fd2624, %rd5402;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5294}, %fd2624;
	}
	setp.lt.s32 	%p2540, %r5294, 0;
	selp.b64 	%rd5403, %rd5401, %rd5402, %p2540;
	shl.b64 	%rd5404, %rd5403, 1;
	sub.s64 	%rd5405, %rd5404, %rd1024;
	mov.b64 	%fd2625, %rd5405;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5295}, %fd2625;
	}
	setp.lt.s32 	%p2541, %r5295, 0;
	selp.b64 	%rd5406, %rd5404, %rd5405, %p2541;
	shl.b64 	%rd5407, %rd5406, 1;
	sub.s64 	%rd5408, %rd5407, %rd1024;
	mov.b64 	%fd2626, %rd5408;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5296}, %fd2626;
	}
	setp.lt.s32 	%p2542, %r5296, 0;
	selp.b64 	%rd5409, %rd5407, %rd5408, %p2542;
	shl.b64 	%rd5410, %rd5409, 1;
	sub.s64 	%rd5411, %rd5410, %rd1024;
	mov.b64 	%fd2627, %rd5411;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5297}, %fd2627;
	}
	setp.lt.s32 	%p2543, %r5297, 0;
	selp.b64 	%rd5412, %rd5410, %rd5411, %p2543;
	shl.b64 	%rd5413, %rd5412, 1;
	sub.s64 	%rd5414, %rd5413, %rd1024;
	mov.b64 	%fd2628, %rd5414;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5298}, %fd2628;
	}
	setp.lt.s32 	%p2544, %r5298, 0;
	selp.b64 	%rd5415, %rd5413, %rd5414, %p2544;
	shl.b64 	%rd5416, %rd5415, 1;
	sub.s64 	%rd5417, %rd5416, %rd1024;
	mov.b64 	%fd2629, %rd5417;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5299}, %fd2629;
	}
	setp.lt.s32 	%p2545, %r5299, 0;
	selp.b64 	%rd6599, %rd5416, %rd5417, %p2545;
	shl.b64 	%rd6596, %rd6599, 1;
	add.s32 	%r1508, %r6464, -16;
	setp.gt.s32 	%p2546, %r6464, 15;
	mov.u32 	%r6464, %r1508;
	@%p2546 bra 	$L__BB0_1285;

$L__BB0_1286:
	and.b64  	%rd1039, %rd6599, 9223372036854775807;
	setp.eq.s64 	%p2547, %rd1039, 0;
	mov.f64 	%fd3143, 0d0000000000000000;
	@%p2547 bra 	$L__BB0_1288;

	mov.b64 	%fd2631, %rd1039;
	mul.f64 	%fd2632, %fd2631, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5300}, %fd2632;
	}
	shr.u32 	%r5301, %r5300, 20;
	mov.u32 	%r5302, 55;
	sub.s32 	%r5303, %r5302, %r5301;
	sub.s32 	%r5304, %r6458, %r5303;
	shl.b64 	%rd5418, %rd1039, %r5303;
	setp.lt.s32 	%p2548, %r5304, 1;
	mov.u32 	%r5305, 1;
	sub.s32 	%r5306, %r5305, %r5304;
	shr.u64 	%rd5419, %rd5418, %r5306;
	add.s32 	%r5307, %r5304, -1;
	cvt.u64.u32 	%rd5420, %r5307;
	shl.b64 	%rd5421, %rd5420, 52;
	add.s64 	%rd5422, %rd5421, %rd5418;
	selp.b64 	%rd5423, %rd5419, %rd5422, %p2548;
	mov.b64 	%fd3143, %rd5423;

$L__BB0_1288:
	and.b32  	%r5308, %r1485, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5309}, %fd3143;
	}
	or.b32  	%r5310, %r5309, %r5308;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5311, %temp}, %fd3143;
	}
	mov.b64 	%fd2958, {%r5311, %r5310};
	bra.uni 	$L__BB0_1292;

$L__BB0_1290:
	mov.f64 	%fd2633, 0d3FF0000000000000;
	add.rn.f64 	%fd2958, %fd675, %fd2633;

$L__BB0_1292:
	.loc	1 30 5, function_name $L__info_string4, inlined_at 1 119 5
	add.s32 	%r6455, %r6456, -1;
	setp.gt.s32 	%p2553, %r6456, 0;
	@%p2553 bra 	$L__BB0_1272;

	.loc	1 0 5
	add.u64 	%rd1040, %SPL, 16;
	.loc	1 122 5, function_name $L__info_string5, inlined_at 1 260 17
	mov.u16 	%rs139, 115;
	st.local.u8 	[%rd1040], %rs139;
	mov.u16 	%rs140, 104;
	st.local.u8 	[%rd1040+1], %rs140;
	mov.u16 	%rs141, 111;
	st.local.u8 	[%rd1040+2], %rs141;
	mov.u16 	%rs142, 112;
	st.local.u8 	[%rd1040+3], %rs142;
	mov.u16 	%rs143, 95;
	st.local.u8 	[%rd1040+4], %rs143;
	st.local.u8 	[%rd1040+5], %rs142;
	mov.u16 	%rs144, 97;
	st.local.u8 	[%rd1040+6], %rs144;
	mov.u16 	%rs145, 99;
	st.local.u8 	[%rd1040+7], %rs145;
	mov.u16 	%rs146, 107;
	st.local.u8 	[%rd1040+8], %rs146;
	mov.u16 	%rs147, 49;
	st.local.u8 	[%rd1040+9], %rs147;
	.loc	1 123 5, function_name $L__info_string5, inlined_at 1 260 17
	st.local.u8 	[%rd1040+10], %rs217;
	st.local.u8 	[%rd1040+11], %rs218;
	st.local.u8 	[%rd1040+12], %rs219;
	st.local.u8 	[%rd1040+13], %rs220;
	st.local.u8 	[%rd1040+14], %rs221;
	st.local.u8 	[%rd1040+15], %rs222;
	st.local.u8 	[%rd1040+16], %rs223;
	st.local.u8 	[%rd1040+17], %rs229;
	.loc	1 124 5, function_name $L__info_string5, inlined_at 1 260 17
	mov.u16 	%rs148, 0;
	st.local.u8 	[%rd1040+18], %rs148;
	mov.f64 	%fd3034, 0d3FF0000000000000;
	mov.u32 	%r6467, 18;
	mov.u32 	%r6466, 17;

$L__BB0_1294:
	.loc	1 0 5
	mov.u32 	%r1511, %r6467;
	mov.u32 	%r6467, %r6466;
	.loc	1 125 5, function_name $L__info_string5, inlined_at 1 260 17
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 125 5
	cvt.s64.s32 	%rd5425, %r6467;
	add.s64 	%rd5426, %rd1040, %rd5425;
	ld.local.u8 	%rs149, [%rd5426];
	cvt.rn.f64.u16 	%fd2635, %rs149;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 125 5
	mov.f64 	%fd2636, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2637, %fd2636, %fd3034;
	mul.f64 	%fd2638, %fd2637, %fd2635;
	mul.f64 	%fd2639, %fd2638, 0d400921FB54442D18;
	cvt.rn.f64.s32 	%fd2640, %r1511;
	fma.rn.f64 	%fd687, %fd2640, 0d400921FB54442D18, %fd2639;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1512}, %fd687;
	}
	and.b32  	%r5314, %r1512, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5315, %temp}, %fd687;
	}
	mov.b64 	%fd3146, {%r5315, %r5314};
	setp.gt.u32 	%p2554, %r5314, 2146435071;
	or.pred  	%p2556, %p2554, %p2211;
	@%p2556 bra 	$L__BB0_1311;
	bra.uni 	$L__BB0_1295;

$L__BB0_1311:
	.loc	1 0 9
	setp.le.f64 	%p2591, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2592, %fd3146, 0d7FF0000000000000;
	and.pred  	%p2593, %p2592, %p2591;
	@%p2593 bra 	$L__BB0_1313;
	bra.uni 	$L__BB0_1312;

$L__BB0_1313:
	setp.eq.f64 	%p2594, %fd3146, 0d7FF0000000000000;
	selp.f64 	%fd3034, 0dFFF8000000000000, %fd687, %p2594;
	bra.uni 	$L__BB0_1314;

$L__BB0_1295:
	.loc	1 0 9
	mov.f64 	%fd3034, 0dFFF8000000000000;
	.loc	1 32 9
	@%p2502 bra 	$L__BB0_1314;

	setp.ltu.f64 	%p2558, %fd3146, %fd3160;
	mov.f64 	%fd3034, %fd687;
	@%p2558 bra 	$L__BB0_1314;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5316}, %fd3146;
	}
	shr.u32 	%r6468, %r5316, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5317}, %fd3160;
	}
	shr.u32 	%r6469, %r5317, 20;
	setp.ne.s32 	%p2559, %r6468, 0;
	@%p2559 bra 	$L__BB0_1299;

	mul.f64 	%fd3146, %fd3146, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5318}, %fd3146;
	}
	shr.u32 	%r5319, %r5318, 20;
	add.s32 	%r6468, %r5319, -54;

$L__BB0_1299:
	setp.ne.s32 	%p2560, %r6469, 0;
	mov.f64 	%fd3147, %fd3160;
	@%p2560 bra 	$L__BB0_1301;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5320}, %fd595;
	}
	shr.u32 	%r5321, %r5320, 20;
	add.s32 	%r6469, %r5321, -54;
	mov.f64 	%fd3147, %fd595;

$L__BB0_1301:
	mov.b64 	%rd5428, %fd3146;
	and.b64  	%rd5429, %rd5428, 4503599627370495;
	or.b64  	%rd6604, %rd5429, 4503599627370496;
	mov.b64 	%rd5430, %fd3147;
	and.b64  	%rd5431, %rd5430, 4503599627370495;
	or.b64  	%rd1042, %rd5431, 4503599627370496;
	sub.s32 	%r6475, %r6468, %r6469;
	not.b32 	%r5322, %r6468;
	add.s32 	%r5323, %r6469, %r5322;
	max.s32 	%r5324, %r5323, -1;
	add.s32 	%r1520, %r5324, %r6468;
	mov.u32 	%r5325, 2;
	sub.s32 	%r5326, %r5325, %r6469;
	add.s32 	%r5327, %r5326, %r1520;
	and.b32  	%r6471, %r5327, 3;
	setp.eq.s32 	%p2561, %r6471, 0;
	@%p2561 bra 	$L__BB0_1303;

$L__BB0_1302:
	.pragma "nounroll";
	sub.s64 	%rd5432, %rd6604, %rd1042;
	mov.b64 	%fd2642, %rd5432;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5328}, %fd2642;
	}
	setp.lt.s32 	%p2562, %r5328, 0;
	selp.b64 	%rd6607, %rd6604, %rd5432, %p2562;
	shl.b64 	%rd6604, %rd6607, 1;
	add.s32 	%r6475, %r6475, -1;
	add.s32 	%r6471, %r6471, -1;
	setp.ne.s32 	%p2563, %r6471, 0;
	@%p2563 bra 	$L__BB0_1302;

$L__BB0_1303:
	mov.u32 	%r5329, 1;
	sub.s32 	%r5330, %r5329, %r6469;
	add.s32 	%r5331, %r5330, %r1520;
	setp.lt.u32 	%p2564, %r5331, 3;
	@%p2564 bra 	$L__BB0_1308;

	not.b32 	%r5332, %r6475;
	max.s32 	%r5333, %r5332, -4;
	add.s32 	%r5334, %r6475, %r5333;
	add.s32 	%r1527, %r5334, 4;
	shr.u32 	%r5335, %r1527, 2;
	add.s32 	%r5336, %r5335, 1;
	and.b32  	%r6474, %r5336, 3;
	setp.eq.s32 	%p2565, %r6474, 0;
	@%p2565 bra 	$L__BB0_1306;

$L__BB0_1305:
	.pragma "nounroll";
	sub.s64 	%rd5434, %rd6604, %rd1042;
	mov.b64 	%fd2643, %rd5434;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5337}, %fd2643;
	}
	setp.lt.s32 	%p2566, %r5337, 0;
	selp.b64 	%rd5435, %rd6604, %rd5434, %p2566;
	shl.b64 	%rd5436, %rd5435, 1;
	sub.s64 	%rd5437, %rd5436, %rd1042;
	mov.b64 	%fd2644, %rd5437;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5338}, %fd2644;
	}
	setp.lt.s32 	%p2567, %r5338, 0;
	selp.b64 	%rd5438, %rd5436, %rd5437, %p2567;
	shl.b64 	%rd5439, %rd5438, 1;
	sub.s64 	%rd5440, %rd5439, %rd1042;
	mov.b64 	%fd2645, %rd5440;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5339}, %fd2645;
	}
	setp.lt.s32 	%p2568, %r5339, 0;
	selp.b64 	%rd5441, %rd5439, %rd5440, %p2568;
	shl.b64 	%rd5442, %rd5441, 1;
	sub.s64 	%rd5443, %rd5442, %rd1042;
	mov.b64 	%fd2646, %rd5443;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5340}, %fd2646;
	}
	setp.lt.s32 	%p2569, %r5340, 0;
	selp.b64 	%rd6607, %rd5442, %rd5443, %p2569;
	shl.b64 	%rd6604, %rd6607, 1;
	add.s32 	%r6475, %r6475, -4;
	add.s32 	%r6474, %r6474, -1;
	setp.ne.s32 	%p2570, %r6474, 0;
	@%p2570 bra 	$L__BB0_1305;

$L__BB0_1306:
	setp.lt.u32 	%p2571, %r1527, 12;
	@%p2571 bra 	$L__BB0_1308;

$L__BB0_1307:
	sub.s64 	%rd5444, %rd6604, %rd1042;
	mov.b64 	%fd2647, %rd5444;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5341}, %fd2647;
	}
	setp.lt.s32 	%p2572, %r5341, 0;
	selp.b64 	%rd5445, %rd6604, %rd5444, %p2572;
	shl.b64 	%rd5446, %rd5445, 1;
	sub.s64 	%rd5447, %rd5446, %rd1042;
	mov.b64 	%fd2648, %rd5447;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5342}, %fd2648;
	}
	setp.lt.s32 	%p2573, %r5342, 0;
	selp.b64 	%rd5448, %rd5446, %rd5447, %p2573;
	shl.b64 	%rd5449, %rd5448, 1;
	sub.s64 	%rd5450, %rd5449, %rd1042;
	mov.b64 	%fd2649, %rd5450;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5343}, %fd2649;
	}
	setp.lt.s32 	%p2574, %r5343, 0;
	selp.b64 	%rd5451, %rd5449, %rd5450, %p2574;
	shl.b64 	%rd5452, %rd5451, 1;
	sub.s64 	%rd5453, %rd5452, %rd1042;
	mov.b64 	%fd2650, %rd5453;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5344}, %fd2650;
	}
	setp.lt.s32 	%p2575, %r5344, 0;
	selp.b64 	%rd5454, %rd5452, %rd5453, %p2575;
	shl.b64 	%rd5455, %rd5454, 1;
	sub.s64 	%rd5456, %rd5455, %rd1042;
	mov.b64 	%fd2651, %rd5456;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5345}, %fd2651;
	}
	setp.lt.s32 	%p2576, %r5345, 0;
	selp.b64 	%rd5457, %rd5455, %rd5456, %p2576;
	shl.b64 	%rd5458, %rd5457, 1;
	sub.s64 	%rd5459, %rd5458, %rd1042;
	mov.b64 	%fd2652, %rd5459;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5346}, %fd2652;
	}
	setp.lt.s32 	%p2577, %r5346, 0;
	selp.b64 	%rd5460, %rd5458, %rd5459, %p2577;
	shl.b64 	%rd5461, %rd5460, 1;
	sub.s64 	%rd5462, %rd5461, %rd1042;
	mov.b64 	%fd2653, %rd5462;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5347}, %fd2653;
	}
	setp.lt.s32 	%p2578, %r5347, 0;
	selp.b64 	%rd5463, %rd5461, %rd5462, %p2578;
	shl.b64 	%rd5464, %rd5463, 1;
	sub.s64 	%rd5465, %rd5464, %rd1042;
	mov.b64 	%fd2654, %rd5465;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5348}, %fd2654;
	}
	setp.lt.s32 	%p2579, %r5348, 0;
	selp.b64 	%rd5466, %rd5464, %rd5465, %p2579;
	shl.b64 	%rd5467, %rd5466, 1;
	sub.s64 	%rd5468, %rd5467, %rd1042;
	mov.b64 	%fd2655, %rd5468;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5349}, %fd2655;
	}
	setp.lt.s32 	%p2580, %r5349, 0;
	selp.b64 	%rd5469, %rd5467, %rd5468, %p2580;
	shl.b64 	%rd5470, %rd5469, 1;
	sub.s64 	%rd5471, %rd5470, %rd1042;
	mov.b64 	%fd2656, %rd5471;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5350}, %fd2656;
	}
	setp.lt.s32 	%p2581, %r5350, 0;
	selp.b64 	%rd5472, %rd5470, %rd5471, %p2581;
	shl.b64 	%rd5473, %rd5472, 1;
	sub.s64 	%rd5474, %rd5473, %rd1042;
	mov.b64 	%fd2657, %rd5474;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5351}, %fd2657;
	}
	setp.lt.s32 	%p2582, %r5351, 0;
	selp.b64 	%rd5475, %rd5473, %rd5474, %p2582;
	shl.b64 	%rd5476, %rd5475, 1;
	sub.s64 	%rd5477, %rd5476, %rd1042;
	mov.b64 	%fd2658, %rd5477;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5352}, %fd2658;
	}
	setp.lt.s32 	%p2583, %r5352, 0;
	selp.b64 	%rd5478, %rd5476, %rd5477, %p2583;
	shl.b64 	%rd5479, %rd5478, 1;
	sub.s64 	%rd5480, %rd5479, %rd1042;
	mov.b64 	%fd2659, %rd5480;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5353}, %fd2659;
	}
	setp.lt.s32 	%p2584, %r5353, 0;
	selp.b64 	%rd5481, %rd5479, %rd5480, %p2584;
	shl.b64 	%rd5482, %rd5481, 1;
	sub.s64 	%rd5483, %rd5482, %rd1042;
	mov.b64 	%fd2660, %rd5483;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5354}, %fd2660;
	}
	setp.lt.s32 	%p2585, %r5354, 0;
	selp.b64 	%rd5484, %rd5482, %rd5483, %p2585;
	shl.b64 	%rd5485, %rd5484, 1;
	sub.s64 	%rd5486, %rd5485, %rd1042;
	mov.b64 	%fd2661, %rd5486;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5355}, %fd2661;
	}
	setp.lt.s32 	%p2586, %r5355, 0;
	selp.b64 	%rd5487, %rd5485, %rd5486, %p2586;
	shl.b64 	%rd5488, %rd5487, 1;
	sub.s64 	%rd5489, %rd5488, %rd1042;
	mov.b64 	%fd2662, %rd5489;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5356}, %fd2662;
	}
	setp.lt.s32 	%p2587, %r5356, 0;
	selp.b64 	%rd6607, %rd5488, %rd5489, %p2587;
	shl.b64 	%rd6604, %rd6607, 1;
	add.s32 	%r1535, %r6475, -16;
	setp.gt.s32 	%p2588, %r6475, 15;
	mov.u32 	%r6475, %r1535;
	@%p2588 bra 	$L__BB0_1307;

$L__BB0_1308:
	and.b64  	%rd1057, %rd6607, 9223372036854775807;
	setp.eq.s64 	%p2589, %rd1057, 0;
	mov.f64 	%fd3148, 0d0000000000000000;
	@%p2589 bra 	$L__BB0_1310;

	mov.b64 	%fd2664, %rd1057;
	mul.f64 	%fd2665, %fd2664, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5357}, %fd2665;
	}
	shr.u32 	%r5358, %r5357, 20;
	mov.u32 	%r5359, 55;
	sub.s32 	%r5360, %r5359, %r5358;
	sub.s32 	%r5361, %r6469, %r5360;
	shl.b64 	%rd5490, %rd1057, %r5360;
	setp.lt.s32 	%p2590, %r5361, 1;
	mov.u32 	%r5362, 1;
	sub.s32 	%r5363, %r5362, %r5361;
	shr.u64 	%rd5491, %rd5490, %r5363;
	add.s32 	%r5364, %r5361, -1;
	cvt.u64.u32 	%rd5492, %r5364;
	shl.b64 	%rd5493, %rd5492, 52;
	add.s64 	%rd5494, %rd5493, %rd5490;
	selp.b64 	%rd5495, %rd5491, %rd5494, %p2590;
	mov.b64 	%fd3148, %rd5495;

$L__BB0_1310:
	and.b32  	%r5365, %r1512, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5366}, %fd3148;
	}
	or.b32  	%r5367, %r5366, %r5365;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5368, %temp}, %fd3148;
	}
	mov.b64 	%fd3034, {%r5368, %r5367};
	bra.uni 	$L__BB0_1314;

$L__BB0_1312:
	mov.f64 	%fd2666, 0d3FF0000000000000;
	add.rn.f64 	%fd3034, %fd687, %fd2666;

$L__BB0_1314:
	.loc	1 30 5, function_name $L__info_string4, inlined_at 1 125 5
	add.s32 	%r6466, %r6467, -1;
	setp.gt.s32 	%p2595, %r6467, 0;
	@%p2595 bra 	$L__BB0_1294;

	.loc	1 0 5
	add.u64 	%rd1058, %SPL, 33;
	.loc	1 131 5, function_name $L__info_string5, inlined_at 1 260 17
	mov.u16 	%rs150, 84;
	st.local.u8 	[%rd1058], %rs150;
	mov.u16 	%rs151, 97;
	st.local.u8 	[%rd1058+1], %rs151;
	mov.u16 	%rs152, 103;
	st.local.u8 	[%rd1058+2], %rs152;
	mov.u16 	%rs153, 95;
	st.local.u8 	[%rd1058+3], %rs153;
	mov.u16 	%rs154, 115;
	st.local.u8 	[%rd1058+4], %rs154;
	mov.u16 	%rs155, 109;
	st.local.u8 	[%rd1058+5], %rs155;
	st.local.u8 	[%rd1058+6], %rs151;
	mov.u16 	%rs156, 108;
	st.local.u8 	[%rd1058+7], %rs156;
	st.local.u8 	[%rd1058+8], %rs156;
	.loc	1 132 5, function_name $L__info_string5, inlined_at 1 260 17
	st.local.u8 	[%rd1058+9], %rs217;
	st.local.u8 	[%rd1058+10], %rs218;
	st.local.u8 	[%rd1058+11], %rs219;
	st.local.u8 	[%rd1058+12], %rs220;
	st.local.u8 	[%rd1058+13], %rs221;
	st.local.u8 	[%rd1058+14], %rs222;
	st.local.u8 	[%rd1058+15], %rs223;
	st.local.u8 	[%rd1058+16], %rs229;
	.loc	1 133 5, function_name $L__info_string5, inlined_at 1 260 17
	mov.u16 	%rs157, 0;
	st.local.u8 	[%rd1058+17], %rs157;
	mov.f64 	%fd3072, 0d3FF0000000000000;
	mov.u32 	%r6478, 17;
	mov.u32 	%r6477, 16;

$L__BB0_1316:
	.loc	1 0 5
	mov.u32 	%r1538, %r6478;
	mov.u32 	%r6478, %r6477;
	.loc	1 134 5, function_name $L__info_string5, inlined_at 1 260 17
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 134 5
	cvt.s64.s32 	%rd5497, %r6478;
	add.s64 	%rd5498, %rd1058, %rd5497;
	ld.local.u8 	%rs158, [%rd5498];
	cvt.rn.f64.u16 	%fd2668, %rs158;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 134 5
	mov.f64 	%fd2669, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2670, %fd2669, %fd3072;
	mul.f64 	%fd2671, %fd2670, %fd2668;
	mul.f64 	%fd2672, %fd2671, 0d400921FB54442D18;
	cvt.rn.f64.s32 	%fd2673, %r1538;
	fma.rn.f64 	%fd699, %fd2673, 0d400921FB54442D18, %fd2672;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1539}, %fd699;
	}
	and.b32  	%r5371, %r1539, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5372, %temp}, %fd699;
	}
	mov.b64 	%fd3151, {%r5372, %r5371};
	setp.gt.u32 	%p2596, %r5371, 2146435071;
	or.pred  	%p2598, %p2596, %p2211;
	@%p2598 bra 	$L__BB0_1333;
	bra.uni 	$L__BB0_1317;

$L__BB0_1333:
	.loc	1 0 9
	setp.le.f64 	%p2633, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2634, %fd3151, 0d7FF0000000000000;
	and.pred  	%p2635, %p2634, %p2633;
	@%p2635 bra 	$L__BB0_1335;
	bra.uni 	$L__BB0_1334;

$L__BB0_1335:
	setp.eq.f64 	%p2636, %fd3151, 0d7FF0000000000000;
	selp.f64 	%fd3072, 0dFFF8000000000000, %fd699, %p2636;
	bra.uni 	$L__BB0_1336;

$L__BB0_1317:
	.loc	1 0 9
	mov.f64 	%fd3072, 0dFFF8000000000000;
	.loc	1 32 9
	@%p2502 bra 	$L__BB0_1336;

	setp.ltu.f64 	%p2600, %fd3151, %fd3160;
	mov.f64 	%fd3072, %fd699;
	@%p2600 bra 	$L__BB0_1336;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5373}, %fd3151;
	}
	shr.u32 	%r6479, %r5373, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5374}, %fd3160;
	}
	shr.u32 	%r6480, %r5374, 20;
	setp.ne.s32 	%p2601, %r6479, 0;
	@%p2601 bra 	$L__BB0_1321;

	mul.f64 	%fd3151, %fd3151, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5375}, %fd3151;
	}
	shr.u32 	%r5376, %r5375, 20;
	add.s32 	%r6479, %r5376, -54;

$L__BB0_1321:
	setp.ne.s32 	%p2602, %r6480, 0;
	mov.f64 	%fd3152, %fd3160;
	@%p2602 bra 	$L__BB0_1323;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5377}, %fd595;
	}
	shr.u32 	%r5378, %r5377, 20;
	add.s32 	%r6480, %r5378, -54;
	mov.f64 	%fd3152, %fd595;

$L__BB0_1323:
	mov.b64 	%rd5500, %fd3151;
	and.b64  	%rd5501, %rd5500, 4503599627370495;
	or.b64  	%rd6612, %rd5501, 4503599627370496;
	mov.b64 	%rd5502, %fd3152;
	and.b64  	%rd5503, %rd5502, 4503599627370495;
	or.b64  	%rd1060, %rd5503, 4503599627370496;
	sub.s32 	%r6486, %r6479, %r6480;
	not.b32 	%r5379, %r6479;
	add.s32 	%r5380, %r6480, %r5379;
	max.s32 	%r5381, %r5380, -1;
	add.s32 	%r1547, %r5381, %r6479;
	mov.u32 	%r5382, 2;
	sub.s32 	%r5383, %r5382, %r6480;
	add.s32 	%r5384, %r5383, %r1547;
	and.b32  	%r6482, %r5384, 3;
	setp.eq.s32 	%p2603, %r6482, 0;
	@%p2603 bra 	$L__BB0_1325;

$L__BB0_1324:
	.pragma "nounroll";
	sub.s64 	%rd5504, %rd6612, %rd1060;
	mov.b64 	%fd2675, %rd5504;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5385}, %fd2675;
	}
	setp.lt.s32 	%p2604, %r5385, 0;
	selp.b64 	%rd6615, %rd6612, %rd5504, %p2604;
	shl.b64 	%rd6612, %rd6615, 1;
	add.s32 	%r6486, %r6486, -1;
	add.s32 	%r6482, %r6482, -1;
	setp.ne.s32 	%p2605, %r6482, 0;
	@%p2605 bra 	$L__BB0_1324;

$L__BB0_1325:
	mov.u32 	%r5386, 1;
	sub.s32 	%r5387, %r5386, %r6480;
	add.s32 	%r5388, %r5387, %r1547;
	setp.lt.u32 	%p2606, %r5388, 3;
	@%p2606 bra 	$L__BB0_1330;

	not.b32 	%r5389, %r6486;
	max.s32 	%r5390, %r5389, -4;
	add.s32 	%r5391, %r6486, %r5390;
	add.s32 	%r1554, %r5391, 4;
	shr.u32 	%r5392, %r1554, 2;
	add.s32 	%r5393, %r5392, 1;
	and.b32  	%r6485, %r5393, 3;
	setp.eq.s32 	%p2607, %r6485, 0;
	@%p2607 bra 	$L__BB0_1328;

$L__BB0_1327:
	.pragma "nounroll";
	sub.s64 	%rd5506, %rd6612, %rd1060;
	mov.b64 	%fd2676, %rd5506;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5394}, %fd2676;
	}
	setp.lt.s32 	%p2608, %r5394, 0;
	selp.b64 	%rd5507, %rd6612, %rd5506, %p2608;
	shl.b64 	%rd5508, %rd5507, 1;
	sub.s64 	%rd5509, %rd5508, %rd1060;
	mov.b64 	%fd2677, %rd5509;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5395}, %fd2677;
	}
	setp.lt.s32 	%p2609, %r5395, 0;
	selp.b64 	%rd5510, %rd5508, %rd5509, %p2609;
	shl.b64 	%rd5511, %rd5510, 1;
	sub.s64 	%rd5512, %rd5511, %rd1060;
	mov.b64 	%fd2678, %rd5512;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5396}, %fd2678;
	}
	setp.lt.s32 	%p2610, %r5396, 0;
	selp.b64 	%rd5513, %rd5511, %rd5512, %p2610;
	shl.b64 	%rd5514, %rd5513, 1;
	sub.s64 	%rd5515, %rd5514, %rd1060;
	mov.b64 	%fd2679, %rd5515;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5397}, %fd2679;
	}
	setp.lt.s32 	%p2611, %r5397, 0;
	selp.b64 	%rd6615, %rd5514, %rd5515, %p2611;
	shl.b64 	%rd6612, %rd6615, 1;
	add.s32 	%r6486, %r6486, -4;
	add.s32 	%r6485, %r6485, -1;
	setp.ne.s32 	%p2612, %r6485, 0;
	@%p2612 bra 	$L__BB0_1327;

$L__BB0_1328:
	setp.lt.u32 	%p2613, %r1554, 12;
	@%p2613 bra 	$L__BB0_1330;

$L__BB0_1329:
	sub.s64 	%rd5516, %rd6612, %rd1060;
	mov.b64 	%fd2680, %rd5516;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5398}, %fd2680;
	}
	setp.lt.s32 	%p2614, %r5398, 0;
	selp.b64 	%rd5517, %rd6612, %rd5516, %p2614;
	shl.b64 	%rd5518, %rd5517, 1;
	sub.s64 	%rd5519, %rd5518, %rd1060;
	mov.b64 	%fd2681, %rd5519;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5399}, %fd2681;
	}
	setp.lt.s32 	%p2615, %r5399, 0;
	selp.b64 	%rd5520, %rd5518, %rd5519, %p2615;
	shl.b64 	%rd5521, %rd5520, 1;
	sub.s64 	%rd5522, %rd5521, %rd1060;
	mov.b64 	%fd2682, %rd5522;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5400}, %fd2682;
	}
	setp.lt.s32 	%p2616, %r5400, 0;
	selp.b64 	%rd5523, %rd5521, %rd5522, %p2616;
	shl.b64 	%rd5524, %rd5523, 1;
	sub.s64 	%rd5525, %rd5524, %rd1060;
	mov.b64 	%fd2683, %rd5525;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5401}, %fd2683;
	}
	setp.lt.s32 	%p2617, %r5401, 0;
	selp.b64 	%rd5526, %rd5524, %rd5525, %p2617;
	shl.b64 	%rd5527, %rd5526, 1;
	sub.s64 	%rd5528, %rd5527, %rd1060;
	mov.b64 	%fd2684, %rd5528;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5402}, %fd2684;
	}
	setp.lt.s32 	%p2618, %r5402, 0;
	selp.b64 	%rd5529, %rd5527, %rd5528, %p2618;
	shl.b64 	%rd5530, %rd5529, 1;
	sub.s64 	%rd5531, %rd5530, %rd1060;
	mov.b64 	%fd2685, %rd5531;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5403}, %fd2685;
	}
	setp.lt.s32 	%p2619, %r5403, 0;
	selp.b64 	%rd5532, %rd5530, %rd5531, %p2619;
	shl.b64 	%rd5533, %rd5532, 1;
	sub.s64 	%rd5534, %rd5533, %rd1060;
	mov.b64 	%fd2686, %rd5534;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5404}, %fd2686;
	}
	setp.lt.s32 	%p2620, %r5404, 0;
	selp.b64 	%rd5535, %rd5533, %rd5534, %p2620;
	shl.b64 	%rd5536, %rd5535, 1;
	sub.s64 	%rd5537, %rd5536, %rd1060;
	mov.b64 	%fd2687, %rd5537;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5405}, %fd2687;
	}
	setp.lt.s32 	%p2621, %r5405, 0;
	selp.b64 	%rd5538, %rd5536, %rd5537, %p2621;
	shl.b64 	%rd5539, %rd5538, 1;
	sub.s64 	%rd5540, %rd5539, %rd1060;
	mov.b64 	%fd2688, %rd5540;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5406}, %fd2688;
	}
	setp.lt.s32 	%p2622, %r5406, 0;
	selp.b64 	%rd5541, %rd5539, %rd5540, %p2622;
	shl.b64 	%rd5542, %rd5541, 1;
	sub.s64 	%rd5543, %rd5542, %rd1060;
	mov.b64 	%fd2689, %rd5543;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5407}, %fd2689;
	}
	setp.lt.s32 	%p2623, %r5407, 0;
	selp.b64 	%rd5544, %rd5542, %rd5543, %p2623;
	shl.b64 	%rd5545, %rd5544, 1;
	sub.s64 	%rd5546, %rd5545, %rd1060;
	mov.b64 	%fd2690, %rd5546;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5408}, %fd2690;
	}
	setp.lt.s32 	%p2624, %r5408, 0;
	selp.b64 	%rd5547, %rd5545, %rd5546, %p2624;
	shl.b64 	%rd5548, %rd5547, 1;
	sub.s64 	%rd5549, %rd5548, %rd1060;
	mov.b64 	%fd2691, %rd5549;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5409}, %fd2691;
	}
	setp.lt.s32 	%p2625, %r5409, 0;
	selp.b64 	%rd5550, %rd5548, %rd5549, %p2625;
	shl.b64 	%rd5551, %rd5550, 1;
	sub.s64 	%rd5552, %rd5551, %rd1060;
	mov.b64 	%fd2692, %rd5552;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5410}, %fd2692;
	}
	setp.lt.s32 	%p2626, %r5410, 0;
	selp.b64 	%rd5553, %rd5551, %rd5552, %p2626;
	shl.b64 	%rd5554, %rd5553, 1;
	sub.s64 	%rd5555, %rd5554, %rd1060;
	mov.b64 	%fd2693, %rd5555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5411}, %fd2693;
	}
	setp.lt.s32 	%p2627, %r5411, 0;
	selp.b64 	%rd5556, %rd5554, %rd5555, %p2627;
	shl.b64 	%rd5557, %rd5556, 1;
	sub.s64 	%rd5558, %rd5557, %rd1060;
	mov.b64 	%fd2694, %rd5558;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5412}, %fd2694;
	}
	setp.lt.s32 	%p2628, %r5412, 0;
	selp.b64 	%rd5559, %rd5557, %rd5558, %p2628;
	shl.b64 	%rd5560, %rd5559, 1;
	sub.s64 	%rd5561, %rd5560, %rd1060;
	mov.b64 	%fd2695, %rd5561;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5413}, %fd2695;
	}
	setp.lt.s32 	%p2629, %r5413, 0;
	selp.b64 	%rd6615, %rd5560, %rd5561, %p2629;
	shl.b64 	%rd6612, %rd6615, 1;
	add.s32 	%r1562, %r6486, -16;
	setp.gt.s32 	%p2630, %r6486, 15;
	mov.u32 	%r6486, %r1562;
	@%p2630 bra 	$L__BB0_1329;

$L__BB0_1330:
	and.b64  	%rd1075, %rd6615, 9223372036854775807;
	setp.eq.s64 	%p2631, %rd1075, 0;
	mov.f64 	%fd3153, 0d0000000000000000;
	@%p2631 bra 	$L__BB0_1332;

	mov.b64 	%fd2697, %rd1075;
	mul.f64 	%fd2698, %fd2697, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5414}, %fd2698;
	}
	shr.u32 	%r5415, %r5414, 20;
	mov.u32 	%r5416, 55;
	sub.s32 	%r5417, %r5416, %r5415;
	sub.s32 	%r5418, %r6480, %r5417;
	shl.b64 	%rd5562, %rd1075, %r5417;
	setp.lt.s32 	%p2632, %r5418, 1;
	mov.u32 	%r5419, 1;
	sub.s32 	%r5420, %r5419, %r5418;
	shr.u64 	%rd5563, %rd5562, %r5420;
	add.s32 	%r5421, %r5418, -1;
	cvt.u64.u32 	%rd5564, %r5421;
	shl.b64 	%rd5565, %rd5564, 52;
	add.s64 	%rd5566, %rd5565, %rd5562;
	selp.b64 	%rd5567, %rd5563, %rd5566, %p2632;
	mov.b64 	%fd3153, %rd5567;

$L__BB0_1332:
	and.b32  	%r5422, %r1539, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5423}, %fd3153;
	}
	or.b32  	%r5424, %r5423, %r5422;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5425, %temp}, %fd3153;
	}
	mov.b64 	%fd3072, {%r5425, %r5424};
	bra.uni 	$L__BB0_1336;

$L__BB0_1334:
	mov.f64 	%fd2699, 0d3FF0000000000000;
	add.rn.f64 	%fd3072, %fd699, %fd2699;

$L__BB0_1336:
	.loc	1 30 5, function_name $L__info_string4, inlined_at 1 134 5
	add.s32 	%r6477, %r6478, -1;
	setp.gt.s32 	%p2637, %r6478, 0;
	@%p2637 bra 	$L__BB0_1316;

	.loc	1 0 5
	add.u64 	%rd1076, %SPL, 50;
	.loc	1 136 5, function_name $L__info_string5, inlined_at 1 260 17
	mov.u16 	%rs159, 84;
	st.local.u8 	[%rd1076], %rs159;
	mov.u16 	%rs160, 97;
	st.local.u8 	[%rd1076+1], %rs160;
	mov.u16 	%rs161, 103;
	st.local.u8 	[%rd1076+2], %rs161;
	mov.u16 	%rs162, 95;
	st.local.u8 	[%rd1076+3], %rs162;
	mov.u16 	%rs163, 98;
	st.local.u8 	[%rd1076+4], %rs163;
	mov.u16 	%rs164, 105;
	st.local.u8 	[%rd1076+5], %rs164;
	st.local.u8 	[%rd1076+6], %rs161;
	.loc	1 137 5, function_name $L__info_string5, inlined_at 1 260 17
	st.local.u8 	[%rd1076+7], %rs217;
	st.local.u8 	[%rd1076+8], %rs218;
	st.local.u8 	[%rd1076+9], %rs219;
	st.local.u8 	[%rd1076+10], %rs220;
	st.local.u8 	[%rd1076+11], %rs221;
	st.local.u8 	[%rd1076+12], %rs222;
	st.local.u8 	[%rd1076+13], %rs223;
	st.local.u8 	[%rd1076+14], %rs229;
	.loc	1 138 5, function_name $L__info_string5, inlined_at 1 260 17
	mov.u16 	%rs165, 0;
	st.local.u8 	[%rd1076+15], %rs165;
	mov.f64 	%fd3110, 0d3FF0000000000000;
	mov.u32 	%r6489, 15;
	mov.u32 	%r6488, 14;

$L__BB0_1338:
	.loc	1 0 5
	mov.u32 	%r1565, %r6489;
	mov.u32 	%r6489, %r6488;
	.loc	1 139 5, function_name $L__info_string5, inlined_at 1 260 17
	.loc	1 31 9, function_name $L__info_string4, inlined_at 1 139 5
	cvt.s64.s32 	%rd5569, %r6489;
	add.s64 	%rd5570, %rd1076, %rd5569;
	ld.local.u8 	%rs166, [%rd5570];
	cvt.rn.f64.u16 	%fd2701, %rs166;
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 139 5
	mov.f64 	%fd2702, 0d3FF1FB9C7406BB70;
	div.rn.f64 	%fd2703, %fd2702, %fd3110;
	mul.f64 	%fd2704, %fd2703, %fd2701;
	mul.f64 	%fd2705, %fd2704, 0d400921FB54442D18;
	cvt.rn.f64.s32 	%fd2706, %r1565;
	fma.rn.f64 	%fd711, %fd2706, 0d400921FB54442D18, %fd2705;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1566}, %fd711;
	}
	and.b32  	%r5428, %r1566, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5429, %temp}, %fd711;
	}
	mov.b64 	%fd3156, {%r5429, %r5428};
	setp.gt.u32 	%p2638, %r5428, 2146435071;
	or.pred  	%p2640, %p2638, %p2211;
	@%p2640 bra 	$L__BB0_1355;
	bra.uni 	$L__BB0_1339;

$L__BB0_1355:
	.loc	1 0 9
	setp.le.f64 	%p2675, %fd3160, 0d7FF0000000000000;
	.loc	1 32 9
	setp.le.f64 	%p2676, %fd3156, 0d7FF0000000000000;
	and.pred  	%p2677, %p2676, %p2675;
	@%p2677 bra 	$L__BB0_1357;
	bra.uni 	$L__BB0_1356;

$L__BB0_1357:
	setp.eq.f64 	%p2678, %fd3156, 0d7FF0000000000000;
	selp.f64 	%fd3110, 0dFFF8000000000000, %fd711, %p2678;
	bra.uni 	$L__BB0_1358;

$L__BB0_1339:
	.loc	1 0 9
	mov.f64 	%fd3110, 0dFFF8000000000000;
	.loc	1 32 9
	@%p2502 bra 	$L__BB0_1358;

	setp.ltu.f64 	%p2642, %fd3156, %fd3160;
	mov.f64 	%fd3110, %fd711;
	@%p2642 bra 	$L__BB0_1358;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5430}, %fd3156;
	}
	shr.u32 	%r6490, %r5430, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5431}, %fd3160;
	}
	shr.u32 	%r6491, %r5431, 20;
	setp.ne.s32 	%p2643, %r6490, 0;
	@%p2643 bra 	$L__BB0_1343;

	mul.f64 	%fd3156, %fd3156, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5432}, %fd3156;
	}
	shr.u32 	%r5433, %r5432, 20;
	add.s32 	%r6490, %r5433, -54;

$L__BB0_1343:
	setp.ne.s32 	%p2644, %r6491, 0;
	mov.f64 	%fd3157, %fd3160;
	@%p2644 bra 	$L__BB0_1345;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5434}, %fd595;
	}
	shr.u32 	%r5435, %r5434, 20;
	add.s32 	%r6491, %r5435, -54;
	mov.f64 	%fd3157, %fd595;

$L__BB0_1345:
	mov.b64 	%rd5572, %fd3156;
	and.b64  	%rd5573, %rd5572, 4503599627370495;
	or.b64  	%rd6620, %rd5573, 4503599627370496;
	mov.b64 	%rd5574, %fd3157;
	and.b64  	%rd5575, %rd5574, 4503599627370495;
	or.b64  	%rd1078, %rd5575, 4503599627370496;
	sub.s32 	%r6497, %r6490, %r6491;
	not.b32 	%r5436, %r6490;
	add.s32 	%r5437, %r6491, %r5436;
	max.s32 	%r5438, %r5437, -1;
	add.s32 	%r1574, %r5438, %r6490;
	mov.u32 	%r5439, 2;
	sub.s32 	%r5440, %r5439, %r6491;
	add.s32 	%r5441, %r5440, %r1574;
	and.b32  	%r6493, %r5441, 3;
	setp.eq.s32 	%p2645, %r6493, 0;
	@%p2645 bra 	$L__BB0_1347;

$L__BB0_1346:
	.pragma "nounroll";
	sub.s64 	%rd5576, %rd6620, %rd1078;
	mov.b64 	%fd2708, %rd5576;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5442}, %fd2708;
	}
	setp.lt.s32 	%p2646, %r5442, 0;
	selp.b64 	%rd6623, %rd6620, %rd5576, %p2646;
	shl.b64 	%rd6620, %rd6623, 1;
	add.s32 	%r6497, %r6497, -1;
	add.s32 	%r6493, %r6493, -1;
	setp.ne.s32 	%p2647, %r6493, 0;
	@%p2647 bra 	$L__BB0_1346;

$L__BB0_1347:
	mov.u32 	%r5443, 1;
	sub.s32 	%r5444, %r5443, %r6491;
	add.s32 	%r5445, %r5444, %r1574;
	setp.lt.u32 	%p2648, %r5445, 3;
	@%p2648 bra 	$L__BB0_1352;

	not.b32 	%r5446, %r6497;
	max.s32 	%r5447, %r5446, -4;
	add.s32 	%r5448, %r6497, %r5447;
	add.s32 	%r1581, %r5448, 4;
	shr.u32 	%r5449, %r1581, 2;
	add.s32 	%r5450, %r5449, 1;
	and.b32  	%r6496, %r5450, 3;
	setp.eq.s32 	%p2649, %r6496, 0;
	@%p2649 bra 	$L__BB0_1350;

$L__BB0_1349:
	.pragma "nounroll";
	sub.s64 	%rd5578, %rd6620, %rd1078;
	mov.b64 	%fd2709, %rd5578;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5451}, %fd2709;
	}
	setp.lt.s32 	%p2650, %r5451, 0;
	selp.b64 	%rd5579, %rd6620, %rd5578, %p2650;
	shl.b64 	%rd5580, %rd5579, 1;
	sub.s64 	%rd5581, %rd5580, %rd1078;
	mov.b64 	%fd2710, %rd5581;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5452}, %fd2710;
	}
	setp.lt.s32 	%p2651, %r5452, 0;
	selp.b64 	%rd5582, %rd5580, %rd5581, %p2651;
	shl.b64 	%rd5583, %rd5582, 1;
	sub.s64 	%rd5584, %rd5583, %rd1078;
	mov.b64 	%fd2711, %rd5584;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5453}, %fd2711;
	}
	setp.lt.s32 	%p2652, %r5453, 0;
	selp.b64 	%rd5585, %rd5583, %rd5584, %p2652;
	shl.b64 	%rd5586, %rd5585, 1;
	sub.s64 	%rd5587, %rd5586, %rd1078;
	mov.b64 	%fd2712, %rd5587;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5454}, %fd2712;
	}
	setp.lt.s32 	%p2653, %r5454, 0;
	selp.b64 	%rd6623, %rd5586, %rd5587, %p2653;
	shl.b64 	%rd6620, %rd6623, 1;
	add.s32 	%r6497, %r6497, -4;
	add.s32 	%r6496, %r6496, -1;
	setp.ne.s32 	%p2654, %r6496, 0;
	@%p2654 bra 	$L__BB0_1349;

$L__BB0_1350:
	setp.lt.u32 	%p2655, %r1581, 12;
	@%p2655 bra 	$L__BB0_1352;

$L__BB0_1351:
	sub.s64 	%rd5588, %rd6620, %rd1078;
	mov.b64 	%fd2713, %rd5588;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5455}, %fd2713;
	}
	setp.lt.s32 	%p2656, %r5455, 0;
	selp.b64 	%rd5589, %rd6620, %rd5588, %p2656;
	shl.b64 	%rd5590, %rd5589, 1;
	sub.s64 	%rd5591, %rd5590, %rd1078;
	mov.b64 	%fd2714, %rd5591;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5456}, %fd2714;
	}
	setp.lt.s32 	%p2657, %r5456, 0;
	selp.b64 	%rd5592, %rd5590, %rd5591, %p2657;
	shl.b64 	%rd5593, %rd5592, 1;
	sub.s64 	%rd5594, %rd5593, %rd1078;
	mov.b64 	%fd2715, %rd5594;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5457}, %fd2715;
	}
	setp.lt.s32 	%p2658, %r5457, 0;
	selp.b64 	%rd5595, %rd5593, %rd5594, %p2658;
	shl.b64 	%rd5596, %rd5595, 1;
	sub.s64 	%rd5597, %rd5596, %rd1078;
	mov.b64 	%fd2716, %rd5597;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5458}, %fd2716;
	}
	setp.lt.s32 	%p2659, %r5458, 0;
	selp.b64 	%rd5598, %rd5596, %rd5597, %p2659;
	shl.b64 	%rd5599, %rd5598, 1;
	sub.s64 	%rd5600, %rd5599, %rd1078;
	mov.b64 	%fd2717, %rd5600;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5459}, %fd2717;
	}
	setp.lt.s32 	%p2660, %r5459, 0;
	selp.b64 	%rd5601, %rd5599, %rd5600, %p2660;
	shl.b64 	%rd5602, %rd5601, 1;
	sub.s64 	%rd5603, %rd5602, %rd1078;
	mov.b64 	%fd2718, %rd5603;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5460}, %fd2718;
	}
	setp.lt.s32 	%p2661, %r5460, 0;
	selp.b64 	%rd5604, %rd5602, %rd5603, %p2661;
	shl.b64 	%rd5605, %rd5604, 1;
	sub.s64 	%rd5606, %rd5605, %rd1078;
	mov.b64 	%fd2719, %rd5606;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5461}, %fd2719;
	}
	setp.lt.s32 	%p2662, %r5461, 0;
	selp.b64 	%rd5607, %rd5605, %rd5606, %p2662;
	shl.b64 	%rd5608, %rd5607, 1;
	sub.s64 	%rd5609, %rd5608, %rd1078;
	mov.b64 	%fd2720, %rd5609;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5462}, %fd2720;
	}
	setp.lt.s32 	%p2663, %r5462, 0;
	selp.b64 	%rd5610, %rd5608, %rd5609, %p2663;
	shl.b64 	%rd5611, %rd5610, 1;
	sub.s64 	%rd5612, %rd5611, %rd1078;
	mov.b64 	%fd2721, %rd5612;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5463}, %fd2721;
	}
	setp.lt.s32 	%p2664, %r5463, 0;
	selp.b64 	%rd5613, %rd5611, %rd5612, %p2664;
	shl.b64 	%rd5614, %rd5613, 1;
	sub.s64 	%rd5615, %rd5614, %rd1078;
	mov.b64 	%fd2722, %rd5615;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5464}, %fd2722;
	}
	setp.lt.s32 	%p2665, %r5464, 0;
	selp.b64 	%rd5616, %rd5614, %rd5615, %p2665;
	shl.b64 	%rd5617, %rd5616, 1;
	sub.s64 	%rd5618, %rd5617, %rd1078;
	mov.b64 	%fd2723, %rd5618;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5465}, %fd2723;
	}
	setp.lt.s32 	%p2666, %r5465, 0;
	selp.b64 	%rd5619, %rd5617, %rd5618, %p2666;
	shl.b64 	%rd5620, %rd5619, 1;
	sub.s64 	%rd5621, %rd5620, %rd1078;
	mov.b64 	%fd2724, %rd5621;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5466}, %fd2724;
	}
	setp.lt.s32 	%p2667, %r5466, 0;
	selp.b64 	%rd5622, %rd5620, %rd5621, %p2667;
	shl.b64 	%rd5623, %rd5622, 1;
	sub.s64 	%rd5624, %rd5623, %rd1078;
	mov.b64 	%fd2725, %rd5624;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5467}, %fd2725;
	}
	setp.lt.s32 	%p2668, %r5467, 0;
	selp.b64 	%rd5625, %rd5623, %rd5624, %p2668;
	shl.b64 	%rd5626, %rd5625, 1;
	sub.s64 	%rd5627, %rd5626, %rd1078;
	mov.b64 	%fd2726, %rd5627;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5468}, %fd2726;
	}
	setp.lt.s32 	%p2669, %r5468, 0;
	selp.b64 	%rd5628, %rd5626, %rd5627, %p2669;
	shl.b64 	%rd5629, %rd5628, 1;
	sub.s64 	%rd5630, %rd5629, %rd1078;
	mov.b64 	%fd2727, %rd5630;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5469}, %fd2727;
	}
	setp.lt.s32 	%p2670, %r5469, 0;
	selp.b64 	%rd5631, %rd5629, %rd5630, %p2670;
	shl.b64 	%rd5632, %rd5631, 1;
	sub.s64 	%rd5633, %rd5632, %rd1078;
	mov.b64 	%fd2728, %rd5633;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5470}, %fd2728;
	}
	setp.lt.s32 	%p2671, %r5470, 0;
	selp.b64 	%rd6623, %rd5632, %rd5633, %p2671;
	shl.b64 	%rd6620, %rd6623, 1;
	add.s32 	%r1589, %r6497, -16;
	setp.gt.s32 	%p2672, %r6497, 15;
	mov.u32 	%r6497, %r1589;
	@%p2672 bra 	$L__BB0_1351;

$L__BB0_1352:
	and.b64  	%rd1093, %rd6623, 9223372036854775807;
	setp.eq.s64 	%p2673, %rd1093, 0;
	mov.f64 	%fd3158, 0d0000000000000000;
	@%p2673 bra 	$L__BB0_1354;

	mov.b64 	%fd2730, %rd1093;
	mul.f64 	%fd2731, %fd2730, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5471}, %fd2731;
	}
	shr.u32 	%r5472, %r5471, 20;
	mov.u32 	%r5473, 55;
	sub.s32 	%r5474, %r5473, %r5472;
	sub.s32 	%r5475, %r6491, %r5474;
	shl.b64 	%rd5634, %rd1093, %r5474;
	setp.lt.s32 	%p2674, %r5475, 1;
	mov.u32 	%r5476, 1;
	sub.s32 	%r5477, %r5476, %r5475;
	shr.u64 	%rd5635, %rd5634, %r5477;
	add.s32 	%r5478, %r5475, -1;
	cvt.u64.u32 	%rd5636, %r5478;
	shl.b64 	%rd5637, %rd5636, 52;
	add.s64 	%rd5638, %rd5637, %rd5634;
	selp.b64 	%rd5639, %rd5635, %rd5638, %p2674;
	mov.b64 	%fd3158, %rd5639;

$L__BB0_1354:
	and.b32  	%r5479, %r1566, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5480}, %fd3158;
	}
	or.b32  	%r5481, %r5480, %r5479;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5482, %temp}, %fd3158;
	}
	mov.b64 	%fd3110, {%r5482, %r5481};
	bra.uni 	$L__BB0_1358;

$L__BB0_1356:
	mov.f64 	%fd2732, 0d3FF0000000000000;
	add.rn.f64 	%fd3110, %fd711, %fd2732;

$L__BB0_1358:
	.loc	1 30 5, function_name $L__info_string4, inlined_at 1 139 5
	add.s32 	%r6488, %r6489, -1;
	setp.gt.s32 	%p2679, %r6489, 0;
	@%p2679 bra 	$L__BB0_1338;

	.loc	1 0 5
	mov.f64 	%fd2996, %fd3034;

$L__BB0_1360:
	.loc	1 32 9, function_name $L__info_string4, inlined_at 1 71 5
	mov.f64 	%fd2733, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5483}, %fd2733;
	}
	and.b32  	%r1591, %r5483, 2146435072;
	.loc	1 266 13
	.loc	1 145 5, function_name $L__info_string7, inlined_at 1 266 13
	fma.rn.f64 	%fd728, %fd2958, 0d3FFB96C889463A4C, 0d4001135C51C7F716;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1592}, %fd728;
	}
	and.b32  	%r5484, %r1592, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5485, %temp}, %fd728;
	}
	mov.b64 	%fd3166, {%r5485, %r5484};
	setp.gt.u32 	%p2680, %r5484, 2146435071;
	setp.eq.s32 	%p2681, %r1591, 2146435072;
	or.pred  	%p2682, %p2680, %p2681;
	@%p2682 bra 	$L__BB0_1377;
	bra.uni 	$L__BB0_1361;

$L__BB0_1377:
	setp.le.f64 	%p2717, %fd3166, 0d7FF0000000000000;
	setp.le.f64 	%p2718, %fd3160, 0d7FF0000000000000;
	and.pred  	%p2719, %p2717, %p2718;
	@%p2719 bra 	$L__BB0_1379;
	bra.uni 	$L__BB0_1378;

$L__BB0_1379:
	setp.eq.f64 	%p2720, %fd3166, 0d7FF0000000000000;
	selp.f64 	%fd3169, 0dFFF8000000000000, %fd728, %p2720;
	bra.uni 	$L__BB0_1380;

$L__BB0_1361:
	setp.eq.f64 	%p2683, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3169, 0dFFF8000000000000;
	@%p2683 bra 	$L__BB0_1380;

	setp.ltu.f64 	%p2684, %fd3166, %fd3160;
	mov.f64 	%fd3169, %fd728;
	@%p2684 bra 	$L__BB0_1380;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5486}, %fd3166;
	}
	shr.u32 	%r6499, %r5486, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5487}, %fd3160;
	}
	shr.u32 	%r6500, %r5487, 20;
	setp.ne.s32 	%p2685, %r6499, 0;
	@%p2685 bra 	$L__BB0_1365;

	mul.f64 	%fd3166, %fd3166, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5488}, %fd3166;
	}
	shr.u32 	%r5489, %r5488, 20;
	add.s32 	%r6499, %r5489, -54;

$L__BB0_1365:
	setp.ne.s32 	%p2686, %r6500, 0;
	mov.f64 	%fd3167, %fd3160;
	@%p2686 bra 	$L__BB0_1367;

	mul.f64 	%fd3167, %fd3160, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5490}, %fd3167;
	}
	shr.u32 	%r5491, %r5490, 20;
	add.s32 	%r6500, %r5491, -54;

$L__BB0_1367:
	mov.b64 	%rd5641, %fd3166;
	and.b64  	%rd5642, %rd5641, 4503599627370495;
	or.b64  	%rd6628, %rd5642, 4503599627370496;
	mov.b64 	%rd5643, %fd3167;
	and.b64  	%rd5644, %rd5643, 4503599627370495;
	or.b64  	%rd1095, %rd5644, 4503599627370496;
	sub.s32 	%r6506, %r6499, %r6500;
	not.b32 	%r5492, %r6499;
	add.s32 	%r5493, %r6500, %r5492;
	max.s32 	%r5494, %r5493, -1;
	add.s32 	%r1600, %r5494, %r6499;
	mov.u32 	%r5495, 2;
	sub.s32 	%r5496, %r5495, %r6500;
	add.s32 	%r5497, %r5496, %r1600;
	and.b32  	%r6502, %r5497, 3;
	setp.eq.s32 	%p2687, %r6502, 0;
	@%p2687 bra 	$L__BB0_1369;

$L__BB0_1368:
	.pragma "nounroll";
	sub.s64 	%rd5645, %rd6628, %rd1095;
	mov.b64 	%fd2735, %rd5645;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5498}, %fd2735;
	}
	setp.lt.s32 	%p2688, %r5498, 0;
	selp.b64 	%rd6631, %rd6628, %rd5645, %p2688;
	shl.b64 	%rd6628, %rd6631, 1;
	add.s32 	%r6506, %r6506, -1;
	add.s32 	%r6502, %r6502, -1;
	setp.ne.s32 	%p2689, %r6502, 0;
	@%p2689 bra 	$L__BB0_1368;

$L__BB0_1369:
	mov.u32 	%r5499, 1;
	sub.s32 	%r5500, %r5499, %r6500;
	add.s32 	%r5501, %r5500, %r1600;
	setp.lt.u32 	%p2690, %r5501, 3;
	@%p2690 bra 	$L__BB0_1374;

	not.b32 	%r5502, %r6506;
	max.s32 	%r5503, %r5502, -4;
	add.s32 	%r5504, %r6506, %r5503;
	add.s32 	%r1607, %r5504, 4;
	shr.u32 	%r5505, %r1607, 2;
	add.s32 	%r5506, %r5505, 1;
	and.b32  	%r6505, %r5506, 3;
	setp.eq.s32 	%p2691, %r6505, 0;
	@%p2691 bra 	$L__BB0_1372;

$L__BB0_1371:
	.pragma "nounroll";
	sub.s64 	%rd5647, %rd6628, %rd1095;
	mov.b64 	%fd2736, %rd5647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5507}, %fd2736;
	}
	setp.lt.s32 	%p2692, %r5507, 0;
	selp.b64 	%rd5648, %rd6628, %rd5647, %p2692;
	shl.b64 	%rd5649, %rd5648, 1;
	sub.s64 	%rd5650, %rd5649, %rd1095;
	mov.b64 	%fd2737, %rd5650;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5508}, %fd2737;
	}
	setp.lt.s32 	%p2693, %r5508, 0;
	selp.b64 	%rd5651, %rd5649, %rd5650, %p2693;
	shl.b64 	%rd5652, %rd5651, 1;
	sub.s64 	%rd5653, %rd5652, %rd1095;
	mov.b64 	%fd2738, %rd5653;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5509}, %fd2738;
	}
	setp.lt.s32 	%p2694, %r5509, 0;
	selp.b64 	%rd5654, %rd5652, %rd5653, %p2694;
	shl.b64 	%rd5655, %rd5654, 1;
	sub.s64 	%rd5656, %rd5655, %rd1095;
	mov.b64 	%fd2739, %rd5656;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5510}, %fd2739;
	}
	setp.lt.s32 	%p2695, %r5510, 0;
	selp.b64 	%rd6631, %rd5655, %rd5656, %p2695;
	shl.b64 	%rd6628, %rd6631, 1;
	add.s32 	%r6506, %r6506, -4;
	add.s32 	%r6505, %r6505, -1;
	setp.ne.s32 	%p2696, %r6505, 0;
	@%p2696 bra 	$L__BB0_1371;

$L__BB0_1372:
	setp.lt.u32 	%p2697, %r1607, 12;
	@%p2697 bra 	$L__BB0_1374;

$L__BB0_1373:
	sub.s64 	%rd5657, %rd6628, %rd1095;
	mov.b64 	%fd2740, %rd5657;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5511}, %fd2740;
	}
	setp.lt.s32 	%p2698, %r5511, 0;
	selp.b64 	%rd5658, %rd6628, %rd5657, %p2698;
	shl.b64 	%rd5659, %rd5658, 1;
	sub.s64 	%rd5660, %rd5659, %rd1095;
	mov.b64 	%fd2741, %rd5660;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5512}, %fd2741;
	}
	setp.lt.s32 	%p2699, %r5512, 0;
	selp.b64 	%rd5661, %rd5659, %rd5660, %p2699;
	shl.b64 	%rd5662, %rd5661, 1;
	sub.s64 	%rd5663, %rd5662, %rd1095;
	mov.b64 	%fd2742, %rd5663;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5513}, %fd2742;
	}
	setp.lt.s32 	%p2700, %r5513, 0;
	selp.b64 	%rd5664, %rd5662, %rd5663, %p2700;
	shl.b64 	%rd5665, %rd5664, 1;
	sub.s64 	%rd5666, %rd5665, %rd1095;
	mov.b64 	%fd2743, %rd5666;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5514}, %fd2743;
	}
	setp.lt.s32 	%p2701, %r5514, 0;
	selp.b64 	%rd5667, %rd5665, %rd5666, %p2701;
	shl.b64 	%rd5668, %rd5667, 1;
	sub.s64 	%rd5669, %rd5668, %rd1095;
	mov.b64 	%fd2744, %rd5669;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5515}, %fd2744;
	}
	setp.lt.s32 	%p2702, %r5515, 0;
	selp.b64 	%rd5670, %rd5668, %rd5669, %p2702;
	shl.b64 	%rd5671, %rd5670, 1;
	sub.s64 	%rd5672, %rd5671, %rd1095;
	mov.b64 	%fd2745, %rd5672;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5516}, %fd2745;
	}
	setp.lt.s32 	%p2703, %r5516, 0;
	selp.b64 	%rd5673, %rd5671, %rd5672, %p2703;
	shl.b64 	%rd5674, %rd5673, 1;
	sub.s64 	%rd5675, %rd5674, %rd1095;
	mov.b64 	%fd2746, %rd5675;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5517}, %fd2746;
	}
	setp.lt.s32 	%p2704, %r5517, 0;
	selp.b64 	%rd5676, %rd5674, %rd5675, %p2704;
	shl.b64 	%rd5677, %rd5676, 1;
	sub.s64 	%rd5678, %rd5677, %rd1095;
	mov.b64 	%fd2747, %rd5678;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5518}, %fd2747;
	}
	setp.lt.s32 	%p2705, %r5518, 0;
	selp.b64 	%rd5679, %rd5677, %rd5678, %p2705;
	shl.b64 	%rd5680, %rd5679, 1;
	sub.s64 	%rd5681, %rd5680, %rd1095;
	mov.b64 	%fd2748, %rd5681;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5519}, %fd2748;
	}
	setp.lt.s32 	%p2706, %r5519, 0;
	selp.b64 	%rd5682, %rd5680, %rd5681, %p2706;
	shl.b64 	%rd5683, %rd5682, 1;
	sub.s64 	%rd5684, %rd5683, %rd1095;
	mov.b64 	%fd2749, %rd5684;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5520}, %fd2749;
	}
	setp.lt.s32 	%p2707, %r5520, 0;
	selp.b64 	%rd5685, %rd5683, %rd5684, %p2707;
	shl.b64 	%rd5686, %rd5685, 1;
	sub.s64 	%rd5687, %rd5686, %rd1095;
	mov.b64 	%fd2750, %rd5687;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5521}, %fd2750;
	}
	setp.lt.s32 	%p2708, %r5521, 0;
	selp.b64 	%rd5688, %rd5686, %rd5687, %p2708;
	shl.b64 	%rd5689, %rd5688, 1;
	sub.s64 	%rd5690, %rd5689, %rd1095;
	mov.b64 	%fd2751, %rd5690;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5522}, %fd2751;
	}
	setp.lt.s32 	%p2709, %r5522, 0;
	selp.b64 	%rd5691, %rd5689, %rd5690, %p2709;
	shl.b64 	%rd5692, %rd5691, 1;
	sub.s64 	%rd5693, %rd5692, %rd1095;
	mov.b64 	%fd2752, %rd5693;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5523}, %fd2752;
	}
	setp.lt.s32 	%p2710, %r5523, 0;
	selp.b64 	%rd5694, %rd5692, %rd5693, %p2710;
	shl.b64 	%rd5695, %rd5694, 1;
	sub.s64 	%rd5696, %rd5695, %rd1095;
	mov.b64 	%fd2753, %rd5696;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5524}, %fd2753;
	}
	setp.lt.s32 	%p2711, %r5524, 0;
	selp.b64 	%rd5697, %rd5695, %rd5696, %p2711;
	shl.b64 	%rd5698, %rd5697, 1;
	sub.s64 	%rd5699, %rd5698, %rd1095;
	mov.b64 	%fd2754, %rd5699;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5525}, %fd2754;
	}
	setp.lt.s32 	%p2712, %r5525, 0;
	selp.b64 	%rd5700, %rd5698, %rd5699, %p2712;
	shl.b64 	%rd5701, %rd5700, 1;
	sub.s64 	%rd5702, %rd5701, %rd1095;
	mov.b64 	%fd2755, %rd5702;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5526}, %fd2755;
	}
	setp.lt.s32 	%p2713, %r5526, 0;
	selp.b64 	%rd6631, %rd5701, %rd5702, %p2713;
	shl.b64 	%rd6628, %rd6631, 1;
	add.s32 	%r1615, %r6506, -16;
	setp.gt.s32 	%p2714, %r6506, 15;
	mov.u32 	%r6506, %r1615;
	@%p2714 bra 	$L__BB0_1373;

$L__BB0_1374:
	and.b64  	%rd1110, %rd6631, 9223372036854775807;
	setp.eq.s64 	%p2715, %rd1110, 0;
	mov.f64 	%fd3168, 0d0000000000000000;
	@%p2715 bra 	$L__BB0_1376;

	mov.b64 	%fd2757, %rd1110;
	mul.f64 	%fd2758, %fd2757, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5527}, %fd2758;
	}
	shr.u32 	%r5528, %r5527, 20;
	mov.u32 	%r5529, 55;
	sub.s32 	%r5530, %r5529, %r5528;
	sub.s32 	%r5531, %r6500, %r5530;
	shl.b64 	%rd5703, %rd1110, %r5530;
	setp.lt.s32 	%p2716, %r5531, 1;
	mov.u32 	%r5532, 1;
	sub.s32 	%r5533, %r5532, %r5531;
	shr.u64 	%rd5704, %rd5703, %r5533;
	add.s32 	%r5534, %r5531, -1;
	cvt.u64.u32 	%rd5705, %r5534;
	shl.b64 	%rd5706, %rd5705, 52;
	add.s64 	%rd5707, %rd5706, %rd5703;
	selp.b64 	%rd5708, %rd5704, %rd5707, %p2716;
	mov.b64 	%fd3168, %rd5708;

$L__BB0_1376:
	and.b32  	%r5535, %r1592, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5536}, %fd3168;
	}
	or.b32  	%r5537, %r5536, %r5535;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5538, %temp}, %fd3168;
	}
	mov.b64 	%fd3169, {%r5538, %r5537};
	bra.uni 	$L__BB0_1380;

$L__BB0_1378:
	mov.f64 	%fd2759, 0d3FF0000000000000;
	add.rn.f64 	%fd3169, %fd728, %fd2759;

$L__BB0_1380:
	.loc	1 146 5, function_name $L__info_string7, inlined_at 1 266 13
	abs.f64 	%fd2760, %fd3169;
	.loc	1 149 5, function_name $L__info_string7, inlined_at 1 266 13
	mul.f64 	%fd740, %fd2760, 0d3FE0000000000000;
	.loc	1 268 13
	@%p17 bra 	$L__BB0_1390;

	.loc	1 271 17
	ld.global.u8 	%r5539, [%rd1206+16];
	ld.global.u8 	%r5540, [%rd1206+17];
	prmt.b32 	%r5541, %r5540, %r5539, 30212;
	ld.global.u8 	%r5542, [%rd1206+18];
	ld.global.u8 	%r5543, [%rd1206+19];
	prmt.b32 	%r5544, %r5543, %r5542, 30212;
	prmt.b32 	%r5545, %r5544, %r5541, 4180;
	setp.eq.s32 	%p2722, %r5545, 0;
	@%p2722 bra 	$L__BB0_1389;

	.loc	1 272 37
	ld.global.u8 	%rd5709, [%rd1206+8];
	ld.global.u8 	%rd5710, [%rd1206+9];
	bfi.b64 	%rd5711, %rd5710, %rd5709, 8, 8;
	ld.global.u8 	%rd5712, [%rd1206+10];
	ld.global.u8 	%rd5713, [%rd1206+11];
	bfi.b64 	%rd5714, %rd5713, %rd5712, 8, 8;
	bfi.b64 	%rd1112, %rd5714, %rd5711, 16, 16;
	ld.global.u8 	%r5547, [%rd1206+12];
	ld.global.u8 	%r5548, [%rd1206+13];
	prmt.b32 	%r5549, %r5548, %r5547, 30212;
	ld.global.u8 	%r5550, [%rd1206+14];
	ld.global.u8 	%r5551, [%rd1206+15];
	prmt.b32 	%r5552, %r5551, %r5550, 30212;
	prmt.b32 	%r1616, %r5552, %r5549, 4180;
	.loc	1 272 37
	.loc	1 161 5, function_name $L__info_string8, inlined_at 1 272 37
	setp.eq.s32 	%p2723, %r1616, 0;
	mov.u32 	%r6514, 0;
	@%p2723 bra 	$L__BB0_1391;

	.loc	1 270 17
	ld.global.u8 	%rd5715, [%rd1206+100];
	ld.global.u8 	%rd5716, [%rd1206+101];
	bfi.b64 	%rd5717, %rd5716, %rd5715, 8, 8;
	ld.global.u8 	%rd5718, [%rd1206+102];
	ld.global.u8 	%rd5719, [%rd1206+103];
	bfi.b64 	%rd5720, %rd5719, %rd5718, 8, 8;
	bfi.b64 	%rd5721, %rd5720, %rd5717, 16, 16;
	add.s64 	%rd1113, %rd9, %rd5721;
	.loc	1 163 5, function_name $L__info_string8, inlined_at 1 272 37
	add.s32 	%r6514, %r1616, -1;
	cvt.u64.u32 	%rd5722, %r6514;
	add.s64 	%rd5723, %rd5722, %rd1112;
	shl.b64 	%rd5724, %rd5723, 3;
	add.s64 	%rd5725, %rd1113, %rd5724;
	ld.global.u64 	%rd5726, [%rd5725];
	.loc	1 164 5, function_name $L__info_string8, inlined_at 1 272 37
	cvt.rn.f64.u64 	%fd2761, %rd5726;
	mul.f64 	%fd741, %fd740, %fd2761;
	mov.u32 	%r6510, 0;
	mov.u32 	%r6509, %r6514;

$L__BB0_1384:
	.loc	1 168 9, function_name $L__info_string8, inlined_at 1 272 37
	add.s32 	%r5554, %r6509, %r6510;
	shr.u32 	%r1621, %r5554, 1;
	.loc	1 169 9, function_name $L__info_string8, inlined_at 1 272 37
	cvt.u64.u32 	%rd5727, %r1621;
	add.s64 	%rd5728, %rd5727, %rd1112;
	shl.b64 	%rd5729, %rd5728, 3;
	add.s64 	%rd5730, %rd1113, %rd5729;
	ld.global.u64 	%rd5731, [%rd5730];
	cvt.rn.f64.u64 	%fd2762, %rd5731;
	setp.lt.f64 	%p2724, %fd741, %fd2762;
	@%p2724 bra 	$L__BB0_1386;
	bra.uni 	$L__BB0_1385;

$L__BB0_1386:
	.loc	1 171 13, function_name $L__info_string8, inlined_at 1 272 37
	setp.eq.s32 	%p2725, %r1621, 0;
	mov.u32 	%r6514, 0;
	@%p2725 bra 	$L__BB0_1391;

	.loc	1 172 13, function_name $L__info_string8, inlined_at 1 272 37
	add.s32 	%r6509, %r1621, -1;
	mov.u32 	%r6514, %r1621;
	bra.uni 	$L__BB0_1388;

$L__BB0_1385:
	.loc	1 174 13, function_name $L__info_string8, inlined_at 1 272 37
	add.s32 	%r6510, %r1621, 1;

$L__BB0_1388:
	.loc	1 167 5, function_name $L__info_string8, inlined_at 1 272 37
	setp.gt.u32 	%p2726, %r6510, %r6509;
	@%p2726 bra 	$L__BB0_1391;
	bra.uni 	$L__BB0_1384;

$L__BB0_1390:
	.loc	1 276 17
	.loc	1 154 5, function_name $L__info_string9, inlined_at 1 276 17
	mul.f64 	%fd2765, %fd740, 0d403E000000000000;
	cvt.rzi.u64.f64 	%rd5736, %fd2765;
	.loc	1 155 5, function_name $L__info_string9, inlined_at 1 276 17
	min.u64 	%rd5737, %rd5736, 29;
	.loc	1 156 5, function_name $L__info_string9, inlined_at 1 276 17
	cvt.u32.u64 	%r6514, %rd5737;
	bra.uni 	$L__BB0_1391;

$L__BB0_1389:
	.loc	1 273 36
	ld.global.u8 	%r5556, [%rd1206+12];
	ld.global.u8 	%r5557, [%rd1206+13];
	prmt.b32 	%r5558, %r5557, %r5556, 30212;
	ld.global.u8 	%r5559, [%rd1206+14];
	ld.global.u8 	%r5560, [%rd1206+15];
	prmt.b32 	%r5561, %r5560, %r5559, 30212;
	prmt.b32 	%r5562, %r5561, %r5558, 4180;
	.loc	1 273 36
	.loc	1 154 5, function_name $L__info_string9, inlined_at 1 273 36
	cvt.rn.f64.u32 	%fd2763, %r5562;
	mul.f64 	%fd2764, %fd740, %fd2763;
	cvt.rzi.u64.f64 	%rd5732, %fd2764;
	.loc	1 155 5, function_name $L__info_string9, inlined_at 1 273 36
	cvt.u64.u32 	%rd5733, %r5562;
	setp.lt.u64 	%p2727, %rd5732, %rd5733;
	add.s32 	%r5563, %r5562, -1;
	cvt.u64.u32 	%rd5734, %r5563;
	selp.b64 	%rd5735, %rd5732, %rd5734, %p2727;
	.loc	1 156 5, function_name $L__info_string9, inlined_at 1 273 36
	cvt.u32.u64 	%r6514, %rd5735;

$L__BB0_1391:
	.loc	1 280 13
	.loc	1 145 5, function_name $L__info_string7, inlined_at 1 280 13
	fma.rn.f64 	%fd742, %fd2996, 0d3FFB96C889463A4C, 0d4001135C51C7F716;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1630}, %fd742;
	}
	and.b32  	%r5564, %r1630, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5565, %temp}, %fd742;
	}
	mov.b64 	%fd3170, {%r5565, %r5564};
	setp.gt.u32 	%p2728, %r5564, 2146435071;
	or.pred  	%p2730, %p2728, %p2681;
	@%p2730 bra 	$L__BB0_1408;
	bra.uni 	$L__BB0_1392;

$L__BB0_1408:
	setp.le.f64 	%p2765, %fd3170, 0d7FF0000000000000;
	setp.le.f64 	%p2766, %fd3160, 0d7FF0000000000000;
	and.pred  	%p2767, %p2765, %p2766;
	@%p2767 bra 	$L__BB0_1410;
	bra.uni 	$L__BB0_1409;

$L__BB0_1410:
	setp.eq.f64 	%p2768, %fd3170, 0d7FF0000000000000;
	selp.f64 	%fd3173, 0dFFF8000000000000, %fd742, %p2768;
	bra.uni 	$L__BB0_1411;

$L__BB0_1392:
	setp.eq.f64 	%p2731, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3173, 0dFFF8000000000000;
	@%p2731 bra 	$L__BB0_1411;

	setp.ltu.f64 	%p2732, %fd3170, %fd3160;
	mov.f64 	%fd3173, %fd742;
	@%p2732 bra 	$L__BB0_1411;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5566}, %fd3170;
	}
	shr.u32 	%r6515, %r5566, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5567}, %fd3160;
	}
	shr.u32 	%r6516, %r5567, 20;
	setp.ne.s32 	%p2733, %r6515, 0;
	@%p2733 bra 	$L__BB0_1396;

	mul.f64 	%fd3170, %fd3170, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5568}, %fd3170;
	}
	shr.u32 	%r5569, %r5568, 20;
	add.s32 	%r6515, %r5569, -54;

$L__BB0_1396:
	setp.ne.s32 	%p2734, %r6516, 0;
	mov.f64 	%fd3171, %fd3160;
	@%p2734 bra 	$L__BB0_1398;

	mul.f64 	%fd3171, %fd3160, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5570}, %fd3171;
	}
	shr.u32 	%r5571, %r5570, 20;
	add.s32 	%r6516, %r5571, -54;

$L__BB0_1398:
	mov.b64 	%rd5739, %fd3170;
	and.b64  	%rd5740, %rd5739, 4503599627370495;
	or.b64  	%rd6636, %rd5740, 4503599627370496;
	mov.b64 	%rd5741, %fd3171;
	and.b64  	%rd5742, %rd5741, 4503599627370495;
	or.b64  	%rd1115, %rd5742, 4503599627370496;
	sub.s32 	%r6522, %r6515, %r6516;
	not.b32 	%r5572, %r6515;
	add.s32 	%r5573, %r6516, %r5572;
	max.s32 	%r5574, %r5573, -1;
	add.s32 	%r1638, %r5574, %r6515;
	mov.u32 	%r5575, 2;
	sub.s32 	%r5576, %r5575, %r6516;
	add.s32 	%r5577, %r5576, %r1638;
	and.b32  	%r6518, %r5577, 3;
	setp.eq.s32 	%p2735, %r6518, 0;
	@%p2735 bra 	$L__BB0_1400;

$L__BB0_1399:
	.pragma "nounroll";
	sub.s64 	%rd5743, %rd6636, %rd1115;
	mov.b64 	%fd2767, %rd5743;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5578}, %fd2767;
	}
	setp.lt.s32 	%p2736, %r5578, 0;
	selp.b64 	%rd6639, %rd6636, %rd5743, %p2736;
	shl.b64 	%rd6636, %rd6639, 1;
	add.s32 	%r6522, %r6522, -1;
	add.s32 	%r6518, %r6518, -1;
	setp.ne.s32 	%p2737, %r6518, 0;
	@%p2737 bra 	$L__BB0_1399;

$L__BB0_1400:
	mov.u32 	%r5579, 1;
	sub.s32 	%r5580, %r5579, %r6516;
	add.s32 	%r5581, %r5580, %r1638;
	setp.lt.u32 	%p2738, %r5581, 3;
	@%p2738 bra 	$L__BB0_1405;

	not.b32 	%r5582, %r6522;
	max.s32 	%r5583, %r5582, -4;
	add.s32 	%r5584, %r6522, %r5583;
	add.s32 	%r1645, %r5584, 4;
	shr.u32 	%r5585, %r1645, 2;
	add.s32 	%r5586, %r5585, 1;
	and.b32  	%r6521, %r5586, 3;
	setp.eq.s32 	%p2739, %r6521, 0;
	@%p2739 bra 	$L__BB0_1403;

$L__BB0_1402:
	.pragma "nounroll";
	sub.s64 	%rd5745, %rd6636, %rd1115;
	mov.b64 	%fd2768, %rd5745;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5587}, %fd2768;
	}
	setp.lt.s32 	%p2740, %r5587, 0;
	selp.b64 	%rd5746, %rd6636, %rd5745, %p2740;
	shl.b64 	%rd5747, %rd5746, 1;
	sub.s64 	%rd5748, %rd5747, %rd1115;
	mov.b64 	%fd2769, %rd5748;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5588}, %fd2769;
	}
	setp.lt.s32 	%p2741, %r5588, 0;
	selp.b64 	%rd5749, %rd5747, %rd5748, %p2741;
	shl.b64 	%rd5750, %rd5749, 1;
	sub.s64 	%rd5751, %rd5750, %rd1115;
	mov.b64 	%fd2770, %rd5751;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5589}, %fd2770;
	}
	setp.lt.s32 	%p2742, %r5589, 0;
	selp.b64 	%rd5752, %rd5750, %rd5751, %p2742;
	shl.b64 	%rd5753, %rd5752, 1;
	sub.s64 	%rd5754, %rd5753, %rd1115;
	mov.b64 	%fd2771, %rd5754;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5590}, %fd2771;
	}
	setp.lt.s32 	%p2743, %r5590, 0;
	selp.b64 	%rd6639, %rd5753, %rd5754, %p2743;
	shl.b64 	%rd6636, %rd6639, 1;
	add.s32 	%r6522, %r6522, -4;
	add.s32 	%r6521, %r6521, -1;
	setp.ne.s32 	%p2744, %r6521, 0;
	@%p2744 bra 	$L__BB0_1402;

$L__BB0_1403:
	setp.lt.u32 	%p2745, %r1645, 12;
	@%p2745 bra 	$L__BB0_1405;

$L__BB0_1404:
	sub.s64 	%rd5755, %rd6636, %rd1115;
	mov.b64 	%fd2772, %rd5755;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5591}, %fd2772;
	}
	setp.lt.s32 	%p2746, %r5591, 0;
	selp.b64 	%rd5756, %rd6636, %rd5755, %p2746;
	shl.b64 	%rd5757, %rd5756, 1;
	sub.s64 	%rd5758, %rd5757, %rd1115;
	mov.b64 	%fd2773, %rd5758;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5592}, %fd2773;
	}
	setp.lt.s32 	%p2747, %r5592, 0;
	selp.b64 	%rd5759, %rd5757, %rd5758, %p2747;
	shl.b64 	%rd5760, %rd5759, 1;
	sub.s64 	%rd5761, %rd5760, %rd1115;
	mov.b64 	%fd2774, %rd5761;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5593}, %fd2774;
	}
	setp.lt.s32 	%p2748, %r5593, 0;
	selp.b64 	%rd5762, %rd5760, %rd5761, %p2748;
	shl.b64 	%rd5763, %rd5762, 1;
	sub.s64 	%rd5764, %rd5763, %rd1115;
	mov.b64 	%fd2775, %rd5764;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5594}, %fd2775;
	}
	setp.lt.s32 	%p2749, %r5594, 0;
	selp.b64 	%rd5765, %rd5763, %rd5764, %p2749;
	shl.b64 	%rd5766, %rd5765, 1;
	sub.s64 	%rd5767, %rd5766, %rd1115;
	mov.b64 	%fd2776, %rd5767;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5595}, %fd2776;
	}
	setp.lt.s32 	%p2750, %r5595, 0;
	selp.b64 	%rd5768, %rd5766, %rd5767, %p2750;
	shl.b64 	%rd5769, %rd5768, 1;
	sub.s64 	%rd5770, %rd5769, %rd1115;
	mov.b64 	%fd2777, %rd5770;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5596}, %fd2777;
	}
	setp.lt.s32 	%p2751, %r5596, 0;
	selp.b64 	%rd5771, %rd5769, %rd5770, %p2751;
	shl.b64 	%rd5772, %rd5771, 1;
	sub.s64 	%rd5773, %rd5772, %rd1115;
	mov.b64 	%fd2778, %rd5773;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5597}, %fd2778;
	}
	setp.lt.s32 	%p2752, %r5597, 0;
	selp.b64 	%rd5774, %rd5772, %rd5773, %p2752;
	shl.b64 	%rd5775, %rd5774, 1;
	sub.s64 	%rd5776, %rd5775, %rd1115;
	mov.b64 	%fd2779, %rd5776;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5598}, %fd2779;
	}
	setp.lt.s32 	%p2753, %r5598, 0;
	selp.b64 	%rd5777, %rd5775, %rd5776, %p2753;
	shl.b64 	%rd5778, %rd5777, 1;
	sub.s64 	%rd5779, %rd5778, %rd1115;
	mov.b64 	%fd2780, %rd5779;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5599}, %fd2780;
	}
	setp.lt.s32 	%p2754, %r5599, 0;
	selp.b64 	%rd5780, %rd5778, %rd5779, %p2754;
	shl.b64 	%rd5781, %rd5780, 1;
	sub.s64 	%rd5782, %rd5781, %rd1115;
	mov.b64 	%fd2781, %rd5782;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5600}, %fd2781;
	}
	setp.lt.s32 	%p2755, %r5600, 0;
	selp.b64 	%rd5783, %rd5781, %rd5782, %p2755;
	shl.b64 	%rd5784, %rd5783, 1;
	sub.s64 	%rd5785, %rd5784, %rd1115;
	mov.b64 	%fd2782, %rd5785;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5601}, %fd2782;
	}
	setp.lt.s32 	%p2756, %r5601, 0;
	selp.b64 	%rd5786, %rd5784, %rd5785, %p2756;
	shl.b64 	%rd5787, %rd5786, 1;
	sub.s64 	%rd5788, %rd5787, %rd1115;
	mov.b64 	%fd2783, %rd5788;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5602}, %fd2783;
	}
	setp.lt.s32 	%p2757, %r5602, 0;
	selp.b64 	%rd5789, %rd5787, %rd5788, %p2757;
	shl.b64 	%rd5790, %rd5789, 1;
	sub.s64 	%rd5791, %rd5790, %rd1115;
	mov.b64 	%fd2784, %rd5791;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5603}, %fd2784;
	}
	setp.lt.s32 	%p2758, %r5603, 0;
	selp.b64 	%rd5792, %rd5790, %rd5791, %p2758;
	shl.b64 	%rd5793, %rd5792, 1;
	sub.s64 	%rd5794, %rd5793, %rd1115;
	mov.b64 	%fd2785, %rd5794;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5604}, %fd2785;
	}
	setp.lt.s32 	%p2759, %r5604, 0;
	selp.b64 	%rd5795, %rd5793, %rd5794, %p2759;
	shl.b64 	%rd5796, %rd5795, 1;
	sub.s64 	%rd5797, %rd5796, %rd1115;
	mov.b64 	%fd2786, %rd5797;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5605}, %fd2786;
	}
	setp.lt.s32 	%p2760, %r5605, 0;
	selp.b64 	%rd5798, %rd5796, %rd5797, %p2760;
	shl.b64 	%rd5799, %rd5798, 1;
	sub.s64 	%rd5800, %rd5799, %rd1115;
	mov.b64 	%fd2787, %rd5800;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5606}, %fd2787;
	}
	setp.lt.s32 	%p2761, %r5606, 0;
	selp.b64 	%rd6639, %rd5799, %rd5800, %p2761;
	shl.b64 	%rd6636, %rd6639, 1;
	add.s32 	%r1653, %r6522, -16;
	setp.gt.s32 	%p2762, %r6522, 15;
	mov.u32 	%r6522, %r1653;
	@%p2762 bra 	$L__BB0_1404;

$L__BB0_1405:
	and.b64  	%rd1130, %rd6639, 9223372036854775807;
	setp.eq.s64 	%p2763, %rd1130, 0;
	mov.f64 	%fd3172, 0d0000000000000000;
	@%p2763 bra 	$L__BB0_1407;

	mov.b64 	%fd2789, %rd1130;
	mul.f64 	%fd2790, %fd2789, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5607}, %fd2790;
	}
	shr.u32 	%r5608, %r5607, 20;
	mov.u32 	%r5609, 55;
	sub.s32 	%r5610, %r5609, %r5608;
	sub.s32 	%r5611, %r6516, %r5610;
	shl.b64 	%rd5801, %rd1130, %r5610;
	setp.lt.s32 	%p2764, %r5611, 1;
	mov.u32 	%r5612, 1;
	sub.s32 	%r5613, %r5612, %r5611;
	shr.u64 	%rd5802, %rd5801, %r5613;
	add.s32 	%r5614, %r5611, -1;
	cvt.u64.u32 	%rd5803, %r5614;
	shl.b64 	%rd5804, %rd5803, 52;
	add.s64 	%rd5805, %rd5804, %rd5801;
	selp.b64 	%rd5806, %rd5802, %rd5805, %p2764;
	mov.b64 	%fd3172, %rd5806;

$L__BB0_1407:
	and.b32  	%r5615, %r1630, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5616}, %fd3172;
	}
	or.b32  	%r5617, %r5616, %r5615;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5618, %temp}, %fd3172;
	}
	mov.b64 	%fd3173, {%r5618, %r5617};
	bra.uni 	$L__BB0_1411;

$L__BB0_1409:
	mov.f64 	%fd2791, 0d3FF0000000000000;
	add.rn.f64 	%fd3173, %fd742, %fd2791;

$L__BB0_1411:
	.loc	1 146 5, function_name $L__info_string7, inlined_at 1 280 13
	abs.f64 	%fd2792, %fd3173;
	.loc	1 149 5, function_name $L__info_string7, inlined_at 1 280 13
	mul.f64 	%fd754, %fd2792, 0d3FE0000000000000;
	.loc	1 281 13
	.loc	1 145 5, function_name $L__info_string7, inlined_at 1 281 13
	fma.rn.f64 	%fd755, %fd3034, 0d3FFB96C889463A4C, 0d4001135C51C7F716;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1654}, %fd755;
	}
	and.b32  	%r5619, %r1654, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5620, %temp}, %fd755;
	}
	mov.b64 	%fd3174, {%r5620, %r5619};
	setp.gt.u32 	%p2769, %r5619, 2146435071;
	or.pred  	%p2771, %p2769, %p2681;
	@%p2771 bra 	$L__BB0_1428;
	bra.uni 	$L__BB0_1412;

$L__BB0_1428:
	setp.le.f64 	%p2806, %fd3174, 0d7FF0000000000000;
	setp.le.f64 	%p2807, %fd3160, 0d7FF0000000000000;
	and.pred  	%p2808, %p2806, %p2807;
	@%p2808 bra 	$L__BB0_1430;
	bra.uni 	$L__BB0_1429;

$L__BB0_1430:
	setp.eq.f64 	%p2809, %fd3174, 0d7FF0000000000000;
	selp.f64 	%fd3177, 0dFFF8000000000000, %fd755, %p2809;
	bra.uni 	$L__BB0_1431;

$L__BB0_1412:
	setp.eq.f64 	%p2772, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3177, 0dFFF8000000000000;
	@%p2772 bra 	$L__BB0_1431;

	setp.ltu.f64 	%p2773, %fd3174, %fd3160;
	mov.f64 	%fd3177, %fd755;
	@%p2773 bra 	$L__BB0_1431;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5621}, %fd3174;
	}
	shr.u32 	%r6524, %r5621, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5622}, %fd3160;
	}
	shr.u32 	%r6525, %r5622, 20;
	setp.ne.s32 	%p2774, %r6524, 0;
	@%p2774 bra 	$L__BB0_1416;

	mul.f64 	%fd3174, %fd3174, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5623}, %fd3174;
	}
	shr.u32 	%r5624, %r5623, 20;
	add.s32 	%r6524, %r5624, -54;

$L__BB0_1416:
	setp.ne.s32 	%p2775, %r6525, 0;
	mov.f64 	%fd3175, %fd3160;
	@%p2775 bra 	$L__BB0_1418;

	mul.f64 	%fd3175, %fd3160, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5625}, %fd3175;
	}
	shr.u32 	%r5626, %r5625, 20;
	add.s32 	%r6525, %r5626, -54;

$L__BB0_1418:
	mov.b64 	%rd5808, %fd3174;
	and.b64  	%rd5809, %rd5808, 4503599627370495;
	or.b64  	%rd6644, %rd5809, 4503599627370496;
	mov.b64 	%rd5810, %fd3175;
	and.b64  	%rd5811, %rd5810, 4503599627370495;
	or.b64  	%rd1132, %rd5811, 4503599627370496;
	sub.s32 	%r6531, %r6524, %r6525;
	not.b32 	%r5627, %r6524;
	add.s32 	%r5628, %r6525, %r5627;
	max.s32 	%r5629, %r5628, -1;
	add.s32 	%r1662, %r5629, %r6524;
	mov.u32 	%r5630, 2;
	sub.s32 	%r5631, %r5630, %r6525;
	add.s32 	%r5632, %r5631, %r1662;
	and.b32  	%r6527, %r5632, 3;
	setp.eq.s32 	%p2776, %r6527, 0;
	@%p2776 bra 	$L__BB0_1420;

$L__BB0_1419:
	.pragma "nounroll";
	sub.s64 	%rd5812, %rd6644, %rd1132;
	mov.b64 	%fd2794, %rd5812;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5633}, %fd2794;
	}
	setp.lt.s32 	%p2777, %r5633, 0;
	selp.b64 	%rd6647, %rd6644, %rd5812, %p2777;
	shl.b64 	%rd6644, %rd6647, 1;
	add.s32 	%r6531, %r6531, -1;
	add.s32 	%r6527, %r6527, -1;
	setp.ne.s32 	%p2778, %r6527, 0;
	@%p2778 bra 	$L__BB0_1419;

$L__BB0_1420:
	mov.u32 	%r5634, 1;
	sub.s32 	%r5635, %r5634, %r6525;
	add.s32 	%r5636, %r5635, %r1662;
	setp.lt.u32 	%p2779, %r5636, 3;
	@%p2779 bra 	$L__BB0_1425;

	not.b32 	%r5637, %r6531;
	max.s32 	%r5638, %r5637, -4;
	add.s32 	%r5639, %r6531, %r5638;
	add.s32 	%r1669, %r5639, 4;
	shr.u32 	%r5640, %r1669, 2;
	add.s32 	%r5641, %r5640, 1;
	and.b32  	%r6530, %r5641, 3;
	setp.eq.s32 	%p2780, %r6530, 0;
	@%p2780 bra 	$L__BB0_1423;

$L__BB0_1422:
	.pragma "nounroll";
	sub.s64 	%rd5814, %rd6644, %rd1132;
	mov.b64 	%fd2795, %rd5814;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5642}, %fd2795;
	}
	setp.lt.s32 	%p2781, %r5642, 0;
	selp.b64 	%rd5815, %rd6644, %rd5814, %p2781;
	shl.b64 	%rd5816, %rd5815, 1;
	sub.s64 	%rd5817, %rd5816, %rd1132;
	mov.b64 	%fd2796, %rd5817;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5643}, %fd2796;
	}
	setp.lt.s32 	%p2782, %r5643, 0;
	selp.b64 	%rd5818, %rd5816, %rd5817, %p2782;
	shl.b64 	%rd5819, %rd5818, 1;
	sub.s64 	%rd5820, %rd5819, %rd1132;
	mov.b64 	%fd2797, %rd5820;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5644}, %fd2797;
	}
	setp.lt.s32 	%p2783, %r5644, 0;
	selp.b64 	%rd5821, %rd5819, %rd5820, %p2783;
	shl.b64 	%rd5822, %rd5821, 1;
	sub.s64 	%rd5823, %rd5822, %rd1132;
	mov.b64 	%fd2798, %rd5823;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5645}, %fd2798;
	}
	setp.lt.s32 	%p2784, %r5645, 0;
	selp.b64 	%rd6647, %rd5822, %rd5823, %p2784;
	shl.b64 	%rd6644, %rd6647, 1;
	add.s32 	%r6531, %r6531, -4;
	add.s32 	%r6530, %r6530, -1;
	setp.ne.s32 	%p2785, %r6530, 0;
	@%p2785 bra 	$L__BB0_1422;

$L__BB0_1423:
	setp.lt.u32 	%p2786, %r1669, 12;
	@%p2786 bra 	$L__BB0_1425;

$L__BB0_1424:
	sub.s64 	%rd5824, %rd6644, %rd1132;
	mov.b64 	%fd2799, %rd5824;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5646}, %fd2799;
	}
	setp.lt.s32 	%p2787, %r5646, 0;
	selp.b64 	%rd5825, %rd6644, %rd5824, %p2787;
	shl.b64 	%rd5826, %rd5825, 1;
	sub.s64 	%rd5827, %rd5826, %rd1132;
	mov.b64 	%fd2800, %rd5827;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5647}, %fd2800;
	}
	setp.lt.s32 	%p2788, %r5647, 0;
	selp.b64 	%rd5828, %rd5826, %rd5827, %p2788;
	shl.b64 	%rd5829, %rd5828, 1;
	sub.s64 	%rd5830, %rd5829, %rd1132;
	mov.b64 	%fd2801, %rd5830;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5648}, %fd2801;
	}
	setp.lt.s32 	%p2789, %r5648, 0;
	selp.b64 	%rd5831, %rd5829, %rd5830, %p2789;
	shl.b64 	%rd5832, %rd5831, 1;
	sub.s64 	%rd5833, %rd5832, %rd1132;
	mov.b64 	%fd2802, %rd5833;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5649}, %fd2802;
	}
	setp.lt.s32 	%p2790, %r5649, 0;
	selp.b64 	%rd5834, %rd5832, %rd5833, %p2790;
	shl.b64 	%rd5835, %rd5834, 1;
	sub.s64 	%rd5836, %rd5835, %rd1132;
	mov.b64 	%fd2803, %rd5836;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5650}, %fd2803;
	}
	setp.lt.s32 	%p2791, %r5650, 0;
	selp.b64 	%rd5837, %rd5835, %rd5836, %p2791;
	shl.b64 	%rd5838, %rd5837, 1;
	sub.s64 	%rd5839, %rd5838, %rd1132;
	mov.b64 	%fd2804, %rd5839;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5651}, %fd2804;
	}
	setp.lt.s32 	%p2792, %r5651, 0;
	selp.b64 	%rd5840, %rd5838, %rd5839, %p2792;
	shl.b64 	%rd5841, %rd5840, 1;
	sub.s64 	%rd5842, %rd5841, %rd1132;
	mov.b64 	%fd2805, %rd5842;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5652}, %fd2805;
	}
	setp.lt.s32 	%p2793, %r5652, 0;
	selp.b64 	%rd5843, %rd5841, %rd5842, %p2793;
	shl.b64 	%rd5844, %rd5843, 1;
	sub.s64 	%rd5845, %rd5844, %rd1132;
	mov.b64 	%fd2806, %rd5845;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5653}, %fd2806;
	}
	setp.lt.s32 	%p2794, %r5653, 0;
	selp.b64 	%rd5846, %rd5844, %rd5845, %p2794;
	shl.b64 	%rd5847, %rd5846, 1;
	sub.s64 	%rd5848, %rd5847, %rd1132;
	mov.b64 	%fd2807, %rd5848;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5654}, %fd2807;
	}
	setp.lt.s32 	%p2795, %r5654, 0;
	selp.b64 	%rd5849, %rd5847, %rd5848, %p2795;
	shl.b64 	%rd5850, %rd5849, 1;
	sub.s64 	%rd5851, %rd5850, %rd1132;
	mov.b64 	%fd2808, %rd5851;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5655}, %fd2808;
	}
	setp.lt.s32 	%p2796, %r5655, 0;
	selp.b64 	%rd5852, %rd5850, %rd5851, %p2796;
	shl.b64 	%rd5853, %rd5852, 1;
	sub.s64 	%rd5854, %rd5853, %rd1132;
	mov.b64 	%fd2809, %rd5854;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5656}, %fd2809;
	}
	setp.lt.s32 	%p2797, %r5656, 0;
	selp.b64 	%rd5855, %rd5853, %rd5854, %p2797;
	shl.b64 	%rd5856, %rd5855, 1;
	sub.s64 	%rd5857, %rd5856, %rd1132;
	mov.b64 	%fd2810, %rd5857;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5657}, %fd2810;
	}
	setp.lt.s32 	%p2798, %r5657, 0;
	selp.b64 	%rd5858, %rd5856, %rd5857, %p2798;
	shl.b64 	%rd5859, %rd5858, 1;
	sub.s64 	%rd5860, %rd5859, %rd1132;
	mov.b64 	%fd2811, %rd5860;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5658}, %fd2811;
	}
	setp.lt.s32 	%p2799, %r5658, 0;
	selp.b64 	%rd5861, %rd5859, %rd5860, %p2799;
	shl.b64 	%rd5862, %rd5861, 1;
	sub.s64 	%rd5863, %rd5862, %rd1132;
	mov.b64 	%fd2812, %rd5863;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5659}, %fd2812;
	}
	setp.lt.s32 	%p2800, %r5659, 0;
	selp.b64 	%rd5864, %rd5862, %rd5863, %p2800;
	shl.b64 	%rd5865, %rd5864, 1;
	sub.s64 	%rd5866, %rd5865, %rd1132;
	mov.b64 	%fd2813, %rd5866;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5660}, %fd2813;
	}
	setp.lt.s32 	%p2801, %r5660, 0;
	selp.b64 	%rd5867, %rd5865, %rd5866, %p2801;
	shl.b64 	%rd5868, %rd5867, 1;
	sub.s64 	%rd5869, %rd5868, %rd1132;
	mov.b64 	%fd2814, %rd5869;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5661}, %fd2814;
	}
	setp.lt.s32 	%p2802, %r5661, 0;
	selp.b64 	%rd6647, %rd5868, %rd5869, %p2802;
	shl.b64 	%rd6644, %rd6647, 1;
	add.s32 	%r1677, %r6531, -16;
	setp.gt.s32 	%p2803, %r6531, 15;
	mov.u32 	%r6531, %r1677;
	@%p2803 bra 	$L__BB0_1424;

$L__BB0_1425:
	and.b64  	%rd1147, %rd6647, 9223372036854775807;
	setp.eq.s64 	%p2804, %rd1147, 0;
	mov.f64 	%fd3176, 0d0000000000000000;
	@%p2804 bra 	$L__BB0_1427;

	mov.b64 	%fd2816, %rd1147;
	mul.f64 	%fd2817, %fd2816, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5662}, %fd2817;
	}
	shr.u32 	%r5663, %r5662, 20;
	mov.u32 	%r5664, 55;
	sub.s32 	%r5665, %r5664, %r5663;
	sub.s32 	%r5666, %r6525, %r5665;
	shl.b64 	%rd5870, %rd1147, %r5665;
	setp.lt.s32 	%p2805, %r5666, 1;
	mov.u32 	%r5667, 1;
	sub.s32 	%r5668, %r5667, %r5666;
	shr.u64 	%rd5871, %rd5870, %r5668;
	add.s32 	%r5669, %r5666, -1;
	cvt.u64.u32 	%rd5872, %r5669;
	shl.b64 	%rd5873, %rd5872, 52;
	add.s64 	%rd5874, %rd5873, %rd5870;
	selp.b64 	%rd5875, %rd5871, %rd5874, %p2805;
	mov.b64 	%fd3176, %rd5875;

$L__BB0_1427:
	and.b32  	%r5670, %r1654, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5671}, %fd3176;
	}
	or.b32  	%r5672, %r5671, %r5670;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5673, %temp}, %fd3176;
	}
	mov.b64 	%fd3177, {%r5673, %r5672};
	bra.uni 	$L__BB0_1431;

$L__BB0_1429:
	mov.f64 	%fd2818, 0d3FF0000000000000;
	add.rn.f64 	%fd3177, %fd755, %fd2818;

$L__BB0_1431:
	.loc	1 146 5, function_name $L__info_string7, inlined_at 1 281 13
	abs.f64 	%fd2819, %fd3177;
	.loc	1 149 5, function_name $L__info_string7, inlined_at 1 281 13
	mul.f64 	%fd767, %fd2819, 0d3FE0000000000000;
	.loc	1 282 13
	.loc	1 145 5, function_name $L__info_string7, inlined_at 1 282 13
	fma.rn.f64 	%fd768, %fd3072, 0d3FFB96C889463A4C, 0d4001135C51C7F716;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1678}, %fd768;
	}
	and.b32  	%r5674, %r1678, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5675, %temp}, %fd768;
	}
	mov.b64 	%fd3178, {%r5675, %r5674};
	setp.gt.u32 	%p2810, %r5674, 2146435071;
	or.pred  	%p2812, %p2810, %p2681;
	@%p2812 bra 	$L__BB0_1448;
	bra.uni 	$L__BB0_1432;

$L__BB0_1448:
	setp.le.f64 	%p2847, %fd3178, 0d7FF0000000000000;
	setp.le.f64 	%p2848, %fd3160, 0d7FF0000000000000;
	and.pred  	%p2849, %p2847, %p2848;
	@%p2849 bra 	$L__BB0_1450;
	bra.uni 	$L__BB0_1449;

$L__BB0_1450:
	setp.eq.f64 	%p2850, %fd3178, 0d7FF0000000000000;
	selp.f64 	%fd3181, 0dFFF8000000000000, %fd768, %p2850;
	bra.uni 	$L__BB0_1451;

$L__BB0_1432:
	setp.eq.f64 	%p2813, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3181, 0dFFF8000000000000;
	@%p2813 bra 	$L__BB0_1451;

	setp.ltu.f64 	%p2814, %fd3178, %fd3160;
	mov.f64 	%fd3181, %fd768;
	@%p2814 bra 	$L__BB0_1451;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5676}, %fd3178;
	}
	shr.u32 	%r6533, %r5676, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5677}, %fd3160;
	}
	shr.u32 	%r6534, %r5677, 20;
	setp.ne.s32 	%p2815, %r6533, 0;
	@%p2815 bra 	$L__BB0_1436;

	mul.f64 	%fd3178, %fd3178, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5678}, %fd3178;
	}
	shr.u32 	%r5679, %r5678, 20;
	add.s32 	%r6533, %r5679, -54;

$L__BB0_1436:
	setp.ne.s32 	%p2816, %r6534, 0;
	mov.f64 	%fd3179, %fd3160;
	@%p2816 bra 	$L__BB0_1438;

	mul.f64 	%fd3179, %fd3160, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5680}, %fd3179;
	}
	shr.u32 	%r5681, %r5680, 20;
	add.s32 	%r6534, %r5681, -54;

$L__BB0_1438:
	mov.b64 	%rd5877, %fd3178;
	and.b64  	%rd5878, %rd5877, 4503599627370495;
	or.b64  	%rd6652, %rd5878, 4503599627370496;
	mov.b64 	%rd5879, %fd3179;
	and.b64  	%rd5880, %rd5879, 4503599627370495;
	or.b64  	%rd1149, %rd5880, 4503599627370496;
	sub.s32 	%r6540, %r6533, %r6534;
	not.b32 	%r5682, %r6533;
	add.s32 	%r5683, %r6534, %r5682;
	max.s32 	%r5684, %r5683, -1;
	add.s32 	%r1686, %r5684, %r6533;
	mov.u32 	%r5685, 2;
	sub.s32 	%r5686, %r5685, %r6534;
	add.s32 	%r5687, %r5686, %r1686;
	and.b32  	%r6536, %r5687, 3;
	setp.eq.s32 	%p2817, %r6536, 0;
	@%p2817 bra 	$L__BB0_1440;

$L__BB0_1439:
	.pragma "nounroll";
	sub.s64 	%rd5881, %rd6652, %rd1149;
	mov.b64 	%fd2821, %rd5881;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5688}, %fd2821;
	}
	setp.lt.s32 	%p2818, %r5688, 0;
	selp.b64 	%rd6655, %rd6652, %rd5881, %p2818;
	shl.b64 	%rd6652, %rd6655, 1;
	add.s32 	%r6540, %r6540, -1;
	add.s32 	%r6536, %r6536, -1;
	setp.ne.s32 	%p2819, %r6536, 0;
	@%p2819 bra 	$L__BB0_1439;

$L__BB0_1440:
	mov.u32 	%r5689, 1;
	sub.s32 	%r5690, %r5689, %r6534;
	add.s32 	%r5691, %r5690, %r1686;
	setp.lt.u32 	%p2820, %r5691, 3;
	@%p2820 bra 	$L__BB0_1445;

	not.b32 	%r5692, %r6540;
	max.s32 	%r5693, %r5692, -4;
	add.s32 	%r5694, %r6540, %r5693;
	add.s32 	%r1693, %r5694, 4;
	shr.u32 	%r5695, %r1693, 2;
	add.s32 	%r5696, %r5695, 1;
	and.b32  	%r6539, %r5696, 3;
	setp.eq.s32 	%p2821, %r6539, 0;
	@%p2821 bra 	$L__BB0_1443;

$L__BB0_1442:
	.pragma "nounroll";
	sub.s64 	%rd5883, %rd6652, %rd1149;
	mov.b64 	%fd2822, %rd5883;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5697}, %fd2822;
	}
	setp.lt.s32 	%p2822, %r5697, 0;
	selp.b64 	%rd5884, %rd6652, %rd5883, %p2822;
	shl.b64 	%rd5885, %rd5884, 1;
	sub.s64 	%rd5886, %rd5885, %rd1149;
	mov.b64 	%fd2823, %rd5886;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5698}, %fd2823;
	}
	setp.lt.s32 	%p2823, %r5698, 0;
	selp.b64 	%rd5887, %rd5885, %rd5886, %p2823;
	shl.b64 	%rd5888, %rd5887, 1;
	sub.s64 	%rd5889, %rd5888, %rd1149;
	mov.b64 	%fd2824, %rd5889;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5699}, %fd2824;
	}
	setp.lt.s32 	%p2824, %r5699, 0;
	selp.b64 	%rd5890, %rd5888, %rd5889, %p2824;
	shl.b64 	%rd5891, %rd5890, 1;
	sub.s64 	%rd5892, %rd5891, %rd1149;
	mov.b64 	%fd2825, %rd5892;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5700}, %fd2825;
	}
	setp.lt.s32 	%p2825, %r5700, 0;
	selp.b64 	%rd6655, %rd5891, %rd5892, %p2825;
	shl.b64 	%rd6652, %rd6655, 1;
	add.s32 	%r6540, %r6540, -4;
	add.s32 	%r6539, %r6539, -1;
	setp.ne.s32 	%p2826, %r6539, 0;
	@%p2826 bra 	$L__BB0_1442;

$L__BB0_1443:
	setp.lt.u32 	%p2827, %r1693, 12;
	@%p2827 bra 	$L__BB0_1445;

$L__BB0_1444:
	sub.s64 	%rd5893, %rd6652, %rd1149;
	mov.b64 	%fd2826, %rd5893;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5701}, %fd2826;
	}
	setp.lt.s32 	%p2828, %r5701, 0;
	selp.b64 	%rd5894, %rd6652, %rd5893, %p2828;
	shl.b64 	%rd5895, %rd5894, 1;
	sub.s64 	%rd5896, %rd5895, %rd1149;
	mov.b64 	%fd2827, %rd5896;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5702}, %fd2827;
	}
	setp.lt.s32 	%p2829, %r5702, 0;
	selp.b64 	%rd5897, %rd5895, %rd5896, %p2829;
	shl.b64 	%rd5898, %rd5897, 1;
	sub.s64 	%rd5899, %rd5898, %rd1149;
	mov.b64 	%fd2828, %rd5899;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5703}, %fd2828;
	}
	setp.lt.s32 	%p2830, %r5703, 0;
	selp.b64 	%rd5900, %rd5898, %rd5899, %p2830;
	shl.b64 	%rd5901, %rd5900, 1;
	sub.s64 	%rd5902, %rd5901, %rd1149;
	mov.b64 	%fd2829, %rd5902;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5704}, %fd2829;
	}
	setp.lt.s32 	%p2831, %r5704, 0;
	selp.b64 	%rd5903, %rd5901, %rd5902, %p2831;
	shl.b64 	%rd5904, %rd5903, 1;
	sub.s64 	%rd5905, %rd5904, %rd1149;
	mov.b64 	%fd2830, %rd5905;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5705}, %fd2830;
	}
	setp.lt.s32 	%p2832, %r5705, 0;
	selp.b64 	%rd5906, %rd5904, %rd5905, %p2832;
	shl.b64 	%rd5907, %rd5906, 1;
	sub.s64 	%rd5908, %rd5907, %rd1149;
	mov.b64 	%fd2831, %rd5908;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5706}, %fd2831;
	}
	setp.lt.s32 	%p2833, %r5706, 0;
	selp.b64 	%rd5909, %rd5907, %rd5908, %p2833;
	shl.b64 	%rd5910, %rd5909, 1;
	sub.s64 	%rd5911, %rd5910, %rd1149;
	mov.b64 	%fd2832, %rd5911;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5707}, %fd2832;
	}
	setp.lt.s32 	%p2834, %r5707, 0;
	selp.b64 	%rd5912, %rd5910, %rd5911, %p2834;
	shl.b64 	%rd5913, %rd5912, 1;
	sub.s64 	%rd5914, %rd5913, %rd1149;
	mov.b64 	%fd2833, %rd5914;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5708}, %fd2833;
	}
	setp.lt.s32 	%p2835, %r5708, 0;
	selp.b64 	%rd5915, %rd5913, %rd5914, %p2835;
	shl.b64 	%rd5916, %rd5915, 1;
	sub.s64 	%rd5917, %rd5916, %rd1149;
	mov.b64 	%fd2834, %rd5917;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5709}, %fd2834;
	}
	setp.lt.s32 	%p2836, %r5709, 0;
	selp.b64 	%rd5918, %rd5916, %rd5917, %p2836;
	shl.b64 	%rd5919, %rd5918, 1;
	sub.s64 	%rd5920, %rd5919, %rd1149;
	mov.b64 	%fd2835, %rd5920;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5710}, %fd2835;
	}
	setp.lt.s32 	%p2837, %r5710, 0;
	selp.b64 	%rd5921, %rd5919, %rd5920, %p2837;
	shl.b64 	%rd5922, %rd5921, 1;
	sub.s64 	%rd5923, %rd5922, %rd1149;
	mov.b64 	%fd2836, %rd5923;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5711}, %fd2836;
	}
	setp.lt.s32 	%p2838, %r5711, 0;
	selp.b64 	%rd5924, %rd5922, %rd5923, %p2838;
	shl.b64 	%rd5925, %rd5924, 1;
	sub.s64 	%rd5926, %rd5925, %rd1149;
	mov.b64 	%fd2837, %rd5926;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5712}, %fd2837;
	}
	setp.lt.s32 	%p2839, %r5712, 0;
	selp.b64 	%rd5927, %rd5925, %rd5926, %p2839;
	shl.b64 	%rd5928, %rd5927, 1;
	sub.s64 	%rd5929, %rd5928, %rd1149;
	mov.b64 	%fd2838, %rd5929;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5713}, %fd2838;
	}
	setp.lt.s32 	%p2840, %r5713, 0;
	selp.b64 	%rd5930, %rd5928, %rd5929, %p2840;
	shl.b64 	%rd5931, %rd5930, 1;
	sub.s64 	%rd5932, %rd5931, %rd1149;
	mov.b64 	%fd2839, %rd5932;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5714}, %fd2839;
	}
	setp.lt.s32 	%p2841, %r5714, 0;
	selp.b64 	%rd5933, %rd5931, %rd5932, %p2841;
	shl.b64 	%rd5934, %rd5933, 1;
	sub.s64 	%rd5935, %rd5934, %rd1149;
	mov.b64 	%fd2840, %rd5935;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5715}, %fd2840;
	}
	setp.lt.s32 	%p2842, %r5715, 0;
	selp.b64 	%rd5936, %rd5934, %rd5935, %p2842;
	shl.b64 	%rd5937, %rd5936, 1;
	sub.s64 	%rd5938, %rd5937, %rd1149;
	mov.b64 	%fd2841, %rd5938;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5716}, %fd2841;
	}
	setp.lt.s32 	%p2843, %r5716, 0;
	selp.b64 	%rd6655, %rd5937, %rd5938, %p2843;
	shl.b64 	%rd6652, %rd6655, 1;
	add.s32 	%r1701, %r6540, -16;
	setp.gt.s32 	%p2844, %r6540, 15;
	mov.u32 	%r6540, %r1701;
	@%p2844 bra 	$L__BB0_1444;

$L__BB0_1445:
	and.b64  	%rd1164, %rd6655, 9223372036854775807;
	setp.eq.s64 	%p2845, %rd1164, 0;
	mov.f64 	%fd3180, 0d0000000000000000;
	@%p2845 bra 	$L__BB0_1447;

	mov.b64 	%fd2843, %rd1164;
	mul.f64 	%fd2844, %fd2843, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5717}, %fd2844;
	}
	shr.u32 	%r5718, %r5717, 20;
	mov.u32 	%r5719, 55;
	sub.s32 	%r5720, %r5719, %r5718;
	sub.s32 	%r5721, %r6534, %r5720;
	shl.b64 	%rd5939, %rd1164, %r5720;
	setp.lt.s32 	%p2846, %r5721, 1;
	mov.u32 	%r5722, 1;
	sub.s32 	%r5723, %r5722, %r5721;
	shr.u64 	%rd5940, %rd5939, %r5723;
	add.s32 	%r5724, %r5721, -1;
	cvt.u64.u32 	%rd5941, %r5724;
	shl.b64 	%rd5942, %rd5941, 52;
	add.s64 	%rd5943, %rd5942, %rd5939;
	selp.b64 	%rd5944, %rd5940, %rd5943, %p2846;
	mov.b64 	%fd3180, %rd5944;

$L__BB0_1447:
	and.b32  	%r5725, %r1678, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5726}, %fd3180;
	}
	or.b32  	%r5727, %r5726, %r5725;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5728, %temp}, %fd3180;
	}
	mov.b64 	%fd3181, {%r5728, %r5727};
	bra.uni 	$L__BB0_1451;

$L__BB0_1449:
	mov.f64 	%fd2845, 0d3FF0000000000000;
	add.rn.f64 	%fd3181, %fd768, %fd2845;

$L__BB0_1451:
	.loc	1 146 5, function_name $L__info_string7, inlined_at 1 282 13
	abs.f64 	%fd2846, %fd3181;
	.loc	1 149 5, function_name $L__info_string7, inlined_at 1 282 13
	mul.f64 	%fd780, %fd2846, 0d3FE0000000000000;
	.loc	1 283 13
	.loc	1 145 5, function_name $L__info_string7, inlined_at 1 283 13
	fma.rn.f64 	%fd781, %fd3110, 0d3FFB96C889463A4C, 0d4001135C51C7F716;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1702}, %fd781;
	}
	and.b32  	%r5729, %r1702, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5730, %temp}, %fd781;
	}
	mov.b64 	%fd3182, {%r5730, %r5729};
	setp.gt.u32 	%p2851, %r5729, 2146435071;
	or.pred  	%p2853, %p2851, %p2681;
	@%p2853 bra 	$L__BB0_1468;
	bra.uni 	$L__BB0_1452;

$L__BB0_1468:
	setp.le.f64 	%p2888, %fd3182, 0d7FF0000000000000;
	setp.le.f64 	%p2889, %fd3160, 0d7FF0000000000000;
	and.pred  	%p2890, %p2888, %p2889;
	@%p2890 bra 	$L__BB0_1470;
	bra.uni 	$L__BB0_1469;

$L__BB0_1470:
	setp.eq.f64 	%p2891, %fd3182, 0d7FF0000000000000;
	selp.f64 	%fd3185, 0dFFF8000000000000, %fd781, %p2891;
	bra.uni 	$L__BB0_1471;

$L__BB0_1452:
	setp.eq.f64 	%p2854, %fd3160, 0d0000000000000000;
	mov.f64 	%fd3185, 0dFFF8000000000000;
	@%p2854 bra 	$L__BB0_1471;

	setp.ltu.f64 	%p2855, %fd3182, %fd3160;
	mov.f64 	%fd3185, %fd781;
	@%p2855 bra 	$L__BB0_1471;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5731}, %fd3182;
	}
	shr.u32 	%r6542, %r5731, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5732}, %fd3160;
	}
	shr.u32 	%r6543, %r5732, 20;
	setp.ne.s32 	%p2856, %r6542, 0;
	@%p2856 bra 	$L__BB0_1456;

	mul.f64 	%fd3182, %fd3182, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5733}, %fd3182;
	}
	shr.u32 	%r5734, %r5733, 20;
	add.s32 	%r6542, %r5734, -54;

$L__BB0_1456:
	setp.ne.s32 	%p2857, %r6543, 0;
	@%p2857 bra 	$L__BB0_1458;

	mul.f64 	%fd3160, %fd3160, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5735}, %fd3160;
	}
	shr.u32 	%r5736, %r5735, 20;
	add.s32 	%r6543, %r5736, -54;

$L__BB0_1458:
	mov.b64 	%rd5946, %fd3182;
	and.b64  	%rd5947, %rd5946, 4503599627370495;
	or.b64  	%rd6660, %rd5947, 4503599627370496;
	mov.b64 	%rd5948, %fd3160;
	and.b64  	%rd5949, %rd5948, 4503599627370495;
	or.b64  	%rd1166, %rd5949, 4503599627370496;
	sub.s32 	%r6549, %r6542, %r6543;
	not.b32 	%r5737, %r6542;
	add.s32 	%r5738, %r6543, %r5737;
	max.s32 	%r5739, %r5738, -1;
	add.s32 	%r1710, %r5739, %r6542;
	mov.u32 	%r5740, 2;
	sub.s32 	%r5741, %r5740, %r6543;
	add.s32 	%r5742, %r5741, %r1710;
	and.b32  	%r6545, %r5742, 3;
	setp.eq.s32 	%p2858, %r6545, 0;
	@%p2858 bra 	$L__BB0_1460;

$L__BB0_1459:
	.pragma "nounroll";
	sub.s64 	%rd5950, %rd6660, %rd1166;
	mov.b64 	%fd2848, %rd5950;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5743}, %fd2848;
	}
	setp.lt.s32 	%p2859, %r5743, 0;
	selp.b64 	%rd6663, %rd6660, %rd5950, %p2859;
	shl.b64 	%rd6660, %rd6663, 1;
	add.s32 	%r6549, %r6549, -1;
	add.s32 	%r6545, %r6545, -1;
	setp.ne.s32 	%p2860, %r6545, 0;
	@%p2860 bra 	$L__BB0_1459;

$L__BB0_1460:
	mov.u32 	%r5744, 1;
	sub.s32 	%r5745, %r5744, %r6543;
	add.s32 	%r5746, %r5745, %r1710;
	setp.lt.u32 	%p2861, %r5746, 3;
	@%p2861 bra 	$L__BB0_1465;

	not.b32 	%r5747, %r6549;
	max.s32 	%r5748, %r5747, -4;
	add.s32 	%r5749, %r6549, %r5748;
	add.s32 	%r1717, %r5749, 4;
	shr.u32 	%r5750, %r1717, 2;
	add.s32 	%r5751, %r5750, 1;
	and.b32  	%r6548, %r5751, 3;
	setp.eq.s32 	%p2862, %r6548, 0;
	@%p2862 bra 	$L__BB0_1463;

$L__BB0_1462:
	.pragma "nounroll";
	sub.s64 	%rd5952, %rd6660, %rd1166;
	mov.b64 	%fd2849, %rd5952;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5752}, %fd2849;
	}
	setp.lt.s32 	%p2863, %r5752, 0;
	selp.b64 	%rd5953, %rd6660, %rd5952, %p2863;
	shl.b64 	%rd5954, %rd5953, 1;
	sub.s64 	%rd5955, %rd5954, %rd1166;
	mov.b64 	%fd2850, %rd5955;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5753}, %fd2850;
	}
	setp.lt.s32 	%p2864, %r5753, 0;
	selp.b64 	%rd5956, %rd5954, %rd5955, %p2864;
	shl.b64 	%rd5957, %rd5956, 1;
	sub.s64 	%rd5958, %rd5957, %rd1166;
	mov.b64 	%fd2851, %rd5958;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5754}, %fd2851;
	}
	setp.lt.s32 	%p2865, %r5754, 0;
	selp.b64 	%rd5959, %rd5957, %rd5958, %p2865;
	shl.b64 	%rd5960, %rd5959, 1;
	sub.s64 	%rd5961, %rd5960, %rd1166;
	mov.b64 	%fd2852, %rd5961;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5755}, %fd2852;
	}
	setp.lt.s32 	%p2866, %r5755, 0;
	selp.b64 	%rd6663, %rd5960, %rd5961, %p2866;
	shl.b64 	%rd6660, %rd6663, 1;
	add.s32 	%r6549, %r6549, -4;
	add.s32 	%r6548, %r6548, -1;
	setp.ne.s32 	%p2867, %r6548, 0;
	@%p2867 bra 	$L__BB0_1462;

$L__BB0_1463:
	setp.lt.u32 	%p2868, %r1717, 12;
	@%p2868 bra 	$L__BB0_1465;

$L__BB0_1464:
	sub.s64 	%rd5962, %rd6660, %rd1166;
	mov.b64 	%fd2853, %rd5962;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5756}, %fd2853;
	}
	setp.lt.s32 	%p2869, %r5756, 0;
	selp.b64 	%rd5963, %rd6660, %rd5962, %p2869;
	shl.b64 	%rd5964, %rd5963, 1;
	sub.s64 	%rd5965, %rd5964, %rd1166;
	mov.b64 	%fd2854, %rd5965;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5757}, %fd2854;
	}
	setp.lt.s32 	%p2870, %r5757, 0;
	selp.b64 	%rd5966, %rd5964, %rd5965, %p2870;
	shl.b64 	%rd5967, %rd5966, 1;
	sub.s64 	%rd5968, %rd5967, %rd1166;
	mov.b64 	%fd2855, %rd5968;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5758}, %fd2855;
	}
	setp.lt.s32 	%p2871, %r5758, 0;
	selp.b64 	%rd5969, %rd5967, %rd5968, %p2871;
	shl.b64 	%rd5970, %rd5969, 1;
	sub.s64 	%rd5971, %rd5970, %rd1166;
	mov.b64 	%fd2856, %rd5971;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5759}, %fd2856;
	}
	setp.lt.s32 	%p2872, %r5759, 0;
	selp.b64 	%rd5972, %rd5970, %rd5971, %p2872;
	shl.b64 	%rd5973, %rd5972, 1;
	sub.s64 	%rd5974, %rd5973, %rd1166;
	mov.b64 	%fd2857, %rd5974;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5760}, %fd2857;
	}
	setp.lt.s32 	%p2873, %r5760, 0;
	selp.b64 	%rd5975, %rd5973, %rd5974, %p2873;
	shl.b64 	%rd5976, %rd5975, 1;
	sub.s64 	%rd5977, %rd5976, %rd1166;
	mov.b64 	%fd2858, %rd5977;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5761}, %fd2858;
	}
	setp.lt.s32 	%p2874, %r5761, 0;
	selp.b64 	%rd5978, %rd5976, %rd5977, %p2874;
	shl.b64 	%rd5979, %rd5978, 1;
	sub.s64 	%rd5980, %rd5979, %rd1166;
	mov.b64 	%fd2859, %rd5980;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5762}, %fd2859;
	}
	setp.lt.s32 	%p2875, %r5762, 0;
	selp.b64 	%rd5981, %rd5979, %rd5980, %p2875;
	shl.b64 	%rd5982, %rd5981, 1;
	sub.s64 	%rd5983, %rd5982, %rd1166;
	mov.b64 	%fd2860, %rd5983;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5763}, %fd2860;
	}
	setp.lt.s32 	%p2876, %r5763, 0;
	selp.b64 	%rd5984, %rd5982, %rd5983, %p2876;
	shl.b64 	%rd5985, %rd5984, 1;
	sub.s64 	%rd5986, %rd5985, %rd1166;
	mov.b64 	%fd2861, %rd5986;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5764}, %fd2861;
	}
	setp.lt.s32 	%p2877, %r5764, 0;
	selp.b64 	%rd5987, %rd5985, %rd5986, %p2877;
	shl.b64 	%rd5988, %rd5987, 1;
	sub.s64 	%rd5989, %rd5988, %rd1166;
	mov.b64 	%fd2862, %rd5989;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5765}, %fd2862;
	}
	setp.lt.s32 	%p2878, %r5765, 0;
	selp.b64 	%rd5990, %rd5988, %rd5989, %p2878;
	shl.b64 	%rd5991, %rd5990, 1;
	sub.s64 	%rd5992, %rd5991, %rd1166;
	mov.b64 	%fd2863, %rd5992;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5766}, %fd2863;
	}
	setp.lt.s32 	%p2879, %r5766, 0;
	selp.b64 	%rd5993, %rd5991, %rd5992, %p2879;
	shl.b64 	%rd5994, %rd5993, 1;
	sub.s64 	%rd5995, %rd5994, %rd1166;
	mov.b64 	%fd2864, %rd5995;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5767}, %fd2864;
	}
	setp.lt.s32 	%p2880, %r5767, 0;
	selp.b64 	%rd5996, %rd5994, %rd5995, %p2880;
	shl.b64 	%rd5997, %rd5996, 1;
	sub.s64 	%rd5998, %rd5997, %rd1166;
	mov.b64 	%fd2865, %rd5998;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5768}, %fd2865;
	}
	setp.lt.s32 	%p2881, %r5768, 0;
	selp.b64 	%rd5999, %rd5997, %rd5998, %p2881;
	shl.b64 	%rd6000, %rd5999, 1;
	sub.s64 	%rd6001, %rd6000, %rd1166;
	mov.b64 	%fd2866, %rd6001;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5769}, %fd2866;
	}
	setp.lt.s32 	%p2882, %r5769, 0;
	selp.b64 	%rd6002, %rd6000, %rd6001, %p2882;
	shl.b64 	%rd6003, %rd6002, 1;
	sub.s64 	%rd6004, %rd6003, %rd1166;
	mov.b64 	%fd2867, %rd6004;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5770}, %fd2867;
	}
	setp.lt.s32 	%p2883, %r5770, 0;
	selp.b64 	%rd6005, %rd6003, %rd6004, %p2883;
	shl.b64 	%rd6006, %rd6005, 1;
	sub.s64 	%rd6007, %rd6006, %rd1166;
	mov.b64 	%fd2868, %rd6007;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5771}, %fd2868;
	}
	setp.lt.s32 	%p2884, %r5771, 0;
	selp.b64 	%rd6663, %rd6006, %rd6007, %p2884;
	shl.b64 	%rd6660, %rd6663, 1;
	add.s32 	%r1725, %r6549, -16;
	setp.gt.s32 	%p2885, %r6549, 15;
	mov.u32 	%r6549, %r1725;
	@%p2885 bra 	$L__BB0_1464;

$L__BB0_1465:
	and.b64  	%rd1181, %rd6663, 9223372036854775807;
	setp.eq.s64 	%p2886, %rd1181, 0;
	mov.f64 	%fd3184, 0d0000000000000000;
	@%p2886 bra 	$L__BB0_1467;

	mov.b64 	%fd2870, %rd1181;
	mul.f64 	%fd2871, %fd2870, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5772}, %fd2871;
	}
	shr.u32 	%r5773, %r5772, 20;
	mov.u32 	%r5774, 55;
	sub.s32 	%r5775, %r5774, %r5773;
	sub.s32 	%r5776, %r6543, %r5775;
	shl.b64 	%rd6008, %rd1181, %r5775;
	setp.lt.s32 	%p2887, %r5776, 1;
	mov.u32 	%r5777, 1;
	sub.s32 	%r5778, %r5777, %r5776;
	shr.u64 	%rd6009, %rd6008, %r5778;
	add.s32 	%r5779, %r5776, -1;
	cvt.u64.u32 	%rd6010, %r5779;
	shl.b64 	%rd6011, %rd6010, 52;
	add.s64 	%rd6012, %rd6011, %rd6008;
	selp.b64 	%rd6013, %rd6009, %rd6012, %p2887;
	mov.b64 	%fd3184, %rd6013;

$L__BB0_1467:
	and.b32  	%r5780, %r1702, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5781}, %fd3184;
	}
	or.b32  	%r5782, %r5781, %r5780;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5783, %temp}, %fd3184;
	}
	mov.b64 	%fd3185, {%r5783, %r5782};
	bra.uni 	$L__BB0_1471;

$L__BB0_1469:
	mov.f64 	%fd2872, 0d3FF0000000000000;
	add.rn.f64 	%fd3185, %fd781, %fd2872;

$L__BB0_1471:
	.loc	1 146 5, function_name $L__info_string7, inlined_at 1 283 13
	abs.f64 	%fd2873, %fd3185;
	.loc	1 149 5, function_name $L__info_string7, inlined_at 1 283 13
	mul.f64 	%fd793, %fd2873, 0d3FE0000000000000;
	.loc	1 287 13
	@%p17 bra 	$L__BB0_1508;

	.loc	1 290 17
	ld.global.u8 	%rd6014, [%rd1206+100];
	ld.global.u8 	%rd6015, [%rd1206+101];
	bfi.b64 	%rd6016, %rd6015, %rd6014, 8, 8;
	ld.global.u8 	%rd6017, [%rd1206+102];
	ld.global.u8 	%rd6018, [%rd1206+103];
	bfi.b64 	%rd6019, %rd6018, %rd6017, 8, 8;
	bfi.b64 	%rd6020, %rd6019, %rd6016, 16, 16;
	add.s64 	%rd1183, %rd9, %rd6020;
	.loc	1 292 17
	ld.global.u8 	%r5784, [%rd1206+36];
	ld.global.u8 	%r5785, [%rd1206+37];
	prmt.b32 	%r5786, %r5785, %r5784, 30212;
	ld.global.u8 	%r5787, [%rd1206+38];
	ld.global.u8 	%r5788, [%rd1206+39];
	prmt.b32 	%r5789, %r5788, %r5787, 30212;
	prmt.b32 	%r5790, %r5789, %r5786, 4180;
	setp.eq.s32 	%p2893, %r5790, 0;
	@%p2893 bra 	$L__BB0_1480;

	.loc	1 293 37
	ld.global.u8 	%rd6021, [%rd1206+28];
	ld.global.u8 	%rd6022, [%rd1206+29];
	bfi.b64 	%rd6023, %rd6022, %rd6021, 8, 8;
	ld.global.u8 	%rd6024, [%rd1206+30];
	ld.global.u8 	%rd6025, [%rd1206+31];
	bfi.b64 	%rd6026, %rd6025, %rd6024, 8, 8;
	bfi.b64 	%rd1184, %rd6026, %rd6023, 16, 16;
	ld.global.u8 	%r5792, [%rd1206+32];
	ld.global.u8 	%r5793, [%rd1206+33];
	prmt.b32 	%r5794, %r5793, %r5792, 30212;
	ld.global.u8 	%r5795, [%rd1206+34];
	ld.global.u8 	%r5796, [%rd1206+35];
	prmt.b32 	%r5797, %r5796, %r5795, 30212;
	prmt.b32 	%r1726, %r5797, %r5794, 4180;
	.loc	1 293 37
	.loc	1 161 5, function_name $L__info_string8, inlined_at 1 293 37
	setp.eq.s32 	%p2894, %r1726, 0;
	mov.u32 	%r6557, 0;
	@%p2894 bra 	$L__BB0_1481;

	.loc	1 163 5, function_name $L__info_string8, inlined_at 1 293 37
	add.s32 	%r6557, %r1726, -1;
	cvt.u64.u32 	%rd6027, %r6557;
	add.s64 	%rd6028, %rd6027, %rd1184;
	shl.b64 	%rd6029, %rd6028, 3;
	add.s64 	%rd6030, %rd1183, %rd6029;
	ld.global.u64 	%rd6031, [%rd6030];
	.loc	1 164 5, function_name $L__info_string8, inlined_at 1 293 37
	cvt.rn.f64.u64 	%fd2874, %rd6031;
	mul.f64 	%fd794, %fd754, %fd2874;
	mov.u32 	%r6553, 0;
	mov.u32 	%r6552, %r6557;

$L__BB0_1475:
	.loc	1 168 9, function_name $L__info_string8, inlined_at 1 293 37
	add.s32 	%r5799, %r6552, %r6553;
	shr.u32 	%r1731, %r5799, 1;
	.loc	1 169 9, function_name $L__info_string8, inlined_at 1 293 37
	cvt.u64.u32 	%rd6032, %r1731;
	add.s64 	%rd6033, %rd6032, %rd1184;
	shl.b64 	%rd6034, %rd6033, 3;
	add.s64 	%rd6035, %rd1183, %rd6034;
	ld.global.u64 	%rd6036, [%rd6035];
	cvt.rn.f64.u64 	%fd2875, %rd6036;
	setp.lt.f64 	%p2895, %fd794, %fd2875;
	@%p2895 bra 	$L__BB0_1477;
	bra.uni 	$L__BB0_1476;

$L__BB0_1477:
	.loc	1 171 13, function_name $L__info_string8, inlined_at 1 293 37
	setp.eq.s32 	%p2896, %r1731, 0;
	mov.u32 	%r6557, 0;
	@%p2896 bra 	$L__BB0_1481;

	.loc	1 172 13, function_name $L__info_string8, inlined_at 1 293 37
	add.s32 	%r6552, %r1731, -1;
	mov.u32 	%r6557, %r1731;
	bra.uni 	$L__BB0_1479;

$L__BB0_1476:
	.loc	1 174 13, function_name $L__info_string8, inlined_at 1 293 37
	add.s32 	%r6553, %r1731, 1;

$L__BB0_1479:
	.loc	1 167 5, function_name $L__info_string8, inlined_at 1 293 37
	setp.gt.u32 	%p2897, %r6553, %r6552;
	@%p2897 bra 	$L__BB0_1481;
	bra.uni 	$L__BB0_1475;

$L__BB0_1508:
	.loc	1 309 17
	.loc	1 154 5, function_name $L__info_string9, inlined_at 1 309 17
	mul.f64 	%fd2890, %fd754, 0d402E000000000000;
	cvt.rzi.u64.f64 	%rd6101, %fd2890;
	.loc	1 155 5, function_name $L__info_string9, inlined_at 1 309 17
	min.u64 	%rd6102, %rd6101, 14;
	.loc	1 156 5, function_name $L__info_string9, inlined_at 1 309 17
	cvt.u32.u64 	%r6557, %rd6102;
	.loc	1 310 17
	.loc	1 154 5, function_name $L__info_string9, inlined_at 1 310 17
	mul.f64 	%fd2891, %fd767, 0d402E000000000000;
	cvt.rzi.u64.f64 	%rd6103, %fd2891;
	.loc	1 155 5, function_name $L__info_string9, inlined_at 1 310 17
	min.u64 	%rd6104, %rd6103, 14;
	.loc	1 156 5, function_name $L__info_string9, inlined_at 1 310 17
	cvt.u32.u64 	%r6564, %rd6104;
	.loc	1 311 17
	.loc	1 154 5, function_name $L__info_string9, inlined_at 1 311 17
	mul.f64 	%fd2892, %fd780, 0d403E000000000000;
	cvt.rzi.u64.f64 	%rd6105, %fd2892;
	.loc	1 155 5, function_name $L__info_string9, inlined_at 1 311 17
	min.u64 	%rd6106, %rd6105, 29;
	.loc	1 156 5, function_name $L__info_string9, inlined_at 1 311 17
	cvt.u32.u64 	%r6571, %rd6106;
	.loc	1 312 17
	.loc	1 154 5, function_name $L__info_string9, inlined_at 1 312 17
	mul.f64 	%fd2893, %fd793, 0d403E000000000000;
	cvt.rzi.u64.f64 	%rd6107, %fd2893;
	.loc	1 155 5, function_name $L__info_string9, inlined_at 1 312 17
	min.u64 	%rd6108, %rd6107, 29;
	.loc	1 156 5, function_name $L__info_string9, inlined_at 1 312 17
	cvt.u32.u64 	%r6581, %rd6108;
	bra.uni 	$L__BB0_1509;

$L__BB0_1480:
	.loc	1 294 36
	ld.global.u8 	%r5801, [%rd1206+32];
	ld.global.u8 	%r5802, [%rd1206+33];
	prmt.b32 	%r5803, %r5802, %r5801, 30212;
	ld.global.u8 	%r5804, [%rd1206+34];
	ld.global.u8 	%r5805, [%rd1206+35];
	prmt.b32 	%r5806, %r5805, %r5804, 30212;
	prmt.b32 	%r5807, %r5806, %r5803, 4180;
	.loc	1 294 36
	.loc	1 154 5, function_name $L__info_string9, inlined_at 1 294 36
	cvt.rn.f64.u32 	%fd2876, %r5807;
	mul.f64 	%fd2877, %fd754, %fd2876;
	cvt.rzi.u64.f64 	%rd6037, %fd2877;
	.loc	1 155 5, function_name $L__info_string9, inlined_at 1 294 36
	cvt.u64.u32 	%rd6038, %r5807;
	setp.lt.u64 	%p2898, %rd6037, %rd6038;
	add.s32 	%r5808, %r5807, -1;
	cvt.u64.u32 	%rd6039, %r5808;
	selp.b64 	%rd6040, %rd6037, %rd6039, %p2898;
	.loc	1 156 5, function_name $L__info_string9, inlined_at 1 294 36
	cvt.u32.u64 	%r6557, %rd6040;

$L__BB0_1481:
	.loc	1 296 17
	ld.global.u8 	%r5809, [%rd1206+56];
	ld.global.u8 	%r5810, [%rd1206+57];
	prmt.b32 	%r5811, %r5810, %r5809, 30212;
	ld.global.u8 	%r5812, [%rd1206+58];
	ld.global.u8 	%r5813, [%rd1206+59];
	prmt.b32 	%r5814, %r5813, %r5812, 30212;
	prmt.b32 	%r5815, %r5814, %r5811, 4180;
	setp.eq.s32 	%p2899, %r5815, 0;
	@%p2899 bra 	$L__BB0_1489;

	.loc	1 297 37
	ld.global.u8 	%rd6041, [%rd1206+48];
	ld.global.u8 	%rd6042, [%rd1206+49];
	bfi.b64 	%rd6043, %rd6042, %rd6041, 8, 8;
	ld.global.u8 	%rd6044, [%rd1206+50];
	ld.global.u8 	%rd6045, [%rd1206+51];
	bfi.b64 	%rd6046, %rd6045, %rd6044, 8, 8;
	bfi.b64 	%rd1185, %rd6046, %rd6043, 16, 16;
	ld.global.u8 	%r5817, [%rd1206+52];
	ld.global.u8 	%r5818, [%rd1206+53];
	prmt.b32 	%r5819, %r5818, %r5817, 30212;
	ld.global.u8 	%r5820, [%rd1206+54];
	ld.global.u8 	%r5821, [%rd1206+55];
	prmt.b32 	%r5822, %r5821, %r5820, 30212;
	prmt.b32 	%r1739, %r5822, %r5819, 4180;
	.loc	1 297 37
	.loc	1 161 5, function_name $L__info_string8, inlined_at 1 297 37
	setp.eq.s32 	%p2900, %r1739, 0;
	mov.u32 	%r6564, 0;
	@%p2900 bra 	$L__BB0_1490;

	.loc	1 163 5, function_name $L__info_string8, inlined_at 1 297 37
	add.s32 	%r6564, %r1739, -1;
	cvt.u64.u32 	%rd6047, %r6564;
	add.s64 	%rd6048, %rd6047, %rd1185;
	shl.b64 	%rd6049, %rd6048, 3;
	add.s64 	%rd6050, %rd1183, %rd6049;
	ld.global.u64 	%rd6051, [%rd6050];
	.loc	1 164 5, function_name $L__info_string8, inlined_at 1 297 37
	cvt.rn.f64.u64 	%fd2878, %rd6051;
	mul.f64 	%fd795, %fd767, %fd2878;
	mov.u32 	%r6560, 0;
	mov.u32 	%r6559, %r6564;

$L__BB0_1484:
	.loc	1 168 9, function_name $L__info_string8, inlined_at 1 297 37
	add.s32 	%r5824, %r6559, %r6560;
	shr.u32 	%r1744, %r5824, 1;
	.loc	1 169 9, function_name $L__info_string8, inlined_at 1 297 37
	cvt.u64.u32 	%rd6052, %r1744;
	add.s64 	%rd6053, %rd6052, %rd1185;
	shl.b64 	%rd6054, %rd6053, 3;
	add.s64 	%rd6055, %rd1183, %rd6054;
	ld.global.u64 	%rd6056, [%rd6055];
	cvt.rn.f64.u64 	%fd2879, %rd6056;
	setp.lt.f64 	%p2901, %fd795, %fd2879;
	@%p2901 bra 	$L__BB0_1486;
	bra.uni 	$L__BB0_1485;

$L__BB0_1486:
	.loc	1 171 13, function_name $L__info_string8, inlined_at 1 297 37
	setp.eq.s32 	%p2902, %r1744, 0;
	mov.u32 	%r6564, 0;
	@%p2902 bra 	$L__BB0_1490;

	.loc	1 172 13, function_name $L__info_string8, inlined_at 1 297 37
	add.s32 	%r6559, %r1744, -1;
	mov.u32 	%r6564, %r1744;
	bra.uni 	$L__BB0_1488;

$L__BB0_1485:
	.loc	1 174 13, function_name $L__info_string8, inlined_at 1 297 37
	add.s32 	%r6560, %r1744, 1;

$L__BB0_1488:
	.loc	1 167 5, function_name $L__info_string8, inlined_at 1 297 37
	setp.gt.u32 	%p2903, %r6560, %r6559;
	@%p2903 bra 	$L__BB0_1490;
	bra.uni 	$L__BB0_1484;

$L__BB0_1489:
	.loc	1 298 36
	ld.global.u8 	%r5826, [%rd1206+52];
	ld.global.u8 	%r5827, [%rd1206+53];
	prmt.b32 	%r5828, %r5827, %r5826, 30212;
	ld.global.u8 	%r5829, [%rd1206+54];
	ld.global.u8 	%r5830, [%rd1206+55];
	prmt.b32 	%r5831, %r5830, %r5829, 30212;
	prmt.b32 	%r5832, %r5831, %r5828, 4180;
	.loc	1 298 36
	.loc	1 154 5, function_name $L__info_string9, inlined_at 1 298 36
	cvt.rn.f64.u32 	%fd2880, %r5832;
	mul.f64 	%fd2881, %fd767, %fd2880;
	cvt.rzi.u64.f64 	%rd6057, %fd2881;
	.loc	1 155 5, function_name $L__info_string9, inlined_at 1 298 36
	cvt.u64.u32 	%rd6058, %r5832;
	setp.lt.u64 	%p2904, %rd6057, %rd6058;
	add.s32 	%r5833, %r5832, -1;
	cvt.u64.u32 	%rd6059, %r5833;
	selp.b64 	%rd6060, %rd6057, %rd6059, %p2904;
	.loc	1 156 5, function_name $L__info_string9, inlined_at 1 298 36
	cvt.u32.u64 	%r6564, %rd6060;

$L__BB0_1490:
	.loc	1 300 17
	ld.global.u8 	%r5834, [%rd1206+76];
	ld.global.u8 	%r5835, [%rd1206+77];
	prmt.b32 	%r5836, %r5835, %r5834, 30212;
	ld.global.u8 	%r5837, [%rd1206+78];
	ld.global.u8 	%r5838, [%rd1206+79];
	prmt.b32 	%r5839, %r5838, %r5837, 30212;
	prmt.b32 	%r5840, %r5839, %r5836, 4180;
	setp.eq.s32 	%p2905, %r5840, 0;
	@%p2905 bra 	$L__BB0_1498;

	.loc	1 301 37
	ld.global.u8 	%rd6061, [%rd1206+68];
	ld.global.u8 	%rd6062, [%rd1206+69];
	bfi.b64 	%rd6063, %rd6062, %rd6061, 8, 8;
	ld.global.u8 	%rd6064, [%rd1206+70];
	ld.global.u8 	%rd6065, [%rd1206+71];
	bfi.b64 	%rd6066, %rd6065, %rd6064, 8, 8;
	bfi.b64 	%rd1186, %rd6066, %rd6063, 16, 16;
	ld.global.u8 	%r5842, [%rd1206+72];
	ld.global.u8 	%r5843, [%rd1206+73];
	prmt.b32 	%r5844, %r5843, %r5842, 30212;
	ld.global.u8 	%r5845, [%rd1206+74];
	ld.global.u8 	%r5846, [%rd1206+75];
	prmt.b32 	%r5847, %r5846, %r5845, 30212;
	prmt.b32 	%r1752, %r5847, %r5844, 4180;
	.loc	1 301 37
	.loc	1 161 5, function_name $L__info_string8, inlined_at 1 301 37
	setp.eq.s32 	%p2906, %r1752, 0;
	mov.u32 	%r6571, 0;
	@%p2906 bra 	$L__BB0_1499;

	.loc	1 163 5, function_name $L__info_string8, inlined_at 1 301 37
	add.s32 	%r6571, %r1752, -1;
	cvt.u64.u32 	%rd6067, %r6571;
	add.s64 	%rd6068, %rd6067, %rd1186;
	shl.b64 	%rd6069, %rd6068, 3;
	add.s64 	%rd6070, %rd1183, %rd6069;
	ld.global.u64 	%rd6071, [%rd6070];
	.loc	1 164 5, function_name $L__info_string8, inlined_at 1 301 37
	cvt.rn.f64.u64 	%fd2882, %rd6071;
	mul.f64 	%fd796, %fd780, %fd2882;
	mov.u32 	%r6567, 0;
	mov.u32 	%r6566, %r6571;

$L__BB0_1493:
	.loc	1 168 9, function_name $L__info_string8, inlined_at 1 301 37
	add.s32 	%r5849, %r6566, %r6567;
	shr.u32 	%r1757, %r5849, 1;
	.loc	1 169 9, function_name $L__info_string8, inlined_at 1 301 37
	cvt.u64.u32 	%rd6072, %r1757;
	add.s64 	%rd6073, %rd6072, %rd1186;
	shl.b64 	%rd6074, %rd6073, 3;
	add.s64 	%rd6075, %rd1183, %rd6074;
	ld.global.u64 	%rd6076, [%rd6075];
	cvt.rn.f64.u64 	%fd2883, %rd6076;
	setp.lt.f64 	%p2907, %fd796, %fd2883;
	@%p2907 bra 	$L__BB0_1495;
	bra.uni 	$L__BB0_1494;

$L__BB0_1495:
	.loc	1 171 13, function_name $L__info_string8, inlined_at 1 301 37
	setp.eq.s32 	%p2908, %r1757, 0;
	mov.u32 	%r6571, 0;
	@%p2908 bra 	$L__BB0_1499;

	.loc	1 172 13, function_name $L__info_string8, inlined_at 1 301 37
	add.s32 	%r6566, %r1757, -1;
	mov.u32 	%r6571, %r1757;
	bra.uni 	$L__BB0_1497;

$L__BB0_1494:
	.loc	1 174 13, function_name $L__info_string8, inlined_at 1 301 37
	add.s32 	%r6567, %r1757, 1;

$L__BB0_1497:
	.loc	1 167 5, function_name $L__info_string8, inlined_at 1 301 37
	setp.gt.u32 	%p2909, %r6567, %r6566;
	@%p2909 bra 	$L__BB0_1499;
	bra.uni 	$L__BB0_1493;

$L__BB0_1498:
	.loc	1 302 36
	ld.global.u8 	%r5851, [%rd1206+72];
	ld.global.u8 	%r5852, [%rd1206+73];
	prmt.b32 	%r5853, %r5852, %r5851, 30212;
	ld.global.u8 	%r5854, [%rd1206+74];
	ld.global.u8 	%r5855, [%rd1206+75];
	prmt.b32 	%r5856, %r5855, %r5854, 30212;
	prmt.b32 	%r5857, %r5856, %r5853, 4180;
	.loc	1 302 36
	.loc	1 154 5, function_name $L__info_string9, inlined_at 1 302 36
	cvt.rn.f64.u32 	%fd2884, %r5857;
	mul.f64 	%fd2885, %fd780, %fd2884;
	cvt.rzi.u64.f64 	%rd6077, %fd2885;
	.loc	1 155 5, function_name $L__info_string9, inlined_at 1 302 36
	cvt.u64.u32 	%rd6078, %r5857;
	setp.lt.u64 	%p2910, %rd6077, %rd6078;
	add.s32 	%r5858, %r5857, -1;
	cvt.u64.u32 	%rd6079, %r5858;
	selp.b64 	%rd6080, %rd6077, %rd6079, %p2910;
	.loc	1 156 5, function_name $L__info_string9, inlined_at 1 302 36
	cvt.u32.u64 	%r6571, %rd6080;

$L__BB0_1499:
	.loc	1 304 17
	ld.global.u8 	%r5859, [%rd1206+96];
	ld.global.u8 	%r5860, [%rd1206+97];
	prmt.b32 	%r5861, %r5860, %r5859, 30212;
	ld.global.u8 	%r5862, [%rd1206+98];
	ld.global.u8 	%r5863, [%rd1206+99];
	prmt.b32 	%r5864, %r5863, %r5862, 30212;
	prmt.b32 	%r5865, %r5864, %r5861, 4180;
	setp.eq.s32 	%p2911, %r5865, 0;
	@%p2911 bra 	$L__BB0_1507;

	.loc	1 305 37
	ld.global.u8 	%rd6081, [%rd1206+88];
	ld.global.u8 	%rd6082, [%rd1206+89];
	bfi.b64 	%rd6083, %rd6082, %rd6081, 8, 8;
	ld.global.u8 	%rd6084, [%rd1206+90];
	ld.global.u8 	%rd6085, [%rd1206+91];
	bfi.b64 	%rd6086, %rd6085, %rd6084, 8, 8;
	bfi.b64 	%rd1187, %rd6086, %rd6083, 16, 16;
	ld.global.u8 	%r5867, [%rd1206+92];
	ld.global.u8 	%r5868, [%rd1206+93];
	prmt.b32 	%r5869, %r5868, %r5867, 30212;
	ld.global.u8 	%r5870, [%rd1206+94];
	ld.global.u8 	%r5871, [%rd1206+95];
	prmt.b32 	%r5872, %r5871, %r5870, 30212;
	prmt.b32 	%r1765, %r5872, %r5869, 4180;
	.loc	1 305 37
	.loc	1 161 5, function_name $L__info_string8, inlined_at 1 305 37
	setp.eq.s32 	%p2912, %r1765, 0;
	mov.u32 	%r6581, 0;
	@%p2912 bra 	$L__BB0_1509;

	.loc	1 163 5, function_name $L__info_string8, inlined_at 1 305 37
	add.s32 	%r6581, %r1765, -1;
	cvt.u64.u32 	%rd6087, %r6581;
	add.s64 	%rd6088, %rd6087, %rd1187;
	shl.b64 	%rd6089, %rd6088, 3;
	add.s64 	%rd6090, %rd1183, %rd6089;
	ld.global.u64 	%rd6091, [%rd6090];
	.loc	1 164 5, function_name $L__info_string8, inlined_at 1 305 37
	cvt.rn.f64.u64 	%fd2886, %rd6091;
	mul.f64 	%fd797, %fd793, %fd2886;
	mov.u32 	%r6574, 0;
	mov.u32 	%r6573, %r6581;

$L__BB0_1502:
	.loc	1 168 9, function_name $L__info_string8, inlined_at 1 305 37
	add.s32 	%r5874, %r6573, %r6574;
	shr.u32 	%r1770, %r5874, 1;
	.loc	1 169 9, function_name $L__info_string8, inlined_at 1 305 37
	cvt.u64.u32 	%rd6092, %r1770;
	add.s64 	%rd6093, %rd6092, %rd1187;
	shl.b64 	%rd6094, %rd6093, 3;
	add.s64 	%rd6095, %rd1183, %rd6094;
	ld.global.u64 	%rd6096, [%rd6095];
	cvt.rn.f64.u64 	%fd2887, %rd6096;
	setp.lt.f64 	%p2913, %fd797, %fd2887;
	@%p2913 bra 	$L__BB0_1504;
	bra.uni 	$L__BB0_1503;

$L__BB0_1504:
	.loc	1 171 13, function_name $L__info_string8, inlined_at 1 305 37
	setp.eq.s32 	%p2914, %r1770, 0;
	mov.u32 	%r6581, 0;
	@%p2914 bra 	$L__BB0_1509;

	.loc	1 172 13, function_name $L__info_string8, inlined_at 1 305 37
	add.s32 	%r6573, %r1770, -1;
	mov.u32 	%r6581, %r1770;
	bra.uni 	$L__BB0_1506;

$L__BB0_1503:
	.loc	1 174 13, function_name $L__info_string8, inlined_at 1 305 37
	add.s32 	%r6574, %r1770, 1;

$L__BB0_1506:
	.loc	1 167 5, function_name $L__info_string8, inlined_at 1 305 37
	setp.gt.u32 	%p2915, %r6574, %r6573;
	@%p2915 bra 	$L__BB0_1509;
	bra.uni 	$L__BB0_1502;

$L__BB0_1507:
	.loc	1 306 36
	ld.global.u8 	%r5876, [%rd1206+92];
	ld.global.u8 	%r5877, [%rd1206+93];
	prmt.b32 	%r5878, %r5877, %r5876, 30212;
	ld.global.u8 	%r5879, [%rd1206+94];
	ld.global.u8 	%r5880, [%rd1206+95];
	prmt.b32 	%r5881, %r5880, %r5879, 30212;
	prmt.b32 	%r5882, %r5881, %r5878, 4180;
	.loc	1 306 36
	.loc	1 154 5, function_name $L__info_string9, inlined_at 1 306 36
	cvt.rn.f64.u32 	%fd2888, %r5882;
	mul.f64 	%fd2889, %fd793, %fd2888;
	cvt.rzi.u64.f64 	%rd6097, %fd2889;
	.loc	1 155 5, function_name $L__info_string9, inlined_at 1 306 36
	cvt.u64.u32 	%rd6098, %r5882;
	setp.lt.u64 	%p2916, %rd6097, %rd6098;
	add.s32 	%r5883, %r5882, -1;
	cvt.u64.u32 	%rd6099, %r5883;
	selp.b64 	%rd6100, %rd6097, %rd6099, %p2916;
	.loc	1 156 5, function_name $L__info_string9, inlined_at 1 306 36
	cvt.u32.u64 	%r6581, %rd6100;

$L__BB0_1509:
	.loc	1 320 17
	ld.global.u32 	%r1785, [%rd1188];
	setp.ne.s32 	%p2918, %r1785, -1;
	mov.pred 	%p2986, -1;
	mov.pred 	%p2985, %p2986;
	@%p2918 bra 	$L__BB0_1511;

	ld.global.u32 	%r5884, [%rd1188+4];
	setp.ne.s32 	%p2985, %r5884, -1;

$L__BB0_1511:
	.loc	1 321 17
	ld.global.u32 	%r1786, [%rd1188+8];
	setp.ne.s32 	%p2920, %r1786, -1;
	@%p2920 bra 	$L__BB0_1513;

	ld.global.u32 	%r5885, [%rd1188+12];
	setp.ne.s32 	%p2986, %r5885, -1;

$L__BB0_1513:
	.loc	1 0 17
	mov.u16 	%rs226, 1;
	.loc	1 323 17
	not.pred 	%p2921, %p2985;
	@%p2921 bra 	$L__BB0_1517;

	.loc	1 0 17
	mov.pred 	%p2987, -1;
	.loc	1 324 21
	setp.eq.s32 	%p2924, %r6571, %r1785;
	and.pred  	%p2925, %p2924, %p2918;
	@%p2925 bra 	$L__BB0_1516;

	.loc	1 325 36
	ld.global.u32 	%r5886, [%rd1188+4];
	setp.ne.s32 	%p2926, %r5886, -1;
	setp.eq.s32 	%p2927, %r6581, %r5886;
	and.pred  	%p2987, %p2927, %p2926;

$L__BB0_1516:
	.loc	1 326 21
	selp.u16 	%rs226, 1, 0, %p2987;

$L__BB0_1517:
	.loc	1 329 17
	setp.eq.s16 	%p2928, %rs226, 0;
	not.pred 	%p2929, %p2986;
	or.pred  	%p2930, %p2929, %p2928;
	@%p2930 bra 	$L__BB0_1521;

	.loc	1 330 21
	setp.eq.s32 	%p2932, %r6571, %r1786;
	and.pred  	%p2933, %p2932, %p2920;
	@%p2933 bra 	$L__BB0_1520;

	.loc	1 331 36
	ld.global.u32 	%r5887, [%rd1188+12];
	setp.eq.s32 	%p2934, %r5887, -1;
	setp.ne.s32 	%p2935, %r6581, %r5887;
	mov.u16 	%rs226, 0;
	or.pred  	%p2936, %p2934, %p2935;
	@%p2936 bra 	$L__BB0_1521;

$L__BB0_1520:
	.loc	1 0 36
	mov.u16 	%rs226, 1;

$L__BB0_1521:
	.loc	1 337 13
	setp.eq.s16 	%p2937, %rs226, 0;
	mov.u16 	%rs227, 0;
	@%p2937 bra 	$L__BB0_1524;

	ld.global.u32 	%r1787, [%rd1188+16];
	setp.eq.s32 	%p2938, %r1787, -1;
	mov.u16 	%rs227, 1;
	@%p2938 bra 	$L__BB0_1524;

	.loc	1 338 17
	setp.eq.s32 	%p2939, %r6514, %r1787;
	selp.u16 	%rs227, 1, 0, %p2939;

$L__BB0_1524:
	.loc	1 342 13
	setp.eq.s16 	%p2940, %rs227, 0;
	@%p2940 bra 	$L__BB0_1539;

	.loc	1 343 17
	ld.global.u32 	%r1788, [%rd1188+20];
	setp.ne.s32 	%p2941, %r1788, -1;
	.loc	1 344 17
	ld.global.u32 	%r1789, [%rd1188+24];
	setp.ne.s32 	%p2942, %r1789, -1;
	.loc	1 345 17
	and.pred  	%p2943, %p2941, %p2942;
	@%p2943 bra 	$L__BB0_1530;
	bra.uni 	$L__BB0_1526;

$L__BB0_1530:
	.loc	1 347 21
	setp.eq.s32 	%p2946, %r6557, %r1788;
	@%p2946 bra 	$L__BB0_1533;

	setp.eq.s32 	%p2988, %r6564, %r1789;
	bra.uni 	$L__BB0_1532;

$L__BB0_1526:
	.loc	1 348 24
	@%p2941 bra 	$L__BB0_1529;
	bra.uni 	$L__BB0_1527;

$L__BB0_1529:
	.loc	1 349 21
	setp.eq.s32 	%p2988, %r6557, %r1788;
	bra.uni 	$L__BB0_1532;

$L__BB0_1081:
	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.ne.s16 	%p2182, %rs229, 90;
	@%p2182 bra 	$L__BB0_1083;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 256 21
	mov.u16 	%rs88, 48;
	st.local.u8 	[%rd8], %rs88;

$L__BB0_1083:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs89, %rs223, -48;
	and.b16  	%rs90, %rs89, 255;
	setp.lt.u16 	%p2183, %rs90, 9;
	mov.u64 	%rd6535, %rd7;
	mov.u16 	%rs229, %rs223;
	@%p2183 bra 	$L__BB0_1120;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.eq.s16 	%p2184, %rs223, 57;
	mov.u64 	%rd6534, %rd7;
	@%p2184 bra 	$L__BB0_1119;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs91, %rs223, -65;
	and.b16  	%rs92, %rs91, 255;
	setp.lt.u16 	%p2185, %rs92, 25;
	mov.u64 	%rd6533, %rd7;
	mov.u16 	%rs229, %rs223;
	@%p2185 bra 	$L__BB0_1118;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.ne.s16 	%p2186, %rs223, 90;
	@%p2186 bra 	$L__BB0_1088;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 256 21
	mov.u16 	%rs93, 48;
	st.local.u8 	[%rd7], %rs93;

$L__BB0_1088:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs94, %rs222, -48;
	and.b16  	%rs95, %rs94, 255;
	setp.lt.u16 	%p2187, %rs95, 9;
	mov.u64 	%rd6535, %rd6;
	mov.u16 	%rs229, %rs222;
	@%p2187 bra 	$L__BB0_1120;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.eq.s16 	%p2188, %rs222, 57;
	mov.u64 	%rd6534, %rd6;
	@%p2188 bra 	$L__BB0_1119;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs96, %rs222, -65;
	and.b16  	%rs97, %rs96, 255;
	setp.lt.u16 	%p2189, %rs97, 25;
	mov.u64 	%rd6533, %rd6;
	mov.u16 	%rs229, %rs222;
	@%p2189 bra 	$L__BB0_1118;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.ne.s16 	%p2190, %rs222, 90;
	@%p2190 bra 	$L__BB0_1093;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 256 21
	mov.u16 	%rs98, 48;
	st.local.u8 	[%rd6], %rs98;

$L__BB0_1093:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs99, %rs221, -48;
	and.b16  	%rs100, %rs99, 255;
	setp.lt.u16 	%p2191, %rs100, 9;
	mov.u64 	%rd6535, %rd5;
	mov.u16 	%rs229, %rs221;
	@%p2191 bra 	$L__BB0_1120;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.eq.s16 	%p2192, %rs221, 57;
	mov.u64 	%rd6534, %rd5;
	@%p2192 bra 	$L__BB0_1119;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs101, %rs221, -65;
	and.b16  	%rs102, %rs101, 255;
	setp.lt.u16 	%p2193, %rs102, 25;
	mov.u64 	%rd6533, %rd5;
	mov.u16 	%rs229, %rs221;
	@%p2193 bra 	$L__BB0_1118;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.ne.s16 	%p2194, %rs221, 90;
	@%p2194 bra 	$L__BB0_1098;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 256 21
	mov.u16 	%rs103, 48;
	st.local.u8 	[%rd5], %rs103;

$L__BB0_1098:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs104, %rs220, -48;
	and.b16  	%rs105, %rs104, 255;
	setp.lt.u16 	%p2195, %rs105, 9;
	mov.u64 	%rd6535, %rd4;
	mov.u16 	%rs229, %rs220;
	@%p2195 bra 	$L__BB0_1120;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.eq.s16 	%p2196, %rs220, 57;
	mov.u64 	%rd6534, %rd4;
	@%p2196 bra 	$L__BB0_1119;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs106, %rs220, -65;
	and.b16  	%rs107, %rs106, 255;
	setp.lt.u16 	%p2197, %rs107, 25;
	mov.u64 	%rd6533, %rd4;
	mov.u16 	%rs229, %rs220;
	@%p2197 bra 	$L__BB0_1118;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.ne.s16 	%p2198, %rs220, 90;
	@%p2198 bra 	$L__BB0_1103;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 256 21
	mov.u16 	%rs108, 48;
	st.local.u8 	[%rd4], %rs108;

$L__BB0_1103:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs109, %rs219, -48;
	and.b16  	%rs110, %rs109, 255;
	setp.lt.u16 	%p2199, %rs110, 9;
	mov.u64 	%rd6535, %rd3;
	mov.u16 	%rs229, %rs219;
	@%p2199 bra 	$L__BB0_1120;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.eq.s16 	%p2200, %rs219, 57;
	mov.u64 	%rd6534, %rd3;
	@%p2200 bra 	$L__BB0_1119;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs111, %rs219, -65;
	and.b16  	%rs112, %rs111, 255;
	setp.lt.u16 	%p2201, %rs112, 25;
	mov.u64 	%rd6533, %rd3;
	mov.u16 	%rs229, %rs219;
	@%p2201 bra 	$L__BB0_1118;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.ne.s16 	%p2202, %rs219, 90;
	@%p2202 bra 	$L__BB0_1108;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 256 21
	mov.u16 	%rs113, 48;
	st.local.u8 	[%rd3], %rs113;

$L__BB0_1108:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs114, %rs218, -48;
	and.b16  	%rs115, %rs114, 255;
	setp.lt.u16 	%p2203, %rs115, 9;
	mov.u64 	%rd6535, %rd2;
	mov.u16 	%rs229, %rs218;
	@%p2203 bra 	$L__BB0_1120;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.eq.s16 	%p2204, %rs218, 57;
	mov.u64 	%rd6534, %rd2;
	@%p2204 bra 	$L__BB0_1119;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs116, %rs218, -65;
	and.b16  	%rs117, %rs116, 255;
	setp.lt.u16 	%p2205, %rs117, 25;
	mov.u64 	%rd6533, %rd2;
	mov.u16 	%rs229, %rs218;
	@%p2205 bra 	$L__BB0_1118;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.ne.s16 	%p2206, %rs218, 90;
	@%p2206 bra 	$L__BB0_1113;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 256 21
	mov.u16 	%rs118, 48;
	st.local.u8 	[%rd2], %rs118;

$L__BB0_1113:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs119, %rs217, -48;
	and.b16  	%rs120, %rs119, 255;
	setp.lt.u16 	%p2207, %rs120, 9;
	mov.u64 	%rd6535, %rd1;
	mov.u16 	%rs229, %rs217;
	@%p2207 bra 	$L__BB0_1120;

	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.eq.s16 	%p2208, %rs217, 57;
	mov.u64 	%rd6534, %rd1;
	@%p2208 bra 	$L__BB0_1119;

	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 256 21
	add.s16 	%rs121, %rs217, -65;
	and.b16  	%rs122, %rs121, 255;
	setp.lt.u16 	%p2209, %rs122, 25;
	mov.u64 	%rd6533, %rd1;
	mov.u16 	%rs229, %rs217;
	@%p2209 bra 	$L__BB0_1118;

	.loc	1 193 16, function_name $L__info_string2, inlined_at 1 256 21
	setp.ne.s16 	%p2210, %rs217, 90;
	@%p2210 bra 	$L__BB0_1582;

	.loc	1 194 13, function_name $L__info_string2, inlined_at 1 256 21
	mov.u16 	%rs123, 48;
	st.local.u8 	[%rd1], %rs123;
	bra.uni 	$L__BB0_1582;

$L__BB0_1527:
	.loc	1 344 17
	setp.eq.s32 	%p2945, %r1789, -1;
	.loc	1 350 24
	@%p2945 bra 	$L__BB0_1533;

	.loc	1 351 21
	setp.eq.s32 	%p2988, %r6564, %r1789;

$L__BB0_1532:
	.loc	1 356 13
	not.pred 	%p2947, %p2988;
	@%p2947 bra 	$L__BB0_1539;

$L__BB0_1533:
	.loc	1 0 13
	setp.eq.s32 	%p2948, %r1798, 0;
	mov.u32 	%r6582, 0;
	.loc	1 357 17
	.loc	3 112 3, function_name $L__info_string10, inlined_at 1 357 17
	atom.global.add.u32 	%r1790, [%rd6109], 1;
	.loc	1 359 17
	@%p2948 bra 	$L__BB0_1535;

	rem.u32 	%r6582, %r1790, %r1798;

$L__BB0_1535:
	.loc	1 360 17
	setp.ge.u32 	%p2949, %r6582, %r1798;
	@%p2949 bra 	$L__BB0_1537;

	.loc	1 361 21
	cvt.u64.u32 	%rd6110, %r5904;
	add.s64 	%rd6111, %rd6110, %rd1192;
	mul.wide.u32 	%rd6113, %r6582, 8;
	add.s64 	%rd6114, %rd6112, %rd6113;
	st.global.u64 	[%rd6114], %rd6111;

$L__BB0_1537:
	.loc	1 364 17
	setp.ne.s32 	%p2950, %r1790, 0;
	@%p2950 bra 	$L__BB0_1539;

	.loc	1 0 17
	cvta.to.global.u64 	%rd6115, %rd1197;
	.loc	1 365 21
	.loc	3 202 3, function_name $L__info_string11, inlined_at 1 365 21
	mov.u32 	%r5889, 1;
	mov.u32 	%r5890, 0;
	atom.global.cas.b32 	%r5891, [%rd6115], %r5890, %r5889;

$L__BB0_1539:
	.loc	1 184 9, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs172, %rs229, -48;
	and.b16  	%rs173, %rs172, 255;
	setp.lt.u16 	%p2951, %rs173, 9;
	mov.u64 	%rd6666, %rd8;
	@%p2951 bra 	$L__BB0_1581;
	bra.uni 	$L__BB0_1540;

$L__BB0_1581:
	.loc	1 185 13, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs214, %rs229, 1;
	st.local.u8 	[%rd6666], %rs214;
	bra.uni 	$L__BB0_1582;

$L__BB0_1540:
	.loc	1 187 16, function_name $L__info_string2, inlined_at 1 370 13
	setp.eq.s16 	%p2952, %rs229, 57;
	mov.u64 	%rd6665, %rd8;
	@%p2952 bra 	$L__BB0_1580;
	bra.uni 	$L__BB0_1541;

$L__BB0_1580:
	.loc	1 188 13, function_name $L__info_string2, inlined_at 1 370 13
	mov.u16 	%rs213, 65;
	st.local.u8 	[%rd6665], %rs213;
	.loc	1 189 13, function_name $L__info_string2, inlined_at 1 370 13
	bra.uni 	$L__BB0_1582;

$L__BB0_1541:
	.loc	1 190 16, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs174, %rs229, -65;
	and.b16  	%rs175, %rs174, 255;
	setp.lt.u16 	%p2953, %rs175, 25;
	mov.u64 	%rd6664, %rd8;
	@%p2953 bra 	$L__BB0_1579;
	bra.uni 	$L__BB0_1542;

$L__BB0_1579:
	.loc	1 191 13, function_name $L__info_string2, inlined_at 1 370 13
	add.s16 	%rs212, %rs229, 1;
	st.local.u8 	[%rd6664], %rs212;

$L__BB0_1582:
	.loc	1 243 55
	add.s32 	%r5904, %r5904, 1;
	.loc	1 236 9
	mad.lo.s32 	%r5892, %r5902, %r1797, %r1797;
	.loc	2 870 3, function_name $L__info_string1, inlined_at 1 236 9
	min.u32 	%r5893, %r5892, %r1796;
	.loc	1 243 9
	setp.lt.u32 	%p2983, %r5904, %r5893;
	@%p2983 bra 	$L__BB0_5;

$L__BB0_1583:
	.loc	1 222 5
	mov.u32 	%r5897, %ntid.x;
	.loc	1 223 5
	mov.u32 	%r5894, %nctaid.x;
	.loc	1 231 54
	mad.lo.s32 	%r5902, %r5897, %r5894, %r5902;
	.loc	1 231 5
	setp.lt.u32 	%p2984, %r5902, %r2;
	@%p2984 bra 	$L__BB0_2;

$L__BB0_1584:
	.loc	1 373 1
	ret;

}
	// .globl	probe_args_kernel
.visible .entry probe_args_kernel(
	.param .u64 probe_args_kernel_param_0,
	.param .u32 probe_args_kernel_param_1,
	.param .u32 probe_args_kernel_param_2,
	.param .u64 probe_args_kernel_param_3,
	.param .u64 probe_args_kernel_param_4,
	.param .u64 probe_args_kernel_param_5,
	.param .u32 probe_args_kernel_param_6,
	.param .u64 probe_args_kernel_param_7,
	.param .u64 probe_args_kernel_param_8,
	.param .u64 probe_args_kernel_param_9
)
{
	.reg .pred 	%p<12>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<29>;
	.loc	1 379 0


	ld.param.u64 	%rd2, [probe_args_kernel_param_0];
	ld.param.u32 	%r1, [probe_args_kernel_param_1];
	ld.param.u32 	%r2, [probe_args_kernel_param_2];
	ld.param.u64 	%rd3, [probe_args_kernel_param_3];
	ld.param.u64 	%rd4, [probe_args_kernel_param_4];
	ld.param.u64 	%rd5, [probe_args_kernel_param_5];
	ld.param.u32 	%r3, [probe_args_kernel_param_6];
	ld.param.u64 	%rd6, [probe_args_kernel_param_7];
	ld.param.u64 	%rd7, [probe_args_kernel_param_8];
	ld.param.u64 	%rd8, [probe_args_kernel_param_9];
	cvta.to.global.u64 	%rd1, %rd8;
	.loc	1 392 5
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	or.b32  	%r6, %r5, %r4;
	setp.ne.s32 	%p1, %r6, 0;
	@%p1 bra 	$L__BB1_8;

	.loc	1 395 5
	st.global.u64 	[%rd1], %rd2;
	.loc	1 396 5
	cvt.u64.u32 	%rd9, %r1;
	st.global.u64 	[%rd1+8], %rd9;
	.loc	1 397 5
	cvt.u64.u32 	%rd10, %r2;
	st.global.u64 	[%rd1+16], %rd10;
	.loc	1 398 5
	st.global.u64 	[%rd1+24], %rd3;
	.loc	1 399 5
	st.global.u64 	[%rd1+32], %rd4;
	.loc	1 400 5
	st.global.u64 	[%rd1+40], %rd5;
	.loc	1 401 5
	cvt.u64.u32 	%rd11, %r3;
	st.global.u64 	[%rd1+48], %rd11;
	.loc	1 402 5
	st.global.u64 	[%rd1+56], %rd6;
	.loc	1 403 5
	st.global.u64 	[%rd1+64], %rd7;
	.loc	1 407 5
	.loc	1 406 25, function_name $L__info_string12, inlined_at 1 407 5
	and.b64  	%rd12, %rd3, 7;
	setp.eq.s64 	%p2, %rd12, 0;
	.loc	1 407 5
	selp.b64 	%rd13, 1, 3134193665, %p2;
	setp.eq.s64 	%p3, %rd3, 0;
	selp.b64 	%rd14, 0, %rd13, %p3;
	st.global.u64 	[%rd1+72], %rd14;
	.loc	1 408 5
	.loc	1 406 25, function_name $L__info_string12, inlined_at 1 408 5
	and.b64  	%rd15, %rd5, 7;
	setp.eq.s64 	%p4, %rd15, 0;
	.loc	1 408 5
	selp.b64 	%rd16, 1, 3134193666, %p4;
	setp.eq.s64 	%p5, %rd5, 0;
	selp.b64 	%rd17, 0, %rd16, %p5;
	st.global.u64 	[%rd1+80], %rd17;
	.loc	1 409 5
	.loc	1 406 25, function_name $L__info_string12, inlined_at 1 409 5
	and.b64  	%rd18, %rd6, 3;
	setp.eq.s64 	%p6, %rd18, 0;
	.loc	1 409 5
	selp.b64 	%rd19, 1, 3134193667, %p6;
	setp.eq.s64 	%p7, %rd6, 0;
	selp.b64 	%rd20, 0, %rd19, %p7;
	st.global.u64 	[%rd1+88], %rd20;
	.loc	1 410 5
	.loc	1 406 25, function_name $L__info_string12, inlined_at 1 410 5
	and.b64  	%rd21, %rd7, 3;
	setp.eq.s64 	%p8, %rd21, 0;
	.loc	1 410 5
	selp.b64 	%rd22, 1, 3134193668, %p8;
	setp.eq.s64 	%p9, %rd7, 0;
	selp.b64 	%rd23, 0, %rd22, %p9;
	st.global.u64 	[%rd1+96], %rd23;
	.loc	1 413 5
	@%p7 bra 	$L__BB1_3;

	.loc	1 0 5
	cvta.to.global.u64 	%rd24, %rd6;
	.loc	1 413 5
	mov.u32 	%r7, 0;
	st.global.u32 	[%rd24], %r7;

$L__BB1_3:
	.loc	1 414 5
	@%p9 bra 	$L__BB1_5;

	.loc	1 0 5
	cvta.to.global.u64 	%rd25, %rd7;
	.loc	1 414 5
	mov.u32 	%r8, 0;
	st.global.u32 	[%rd25], %r8;

$L__BB1_5:
	.loc	1 415 5
	@%p5 bra 	$L__BB1_7;

	.loc	1 0 5
	cvta.to.global.u64 	%rd26, %rd5;
	.loc	1 415 5
	mov.u64 	%rd27, -3819410105021120785;
	st.global.u64 	[%rd26], %rd27;

$L__BB1_7:
	.loc	1 418 5
	mov.u64 	%rd28, 12648430;
	st.global.u64 	[%rd1+104], %rd28;

$L__BB1_8:
	.loc	1 419 1
	ret;

}
	// .globl	probe_args_struct
.visible .entry probe_args_struct(
	.param .align 8 .b8 probe_args_struct_param_0[64],
	.param .u64 probe_args_struct_param_1
)
{
	.reg .pred 	%p<22>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<32>;
	.loc	1 435 0


	ld.param.v2.u32 	{%r5, %r6}, [probe_args_struct_param_0+8];
	ld.param.u64 	%rd11, [probe_args_struct_param_1];
	ld.param.u64 	%rd10, [probe_args_struct_param_0+56];
	ld.param.u64 	%rd9, [probe_args_struct_param_0+48];
	ld.param.u32 	%r4, [probe_args_struct_param_0+40];
	ld.param.u64 	%rd8, [probe_args_struct_param_0+32];
	ld.param.u64 	%rd7, [probe_args_struct_param_0+24];
	ld.param.u64 	%rd6, [probe_args_struct_param_0+16];
	ld.param.u64 	%rd5, [probe_args_struct_param_0];
	cvta.to.global.u64 	%rd1, %rd11;
	.loc	1 436 5
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	or.b32  	%r9, %r8, %r7;
	setp.ne.s32 	%p1, %r9, 0;
	@%p1 bra 	$L__BB2_8;

	.loc	1 439 5
	st.global.u64 	[%rd1], %rd5;
	.loc	1 440 5
	cvt.u64.u32 	%rd12, %r5;
	st.global.u64 	[%rd1+8], %rd12;
	.loc	1 441 5
	cvt.u64.u32 	%rd13, %r6;
	st.global.u64 	[%rd1+16], %rd13;
	.loc	1 442 5
	st.global.u64 	[%rd1+24], %rd6;
	.loc	1 443 5
	st.global.u64 	[%rd1+32], %rd7;
	.loc	1 444 5
	st.global.u64 	[%rd1+40], %rd8;
	.loc	1 445 5
	cvt.u64.u32 	%rd14, %r4;
	st.global.u64 	[%rd1+48], %rd14;
	.loc	1 446 5
	st.global.u64 	[%rd1+56], %rd9;
	.loc	1 447 5
	st.global.u64 	[%rd1+64], %rd10;
	.loc	1 451 5
	setp.eq.s64 	%p2, %rd6, 0;
	setp.ne.s64 	%p3, %rd6, 0;
	.loc	1 451 5
	.loc	1 450 25, function_name $L__info_string13, inlined_at 1 451 5
	and.b64  	%rd15, %rd6, 7;
	setp.eq.s64 	%p4, %rd15, 0;
	.loc	1 451 5
	and.pred  	%p5, %p4, %p3;
	selp.b64 	%rd16, 0, 3134193665, %p2;
	selp.b64 	%rd17, 1, %rd16, %p5;
	st.global.u64 	[%rd1+72], %rd17;
	.loc	1 452 5
	setp.eq.s64 	%p6, %rd8, 0;
	setp.ne.s64 	%p7, %rd8, 0;
	.loc	1 452 5
	.loc	1 450 25, function_name $L__info_string13, inlined_at 1 452 5
	and.b64  	%rd18, %rd8, 7;
	setp.eq.s64 	%p8, %rd18, 0;
	.loc	1 452 5
	and.pred  	%p9, %p8, %p7;
	selp.b64 	%rd19, 0, 3134193666, %p6;
	selp.b64 	%rd20, 1, %rd19, %p9;
	st.global.u64 	[%rd1+80], %rd20;
	.loc	1 453 5
	setp.eq.s64 	%p10, %rd9, 0;
	setp.ne.s64 	%p11, %rd9, 0;
	.loc	1 453 5
	.loc	1 450 25, function_name $L__info_string13, inlined_at 1 453 5
	and.b64  	%rd21, %rd9, 3;
	setp.eq.s64 	%p12, %rd21, 0;
	.loc	1 453 5
	and.pred  	%p13, %p12, %p11;
	selp.b64 	%rd22, 0, 3134193667, %p10;
	selp.b64 	%rd23, 1, %rd22, %p13;
	st.global.u64 	[%rd1+88], %rd23;
	.loc	1 454 5
	setp.eq.s64 	%p14, %rd10, 0;
	setp.ne.s64 	%p15, %rd10, 0;
	.loc	1 454 5
	.loc	1 450 25, function_name $L__info_string13, inlined_at 1 454 5
	and.b64  	%rd24, %rd10, 3;
	setp.eq.s64 	%p16, %rd24, 0;
	.loc	1 454 5
	and.pred  	%p17, %p16, %p15;
	selp.b64 	%rd25, 0, 3134193668, %p14;
	selp.b64 	%rd26, 1, %rd25, %p17;
	st.global.u64 	[%rd1+96], %rd26;
	.loc	1 457 5
	@%p10 bra 	$L__BB2_3;

	.loc	1 0 5
	cvta.to.global.u64 	%rd27, %rd9;
	.loc	1 457 5
	mov.u32 	%r10, 0;
	st.global.u32 	[%rd27], %r10;

$L__BB2_3:
	.loc	1 458 5
	@%p14 bra 	$L__BB2_5;

	.loc	1 0 5
	cvta.to.global.u64 	%rd28, %rd10;
	.loc	1 458 5
	mov.u32 	%r11, 0;
	st.global.u32 	[%rd28], %r11;

$L__BB2_5:
	.loc	1 459 5
	setp.eq.s32 	%p20, %r4, 0;
	or.pred  	%p21, %p20, %p6;
	@%p21 bra 	$L__BB2_7;

	.loc	1 0 5
	cvta.to.global.u64 	%rd29, %rd8;
	.loc	1 459 5
	mov.u64 	%rd30, -3819410105021120785;
	st.global.u64 	[%rd29], %rd30;

$L__BB2_7:
	.loc	1 461 5
	mov.u64 	%rd31, 12648430;
	st.global.u64 	[%rd1+104], %rd31;

$L__BB2_8:
	.loc	1 462 1
	ret;

}
	.file	1 "/home/krvh/personal/Brainstorm/ImmolateCPP/combined_kernels.cu"
	.file	2 "/usr/local/cuda/bin/../targets/x86_64-linux/include/crt/math_functions.hpp"
	.file	3 "/usr/local/cuda/bin/../targets/x86_64-linux/include/device_atomic_functions.hpp"
	.section	.debug_str
	{
$L__info_string0:
.b8 95,90,49,50,105,100,120,95,116,111,95,99,104,97,114,115,109,80,99,0
$L__info_string1:
.b8 95,90,78,53,48,95,73,78,84,69,82,78,65,76,95,102,57,49,99,51,100,54,101,95,49,57,95,99,111,109,98,105,110,101,100,95,107,101,114,110
.b8 101,108,115,95,99,117,95,54,101,48,55,49,101,98,57,51,109,105,110,69,106,106,0
$L__info_string2:
.b8 95,90,49,48,105,110,99,95,98,97,115,101,51,54,80,99,0
$L__info_string3:
.b8 95,90,50,50,105,110,105,116,95,114,110,103,95,115,116,97,116,101,95,100,121,110,97,109,105,99,80,49,53,66,97,108,97,116,114,111,82,78,71,83
.b8 116,97,116,101,80,75,99,80,75,49,49,68,101,118,105,99,101,80,111,111,108,115,0
$L__info_string4:
.b8 95,90,49,52,112,115,101,117,100,111,104,97,115,104,95,103,112,117,80,75,99,105,0
$L__info_string5:
.b8 95,90,49,52,105,110,105,116,95,114,110,103,95,115,116,97,116,101,80,49,53,66,97,108,97,116,114,111,82,78,71,83,116,97,116,101,80,75,99,0
$L__info_string6:
.b8 95,90,50,51,112,115,101,117,100,111,104,97,115,104,95,116,119,111,95,115,101,103,109,101,110,116,115,80,75,104,106,80,75,99,0
$L__info_string7:
.b8 95,90,49,53,112,115,101,117,100,111,115,101,101,100,95,110,101,120,116,80,100,0
$L__info_string8:
.b8 95,90,49,53,99,104,111,111,115,101,95,119,101,105,103,104,116,101,100,100,80,75,109,106,0
$L__info_string9:
.b8 95,90,49,52,99,104,111,111,115,101,95,117,110,105,102,111,114,109,100,106,0
$L__info_string10:
.b8 95,90,78,53,48,95,73,78,84,69,82,78,65,76,95,102,57,49,99,51,100,54,101,95,49,57,95,99,111,109,98,105,110,101,100,95,107,101,114,110
.b8 101,108,115,95,99,117,95,54,101,48,55,49,101,98,57,57,97,116,111,109,105,99,65,100,100,69,80,106,106,0
$L__info_string11:
.b8 95,90,78,53,48,95,73,78,84,69,82,78,65,76,95,102,57,49,99,51,100,54,101,95,49,57,95,99,111,109,98,105,110,101,100,95,107,101,114,110
.b8 101,108,115,95,99,117,95,54,101,48,55,49,101,98,57,57,97,116,111,109,105,99,67,65,83,69,80,105,105,105,0
$L__info_string12:
.b8 95,90,90,49,55,112,114,111,98,101,95,97,114,103,115,95,107,101,114,110,101,108,109,106,106,80,75,118,83,48,95,80,109,106,80,106,80,86,105,83
.b8 49,95,69,78,75,85,108,109,109,69,95,99,108,69,109,109,0
$L__info_string13:
.b8 95,90,90,49,55,112,114,111,98,101,95,97,114,103,115,95,115,116,114,117,99,116,49,48,75,101,114,110,101,108,65,114,103,115,80,109,69,78,75,85
.b8 108,109,109,69,95,99,108,69,109,109,0

	}
